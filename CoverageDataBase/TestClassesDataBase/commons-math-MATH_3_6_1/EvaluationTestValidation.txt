/** 
 * This class demonstrates the main functionality of the {@link LeastSquaresProblem.Evaluation}, common to the optimizer implementations in package {@link org.apache.commons.math3.fitting.leastsquares}. <br/> Not enabled by default, as the class name does not end with "Test". <br/> Invoke by running <pre><code> mvn test -Dtest=EvaluationTestValidation </code></pre> or by running <pre><code> mvn test -Dtest=EvaluationTestValidation -DargLine="-DmcRuns=1234 -server" </code></pre>
 */
public class EvaluationTestValidation {
  /** 
 * Number of runs. 
 */
  private static final int MONTE_CARLO_RUNS=Integer.parseInt(System.getProperty("mcRuns","100"));
  /** 
 * Using a Monte-Carlo procedure, this test checks the error estimations as provided by the square-root of the diagonal elements of the covariance matrix. <br/> The test generates sets of observations, each sampled from a Gaussian distribution. <br/> The optimization problem solved is defined in class {@link StraightLineProblem}. <br/> The output (on stdout) will be a table summarizing the distribution of parameters generated by the Monte-Carlo process and by the direct estimation provided by the diagonal elements of the covariance matrix.
 */
  @Test public void testParametersErrorMonteCarloObservations(){
    final double yError=15;
    final double slope=123.456;
    final double offset=-98.765;
    final RandomStraightLinePointGenerator lineGenerator=new RandomStraightLinePointGenerator(slope,offset,yError,-1e3,1e4,138577L);
    final int numObs=100;
    final int numParams=2;
    final SummaryStatistics[] paramsFoundByDirectSolution=new SummaryStatistics[numParams];
    final SummaryStatistics[] sigmaEstimate=new SummaryStatistics[numParams];
    for (int i=0; i < numParams; i++) {
      paramsFoundByDirectSolution[i]=new SummaryStatistics();
      sigmaEstimate[i]=new SummaryStatistics();
    }
    final RealVector init=new ArrayRealVector(new double[]{slope,offset},false);
    final int mcRepeat=MONTE_CARLO_RUNS;
    int mcCount=0;
    while (mcCount < mcRepeat) {
      final Point2D.Double[] obs=lineGenerator.generate(numObs);
      final StraightLineProblem problem=new StraightLineProblem(yError);
      for (int i=0; i < numObs; i++) {
        final Point2D.Double p=obs[i];
        problem.addPoint(p.x,p.y);
      }
      final double[] regress=problem.solve();
      final LeastSquaresProblem lsp=builder(problem).build();
      final RealVector sigma=lsp.evaluate(init).getSigma(1e-14);
      for (int i=0; i < numParams; i++) {
        paramsFoundByDirectSolution[i].addValue(regress[i]);
        sigmaEstimate[i].addValue(sigma.getEntry(i));
      }
      ++mcCount;
    }
    final String line="--------------------------------------------------------------";
    System.out.println("                 True value       Mean        Std deviation");
    for (int i=0; i < numParams; i++) {
      System.out.println(line);
      System.out.println("Parameter #" + i);
      StatisticalSummary s=paramsFoundByDirectSolution[i].getSummary();
      System.out.printf("              %+.6e   %+.6e   %+.6e\n",init.getEntry(i),s.getMean(),s.getStandardDeviation());
      s=sigmaEstimate[i].getSummary();
      System.out.printf("sigma: %+.6e (%+.6e)\n",s.getMean(),s.getStandardDeviation());
    }
    System.out.println(line);
    for (int i=0; i < numParams; i++) {
      Assert.assertEquals(paramsFoundByDirectSolution[i].getSummary().getStandardDeviation(),sigmaEstimate[i].getSummary().getMean(),8e-2);
    }
  }
  /** 
 * In this test, the set of observations is fixed. Using a Monte-Carlo procedure, it generates sets of parameters, and determine the parameter change that will result in the normalized chi-square becoming larger by one than the value from the best fit solution. <br/> The optimization problem solved is defined in class {@link StraightLineProblem}. <br/> The output (on stdout) will be a list of lines containing: <ul> <li>slope of the straight line,</li> <li>intercept of the straight line,</li> <li>chi-square of the solution defined by the above two values.</li> </ul> The output is separated into two blocks (with a blank line between them); the first block will contain all parameter sets for which {@code chi2 < chi2_b + 1}and the second block, all sets for which {@code chi2 >= chi2_b + 1}where  {@code chi2_b} is the lowest chi-square (corresponding to thebest solution).
 */
  @Test public void testParametersErrorMonteCarloParameters(){
    final double yError=15;
    final double slope=123.456;
    final double offset=-98.765;
    final RandomStraightLinePointGenerator lineGenerator=new RandomStraightLinePointGenerator(slope,offset,yError,-1e3,1e4,13839013L);
    final int numObs=10;
    final Point2D.Double[] obs=lineGenerator.generate(numObs);
    final StraightLineProblem problem=new StraightLineProblem(yError);
    for (int i=0; i < numObs; i++) {
      final Point2D.Double p=obs[i];
      problem.addPoint(p.x,p.y);
    }
    final RealVector regress=new ArrayRealVector(problem.solve(),false);
    final LeastSquaresProblem lsp=builder(problem).build();
    final double bestChi2N=getChi2N(lsp,regress);
    final RealVector sigma=lsp.evaluate(regress).getSigma(1e-14);
    final int mcRepeat=MONTE_CARLO_RUNS;
    final int gridSize=(int)FastMath.sqrt(mcRepeat);
    final List<double[]> paramsAndChi2=new ArrayList<double[]>(gridSize * gridSize);
    final double slopeRange=10 * sigma.getEntry(0);
    final double offsetRange=10 * sigma.getEntry(1);
    final double minSlope=slope - 0.5 * slopeRange;
    final double minOffset=offset - 0.5 * offsetRange;
    final double deltaSlope=slopeRange / gridSize;
    final double deltaOffset=offsetRange / gridSize;
    for (int i=0; i < gridSize; i++) {
      final double s=minSlope + i * deltaSlope;
      for (int j=0; j < gridSize; j++) {
        final double o=minOffset + j * deltaOffset;
        final double chi2N=getChi2N(lsp,new ArrayRealVector(new double[]{s,o},false));
        paramsAndChi2.add(new double[]{s,o,chi2N});
      }
    }
    final double chi2NPlusOne=bestChi2N + 1;
    int numLarger=0;
    final String lineFmt="%+.10e %+.10e   %.8e\n";
    System.out.printf(lineFmt,regress.getEntry(0),regress.getEntry(1),bestChi2N);
    System.out.println();
    for (    double[] d : paramsAndChi2) {
      if (d[2] <= chi2NPlusOne) {
        System.out.printf(lineFmt,d[0],d[1],d[2]);
      }
    }
    System.out.println();
    for (    double[] d : paramsAndChi2) {
      if (d[2] > chi2NPlusOne) {
        ++numLarger;
        System.out.printf(lineFmt,d[0],d[1],d[2]);
      }
    }
    System.out.println();
    System.out.println("# sigma=" + sigma.toString());
    System.out.println("# " + numLarger + " sets filtered out");
  }
  LeastSquaresBuilder builder(  StraightLineProblem problem){
    return new LeastSquaresBuilder().model(problem.getModelFunction(),problem.getModelFunctionJacobian()).target(problem.target()).weight(new DiagonalMatrix(problem.weight())).start(new double[2]);
  }
  /** 
 * @return the normalized chi-square.
 */
  private double getChi2N(  LeastSquaresProblem lsp,  RealVector params){
    final double cost=lsp.evaluate(params).getCost();
    return cost * cost / (lsp.getObservationSize() - params.getDimension());
  }
}
