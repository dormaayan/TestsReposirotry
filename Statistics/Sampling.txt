~~~~~~~~~~~~~~~~~~~ Random Samplings from AndroidUtilCode-1.22.4~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package cc.arduino.net;
import cc.arduino.Constants;
import org.junit.Before;
import org.junit.Test;
import java.net.*;
import java.util.HashMap;
import java.util.Map;
import static org.junit.Assert.assertEquals;
public class CustomProxySelectorTest {
  private Map<String,String> preferences;
  private URI uri;
  @Before public void setUp() throws Exception {
    System.setProperty("java.net.useSystemProxies","true");
    uri=new URL("https://www.arduino.cc").toURI();
    preferences=new HashMap<>();
  }
  @Test public void testNoProxy() throws Exception {
    preferences.put(Constants.PREF_PROXY_TYPE,Constants.PROXY_TYPE_NONE);
    CustomProxySelector proxySelector=new CustomProxySelector(preferences);
    Proxy proxy=proxySelector.getProxyFor(uri);
    assertEquals(Proxy.NO_PROXY,proxy);
  }
  @Test public void testSystemProxy() throws Exception {
    preferences.put(Constants.PREF_PROXY_TYPE,Constants.PROXY_TYPE_AUTO);
    CustomProxySelector proxySelector=new CustomProxySelector(preferences);
    Proxy proxy=proxySelector.getProxyFor(uri);
    assertEquals(ProxySelector.getDefault().select(uri).get(0),proxy);
  }
  @Test public void testProxyPACHTTP() throws Exception {
    preferences.put(Constants.PREF_PROXY_TYPE,Constants.PROXY_TYPE_AUTO);
    preferences.put(Constants.PREF_PROXY_PAC_URL,CustomProxySelectorTest.class.getResource("proxy_http.pac").toExternalForm());
    CustomProxySelector proxySelector=new CustomProxySelector(preferences);
    Proxy proxy=proxySelector.getProxyFor(uri);
    assertEquals(new Proxy(Proxy.Type.HTTP,new InetSocketAddress("proxy.example.com",8080)),proxy);
  }
  @Test public void testProxyPACHTTPWithLogin() throws Exception {
    preferences.put(Constants.PREF_PROXY_TYPE,Constants.PROXY_TYPE_AUTO);
    preferences.put(Constants.PREF_PROXY_PAC_URL,CustomProxySelectorTest.class.getResource("proxy_http.pac").toExternalForm());
    preferences.put(Constants.PREF_PROXY_AUTO_USERNAME,"auto");
    preferences.put(Constants.PREF_PROXY_AUTO_PASSWORD,"autopassword");
    CustomProxySelector proxySelector=new CustomProxySelector(preferences);
    Proxy proxy=proxySelector.getProxyFor(uri);
    assertEquals(new Proxy(Proxy.Type.HTTP,new InetSocketAddress("proxy.example.com",8080)),proxy);
    PasswordAuthentication authentication=Authenticator.requestPasswordAuthentication(null,8080,uri.toURL().getProtocol(),"ciao","");
    assertEquals(authentication.getUserName(),"auto");
    assertEquals(String.valueOf(authentication.getPassword()),"autopassword");
  }
  @Test public void testProxyPACSOCKS() throws Exception {
    preferences.put(Constants.PREF_PROXY_TYPE,Constants.PROXY_TYPE_AUTO);
    preferences.put(Constants.PREF_PROXY_PAC_URL,CustomProxySelectorTest.class.getResource("proxy_socks.pac").toExternalForm());
    CustomProxySelector proxySelector=new CustomProxySelector(preferences);
    Proxy proxy=proxySelector.getProxyFor(uri);
    assertEquals(new Proxy(Proxy.Type.SOCKS,new InetSocketAddress("proxy.example.com",8080)),proxy);
  }
  @Test public void testProxyPACDirect() throws Exception {
    preferences.put(Constants.PREF_PROXY_TYPE,Constants.PROXY_TYPE_AUTO);
    preferences.put(Constants.PREF_PROXY_PAC_URL,CustomProxySelectorTest.class.getResource("proxy_direct.pac").toExternalForm());
    CustomProxySelector proxySelector=new CustomProxySelector(preferences);
    Proxy proxy=proxySelector.getProxyFor(uri);
    assertEquals(Proxy.NO_PROXY,proxy);
  }
  @Test public void testProxyPACComplex() throws Exception {
    preferences.put(Constants.PREF_PROXY_TYPE,Constants.PROXY_TYPE_AUTO);
    preferences.put(Constants.PREF_PROXY_PAC_URL,CustomProxySelectorTest.class.getResource("proxy_complex.pac").toExternalForm());
    CustomProxySelector proxySelector=new CustomProxySelector(preferences);
    Proxy proxy=proxySelector.getProxyFor(uri);
    assertEquals(new Proxy(Proxy.Type.HTTP,new InetSocketAddress("4.5.6.7",8080)),proxy);
  }
  @Test public void testProxyPACComplex2() throws Exception {
    preferences.put(Constants.PREF_PROXY_TYPE,Constants.PROXY_TYPE_AUTO);
    preferences.put(Constants.PREF_PROXY_PAC_URL,CustomProxySelectorTest.class.getResource("proxy_complex.pac").toExternalForm());
    CustomProxySelector proxySelector=new CustomProxySelector(preferences);
    Proxy proxy=proxySelector.getProxyFor(new URL("http://www.intranet.domain.com/ciao").toURI());
    assertEquals(Proxy.NO_PROXY,proxy);
  }
  @Test public void testManualProxy() throws Exception {
    preferences.put(Constants.PREF_PROXY_TYPE,Constants.PROXY_TYPE_MANUAL);
    preferences.put(Constants.PREF_PROXY_MANUAL_TYPE,Constants.PROXY_MANUAL_TYPE_HTTP);
    preferences.put(Constants.PREF_PROXY_MANUAL_HOSTNAME,"localhost");
    preferences.put(Constants.PREF_PROXY_MANUAL_PORT,"8080");
    CustomProxySelector proxySelector=new CustomProxySelector(preferences);
    Proxy proxy=proxySelector.getProxyFor(uri);
    assertEquals(new Proxy(Proxy.Type.HTTP,new InetSocketAddress("localhost",8080)),proxy);
  }
  @Test public void testManualProxyWithLogin() throws Exception {
    preferences.put(Constants.PREF_PROXY_TYPE,Constants.PROXY_TYPE_MANUAL);
    preferences.put(Constants.PREF_PROXY_MANUAL_TYPE,Constants.PROXY_MANUAL_TYPE_HTTP);
    preferences.put(Constants.PREF_PROXY_MANUAL_HOSTNAME,"localhost");
    preferences.put(Constants.PREF_PROXY_MANUAL_PORT,"8080");
    preferences.put(Constants.PREF_PROXY_MANUAL_USERNAME,"username");
    preferences.put(Constants.PREF_PROXY_MANUAL_PASSWORD,"pwd");
    CustomProxySelector proxySelector=new CustomProxySelector(preferences);
    Proxy proxy=proxySelector.getProxyFor(uri);
    assertEquals(new Proxy(Proxy.Type.HTTP,new InetSocketAddress("localhost",8080)),proxy);
    PasswordAuthentication authentication=Authenticator.requestPasswordAuthentication(null,8080,uri.toURL().getProtocol(),"ciao","");
    assertEquals(authentication.getUserName(),"username");
    assertEquals(String.valueOf(authentication.getPassword()),"pwd");
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from Arduino-1.8.8~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from MPAndroidChart-3.1.0-alpha~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.github.mikephil.charting.test;
import com.github.mikephil.charting.components.YAxis;
import com.github.mikephil.charting.renderer.AxisRenderer;
import com.github.mikephil.charting.renderer.YAxisRenderer;
import org.junit.Test;
import static junit.framework.Assert.assertEquals;
/** 
 * Created by philipp on 31/05/16.
 */
public class AxisRendererTest {
  @Test public void testComputeAxisValues(){
    YAxis yAxis=new YAxis();
    yAxis.setLabelCount(6);
    AxisRenderer renderer=new YAxisRenderer(null,yAxis,null);
    renderer.computeAxis(0,100,false);
    float[] entries=yAxis.mEntries;
    assertEquals(6,entries.length);
    assertEquals(20,entries[1] - entries[0],0.01);
    assertEquals(0,entries[0],0.01);
    assertEquals(100,entries[entries.length - 1],0.01);
    yAxis=new YAxis();
    yAxis.setLabelCount(6);
    yAxis.setGranularity(50f);
    renderer=new YAxisRenderer(null,yAxis,null);
    renderer.computeAxis(0,100,false);
    entries=yAxis.mEntries;
    assertEquals(3,entries.length);
    assertEquals(50,entries[1] - entries[0],0.01);
    assertEquals(0,entries[0],0.01);
    assertEquals(100,entries[entries.length - 1],0.01);
    yAxis=new YAxis();
    yAxis.setLabelCount(5,true);
    renderer=new YAxisRenderer(null,yAxis,null);
    renderer.computeAxis(0,100,false);
    entries=yAxis.mEntries;
    assertEquals(5,entries.length);
    assertEquals(25,entries[1] - entries[0],0.01);
    assertEquals(0,entries[0],0.01);
    assertEquals(100,entries[entries.length - 1],0.01);
    yAxis=new YAxis();
    yAxis.setLabelCount(5,true);
    renderer=new YAxisRenderer(null,yAxis,null);
    renderer.computeAxis(0,0.01f,false);
    entries=yAxis.mEntries;
    assertEquals(5,entries.length);
    assertEquals(0.0025,entries[1] - entries[0],0.0001);
    assertEquals(0,entries[0],0.0001);
    assertEquals(0.01,entries[entries.length - 1],0.0001);
    yAxis=new YAxis();
    yAxis.setLabelCount(5,false);
    renderer=new YAxisRenderer(null,yAxis,null);
    renderer.computeAxis(0,0.01f,false);
    entries=yAxis.mEntries;
    assertEquals(5,entries.length);
    assertEquals(0.0020,entries[1] - entries[0],0.0001);
    assertEquals(0,entries[0],0.0001);
    assertEquals(0.0080,entries[entries.length - 1],0.0001);
    yAxis=new YAxis();
    yAxis.setLabelCount(6);
    renderer=new YAxisRenderer(null,yAxis,null);
    renderer.computeAxis(-50,50,false);
    entries=yAxis.mEntries;
    assertEquals(5,entries.length);
    assertEquals(-40,entries[0],0.0001);
    assertEquals(0,entries[2],0.0001);
    assertEquals(40,entries[entries.length - 1],0.0001);
    yAxis=new YAxis();
    yAxis.setLabelCount(6);
    renderer=new YAxisRenderer(null,yAxis,null);
    renderer.computeAxis(-50,100,false);
    entries=yAxis.mEntries;
    assertEquals(5,entries.length);
    assertEquals(-30,entries[0],0.0001);
    assertEquals(30,entries[2],0.0001);
    assertEquals(90,entries[entries.length - 1],0.0001);
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from MPAndroidChart-3.1.0-alpha~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright (c) 2016-present, RxJava Contributors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package io.reactivex.disposables;
import static org.junit.Assert.*;
import static org.mockito.Mockito.*;
import java.util.*;
import java.util.concurrent.CountDownLatch;
import org.junit.*;
import org.junit.runner.RunWith;
import org.mockito.runners.MockitoJUnitRunner;
import io.reactivex.internal.disposables.DisposableHelper;
@RunWith(MockitoJUnitRunner.class) public class SerialDisposableTests {
  private SerialDisposable serialDisposable;
  @Before public void setUp(){
    serialDisposable=new SerialDisposable();
  }
  @Test public void unsubscribingWithoutUnderlyingDoesNothing(){
    serialDisposable.dispose();
  }
  @Test public void getDisposableShouldReturnset(){
    final Disposable underlying=mock(Disposable.class);
    serialDisposable.set(underlying);
    assertSame(underlying,serialDisposable.get());
    final Disposable another=mock(Disposable.class);
    serialDisposable.set(another);
    assertSame(another,serialDisposable.get());
  }
  @Test public void notDisposedWhenReplaced(){
    final Disposable underlying=mock(Disposable.class);
    serialDisposable.set(underlying);
    serialDisposable.replace(Disposables.empty());
    serialDisposable.dispose();
    verify(underlying,never()).dispose();
  }
  @Test public void unsubscribingTwiceDoesUnsubscribeOnce(){
    Disposable underlying=mock(Disposable.class);
    serialDisposable.set(underlying);
    serialDisposable.dispose();
    verify(underlying).dispose();
    serialDisposable.dispose();
    verifyNoMoreInteractions(underlying);
  }
  @Test public void settingSameDisposableTwiceDoesUnsubscribeIt(){
    Disposable underlying=mock(Disposable.class);
    serialDisposable.set(underlying);
    verifyZeroInteractions(underlying);
    serialDisposable.set(underlying);
    verify(underlying).dispose();
  }
  @Test public void unsubscribingWithSingleUnderlyingUnsubscribes(){
    Disposable underlying=mock(Disposable.class);
    serialDisposable.set(underlying);
    underlying.dispose();
    verify(underlying).dispose();
  }
  @Test public void replacingFirstUnderlyingCausesUnsubscription(){
    Disposable first=mock(Disposable.class);
    serialDisposable.set(first);
    Disposable second=mock(Disposable.class);
    serialDisposable.set(second);
    verify(first).dispose();
  }
  @Test public void whenUnsubscribingSecondUnderlyingUnsubscribed(){
    Disposable first=mock(Disposable.class);
    serialDisposable.set(first);
    Disposable second=mock(Disposable.class);
    serialDisposable.set(second);
    serialDisposable.dispose();
    verify(second).dispose();
  }
  @Test public void settingUnderlyingWhenUnsubscribedCausesImmediateUnsubscription(){
    serialDisposable.dispose();
    Disposable underlying=mock(Disposable.class);
    serialDisposable.set(underlying);
    verify(underlying).dispose();
  }
  @Test(timeout=1000) public void settingUnderlyingWhenUnsubscribedCausesImmediateUnsubscriptionConcurrently() throws InterruptedException {
    final Disposable firstSet=mock(Disposable.class);
    serialDisposable.set(firstSet);
    final CountDownLatch start=new CountDownLatch(1);
    final int count=10;
    final CountDownLatch end=new CountDownLatch(count);
    final List<Thread> threads=new ArrayList<Thread>();
    for (int i=0; i < count; i++) {
      final Thread t=new Thread(){
        @Override public void run(){
          try {
            start.await();
            serialDisposable.dispose();
          }
 catch (          InterruptedException e) {
            fail(e.getMessage());
          }
 finally {
            end.countDown();
          }
        }
      }
;
      t.start();
      threads.add(t);
    }
    final Disposable underlying=mock(Disposable.class);
    start.countDown();
    serialDisposable.set(underlying);
    end.await();
    verify(firstSet).dispose();
    verify(underlying).dispose();
    for (    final Thread t : threads) {
      t.join();
    }
  }
  @Test public void concurrentSetDisposableShouldNotInterleave() throws InterruptedException {
    final int count=10;
    final List<Disposable> subscriptions=new ArrayList<Disposable>();
    final CountDownLatch start=new CountDownLatch(1);
    final CountDownLatch end=new CountDownLatch(count);
    final List<Thread> threads=new ArrayList<Thread>();
    for (int i=0; i < count; i++) {
      final Disposable subscription=mock(Disposable.class);
      subscriptions.add(subscription);
      final Thread t=new Thread(){
        @Override public void run(){
          try {
            start.await();
            serialDisposable.set(subscription);
          }
 catch (          InterruptedException e) {
            fail(e.getMessage());
          }
 finally {
            end.countDown();
          }
        }
      }
;
      t.start();
      threads.add(t);
    }
    start.countDown();
    end.await();
    serialDisposable.dispose();
    for (    final Disposable subscription : subscriptions) {
      verify(subscription).dispose();
    }
    for (    final Thread t : threads) {
      t.join();
    }
  }
  @Test public void disposeState(){
    Disposable empty=Disposables.empty();
    SerialDisposable d=new SerialDisposable(empty);
    assertFalse(d.isDisposed());
    assertSame(empty,d.get());
    d.dispose();
    assertTrue(d.isDisposed());
    assertNotSame(empty,d.get());
    assertNotSame(DisposableHelper.DISPOSED,d.get());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright (c) 2016-present, RxJava Contributors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package io.reactivex.internal.operators.maybe;
import java.util.concurrent.Callable;
import org.junit.Test;
import io.reactivex.*;
public class MaybeConcatPublisherTest {
  @Test public void scalar(){
    Maybe.concat(Flowable.just(Maybe.just(1))).test().assertResult(1);
  }
  @Test public void callable(){
    Maybe.concat(Flowable.fromCallable(new Callable<Maybe<Integer>>(){
      @Override public Maybe<Integer> call() throws Exception {
        return Maybe.just(1);
      }
    }
)).test().assertResult(1);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright (c) 2016-present, RxJava Contributors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package io.reactivex.internal.operators.maybe;
import static org.junit.Assert.*;
import org.junit.Test;
import io.reactivex.*;
import io.reactivex.exceptions.TestException;
import io.reactivex.functions.Function;
import io.reactivex.internal.fuseable.HasUpstreamMaybeSource;
import io.reactivex.observers.TestObserver;
import io.reactivex.processors.PublishProcessor;
public class MaybeContainsTest {
  @Test public void doesContain(){
    Maybe.just(1).contains(1).test().assertResult(true);
  }
  @Test public void doesntContain(){
    Maybe.just(1).contains(2).test().assertResult(false);
  }
  @Test public void empty(){
    Maybe.empty().contains(2).test().assertResult(false);
  }
  @Test public void error(){
    Maybe.error(new TestException()).contains(2).test().assertFailure(TestException.class);
  }
  @Test public void dispose(){
    PublishProcessor<Integer> pp=PublishProcessor.create();
    TestObserver<Boolean> to=pp.singleElement().contains(1).test();
    assertTrue(pp.hasSubscribers());
    to.cancel();
    assertFalse(pp.hasSubscribers());
  }
  @Test public void isDisposed(){
    PublishProcessor<Integer> pp=PublishProcessor.create();
    TestHelper.checkDisposed(pp.singleElement().contains(1));
  }
  @Test public void doubleOnSubscribe(){
    TestHelper.checkDoubleOnSubscribeMaybeToSingle(new Function<Maybe<Object>,SingleSource<Boolean>>(){
      @Override public SingleSource<Boolean> apply(      Maybe<Object> f) throws Exception {
        return f.contains(1);
      }
    }
);
  }
  @SuppressWarnings("unchecked") @Test public void hasSource(){
    assertSame(Maybe.empty(),((HasUpstreamMaybeSource<Object>)(Maybe.empty().contains(0))).source());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright (c) 2016-present, RxJava Contributors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package io.reactivex.internal.operators.single;
import static org.junit.Assert.assertTrue;
import java.util.*;
import org.junit.Test;
import io.reactivex.*;
import io.reactivex.exceptions.TestException;
import io.reactivex.plugins.RxJavaPlugins;
public class SingleMergeTest {
  @Test public void mergeSingleSingle(){
    Single.merge(Single.just(Single.just(1))).test().assertResult(1);
  }
  @Test public void merge2(){
    Single.merge(Single.just(1),Single.just(2)).test().assertResult(1,2);
  }
  @Test public void merge3(){
    Single.merge(Single.just(1),Single.just(2),Single.just(3)).test().assertResult(1,2,3);
  }
  @Test public void merge4(){
    Single.merge(Single.just(1),Single.just(2),Single.just(3),Single.just(4)).test().assertResult(1,2,3,4);
  }
  @Test public void mergeErrors(){
    List<Throwable> errors=TestHelper.trackPluginErrors();
    try {
      Single<Integer> source1=Single.error(new TestException("First"));
      Single<Integer> source2=Single.error(new TestException("Second"));
      Single.merge(source1,source2).test().assertFailureAndMessage(TestException.class,"First");
      assertTrue(errors.toString(),errors.isEmpty());
    }
  finally {
      RxJavaPlugins.reset();
    }
  }
  @SuppressWarnings("unchecked") @Test public void mergeDelayErrorIterable(){
    Single.mergeDelayError(Arrays.asList(Single.just(1),Single.<Integer>error(new TestException()),Single.just(2))).test().assertFailure(TestException.class,1,2);
  }
  @Test public void mergeDelayErrorPublisher(){
    Single.mergeDelayError(Flowable.just(Single.just(1),Single.<Integer>error(new TestException()),Single.just(2))).test().assertFailure(TestException.class,1,2);
  }
  @Test public void mergeDelayError2(){
    Single.mergeDelayError(Single.just(1),Single.<Integer>error(new TestException())).test().assertFailure(TestException.class,1);
  }
  @Test public void mergeDelayError2ErrorFirst(){
    Single.mergeDelayError(Single.<Integer>error(new TestException()),Single.just(1)).test().assertFailure(TestException.class,1);
  }
  @Test public void mergeDelayError3(){
    Single.mergeDelayError(Single.just(1),Single.<Integer>error(new TestException()),Single.just(2)).test().assertFailure(TestException.class,1,2);
  }
  @Test public void mergeDelayError4(){
    Single.mergeDelayError(Single.just(1),Single.<Integer>error(new TestException()),Single.just(2),Single.just(3)).test().assertFailure(TestException.class,1,2,3);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright (c) 2016-present, RxJava Contributors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package io.reactivex.internal.operators.flowable;
import static org.junit.Assert.*;
import static org.mockito.ArgumentMatchers.any;
import static org.mockito.Mockito.*;
import java.util.*;
import java.util.concurrent.atomic.*;
import org.junit.Test;
import org.reactivestreams.Subscriber;
import io.reactivex.*;
import io.reactivex.functions.*;
import io.reactivex.internal.functions.Functions;
import io.reactivex.internal.fuseable.*;
import io.reactivex.subscribers.*;
public class FlowableRangeTest {
  @Test public void testRangeStartAt2Count3(){
    Subscriber<Integer> subscriber=TestHelper.mockSubscriber();
    Flowable.range(2,3).subscribe(subscriber);
    verify(subscriber,times(1)).onNext(2);
    verify(subscriber,times(1)).onNext(3);
    verify(subscriber,times(1)).onNext(4);
    verify(subscriber,never()).onNext(5);
    verify(subscriber,never()).onError(any(Throwable.class));
    verify(subscriber,times(1)).onComplete();
  }
  @Test public void testRangeUnsubscribe(){
    Subscriber<Integer> subscriber=TestHelper.mockSubscriber();
    final AtomicInteger count=new AtomicInteger();
    Flowable.range(1,1000).doOnNext(new Consumer<Integer>(){
      @Override public void accept(      Integer t1){
        count.incrementAndGet();
      }
    }
).take(3).subscribe(subscriber);
    verify(subscriber,times(1)).onNext(1);
    verify(subscriber,times(1)).onNext(2);
    verify(subscriber,times(1)).onNext(3);
    verify(subscriber,never()).onNext(4);
    verify(subscriber,never()).onError(any(Throwable.class));
    verify(subscriber,times(1)).onComplete();
    assertEquals(3,count.get());
  }
  @Test public void testRangeWithZero(){
    Flowable.range(1,0);
  }
  @Test public void testRangeWithOverflow2(){
    Flowable.range(Integer.MAX_VALUE,0);
  }
  @Test public void testRangeWithOverflow3(){
    Flowable.range(1,Integer.MAX_VALUE);
  }
  @Test(expected=IllegalArgumentException.class) public void testRangeWithOverflow4(){
    Flowable.range(2,Integer.MAX_VALUE);
  }
  @Test public void testRangeWithOverflow5(){
    assertFalse(Flowable.range(Integer.MIN_VALUE,0).blockingIterable().iterator().hasNext());
  }
  @Test public void testBackpressureViaRequest(){
    Flowable<Integer> f=Flowable.range(1,Flowable.bufferSize());
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(0L);
    ts.assertNoValues();
    ts.request(1);
    f.subscribe(ts);
    ts.assertValue(1);
    ts.request(2);
    ts.assertValues(1,2,3);
    ts.request(3);
    ts.assertValues(1,2,3,4,5,6);
    ts.request(Flowable.bufferSize());
    ts.assertTerminated();
  }
  @Test public void testNoBackpressure(){
    ArrayList<Integer> list=new ArrayList<Integer>(Flowable.bufferSize() * 2);
    for (int i=1; i <= Flowable.bufferSize() * 2 + 1; i++) {
      list.add(i);
    }
    Flowable<Integer> f=Flowable.range(1,list.size());
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(0L);
    ts.assertNoValues();
    ts.request(Long.MAX_VALUE);
    f.subscribe(ts);
    ts.assertValueSequence(list);
    ts.assertTerminated();
  }
  void testWithBackpressureOneByOne(  int start){
    Flowable<Integer> source=Flowable.range(start,100);
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(0L);
    ts.request(1);
    source.subscribe(ts);
    List<Integer> list=new ArrayList<Integer>(100);
    for (int i=0; i < 100; i++) {
      list.add(i + start);
      ts.request(1);
    }
    ts.assertValueSequence(list);
    ts.assertTerminated();
  }
  void testWithBackpressureAllAtOnce(  int start){
    Flowable<Integer> source=Flowable.range(start,100);
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(0L);
    ts.request(100);
    source.subscribe(ts);
    List<Integer> list=new ArrayList<Integer>(100);
    for (int i=0; i < 100; i++) {
      list.add(i + start);
    }
    ts.assertValueSequence(list);
    ts.assertTerminated();
  }
  @Test public void testWithBackpressure1(){
    for (int i=0; i < 100; i++) {
      testWithBackpressureOneByOne(i);
    }
  }
  @Test public void testWithBackpressureAllAtOnce(){
    for (int i=0; i < 100; i++) {
      testWithBackpressureAllAtOnce(i);
    }
  }
  @Test public void testWithBackpressureRequestWayMore(){
    Flowable<Integer> source=Flowable.range(50,100);
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(0L);
    ts.request(150);
    source.subscribe(ts);
    List<Integer> list=new ArrayList<Integer>(100);
    for (int i=0; i < 100; i++) {
      list.add(i + 50);
    }
    ts.request(50);
    ts.assertValueSequence(list);
    ts.assertTerminated();
  }
  @Test public void testRequestOverflow(){
    final AtomicInteger count=new AtomicInteger();
    int n=10;
    Flowable.range(1,n).subscribe(new DefaultSubscriber<Integer>(){
      @Override public void onStart(){
        request(2);
      }
      @Override public void onComplete(){
      }
      @Override public void onError(      Throwable e){
        throw new RuntimeException(e);
      }
      @Override public void onNext(      Integer t){
        count.incrementAndGet();
        request(Long.MAX_VALUE - 1);
      }
    }
);
    assertEquals(n,count.get());
  }
  @Test public void testEmptyRangeSendsOnCompleteEagerlyWithRequestZero(){
    final AtomicBoolean completed=new AtomicBoolean(false);
    Flowable.range(1,0).subscribe(new DefaultSubscriber<Integer>(){
      @Override public void onStart(){
      }
      @Override public void onComplete(){
        completed.set(true);
      }
      @Override public void onError(      Throwable e){
      }
      @Override public void onNext(      Integer t){
      }
    }
);
    assertTrue(completed.get());
  }
  @Test(timeout=1000) public void testNearMaxValueWithoutBackpressure(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>();
    Flowable.range(Integer.MAX_VALUE - 1,2).subscribe(ts);
    ts.assertComplete();
    ts.assertNoErrors();
    ts.assertValues(Integer.MAX_VALUE - 1,Integer.MAX_VALUE);
  }
  @Test(timeout=1000) public void testNearMaxValueWithBackpressure(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(3L);
    Flowable.range(Integer.MAX_VALUE - 1,2).subscribe(ts);
    ts.assertComplete();
    ts.assertNoErrors();
    ts.assertValues(Integer.MAX_VALUE - 1,Integer.MAX_VALUE);
  }
  @Test public void negativeCount(){
    try {
      Flowable.range(1,-1);
      fail("Should have thrown IllegalArgumentException");
    }
 catch (    IllegalArgumentException ex) {
      assertEquals("count >= 0 required but it was -1",ex.getMessage());
    }
  }
  @Test public void requestWrongFusion(){
    TestSubscriber<Integer> ts=SubscriberFusion.newTest(QueueFuseable.ASYNC);
    Flowable.range(1,5).subscribe(ts);
    SubscriberFusion.assertFusion(ts,QueueFuseable.NONE).assertResult(1,2,3,4,5);
  }
  @Test public void countOne(){
    Flowable.range(5495454,1).test().assertResult(5495454);
  }
  @Test public void fused(){
    TestSubscriber<Integer> ts=SubscriberFusion.newTest(QueueFuseable.ANY);
    Flowable.range(1,2).subscribe(ts);
    SubscriberFusion.assertFusion(ts,QueueFuseable.SYNC).assertResult(1,2);
  }
  @Test public void fusedReject(){
    TestSubscriber<Integer> ts=SubscriberFusion.newTest(QueueFuseable.ASYNC);
    Flowable.range(1,2).subscribe(ts);
    SubscriberFusion.assertFusion(ts,QueueFuseable.NONE).assertResult(1,2);
  }
  @Test public void disposed(){
    TestHelper.checkDisposed(Flowable.range(1,2));
  }
  @Test public void fusedClearIsEmpty(){
    TestHelper.checkFusedIsEmptyClear(Flowable.range(1,2));
  }
  @Test public void noOverflow(){
    Flowable.range(Integer.MAX_VALUE - 1,2);
    Flowable.range(Integer.MIN_VALUE,2);
    Flowable.range(Integer.MIN_VALUE,Integer.MAX_VALUE);
  }
  @Test public void conditionalNormal(){
    Flowable.range(1,5).filter(Functions.alwaysTrue()).test().assertResult(1,2,3,4,5);
  }
  @Test public void badRequest(){
    TestHelper.assertBadRequestReported(Flowable.range(1,5));
    TestHelper.assertBadRequestReported(Flowable.range(1,5).filter(Functions.alwaysTrue()));
  }
  @Test public void conditionalNormalSlowpath(){
    Flowable.range(1,5).filter(Functions.alwaysTrue()).test(5).assertResult(1,2,3,4,5);
  }
  @Test public void conditionalSlowPathTakeExact(){
    Flowable.range(1,5).filter(Functions.alwaysTrue()).take(5).test().assertResult(1,2,3,4,5);
  }
  @Test public void slowPathTakeExact(){
    Flowable.range(1,5).filter(Functions.alwaysTrue()).take(5).test().assertResult(1,2,3,4,5);
  }
  @Test public void conditionalSlowPathRebatch(){
    Flowable.range(1,5).filter(Functions.alwaysTrue()).rebatchRequests(1).test().assertResult(1,2,3,4,5);
  }
  @Test public void slowPathRebatch(){
    Flowable.range(1,5).rebatchRequests(1).test().assertResult(1,2,3,4,5);
  }
  @Test public void slowPathCancel(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(2L){
      @Override public void onNext(      Integer t){
        super.onNext(t);
        cancel();
        onComplete();
      }
    }
;
    Flowable.range(1,5).subscribe(ts);
    ts.assertResult(1);
  }
  @Test public void fastPathCancel(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(){
      @Override public void onNext(      Integer t){
        super.onNext(t);
        cancel();
        onComplete();
      }
    }
;
    Flowable.range(1,5).subscribe(ts);
    ts.assertResult(1);
  }
  @Test public void conditionalSlowPathCancel(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(1L){
      @Override public void onNext(      Integer t){
        super.onNext(t);
        cancel();
        onComplete();
      }
    }
;
    Flowable.range(1,5).filter(Functions.alwaysTrue()).subscribe(ts);
    ts.assertResult(1);
  }
  @Test public void conditionalFastPathCancel(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(){
      @Override public void onNext(      Integer t){
        super.onNext(t);
        cancel();
        onComplete();
      }
    }
;
    Flowable.range(1,5).filter(Functions.alwaysTrue()).subscribe(ts);
    ts.assertResult(1);
  }
  @Test public void conditionalRequestOneByOne(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(1L){
      @Override public void onNext(      Integer t){
        super.onNext(t);
        request(1);
      }
    }
;
    Flowable.range(1,5).filter(new Predicate<Integer>(){
      @Override public boolean test(      Integer v) throws Exception {
        return v % 2 == 0;
      }
    }
).subscribe(ts);
    ts.assertResult(2,4);
  }
  @Test public void conditionalRequestOneByOne2(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(1L){
      @Override public void onNext(      Integer t){
        super.onNext(t);
        request(1);
      }
    }
;
    Flowable.range(1,5).filter(Functions.alwaysTrue()).subscribe(ts);
    ts.assertResult(1,2,3,4,5);
  }
  @Test public void fastPathCancelExact(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(){
      @Override public void onNext(      Integer t){
        super.onNext(t);
        if (t == 5L) {
          cancel();
          onComplete();
        }
      }
    }
;
    Flowable.range(1,5).subscribe(ts);
    ts.assertResult(1,2,3,4,5);
  }
  @Test public void conditionalFastPathCancelExact(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(){
      @Override public void onNext(      Integer t){
        super.onNext(t);
        if (t == 5L) {
          cancel();
          onComplete();
        }
      }
    }
;
    Flowable.range(1,5).filter(new Predicate<Integer>(){
      @Override public boolean test(      Integer v) throws Exception {
        return v % 2 == 0;
      }
    }
).subscribe(ts);
    ts.assertResult(2,4);
  }
  @Test public void conditionalCancel1(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(2L){
      @Override public void onNext(      Integer t){
        super.onNext(t);
        if (t == 1) {
          cancel();
          onComplete();
        }
      }
    }
;
    Flowable.range(1,2).filter(Functions.alwaysTrue()).subscribe(ts);
    ts.assertResult(1);
  }
  @Test public void conditionalCancel2(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>(2L){
      @Override public void onNext(      Integer t){
        super.onNext(t);
        if (t == 2) {
          cancel();
          onComplete();
        }
      }
    }
;
    Flowable.range(1,2).filter(Functions.alwaysTrue()).subscribe(ts);
    ts.assertResult(1,2);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright (c) 2016-present, RxJava Contributors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package io.reactivex.internal.operators.flowable;
import static org.junit.Assert.*;
import static org.mockito.Mockito.*;
import java.lang.reflect.Method;
import java.util.*;
import java.util.concurrent.*;
import org.junit.*;
import org.mockito.InOrder;
import org.reactivestreams.*;
import io.reactivex.*;
import io.reactivex.Flowable;
import io.reactivex.exceptions.*;
import io.reactivex.functions.LongConsumer;
import io.reactivex.internal.subscriptions.BooleanSubscription;
import io.reactivex.processors.PublishProcessor;
import io.reactivex.subscribers.*;
public class FlowableMergeDelayErrorTest {
  Subscriber<String> stringSubscriber;
  @Before public void before(){
    stringSubscriber=TestHelper.mockSubscriber();
  }
  @Test public void testErrorDelayed1(){
    final Flowable<String> f1=Flowable.unsafeCreate(new TestErrorFlowable("four",null,"six"));
    final Flowable<String> f2=Flowable.unsafeCreate(new TestErrorFlowable("one","two","three"));
    Flowable<String> m=Flowable.mergeDelayError(f1,f2);
    m.subscribe(stringSubscriber);
    verify(stringSubscriber,times(1)).onError(any(NullPointerException.class));
    verify(stringSubscriber,never()).onComplete();
    verify(stringSubscriber,times(1)).onNext("one");
    verify(stringSubscriber,times(1)).onNext("two");
    verify(stringSubscriber,times(1)).onNext("three");
    verify(stringSubscriber,times(1)).onNext("four");
    verify(stringSubscriber,times(0)).onNext("five");
  }
  @Test public void testErrorDelayed2(){
    final Flowable<String> f1=Flowable.unsafeCreate(new TestErrorFlowable("one","two","three"));
    final Flowable<String> f2=Flowable.unsafeCreate(new TestErrorFlowable("four",null,"six"));
    final Flowable<String> f3=Flowable.unsafeCreate(new TestErrorFlowable("seven","eight",null));
    final Flowable<String> f4=Flowable.unsafeCreate(new TestErrorFlowable("nine"));
    Flowable<String> m=Flowable.mergeDelayError(f1,f2,f3,f4);
    m.subscribe(stringSubscriber);
    verify(stringSubscriber,times(1)).onError(any(CompositeException.class));
    verify(stringSubscriber,never()).onComplete();
    verify(stringSubscriber,times(1)).onNext("one");
    verify(stringSubscriber,times(1)).onNext("two");
    verify(stringSubscriber,times(1)).onNext("three");
    verify(stringSubscriber,times(1)).onNext("four");
    verify(stringSubscriber,times(0)).onNext("five");
    verify(stringSubscriber,times(1)).onNext("seven");
    verify(stringSubscriber,times(1)).onNext("eight");
    verify(stringSubscriber,times(1)).onNext("nine");
  }
  @Test public void testErrorDelayed3(){
    final Flowable<String> f1=Flowable.unsafeCreate(new TestErrorFlowable("one","two","three"));
    final Flowable<String> f2=Flowable.unsafeCreate(new TestErrorFlowable("four","five","six"));
    final Flowable<String> f3=Flowable.unsafeCreate(new TestErrorFlowable("seven","eight",null));
    final Flowable<String> f4=Flowable.unsafeCreate(new TestErrorFlowable("nine"));
    Flowable<String> m=Flowable.mergeDelayError(f1,f2,f3,f4);
    m.subscribe(stringSubscriber);
    verify(stringSubscriber,times(1)).onError(any(NullPointerException.class));
    verify(stringSubscriber,never()).onComplete();
    verify(stringSubscriber,times(1)).onNext("one");
    verify(stringSubscriber,times(1)).onNext("two");
    verify(stringSubscriber,times(1)).onNext("three");
    verify(stringSubscriber,times(1)).onNext("four");
    verify(stringSubscriber,times(1)).onNext("five");
    verify(stringSubscriber,times(1)).onNext("six");
    verify(stringSubscriber,times(1)).onNext("seven");
    verify(stringSubscriber,times(1)).onNext("eight");
    verify(stringSubscriber,times(1)).onNext("nine");
  }
  @Test public void testErrorDelayed4(){
    final Flowable<String> f1=Flowable.unsafeCreate(new TestErrorFlowable("one","two","three"));
    final Flowable<String> f2=Flowable.unsafeCreate(new TestErrorFlowable("four","five","six"));
    final Flowable<String> f3=Flowable.unsafeCreate(new TestErrorFlowable("seven","eight"));
    final Flowable<String> f4=Flowable.unsafeCreate(new TestErrorFlowable("nine",null));
    Flowable<String> m=Flowable.mergeDelayError(f1,f2,f3,f4);
    m.subscribe(stringSubscriber);
    verify(stringSubscriber,times(1)).onError(any(NullPointerException.class));
    verify(stringSubscriber,never()).onComplete();
    verify(stringSubscriber,times(1)).onNext("one");
    verify(stringSubscriber,times(1)).onNext("two");
    verify(stringSubscriber,times(1)).onNext("three");
    verify(stringSubscriber,times(1)).onNext("four");
    verify(stringSubscriber,times(1)).onNext("five");
    verify(stringSubscriber,times(1)).onNext("six");
    verify(stringSubscriber,times(1)).onNext("seven");
    verify(stringSubscriber,times(1)).onNext("eight");
    verify(stringSubscriber,times(1)).onNext("nine");
  }
  @Test public void testErrorDelayed4WithThreading(){
    final TestAsyncErrorFlowable f1=new TestAsyncErrorFlowable("one","two","three");
    final TestAsyncErrorFlowable f2=new TestAsyncErrorFlowable("four","five","six");
    final TestAsyncErrorFlowable f3=new TestAsyncErrorFlowable("seven","eight");
    final TestAsyncErrorFlowable f4=new TestAsyncErrorFlowable("nine",null);
    Flowable<String> m=Flowable.mergeDelayError(Flowable.unsafeCreate(f1),Flowable.unsafeCreate(f2),Flowable.unsafeCreate(f3),Flowable.unsafeCreate(f4));
    m.subscribe(stringSubscriber);
    try {
      f1.t.join();
      f2.t.join();
      f3.t.join();
      f4.t.join();
    }
 catch (    InterruptedException e) {
      throw new RuntimeException(e);
    }
    verify(stringSubscriber,times(1)).onNext("one");
    verify(stringSubscriber,times(1)).onNext("two");
    verify(stringSubscriber,times(1)).onNext("three");
    verify(stringSubscriber,times(1)).onNext("four");
    verify(stringSubscriber,times(1)).onNext("five");
    verify(stringSubscriber,times(1)).onNext("six");
    verify(stringSubscriber,times(1)).onNext("seven");
    verify(stringSubscriber,times(1)).onNext("eight");
    verify(stringSubscriber,times(1)).onNext("nine");
    verify(stringSubscriber,times(1)).onError(any(NullPointerException.class));
    verify(stringSubscriber,never()).onComplete();
  }
  @Test public void testCompositeErrorDelayed1(){
    final Flowable<String> f1=Flowable.unsafeCreate(new TestErrorFlowable("four",null,"six"));
    final Flowable<String> f2=Flowable.unsafeCreate(new TestErrorFlowable("one","two",null));
    Flowable<String> m=Flowable.mergeDelayError(f1,f2);
    m.subscribe(stringSubscriber);
    verify(stringSubscriber,times(1)).onError(any(Throwable.class));
    verify(stringSubscriber,never()).onComplete();
    verify(stringSubscriber,times(1)).onNext("one");
    verify(stringSubscriber,times(1)).onNext("two");
    verify(stringSubscriber,times(0)).onNext("three");
    verify(stringSubscriber,times(1)).onNext("four");
    verify(stringSubscriber,times(0)).onNext("five");
  }
  @Test public void testCompositeErrorDelayed2(){
    final Flowable<String> f1=Flowable.unsafeCreate(new TestErrorFlowable("four",null,"six"));
    final Flowable<String> f2=Flowable.unsafeCreate(new TestErrorFlowable("one","two",null));
    Flowable<String> m=Flowable.mergeDelayError(f1,f2);
    CaptureObserver w=new CaptureObserver();
    m.subscribe(w);
    assertNotNull(w.e);
    int size=((CompositeException)w.e).size();
    if (size != 2) {
      w.e.printStackTrace();
    }
    assertEquals(2,size);
  }
  /** 
 * The unit tests below are from OperationMerge and should ensure the normal merge functionality is correct.
 */
  @Test public void testMergeFlowableOfFlowables(){
    final Flowable<String> f1=Flowable.unsafeCreate(new TestSynchronousFlowable());
    final Flowable<String> f2=Flowable.unsafeCreate(new TestSynchronousFlowable());
    Flowable<Flowable<String>> flowableOfFlowables=Flowable.unsafeCreate(new Publisher<Flowable<String>>(){
      @Override public void subscribe(      Subscriber<? super Flowable<String>> subscriber){
        subscriber.onSubscribe(new BooleanSubscription());
        subscriber.onNext(f1);
        subscriber.onNext(f2);
        subscriber.onComplete();
      }
    }
);
    Flowable<String> m=Flowable.mergeDelayError(flowableOfFlowables);
    m.subscribe(stringSubscriber);
    verify(stringSubscriber,never()).onError(any(Throwable.class));
    verify(stringSubscriber,times(1)).onComplete();
    verify(stringSubscriber,times(2)).onNext("hello");
  }
  @Test public void testMergeArray(){
    final Flowable<String> f1=Flowable.unsafeCreate(new TestSynchronousFlowable());
    final Flowable<String> f2=Flowable.unsafeCreate(new TestSynchronousFlowable());
    Flowable<String> m=Flowable.mergeDelayError(f1,f2);
    m.subscribe(stringSubscriber);
    verify(stringSubscriber,never()).onError(any(Throwable.class));
    verify(stringSubscriber,times(2)).onNext("hello");
    verify(stringSubscriber,times(1)).onComplete();
  }
  @Test public void testMergeList(){
    final Flowable<String> f1=Flowable.unsafeCreate(new TestSynchronousFlowable());
    final Flowable<String> f2=Flowable.unsafeCreate(new TestSynchronousFlowable());
    List<Flowable<String>> listOfFlowables=new ArrayList<Flowable<String>>();
    listOfFlowables.add(f1);
    listOfFlowables.add(f2);
    Flowable<String> m=Flowable.mergeDelayError(Flowable.fromIterable(listOfFlowables));
    m.subscribe(stringSubscriber);
    verify(stringSubscriber,never()).onError(any(Throwable.class));
    verify(stringSubscriber,times(1)).onComplete();
    verify(stringSubscriber,times(2)).onNext("hello");
  }
  @Test public void testMergeArrayWithThreading(){
    final TestASynchronousFlowable f1=new TestASynchronousFlowable();
    final TestASynchronousFlowable f2=new TestASynchronousFlowable();
    Flowable<String> m=Flowable.mergeDelayError(Flowable.unsafeCreate(f1),Flowable.unsafeCreate(f2));
    m.subscribe(stringSubscriber);
    try {
      f1.t.join();
      f2.t.join();
    }
 catch (    InterruptedException e) {
      throw new RuntimeException(e);
    }
    verify(stringSubscriber,never()).onError(any(Throwable.class));
    verify(stringSubscriber,times(2)).onNext("hello");
    verify(stringSubscriber,times(1)).onComplete();
  }
  @Test(timeout=1000L) public void testSynchronousError(){
    final Flowable<Flowable<String>> f1=Flowable.error(new RuntimeException("unit test"));
    final CountDownLatch latch=new CountDownLatch(1);
    Flowable.mergeDelayError(f1).subscribe(new DefaultSubscriber<String>(){
      @Override public void onComplete(){
        fail("Expected onError path");
      }
      @Override public void onError(      Throwable e){
        latch.countDown();
      }
      @Override public void onNext(      String s){
        fail("Expected onError path");
      }
    }
);
    try {
      latch.await();
    }
 catch (    InterruptedException ex) {
      fail("interrupted");
    }
  }
private static class TestSynchronousFlowable implements Publisher<String> {
    @Override public void subscribe(    Subscriber<? super String> subscriber){
      subscriber.onSubscribe(new BooleanSubscription());
      subscriber.onNext("hello");
      subscriber.onComplete();
    }
  }
private static class TestASynchronousFlowable implements Publisher<String> {
    Thread t;
    @Override public void subscribe(    final Subscriber<? super String> subscriber){
      subscriber.onSubscribe(new BooleanSubscription());
      t=new Thread(new Runnable(){
        @Override public void run(){
          subscriber.onNext("hello");
          subscriber.onComplete();
        }
      }
);
      t.start();
    }
  }
private static class TestErrorFlowable implements Publisher<String> {
    String[] valuesToReturn;
    TestErrorFlowable(    String... values){
      valuesToReturn=values;
    }
    @Override public void subscribe(    Subscriber<? super String> subscriber){
      subscriber.onSubscribe(new BooleanSubscription());
      boolean errorThrown=false;
      for (      String s : valuesToReturn) {
        if (s == null) {
          System.out.println("throwing exception");
          subscriber.onError(new NullPointerException());
          errorThrown=true;
        }
 else {
          subscriber.onNext(s);
        }
      }
      if (!errorThrown) {
        subscriber.onComplete();
      }
    }
  }
private static class TestAsyncErrorFlowable implements Publisher<String> {
    String[] valuesToReturn;
    TestAsyncErrorFlowable(    String... values){
      valuesToReturn=values;
    }
    Thread t;
    @Override public void subscribe(    final Subscriber<? super String> subscriber){
      subscriber.onSubscribe(new BooleanSubscription());
      t=new Thread(new Runnable(){
        @Override public void run(){
          for (          String s : valuesToReturn) {
            if (s == null) {
              System.out.println("throwing exception");
              try {
                Thread.sleep(100);
              }
 catch (              Throwable e) {
              }
              subscriber.onError(new NullPointerException());
              return;
            }
 else {
              subscriber.onNext(s);
            }
          }
          System.out.println("subscription complete");
          subscriber.onComplete();
        }
      }
);
      t.start();
    }
  }
private static class CaptureObserver extends DefaultSubscriber<String> {
    volatile Throwable e;
    @Override public void onComplete(){
    }
    @Override public void onError(    Throwable e){
      this.e=e;
    }
    @Override public void onNext(    String args){
    }
  }
  @Test @Ignore("Subscribers should not throw") public void testMergeSourceWhichDoesntPropagateExceptionBack(){
    Flowable<Integer> source=Flowable.unsafeCreate(new Publisher<Integer>(){
      @Override public void subscribe(      Subscriber<? super Integer> t1){
        t1.onSubscribe(new BooleanSubscription());
        try {
          t1.onNext(0);
        }
 catch (        Throwable swallow) {
        }
        t1.onNext(1);
        t1.onComplete();
      }
    }
);
    Flowable<Integer> result=Flowable.mergeDelayError(source,Flowable.just(2));
    final Subscriber<Integer> subscriber=TestHelper.mockSubscriber();
    InOrder inOrder=inOrder(subscriber);
    result.subscribe(new DefaultSubscriber<Integer>(){
      int calls;
      @Override public void onNext(      Integer t){
        if (calls++ == 0) {
          throw new TestException();
        }
        subscriber.onNext(t);
      }
      @Override public void onError(      Throwable e){
        subscriber.onError(e);
      }
      @Override public void onComplete(){
        subscriber.onComplete();
      }
    }
);
    inOrder.verify(subscriber).onNext(2);
    inOrder.verify(subscriber,never()).onNext(0);
    inOrder.verify(subscriber,never()).onNext(1);
    inOrder.verify(subscriber,never()).onNext(anyInt());
    inOrder.verify(subscriber).onError(any(TestException.class));
    verify(subscriber,never()).onComplete();
  }
  @Test public void testErrorInParentFlowable(){
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>();
    Flowable.mergeDelayError(Flowable.just(Flowable.just(1),Flowable.just(2)).startWith(Flowable.<Integer>error(new RuntimeException()))).subscribe(ts);
    ts.awaitTerminalEvent();
    ts.assertTerminated();
    ts.assertValues(1,2);
    assertEquals(1,ts.errorCount());
  }
  @Test public void testErrorInParentFlowableDelayed() throws Exception {
    for (int i=0; i < 50; i++) {
      final TestASynchronous1sDelayedFlowable f1=new TestASynchronous1sDelayedFlowable();
      final TestASynchronous1sDelayedFlowable f2=new TestASynchronous1sDelayedFlowable();
      Flowable<Flowable<String>> parentFlowable=Flowable.unsafeCreate(new Publisher<Flowable<String>>(){
        @Override public void subscribe(        Subscriber<? super Flowable<String>> op){
          op.onSubscribe(new BooleanSubscription());
          op.onNext(Flowable.unsafeCreate(f1));
          op.onNext(Flowable.unsafeCreate(f2));
          op.onError(new NullPointerException("throwing exception in parent"));
        }
      }
);
      stringSubscriber=TestHelper.mockSubscriber();
      TestSubscriber<String> ts=new TestSubscriber<String>(stringSubscriber);
      Flowable<String> m=Flowable.mergeDelayError(parentFlowable);
      m.subscribe(ts);
      System.out.println("testErrorInParentFlowableDelayed | " + i);
      ts.awaitTerminalEvent(2000,TimeUnit.MILLISECONDS);
      ts.assertTerminated();
      verify(stringSubscriber,times(2)).onNext("hello");
      verify(stringSubscriber,times(1)).onError(any(NullPointerException.class));
      verify(stringSubscriber,never()).onComplete();
    }
  }
private static class TestASynchronous1sDelayedFlowable implements Publisher<String> {
    Thread t;
    @Override public void subscribe(    final Subscriber<? super String> subscriber){
      subscriber.onSubscribe(new BooleanSubscription());
      t=new Thread(new Runnable(){
        @Override public void run(){
          try {
            Thread.sleep(100);
          }
 catch (          InterruptedException e) {
            subscriber.onError(e);
          }
          subscriber.onNext("hello");
          subscriber.onComplete();
        }
      }
);
      t.start();
    }
  }
  @Test public void testDelayErrorMaxConcurrent(){
    final List<Long> requests=new ArrayList<Long>();
    Flowable<Integer> source=Flowable.mergeDelayError(Flowable.just(Flowable.just(1).hide(),Flowable.<Integer>error(new TestException())).doOnRequest(new LongConsumer(){
      @Override public void accept(      long t1){
        requests.add(t1);
      }
    }
),1);
    TestSubscriber<Integer> ts=new TestSubscriber<Integer>();
    source.subscribe(ts);
    ts.assertValue(1);
    ts.assertTerminated();
    ts.assertError(TestException.class);
    assertEquals(Arrays.asList(1L,1L,1L),requests);
  }
  @Test public void mergeIterable(){
    final Flowable<String> f1=Flowable.unsafeCreate(new TestSynchronousFlowable());
    final Flowable<String> f2=Flowable.unsafeCreate(new TestSynchronousFlowable());
    List<Flowable<String>> listOfFlowables=new ArrayList<Flowable<String>>();
    listOfFlowables.add(f1);
    listOfFlowables.add(f2);
    Flowable<String> m=Flowable.mergeDelayError(listOfFlowables);
    m.subscribe(stringSubscriber);
    verify(stringSubscriber,never()).onError(any(Throwable.class));
    verify(stringSubscriber,times(1)).onComplete();
    verify(stringSubscriber,times(2)).onNext("hello");
  }
  @SuppressWarnings("unchecked") @Test public void iterableMaxConcurrent(){
    TestSubscriber<Integer> ts=TestSubscriber.create();
    PublishProcessor<Integer> pp1=PublishProcessor.create();
    PublishProcessor<Integer> pp2=PublishProcessor.create();
    Flowable.mergeDelayError(Arrays.asList(pp1,pp2),1).subscribe(ts);
    assertTrue("ps1 has no subscribers?!",pp1.hasSubscribers());
    assertFalse("ps2 has subscribers?!",pp2.hasSubscribers());
    pp1.onNext(1);
    pp1.onComplete();
    assertFalse("ps1 has subscribers?!",pp1.hasSubscribers());
    assertTrue("ps2 has no subscribers?!",pp2.hasSubscribers());
    pp2.onNext(2);
    pp2.onComplete();
    ts.assertValues(1,2);
    ts.assertNoErrors();
    ts.assertComplete();
  }
  @SuppressWarnings("unchecked") @Test public void iterableMaxConcurrentError(){
    TestSubscriber<Integer> ts=TestSubscriber.create();
    PublishProcessor<Integer> pp1=PublishProcessor.create();
    PublishProcessor<Integer> pp2=PublishProcessor.create();
    Flowable.mergeDelayError(Arrays.asList(pp1,pp2),1).subscribe(ts);
    assertTrue("ps1 has no subscribers?!",pp1.hasSubscribers());
    assertFalse("ps2 has subscribers?!",pp2.hasSubscribers());
    pp1.onNext(1);
    pp1.onError(new TestException());
    assertFalse("ps1 has subscribers?!",pp1.hasSubscribers());
    assertTrue("ps2 has no subscribers?!",pp2.hasSubscribers());
    pp2.onNext(2);
    pp2.onError(new TestException());
    ts.assertValues(1,2);
    ts.assertError(CompositeException.class);
    ts.assertNotComplete();
    CompositeException ce=(CompositeException)ts.errors().get(0);
    assertEquals(2,ce.getExceptions().size());
  }
  @SuppressWarnings("unchecked") @Test @Ignore("No 2-9 parameter mergeDelayError() overloads") public void mergeMany() throws Exception {
    for (int i=2; i < 10; i++) {
      Class<?>[] clazz=new Class[i];
      Arrays.fill(clazz,Flowable.class);
      Flowable<Integer>[] obs=new Flowable[i];
      Arrays.fill(obs,Flowable.just(1));
      Integer[] expected=new Integer[i];
      Arrays.fill(expected,1);
      Method m=Flowable.class.getMethod("mergeDelayError",clazz);
      TestSubscriber<Integer> ts=TestSubscriber.create();
      ((Flowable<Integer>)m.invoke(null,(Object[])obs)).subscribe(ts);
      ts.assertValues(expected);
      ts.assertNoErrors();
      ts.assertComplete();
    }
  }
  static <T>Flowable<T> withError(  Flowable<T> source){
    return source.concatWith(Flowable.<T>error(new TestException()));
  }
  @SuppressWarnings("unchecked") @Test @Ignore("No 2-9 parameter mergeDelayError() overloads") public void mergeManyError() throws Exception {
    for (int i=2; i < 10; i++) {
      Class<?>[] clazz=new Class[i];
      Arrays.fill(clazz,Flowable.class);
      Flowable<Integer>[] obs=new Flowable[i];
      for (int j=0; j < i; j++) {
        obs[j]=withError(Flowable.just(1));
      }
      Integer[] expected=new Integer[i];
      Arrays.fill(expected,1);
      Method m=Flowable.class.getMethod("mergeDelayError",clazz);
      TestSubscriber<Integer> ts=TestSubscriber.create();
      ((Flowable<Integer>)m.invoke(null,(Object[])obs)).subscribe(ts);
      ts.assertValues(expected);
      ts.assertError(CompositeException.class);
      ts.assertNotComplete();
      CompositeException ce=(CompositeException)ts.errors().get(0);
      assertEquals(i,ce.getExceptions().size());
    }
  }
  @Test public void array(){
    for (int i=1; i < 100; i++) {
      @SuppressWarnings("unchecked") Flowable<Integer>[] sources=new Flowable[i];
      Arrays.fill(sources,Flowable.just(1));
      Integer[] expected=new Integer[i];
      for (int j=0; j < i; j++) {
        expected[j]=1;
      }
      Flowable.mergeArrayDelayError(sources).test().assertResult(expected);
    }
  }
  @SuppressWarnings("unchecked") @Test public void mergeArrayDelayError(){
    Flowable.mergeArrayDelayError(Flowable.just(1),Flowable.just(2)).test().assertResult(1,2);
  }
  @SuppressWarnings("unchecked") @Test public void mergeIterableDelayErrorWithError(){
    Flowable.mergeDelayError(Arrays.asList(Flowable.just(1).concatWith(Flowable.<Integer>error(new TestException())),Flowable.just(2))).test().assertFailure(TestException.class,1,2);
  }
  @Test public void mergeDelayError(){
    Flowable.mergeDelayError(Flowable.just(Flowable.just(1),Flowable.just(2))).test().assertResult(1,2);
  }
  @Test public void mergeDelayErrorWithError(){
    Flowable.mergeDelayError(Flowable.just(Flowable.just(1).concatWith(Flowable.<Integer>error(new TestException())),Flowable.just(2))).test().assertFailure(TestException.class,1,2);
  }
  @Test public void mergeDelayErrorMaxConcurrency(){
    Flowable.mergeDelayError(Flowable.just(Flowable.just(1),Flowable.just(2)),1).test().assertResult(1,2);
  }
  @Test public void mergeDelayErrorWithErrorMaxConcurrency(){
    Flowable.mergeDelayError(Flowable.just(Flowable.just(1).concatWith(Flowable.<Integer>error(new TestException())),Flowable.just(2)),1).test().assertFailure(TestException.class,1,2);
  }
  @SuppressWarnings("unchecked") @Test public void mergeIterableDelayErrorMaxConcurrency(){
    Flowable.mergeDelayError(Arrays.asList(Flowable.just(1),Flowable.just(2)),1).test().assertResult(1,2);
  }
  @SuppressWarnings("unchecked") @Test public void mergeIterableDelayErrorWithErrorMaxConcurrency(){
    Flowable.mergeDelayError(Arrays.asList(Flowable.just(1).concatWith(Flowable.<Integer>error(new TestException())),Flowable.just(2)),1).test().assertFailure(TestException.class,1,2);
  }
  @Test public void mergeDelayError3(){
    Flowable.mergeDelayError(Flowable.just(1),Flowable.just(2),Flowable.just(3)).test().assertResult(1,2,3);
  }
  @Test public void mergeDelayError3WithError(){
    Flowable.mergeDelayError(Flowable.just(1),Flowable.just(2).concatWith(Flowable.<Integer>error(new TestException())),Flowable.just(3)).test().assertFailure(TestException.class,1,2,3);
  }
  @SuppressWarnings("unchecked") @Test public void mergeIterableDelayError(){
    Flowable.mergeDelayError(Arrays.asList(Flowable.just(1),Flowable.just(2))).test().assertResult(1,2);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright (c) 2016-present, RxJava Contributors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package io.reactivex.internal.operators.observable;
import static org.junit.Assert.*;
import static org.mockito.ArgumentMatchers.*;
import static org.mockito.Mockito.*;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicReference;
import org.junit.*;
import org.mockito.InOrder;
import io.reactivex.*;
import io.reactivex.Observable;
import io.reactivex.Observer;
import io.reactivex.exceptions.TestException;
import io.reactivex.functions.*;
import io.reactivex.internal.functions.Functions;
import io.reactivex.observers.*;
import io.reactivex.schedulers.*;
import io.reactivex.subjects.PublishSubject;
public class ObservableDelayTest {
  private Observer<Long> observer;
  private Observer<Long> observer2;
  private TestScheduler scheduler;
  @Before public void before(){
    observer=TestHelper.mockObserver();
    observer2=TestHelper.mockObserver();
    scheduler=new TestScheduler();
  }
  @Test public void testDelay(){
    Observable<Long> source=Observable.interval(1L,TimeUnit.SECONDS,scheduler).take(3);
    Observable<Long> delayed=source.delay(500L,TimeUnit.MILLISECONDS,scheduler);
    delayed.subscribe(observer);
    InOrder inOrder=inOrder(observer);
    scheduler.advanceTimeTo(1499L,TimeUnit.MILLISECONDS);
    verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(1500L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(0L);
    inOrder.verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(2400L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(2500L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(1L);
    inOrder.verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(3400L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(3500L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(2L);
    verify(observer,times(1)).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
  }
  @Test public void testLongDelay(){
    Observable<Long> source=Observable.interval(1L,TimeUnit.SECONDS,scheduler).take(3);
    Observable<Long> delayed=source.delay(5L,TimeUnit.SECONDS,scheduler);
    delayed.subscribe(observer);
    InOrder inOrder=inOrder(observer);
    scheduler.advanceTimeTo(5999L,TimeUnit.MILLISECONDS);
    verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(6000L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(0L);
    scheduler.advanceTimeTo(6999L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,never()).onNext(anyLong());
    scheduler.advanceTimeTo(7000L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(1L);
    scheduler.advanceTimeTo(7999L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,never()).onNext(anyLong());
    scheduler.advanceTimeTo(8000L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(2L);
    inOrder.verify(observer,times(1)).onComplete();
    inOrder.verify(observer,never()).onNext(anyLong());
    inOrder.verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
  }
  @Test public void testDelayWithError(){
    Observable<Long> source=Observable.interval(1L,TimeUnit.SECONDS,scheduler).map(new Function<Long,Long>(){
      @Override public Long apply(      Long value){
        if (value == 1L) {
          throw new RuntimeException("error!");
        }
        return value;
      }
    }
);
    Observable<Long> delayed=source.delay(1L,TimeUnit.SECONDS,scheduler);
    delayed.subscribe(observer);
    InOrder inOrder=inOrder(observer);
    scheduler.advanceTimeTo(1999L,TimeUnit.MILLISECONDS);
    verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(2000L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onError(any(Throwable.class));
    inOrder.verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    scheduler.advanceTimeTo(5000L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,never()).onNext(anyLong());
    inOrder.verify(observer,never()).onError(any(Throwable.class));
    verify(observer,never()).onComplete();
  }
  @Test public void testDelayWithMultipleSubscriptions(){
    Observable<Long> source=Observable.interval(1L,TimeUnit.SECONDS,scheduler).take(3);
    Observable<Long> delayed=source.delay(500L,TimeUnit.MILLISECONDS,scheduler);
    delayed.subscribe(observer);
    delayed.subscribe(observer2);
    InOrder inOrder=inOrder(observer);
    InOrder inOrder2=inOrder(observer2);
    scheduler.advanceTimeTo(1499L,TimeUnit.MILLISECONDS);
    verify(observer,never()).onNext(anyLong());
    verify(observer2,never()).onNext(anyLong());
    scheduler.advanceTimeTo(1500L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(0L);
    inOrder2.verify(observer2,times(1)).onNext(0L);
    scheduler.advanceTimeTo(2499L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,never()).onNext(anyLong());
    inOrder2.verify(observer2,never()).onNext(anyLong());
    scheduler.advanceTimeTo(2500L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(1L);
    inOrder2.verify(observer2,times(1)).onNext(1L);
    verify(observer,never()).onComplete();
    verify(observer2,never()).onComplete();
    scheduler.advanceTimeTo(3500L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(2L);
    inOrder2.verify(observer2,times(1)).onNext(2L);
    inOrder.verify(observer,never()).onNext(anyLong());
    inOrder2.verify(observer2,never()).onNext(anyLong());
    inOrder.verify(observer,times(1)).onComplete();
    inOrder2.verify(observer2,times(1)).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    verify(observer2,never()).onError(any(Throwable.class));
  }
  @Test public void testDelaySubscription(){
    Observable<Integer> result=Observable.just(1,2,3).delaySubscription(100,TimeUnit.MILLISECONDS,scheduler);
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    result.subscribe(o);
    inOrder.verify(o,never()).onNext(any());
    inOrder.verify(o,never()).onComplete();
    scheduler.advanceTimeBy(100,TimeUnit.MILLISECONDS);
    inOrder.verify(o,times(1)).onNext(1);
    inOrder.verify(o,times(1)).onNext(2);
    inOrder.verify(o,times(1)).onNext(3);
    inOrder.verify(o,times(1)).onComplete();
    verify(o,never()).onError(any(Throwable.class));
  }
  @Test public void testDelaySubscriptionDisposeBeforeTime(){
    Observable<Integer> result=Observable.just(1,2,3).delaySubscription(100,TimeUnit.MILLISECONDS,scheduler);
    Observer<Object> o=TestHelper.mockObserver();
    TestObserver<Object> to=new TestObserver<Object>(o);
    result.subscribe(to);
    to.dispose();
    scheduler.advanceTimeBy(100,TimeUnit.MILLISECONDS);
    verify(o,never()).onNext(any());
    verify(o,never()).onComplete();
    verify(o,never()).onError(any(Throwable.class));
  }
  @Test public void testDelayWithObservableNormal1(){
    PublishSubject<Integer> source=PublishSubject.create();
    final List<PublishSubject<Integer>> delays=new ArrayList<PublishSubject<Integer>>();
    final int n=10;
    for (int i=0; i < n; i++) {
      PublishSubject<Integer> delay=PublishSubject.create();
      delays.add(delay);
    }
    Function<Integer,Observable<Integer>> delayFunc=new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        return delays.get(t1);
      }
    }
;
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    source.delay(delayFunc).subscribe(o);
    for (int i=0; i < n; i++) {
      source.onNext(i);
      delays.get(i).onNext(i);
      inOrder.verify(o).onNext(i);
    }
    source.onComplete();
    inOrder.verify(o).onComplete();
    inOrder.verifyNoMoreInteractions();
    verify(o,never()).onError(any(Throwable.class));
  }
  @Test public void testDelayWithObservableSingleSend1(){
    PublishSubject<Integer> source=PublishSubject.create();
    final PublishSubject<Integer> delay=PublishSubject.create();
    Function<Integer,Observable<Integer>> delayFunc=new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        return delay;
      }
    }
;
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    source.delay(delayFunc).subscribe(o);
    source.onNext(1);
    delay.onNext(1);
    delay.onNext(2);
    inOrder.verify(o).onNext(1);
    inOrder.verifyNoMoreInteractions();
    verify(o,never()).onError(any(Throwable.class));
  }
  @Test public void testDelayWithObservableSourceThrows(){
    PublishSubject<Integer> source=PublishSubject.create();
    final PublishSubject<Integer> delay=PublishSubject.create();
    Function<Integer,Observable<Integer>> delayFunc=new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        return delay;
      }
    }
;
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    source.delay(delayFunc).subscribe(o);
    source.onNext(1);
    source.onError(new TestException());
    delay.onNext(1);
    inOrder.verify(o).onError(any(TestException.class));
    inOrder.verifyNoMoreInteractions();
    verify(o,never()).onNext(any());
    verify(o,never()).onComplete();
  }
  @Test public void testDelayWithObservableDelayFunctionThrows(){
    PublishSubject<Integer> source=PublishSubject.create();
    Function<Integer,Observable<Integer>> delayFunc=new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        throw new TestException();
      }
    }
;
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    source.delay(delayFunc).subscribe(o);
    source.onNext(1);
    inOrder.verify(o).onError(any(TestException.class));
    inOrder.verifyNoMoreInteractions();
    verify(o,never()).onNext(any());
    verify(o,never()).onComplete();
  }
  @Test public void testDelayWithObservableDelayThrows(){
    PublishSubject<Integer> source=PublishSubject.create();
    final PublishSubject<Integer> delay=PublishSubject.create();
    Function<Integer,Observable<Integer>> delayFunc=new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        return delay;
      }
    }
;
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    source.delay(delayFunc).subscribe(o);
    source.onNext(1);
    delay.onError(new TestException());
    inOrder.verify(o).onError(any(TestException.class));
    inOrder.verifyNoMoreInteractions();
    verify(o,never()).onNext(any());
    verify(o,never()).onComplete();
  }
  @Test public void testDelayWithObservableSubscriptionNormal(){
    PublishSubject<Integer> source=PublishSubject.create();
    final PublishSubject<Integer> delay=PublishSubject.create();
    Callable<Observable<Integer>> subFunc=new Callable<Observable<Integer>>(){
      @Override public Observable<Integer> call(){
        return delay;
      }
    }
;
    Function<Integer,Observable<Integer>> delayFunc=new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        return delay;
      }
    }
;
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    source.delay(Observable.defer(subFunc),delayFunc).subscribe(o);
    source.onNext(1);
    delay.onNext(1);
    source.onNext(2);
    delay.onNext(2);
    inOrder.verify(o).onNext(2);
    inOrder.verifyNoMoreInteractions();
    verify(o,never()).onError(any(Throwable.class));
    verify(o,never()).onComplete();
  }
  @Test public void testDelayWithObservableSubscriptionFunctionThrows(){
    PublishSubject<Integer> source=PublishSubject.create();
    final PublishSubject<Integer> delay=PublishSubject.create();
    Callable<Observable<Integer>> subFunc=new Callable<Observable<Integer>>(){
      @Override public Observable<Integer> call(){
        throw new TestException();
      }
    }
;
    Function<Integer,Observable<Integer>> delayFunc=new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        return delay;
      }
    }
;
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    source.delay(Observable.defer(subFunc),delayFunc).subscribe(o);
    source.onNext(1);
    delay.onNext(1);
    source.onNext(2);
    inOrder.verify(o).onError(any(TestException.class));
    inOrder.verifyNoMoreInteractions();
    verify(o,never()).onNext(any());
    verify(o,never()).onComplete();
  }
  @Test public void testDelayWithObservableSubscriptionThrows(){
    PublishSubject<Integer> source=PublishSubject.create();
    final PublishSubject<Integer> delay=PublishSubject.create();
    Callable<Observable<Integer>> subFunc=new Callable<Observable<Integer>>(){
      @Override public Observable<Integer> call(){
        return delay;
      }
    }
;
    Function<Integer,Observable<Integer>> delayFunc=new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        return delay;
      }
    }
;
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    source.delay(Observable.defer(subFunc),delayFunc).subscribe(o);
    source.onNext(1);
    delay.onError(new TestException());
    source.onNext(2);
    inOrder.verify(o).onError(any(TestException.class));
    inOrder.verifyNoMoreInteractions();
    verify(o,never()).onNext(any());
    verify(o,never()).onComplete();
  }
  @Test public void testDelayWithObservableEmptyDelayer(){
    PublishSubject<Integer> source=PublishSubject.create();
    Function<Integer,Observable<Integer>> delayFunc=new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        return Observable.empty();
      }
    }
;
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    source.delay(delayFunc).subscribe(o);
    source.onNext(1);
    source.onComplete();
    inOrder.verify(o).onNext(1);
    inOrder.verify(o).onComplete();
    inOrder.verifyNoMoreInteractions();
    verify(o,never()).onError(any(Throwable.class));
  }
  @Test public void testDelayWithObservableSubscriptionRunCompletion(){
    PublishSubject<Integer> source=PublishSubject.create();
    final PublishSubject<Integer> sdelay=PublishSubject.create();
    final PublishSubject<Integer> delay=PublishSubject.create();
    Callable<Observable<Integer>> subFunc=new Callable<Observable<Integer>>(){
      @Override public Observable<Integer> call(){
        return sdelay;
      }
    }
;
    Function<Integer,Observable<Integer>> delayFunc=new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        return delay;
      }
    }
;
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    source.delay(Observable.defer(subFunc),delayFunc).subscribe(o);
    source.onNext(1);
    sdelay.onComplete();
    source.onNext(2);
    delay.onNext(2);
    inOrder.verify(o).onNext(2);
    inOrder.verifyNoMoreInteractions();
    verify(o,never()).onError(any(Throwable.class));
    verify(o,never()).onComplete();
  }
  @Test public void testDelayWithObservableAsTimed(){
    Observable<Long> source=Observable.interval(1L,TimeUnit.SECONDS,scheduler).take(3);
    final Observable<Long> delayer=Observable.timer(500L,TimeUnit.MILLISECONDS,scheduler);
    Function<Long,Observable<Long>> delayFunc=new Function<Long,Observable<Long>>(){
      @Override public Observable<Long> apply(      Long t1){
        return delayer;
      }
    }
;
    Observable<Long> delayed=source.delay(delayFunc);
    delayed.subscribe(observer);
    InOrder inOrder=inOrder(observer);
    scheduler.advanceTimeTo(1499L,TimeUnit.MILLISECONDS);
    verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(1500L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(0L);
    inOrder.verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(2400L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(2500L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(1L);
    inOrder.verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(3400L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,never()).onNext(anyLong());
    verify(observer,never()).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
    scheduler.advanceTimeTo(3500L,TimeUnit.MILLISECONDS);
    inOrder.verify(observer,times(1)).onNext(2L);
    verify(observer,times(1)).onComplete();
    verify(observer,never()).onError(any(Throwable.class));
  }
  @Test public void testDelayWithObservableReorder(){
    int n=3;
    PublishSubject<Integer> source=PublishSubject.create();
    final List<PublishSubject<Integer>> subjects=new ArrayList<PublishSubject<Integer>>();
    for (int i=0; i < n; i++) {
      subjects.add(PublishSubject.<Integer>create());
    }
    Observable<Integer> result=source.delay(new Function<Integer,Observable<Integer>>(){
      @Override public Observable<Integer> apply(      Integer t1){
        return subjects.get(t1);
      }
    }
);
    Observer<Object> o=TestHelper.mockObserver();
    InOrder inOrder=inOrder(o);
    result.subscribe(o);
    for (int i=0; i < n; i++) {
      source.onNext(i);
    }
    source.onComplete();
    inOrder.verify(o,never()).onNext(anyInt());
    inOrder.verify(o,never()).onComplete();
    for (int i=n - 1; i >= 0; i--) {
      subjects.get(i).onComplete();
      inOrder.verify(o).onNext(i);
    }
    inOrder.verify(o).onComplete();
    verify(o,never()).onError(any(Throwable.class));
  }
  @Test public void testDelayEmitsEverything(){
    Observable<Integer> source=Observable.range(1,5);
    Observable<Integer> delayed=source.delay(500L,TimeUnit.MILLISECONDS,scheduler);
    delayed=delayed.doOnEach(new Consumer<Notification<Integer>>(){
      @Override public void accept(      Notification<Integer> t1){
        System.out.println(t1);
      }
    }
);
    TestObserver<Integer> observer=new TestObserver<Integer>();
    delayed.subscribe(observer);
    scheduler.advanceTimeBy(500L,TimeUnit.MILLISECONDS);
    observer.assertValues(1,2,3,4,5);
  }
  @Test public void testBackpressureWithTimedDelay(){
    TestObserver<Integer> to=new TestObserver<Integer>();
    Observable.range(1,Flowable.bufferSize() * 2).delay(100,TimeUnit.MILLISECONDS).observeOn(Schedulers.computation()).map(new Function<Integer,Integer>(){
      int c;
      @Override public Integer apply(      Integer t){
        if (c++ <= 0) {
          try {
            Thread.sleep(500);
          }
 catch (          InterruptedException e) {
          }
        }
        return t;
      }
    }
).subscribe(to);
    to.awaitTerminalEvent();
    to.assertNoErrors();
    assertEquals(Flowable.bufferSize() * 2,to.valueCount());
  }
  @Test public void testBackpressureWithSubscriptionTimedDelay(){
    TestObserver<Integer> to=new TestObserver<Integer>();
    Observable.range(1,Flowable.bufferSize() * 2).delaySubscription(100,TimeUnit.MILLISECONDS).delay(100,TimeUnit.MILLISECONDS).observeOn(Schedulers.computation()).map(new Function<Integer,Integer>(){
      int c;
      @Override public Integer apply(      Integer t){
        if (c++ <= 0) {
          try {
            Thread.sleep(500);
          }
 catch (          InterruptedException e) {
          }
        }
        return t;
      }
    }
).subscribe(to);
    to.awaitTerminalEvent();
    to.assertNoErrors();
    assertEquals(Flowable.bufferSize() * 2,to.valueCount());
  }
  @Test public void testBackpressureWithSelectorDelay(){
    TestObserver<Integer> to=new TestObserver<Integer>();
    Observable.range(1,Flowable.bufferSize() * 2).delay(new Function<Integer,Observable<Long>>(){
      @Override public Observable<Long> apply(      Integer i){
        return Observable.timer(100,TimeUnit.MILLISECONDS);
      }
    }
).observeOn(Schedulers.computation()).map(new Function<Integer,Integer>(){
      int c;
      @Override public Integer apply(      Integer t){
        if (c++ <= 0) {
          try {
            Thread.sleep(500);
          }
 catch (          InterruptedException e) {
          }
        }
        return t;
      }
    }
).subscribe(to);
    to.awaitTerminalEvent();
    to.assertNoErrors();
    assertEquals(Flowable.bufferSize() * 2,to.valueCount());
  }
  @Test public void testBackpressureWithSelectorDelayAndSubscriptionDelay(){
    TestObserver<Integer> to=new TestObserver<Integer>();
    Observable.range(1,Flowable.bufferSize() * 2).delay(Observable.timer(500,TimeUnit.MILLISECONDS),new Function<Integer,Observable<Long>>(){
      @Override public Observable<Long> apply(      Integer i){
        return Observable.timer(100,TimeUnit.MILLISECONDS);
      }
    }
).observeOn(Schedulers.computation()).map(new Function<Integer,Integer>(){
      int c;
      @Override public Integer apply(      Integer t){
        if (c++ <= 0) {
          try {
            Thread.sleep(500);
          }
 catch (          InterruptedException e) {
          }
        }
        return t;
      }
    }
).subscribe(to);
    to.awaitTerminalEvent();
    to.assertNoErrors();
    assertEquals(Flowable.bufferSize() * 2,to.valueCount());
  }
  @Test public void testErrorRunsBeforeOnNext(){
    TestScheduler test=new TestScheduler();
    PublishSubject<Integer> ps=PublishSubject.create();
    TestObserver<Integer> to=new TestObserver<Integer>();
    ps.delay(1,TimeUnit.SECONDS,test).subscribe(to);
    ps.onNext(1);
    test.advanceTimeBy(500,TimeUnit.MILLISECONDS);
    ps.onError(new TestException());
    test.advanceTimeBy(1,TimeUnit.SECONDS);
    to.assertNoValues();
    to.assertError(TestException.class);
    to.assertNotComplete();
  }
  @Test public void testDelaySupplierSimple(){
    final PublishSubject<Integer> ps=PublishSubject.create();
    Observable<Integer> source=Observable.range(1,5);
    TestObserver<Integer> to=new TestObserver<Integer>();
    source.delaySubscription(ps).subscribe(to);
    to.assertNoValues();
    to.assertNoErrors();
    to.assertNotComplete();
    ps.onNext(1);
    to.assertValues(1,2,3,4,5);
    to.assertComplete();
    to.assertNoErrors();
  }
  @Test public void testDelaySupplierCompletes(){
    final PublishSubject<Integer> ps=PublishSubject.create();
    Observable<Integer> source=Observable.range(1,5);
    TestObserver<Integer> to=new TestObserver<Integer>();
    source.delaySubscription(ps).subscribe(to);
    to.assertNoValues();
    to.assertNoErrors();
    to.assertNotComplete();
    ps.onComplete();
    to.assertValues(1,2,3,4,5);
    to.assertComplete();
    to.assertNoErrors();
  }
  @Test public void testDelaySupplierErrors(){
    final PublishSubject<Integer> ps=PublishSubject.create();
    Observable<Integer> source=Observable.range(1,5);
    TestObserver<Integer> to=new TestObserver<Integer>();
    source.delaySubscription(ps).subscribe(to);
    to.assertNoValues();
    to.assertNoErrors();
    to.assertNotComplete();
    ps.onError(new TestException());
    to.assertNoValues();
    to.assertNotComplete();
    to.assertError(TestException.class);
  }
  @Test public void delayWithTimeDelayError() throws Exception {
    Observable.just(1).concatWith(Observable.<Integer>error(new TestException())).delay(100,TimeUnit.MILLISECONDS,true).test().awaitDone(5,TimeUnit.SECONDS).assertFailure(TestException.class,1);
  }
  @Test public void testOnErrorCalledOnScheduler() throws Exception {
    final CountDownLatch latch=new CountDownLatch(1);
    final AtomicReference<Thread> thread=new AtomicReference<Thread>();
    Observable.<String>error(new Exception()).delay(0,TimeUnit.MILLISECONDS,Schedulers.newThread()).doOnError(new Consumer<Throwable>(){
      @Override public void accept(      Throwable throwable) throws Exception {
        thread.set(Thread.currentThread());
        latch.countDown();
      }
    }
).onErrorResumeNext(Observable.<String>empty()).subscribe();
    latch.await();
    assertNotEquals(Thread.currentThread(),thread.get());
  }
  @Test public void dispose(){
    TestHelper.checkDisposed(PublishSubject.create().delay(1,TimeUnit.SECONDS));
    TestHelper.checkDisposed(PublishSubject.create().delay(Functions.justFunction(Observable.never())));
  }
  @Test public void doubleOnSubscribe(){
    TestHelper.checkDoubleOnSubscribeObservable(new Function<Observable<Object>,ObservableSource<Object>>(){
      @Override public ObservableSource<Object> apply(      Observable<Object> o) throws Exception {
        return o.delay(1,TimeUnit.SECONDS);
      }
    }
);
    TestHelper.checkDoubleOnSubscribeObservable(new Function<Observable<Object>,ObservableSource<Object>>(){
      @Override public ObservableSource<Object> apply(      Observable<Object> o) throws Exception {
        return o.delay(Functions.justFunction(Observable.never()));
      }
    }
);
  }
  @Test public void onCompleteFinal(){
    TestScheduler scheduler=new TestScheduler();
    Observable.empty().delay(1,TimeUnit.MILLISECONDS,scheduler).subscribe(new DisposableObserver<Object>(){
      @Override public void onNext(      Object value){
      }
      @Override public void onError(      Throwable e){
      }
      @Override public void onComplete(){
        throw new TestException();
      }
    }
);
    try {
      scheduler.advanceTimeBy(1,TimeUnit.SECONDS);
      fail("Should have thrown");
    }
 catch (    TestException ex) {
    }
  }
  @Test public void onErrorFinal(){
    TestScheduler scheduler=new TestScheduler();
    Observable.error(new TestException()).delay(1,TimeUnit.MILLISECONDS,scheduler).subscribe(new DisposableObserver<Object>(){
      @Override public void onNext(      Object value){
      }
      @Override public void onError(      Throwable e){
        throw new TestException();
      }
      @Override public void onComplete(){
      }
    }
);
    try {
      scheduler.advanceTimeBy(1,TimeUnit.SECONDS);
      fail("Should have thrown");
    }
 catch (    TestException ex) {
    }
  }
  @Test public void itemDelayReturnsNull(){
    Observable.just(1).delay(new Function<Integer,Observable<Object>>(){
      @Override public Observable<Object> apply(      Integer t) throws Exception {
        return null;
      }
    }
).test().assertFailureAndMessage(NullPointerException.class,"The itemDelay returned a null ObservableSource");
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright (c) 2016-present, RxJava Contributors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package io.reactivex.internal.operators.completable;
import static org.junit.Assert.*;
import java.util.concurrent.TimeUnit;
import org.junit.Test;
import io.reactivex.*;
import io.reactivex.exceptions.TestException;
import io.reactivex.processors.PublishProcessor;
public class CompletableAwaitTest {
  @Test public void awaitInterrupted(){
    Thread.currentThread().interrupt();
    try {
      PublishProcessor.create().ignoreElements().blockingAwait();
      fail("Should have thrown RuntimeException");
    }
 catch (    RuntimeException ex) {
      if (!(ex.getCause() instanceof InterruptedException)) {
        fail("Wrong cause: " + ex.getCause());
      }
    }
  }
  @Test public void awaitTimeoutInterrupted(){
    Thread.currentThread().interrupt();
    try {
      PublishProcessor.create().ignoreElements().blockingAwait(1,TimeUnit.SECONDS);
      fail("Should have thrown RuntimeException");
    }
 catch (    RuntimeException ex) {
      if (!(ex.getCause() instanceof InterruptedException)) {
        fail("Wrong cause: " + ex.getCause());
      }
    }
  }
  @Test public void awaitTimeout(){
    assertFalse(PublishProcessor.create().ignoreElements().blockingAwait(100,TimeUnit.MILLISECONDS));
  }
  @Test public void blockingGet(){
    assertNull(Completable.complete().blockingGet());
  }
  @Test public void blockingGetTimeout(){
    assertNull(Completable.complete().blockingGet(1,TimeUnit.SECONDS));
  }
  @Test public void blockingGetError(){
    TestException ex=new TestException();
    assertSame(ex,Completable.error(ex).blockingGet());
  }
  @Test public void blockingGetErrorTimeout(){
    TestException ex=new TestException();
    assertSame(ex,Completable.error(ex).blockingGet(1,TimeUnit.SECONDS));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright (c) 2016-present, RxJava Contributors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package io.reactivex.internal.operators.completable;
import static org.junit.Assert.*;
import java.util.*;
import org.junit.Test;
import org.reactivestreams.Subscriber;
import io.reactivex.*;
import io.reactivex.disposables.*;
import io.reactivex.exceptions.*;
import io.reactivex.functions.Function;
import io.reactivex.internal.subscriptions.BooleanSubscription;
import io.reactivex.observers.TestObserver;
import io.reactivex.plugins.RxJavaPlugins;
import io.reactivex.processors.PublishProcessor;
public class CompletableMergeTest {
  @Test public void invalidPrefetch(){
    try {
      Completable.merge(Flowable.just(Completable.complete()),-99);
      fail("Should have thrown IllegalArgumentExceptio");
    }
 catch (    IllegalArgumentException ex) {
      assertEquals("maxConcurrency > 0 required but it was -99",ex.getMessage());
    }
  }
  @Test public void cancelAfterFirst(){
    final TestObserver<Void> to=new TestObserver<Void>();
    Completable.mergeArray(new Completable(){
      @Override protected void subscribeActual(      CompletableObserver observer){
        observer.onSubscribe(Disposables.empty());
        observer.onComplete();
        to.cancel();
      }
    }
,Completable.complete()).subscribe(to);
    to.assertEmpty();
  }
  @Test public void cancelAfterFirstDelayError(){
    final TestObserver<Void> to=new TestObserver<Void>();
    Completable.mergeArrayDelayError(new Completable(){
      @Override protected void subscribeActual(      CompletableObserver observer){
        observer.onSubscribe(Disposables.empty());
        observer.onComplete();
        to.cancel();
      }
    }
,Completable.complete()).subscribe(to);
    to.assertEmpty();
  }
  @Test public void onErrorAfterComplete(){
    List<Throwable> errors=TestHelper.trackPluginErrors();
    try {
      final CompletableObserver[] co={null};
      Completable.mergeArrayDelayError(Completable.complete(),new Completable(){
        @Override protected void subscribeActual(        CompletableObserver observer){
          observer.onSubscribe(Disposables.empty());
          observer.onComplete();
          co[0]=observer;
        }
      }
).test().assertResult();
      co[0].onError(new TestException());
      TestHelper.assertUndeliverable(errors,0,TestException.class);
    }
  finally {
      RxJavaPlugins.reset();
    }
  }
  @Test public void completeAfterMain(){
    PublishProcessor<Integer> pp=PublishProcessor.create();
    TestObserver<Void> to=Completable.mergeArray(Completable.complete(),pp.ignoreElements()).test();
    pp.onComplete();
    to.assertResult();
  }
  @Test public void completeAfterMainDelayError(){
    PublishProcessor<Integer> pp=PublishProcessor.create();
    TestObserver<Void> to=Completable.mergeArrayDelayError(Completable.complete(),pp.ignoreElements()).test();
    pp.onComplete();
    to.assertResult();
  }
  @Test public void errorAfterMainDelayError(){
    PublishProcessor<Integer> pp=PublishProcessor.create();
    TestObserver<Void> to=Completable.mergeArrayDelayError(Completable.complete(),pp.ignoreElements()).test();
    pp.onError(new TestException());
    to.assertFailure(TestException.class);
  }
  @Test public void dispose(){
    TestHelper.checkDisposed(Completable.merge(Flowable.just(Completable.complete())));
  }
  @Test public void disposePropagates(){
    PublishProcessor<Integer> pp=PublishProcessor.create();
    TestObserver<Void> to=Completable.merge(Flowable.just(pp.ignoreElements())).test();
    assertTrue(pp.hasSubscribers());
    to.cancel();
    assertFalse(pp.hasSubscribers());
    to.assertEmpty();
  }
  @Test public void innerComplete(){
    PublishProcessor<Integer> pp=PublishProcessor.create();
    TestObserver<Void> to=Completable.merge(Flowable.just(pp.ignoreElements())).test();
    pp.onComplete();
    to.assertResult();
  }
  @Test public void innerError(){
    PublishProcessor<Integer> pp=PublishProcessor.create();
    TestObserver<Void> to=Completable.merge(Flowable.just(pp.ignoreElements())).test();
    pp.onError(new TestException());
    to.assertFailure(TestException.class);
  }
  @Test public void innerErrorDelayError(){
    PublishProcessor<Integer> pp=PublishProcessor.create();
    TestObserver<Void> to=Completable.mergeDelayError(Flowable.just(pp.ignoreElements())).test();
    pp.onError(new TestException());
    to.assertFailure(TestException.class);
  }
  @Test public void mainErrorInnerErrorRace(){
    for (int i=0; i < TestHelper.RACE_DEFAULT_LOOPS; i++) {
      List<Throwable> errors=TestHelper.trackPluginErrors();
      try {
        final PublishProcessor<Integer> pp1=PublishProcessor.create();
        final PublishProcessor<Integer> pp2=PublishProcessor.create();
        TestObserver<Void> to=Completable.merge(pp1.map(new Function<Integer,Completable>(){
          @Override public Completable apply(          Integer v) throws Exception {
            return pp2.ignoreElements();
          }
        }
)).test();
        pp1.onNext(1);
        final Throwable ex1=new TestException();
        final Throwable ex2=new TestException();
        Runnable r1=new Runnable(){
          @Override public void run(){
            pp1.onError(ex1);
          }
        }
;
        Runnable r2=new Runnable(){
          @Override public void run(){
            pp2.onError(ex2);
          }
        }
;
        TestHelper.race(r1,r2);
        Throwable ex=to.errors().get(0);
        if (ex instanceof CompositeException) {
          to.assertSubscribed().assertNoValues().assertNotComplete();
          errors=TestHelper.compositeList(ex);
          TestHelper.assertError(errors,0,TestException.class);
          TestHelper.assertError(errors,1,TestException.class);
        }
 else {
          to.assertFailure(TestException.class);
          if (!errors.isEmpty()) {
            TestHelper.assertUndeliverable(errors,0,TestException.class);
          }
        }
      }
  finally {
        RxJavaPlugins.reset();
      }
    }
  }
  @Test public void mainErrorInnerErrorDelayedRace(){
    for (int i=0; i < TestHelper.RACE_DEFAULT_LOOPS; i++) {
      final PublishProcessor<Integer> pp1=PublishProcessor.create();
      final PublishProcessor<Integer> pp2=PublishProcessor.create();
      TestObserver<Void> to=Completable.mergeDelayError(pp1.map(new Function<Integer,Completable>(){
        @Override public Completable apply(        Integer v) throws Exception {
          return pp2.ignoreElements();
        }
      }
)).test();
      pp1.onNext(1);
      final Throwable ex1=new TestException();
      Runnable r1=new Runnable(){
        @Override public void run(){
          pp1.onError(ex1);
        }
      }
;
      final Throwable ex2=new TestException();
      Runnable r2=new Runnable(){
        @Override public void run(){
          pp2.onError(ex2);
        }
      }
;
      TestHelper.race(r1,r2);
      to.assertFailure(CompositeException.class);
      List<Throwable> errors=TestHelper.compositeList(to.errors().get(0));
      TestHelper.assertError(errors,0,TestException.class);
      TestHelper.assertError(errors,1,TestException.class);
    }
  }
  @Test public void maxConcurrencyOne(){
    final PublishProcessor<Integer> pp1=PublishProcessor.create();
    final PublishProcessor<Integer> pp2=PublishProcessor.create();
    TestObserver<Void> to=Completable.merge(Flowable.just(pp1.ignoreElements(),pp2.ignoreElements()),1).test();
    assertTrue(pp1.hasSubscribers());
    assertFalse(pp2.hasSubscribers());
    pp1.onComplete();
    assertTrue(pp2.hasSubscribers());
    pp2.onComplete();
    to.assertResult();
  }
  @Test public void maxConcurrencyOneDelayError(){
    final PublishProcessor<Integer> pp1=PublishProcessor.create();
    final PublishProcessor<Integer> pp2=PublishProcessor.create();
    TestObserver<Void> to=Completable.mergeDelayError(Flowable.just(pp1.ignoreElements(),pp2.ignoreElements()),1).test();
    assertTrue(pp1.hasSubscribers());
    assertFalse(pp2.hasSubscribers());
    pp1.onComplete();
    assertTrue(pp2.hasSubscribers());
    pp2.onComplete();
    to.assertResult();
  }
  @Test public void maxConcurrencyOneDelayErrorFirst(){
    final PublishProcessor<Integer> pp1=PublishProcessor.create();
    final PublishProcessor<Integer> pp2=PublishProcessor.create();
    TestObserver<Void> to=Completable.mergeDelayError(Flowable.just(pp1.ignoreElements(),pp2.ignoreElements()),1).test();
    assertTrue(pp1.hasSubscribers());
    assertFalse(pp2.hasSubscribers());
    pp1.onError(new TestException());
    assertTrue(pp2.hasSubscribers());
    pp2.onComplete();
    to.assertFailure(TestException.class);
  }
  @Test public void maxConcurrencyOneDelayMainErrors(){
    final PublishProcessor<PublishProcessor<Integer>> pp0=PublishProcessor.create();
    final PublishProcessor<Integer> pp1=PublishProcessor.create();
    final PublishProcessor<Integer> pp2=PublishProcessor.create();
    TestObserver<Void> to=Completable.mergeDelayError(pp0.map(new Function<PublishProcessor<Integer>,Completable>(){
      @Override public Completable apply(      PublishProcessor<Integer> v) throws Exception {
        return v.ignoreElements();
      }
    }
),1).test();
    pp0.onNext(pp1);
    assertTrue(pp1.hasSubscribers());
    assertFalse(pp2.hasSubscribers());
    pp1.onComplete();
    pp0.onNext(pp2);
    pp0.onError(new TestException());
    assertTrue(pp2.hasSubscribers());
    pp2.onComplete();
    to.assertFailure(TestException.class);
  }
  @Test public void mainDoubleOnError(){
    List<Throwable> errors=TestHelper.trackPluginErrors();
    try {
      Completable.mergeDelayError(new Flowable<Completable>(){
        @Override protected void subscribeActual(        Subscriber<? super Completable> s){
          s.onSubscribe(new BooleanSubscription());
          s.onNext(Completable.complete());
          s.onError(new TestException("First"));
          s.onError(new TestException("Second"));
        }
      }
).test().assertFailureAndMessage(TestException.class,"First");
      TestHelper.assertUndeliverable(errors,0,TestException.class,"Second");
    }
  finally {
      RxJavaPlugins.reset();
    }
  }
  @Test public void innerDoubleOnError(){
    List<Throwable> errors=TestHelper.trackPluginErrors();
    try {
      final CompletableObserver[] o={null};
      Completable.mergeDelayError(Flowable.just(new Completable(){
        @Override protected void subscribeActual(        CompletableObserver observer){
          observer.onSubscribe(Disposables.empty());
          observer.onError(new TestException("First"));
          o[0]=observer;
        }
      }
)).test().assertFailureAndMessage(TestException.class,"First");
      o[0].onError(new TestException("Second"));
      TestHelper.assertUndeliverable(errors,0,TestException.class,"Second");
    }
  finally {
      RxJavaPlugins.reset();
    }
  }
  @Test public void innerIsDisposed(){
    final TestObserver<Void> to=new TestObserver<Void>();
    Completable.mergeDelayError(Flowable.just(new Completable(){
      @Override protected void subscribeActual(      CompletableObserver observer){
        observer.onSubscribe(Disposables.empty());
        assertFalse(((Disposable)observer).isDisposed());
        to.dispose();
        assertTrue(((Disposable)observer).isDisposed());
      }
    }
)).subscribe(to);
  }
  @Test public void mergeArrayInnerErrorRace(){
    for (int i=0; i < TestHelper.RACE_DEFAULT_LOOPS; i++) {
      List<Throwable> errors=TestHelper.trackPluginErrors();
      try {
        final PublishProcessor<Integer> pp1=PublishProcessor.create();
        final PublishProcessor<Integer> pp2=PublishProcessor.create();
        TestObserver<Void> to=Completable.mergeArray(pp1.ignoreElements(),pp2.ignoreElements()).test();
        pp1.onNext(1);
        final Throwable ex1=new TestException();
        final Throwable ex2=new TestException();
        Runnable r1=new Runnable(){
          @Override public void run(){
            pp1.onError(ex1);
          }
        }
;
        Runnable r2=new Runnable(){
          @Override public void run(){
            pp2.onError(ex2);
          }
        }
;
        TestHelper.race(r1,r2);
        to.assertFailure(TestException.class);
        if (!errors.isEmpty()) {
          TestHelper.assertUndeliverable(errors,0,TestException.class);
        }
      }
  finally {
        RxJavaPlugins.reset();
      }
    }
  }
  @Test public void delayErrorIterableCancel(){
    Completable.mergeDelayError(Arrays.asList(Completable.complete())).test(true).assertEmpty();
  }
  @Test public void delayErrorIterableCancelAfterHasNext(){
    final TestObserver<Void> to=new TestObserver<Void>();
    Completable.mergeDelayError(new Iterable<Completable>(){
      @Override public Iterator<Completable> iterator(){
        return new Iterator<Completable>(){
          @Override public boolean hasNext(){
            to.cancel();
            return true;
          }
          @Override public Completable next(){
            return Completable.complete();
          }
          @Override public void remove(){
            throw new UnsupportedOperationException();
          }
        }
;
      }
    }
).subscribe(to);
    to.assertEmpty();
  }
  @Test public void delayErrorIterableCancelAfterNext(){
    final TestObserver<Void> to=new TestObserver<Void>();
    Completable.mergeDelayError(new Iterable<Completable>(){
      @Override public Iterator<Completable> iterator(){
        return new Iterator<Completable>(){
          @Override public boolean hasNext(){
            return true;
          }
          @Override public Completable next(){
            to.cancel();
            return Completable.complete();
          }
          @Override public void remove(){
            throw new UnsupportedOperationException();
          }
        }
;
      }
    }
).subscribe(to);
    to.assertEmpty();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright (c) 2016-present, RxJava Contributors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package io.reactivex.observable;
import java.util.Arrays;
import org.junit.Test;
import io.reactivex.Observable;
import io.reactivex.internal.fuseable.QueueFuseable;
import io.reactivex.observers.ObserverFusion;
public class ObservableFuseableTest {
  @Test public void syncRange(){
    Observable.range(1,10).to(ObserverFusion.<Integer>test(QueueFuseable.ANY,false)).assertOf(ObserverFusion.<Integer>assertFusionMode(QueueFuseable.SYNC)).assertValues(1,2,3,4,5,6,7,8,9,10).assertNoErrors().assertComplete();
  }
  @Test public void syncArray(){
    Observable.fromArray(new Integer[]{1,2,3,4,5,6,7,8,9,10}).to(ObserverFusion.<Integer>test(QueueFuseable.ANY,false)).assertOf(ObserverFusion.<Integer>assertFusionMode(QueueFuseable.SYNC)).assertValues(1,2,3,4,5,6,7,8,9,10).assertNoErrors().assertComplete();
  }
  @Test public void syncIterable(){
    Observable.fromIterable(Arrays.asList(1,2,3,4,5,6,7,8,9,10)).to(ObserverFusion.<Integer>test(QueueFuseable.ANY,false)).assertOf(ObserverFusion.<Integer>assertFusionMode(QueueFuseable.SYNC)).assertValues(1,2,3,4,5,6,7,8,9,10).assertNoErrors().assertComplete();
  }
  @Test public void syncRangeHidden(){
    Observable.range(1,10).hide().to(ObserverFusion.<Integer>test(QueueFuseable.ANY,false)).assertOf(ObserverFusion.<Integer>assertNotFuseable()).assertOf(ObserverFusion.<Integer>assertFusionMode(QueueFuseable.NONE)).assertValues(1,2,3,4,5,6,7,8,9,10).assertNoErrors().assertComplete();
  }
  @Test public void syncArrayHidden(){
    Observable.fromArray(new Integer[]{1,2,3,4,5,6,7,8,9,10}).hide().to(ObserverFusion.<Integer>test(QueueFuseable.ANY,false)).assertOf(ObserverFusion.<Integer>assertNotFuseable()).assertOf(ObserverFusion.<Integer>assertFusionMode(QueueFuseable.NONE)).assertValues(1,2,3,4,5,6,7,8,9,10).assertNoErrors().assertComplete();
  }
  @Test public void syncIterableHidden(){
    Observable.fromIterable(Arrays.asList(1,2,3,4,5,6,7,8,9,10)).hide().to(ObserverFusion.<Integer>test(QueueFuseable.ANY,false)).assertOf(ObserverFusion.<Integer>assertNotFuseable()).assertOf(ObserverFusion.<Integer>assertFusionMode(QueueFuseable.NONE)).assertValues(1,2,3,4,5,6,7,8,9,10).assertNoErrors().assertComplete();
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from RxJava-2.2.4~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.puppycrawl.tools.checkstyle.grammar;
import org.junit.Test;
import com.puppycrawl.tools.checkstyle.AbstractModuleTestSupport;
import com.puppycrawl.tools.checkstyle.DefaultConfiguration;
import com.puppycrawl.tools.checkstyle.checks.naming.MemberNameCheck;
import com.puppycrawl.tools.checkstyle.utils.CommonUtil;
/** 
 * Tests Java 7 String in switch can be parsed.
 */
public class Java7StringSwitchTest extends AbstractModuleTestSupport {
  @Override protected String getPackageLocation(){
    return "com/puppycrawl/tools/checkstyle/grammar";
  }
  @Test public void testCanParse() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(MemberNameCheck.class);
    final String[] expected=CommonUtil.EMPTY_STRING_ARRAY;
    verify(checkConfig,getPath("InputJava7StringSwitch.java"),expected);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.puppycrawl.tools.checkstyle.checks.metrics;
import static com.puppycrawl.tools.checkstyle.checks.metrics.ClassDataAbstractionCouplingCheck.MSG_KEY;
import static org.junit.Assert.assertArrayEquals;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import org.junit.Test;
import antlr.CommonHiddenStreamToken;
import com.puppycrawl.tools.checkstyle.AbstractModuleTestSupport;
import com.puppycrawl.tools.checkstyle.DefaultConfiguration;
import com.puppycrawl.tools.checkstyle.api.CheckstyleException;
import com.puppycrawl.tools.checkstyle.api.DetailAST;
import com.puppycrawl.tools.checkstyle.api.TokenTypes;
import com.puppycrawl.tools.checkstyle.utils.CommonUtil;
public class ClassDataAbstractionCouplingCheckTest extends AbstractModuleTestSupport {
  @Override protected String getPackageLocation(){
    return "com/puppycrawl/tools/checkstyle/checks/metrics/classdataabstractioncoupling";
  }
  @Test public void testTokens(){
    final ClassDataAbstractionCouplingCheck check=new ClassDataAbstractionCouplingCheck();
    assertNotNull("Required tokens should not be null",check.getRequiredTokens());
    assertNotNull("Acceptable tokens should not be null",check.getAcceptableTokens());
    assertArrayEquals("Invalid default tokens",check.getDefaultTokens(),check.getAcceptableTokens());
    assertArrayEquals("Invalid acceptable tokens",check.getDefaultTokens(),check.getRequiredTokens());
  }
  @Test public void test() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(ClassDataAbstractionCouplingCheck.class);
    checkConfig.addAttribute("max","0");
    checkConfig.addAttribute("excludedClasses","InnerClass");
    final String[] expected={"6:1: " + getCheckMessage(MSG_KEY,4,0,"[AnotherInnerClass, HashMap, HashSet, int]"),"7:5: " + getCheckMessage(MSG_KEY,1,0,"[ArrayList]"),"27:1: " + getCheckMessage(MSG_KEY,2,0,"[HashMap, HashSet]")};
    verify(checkConfig,getPath("InputClassDataAbstractionCoupling.java"),expected);
  }
  @Test public void testExcludedPackageDirectPackages() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(ClassDataAbstractionCouplingCheck.class);
    checkConfig.addAttribute("max","0");
    checkConfig.addAttribute("excludedPackages","com.puppycrawl.tools.checkstyle.checks.metrics.classdataabstractioncoupling.inputs.c," + "com.puppycrawl.tools.checkstyle.checks.metrics.classdataabstractioncoupling." + "inputs.b");
    final String[] expected={"8:1: " + getCheckMessage(MSG_KEY,2,0,"[AAClass, ABClass]")};
    verify(checkConfig,getPath("InputClassDataAbstractionCouplingExcludedPackagesDirectPackages.java"),expected);
  }
  @Test public void testExcludedPackageCommonPackages() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(ClassDataAbstractionCouplingCheck.class);
    checkConfig.addAttribute("max","0");
    checkConfig.addAttribute("excludedPackages","com.puppycrawl.tools.checkstyle.checks.metrics.inputs.a");
    final String[] expected={"8:1: " + getCheckMessage(MSG_KEY,2,0,"[AAClass, ABClass]"),"12:5: " + getCheckMessage(MSG_KEY,2,0,"[BClass, CClass]"),"18:1: " + getCheckMessage(MSG_KEY,1,0,"[CClass]")};
    verify(checkConfig,getPath("InputClassDataAbstractionCouplingExcludedPackagesCommonPackage.java"),expected);
  }
  @Test public void testExcludedPackageWithEndingDot() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(ClassDataAbstractionCouplingCheck.class);
    checkConfig.addAttribute("max","0");
    checkConfig.addAttribute("excludedPackages","com.puppycrawl.tools.checkstyle.checks.metrics.inputs.a.");
    try {
      createChecker(checkConfig);
      fail("exception expected");
    }
 catch (    CheckstyleException ex) {
      final String messageStart="cannot initialize module com.puppycrawl.tools.checkstyle.TreeWalker - " + "Cannot set property 'excludedPackages' to " + "'com.puppycrawl.tools.checkstyle.checks.metrics.inputs.a.' in module "+ "com.puppycrawl.tools.checkstyle.checks.metrics."+ "ClassDataAbstractionCouplingCheck";
      assertTrue("Invalid exception message, should start with: " + messageStart,ex.getMessage().startsWith(messageStart));
    }
  }
  @Test public void testExcludedPackageCommonPackagesAllIgnored() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(ClassDataAbstractionCouplingCheck.class);
    checkConfig.addAttribute("max","0");
    checkConfig.addAttribute("excludedPackages","com.puppycrawl.tools.checkstyle.checks.metrics.classdataabstractioncoupling.inputs." + "a.aa," + "com.puppycrawl.tools.checkstyle.checks.metrics.classdataabstractioncoupling."+ "inputs.a.ab,"+ "com.puppycrawl.tools.checkstyle.checks.metrics.classdataabstractioncoupling."+ "inputs.b,"+ "com.puppycrawl.tools.checkstyle.checks.metrics.classdataabstractioncoupling."+ "inputs.c");
    final String[] expected=CommonUtil.EMPTY_STRING_ARRAY;
    verify(checkConfig,getPath("InputClassDataAbstractionCouplingExcludedPackagesAllIgnored.java"),expected);
  }
  @Test public void testDefaultConfiguration() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(ClassDataAbstractionCouplingCheck.class);
    createChecker(checkConfig);
    final String[] expected=CommonUtil.EMPTY_STRING_ARRAY;
    verify(checkConfig,getPath("InputClassDataAbstractionCoupling.java"),expected);
  }
  @Test public void testWrongToken(){
    final ClassDataAbstractionCouplingCheck classDataAbstractionCouplingCheckObj=new ClassDataAbstractionCouplingCheck();
    final DetailAST ast=new DetailAST();
    ast.initialize(new CommonHiddenStreamToken(TokenTypes.CTOR_DEF,"ctor"));
    try {
      classDataAbstractionCouplingCheckObj.visitToken(ast);
      fail("exception expected");
    }
 catch (    IllegalArgumentException ex) {
      assertEquals("Invalid exception message","Unknown type: ctor[0x-1]",ex.getMessage());
    }
  }
  @Test public void testRegularExpression() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(ClassDataAbstractionCouplingCheck.class);
    checkConfig.addAttribute("max","0");
    checkConfig.addAttribute("excludedClasses","InnerClass");
    checkConfig.addAttribute("excludeClassesRegexps","^Hash.*");
    final String[] expected={"6:1: " + getCheckMessage(MSG_KEY,2,0,"[AnotherInnerClass, int]"),"7:5: " + getCheckMessage(MSG_KEY,1,0,"[ArrayList]")};
    verify(checkConfig,getPath("InputClassDataAbstractionCoupling.java"),expected);
  }
  @Test public void testEmptyRegularExpression() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(ClassDataAbstractionCouplingCheck.class);
    checkConfig.addAttribute("max","0");
    checkConfig.addAttribute("excludedClasses","InnerClass");
    checkConfig.addAttribute("excludeClassesRegexps","");
    final String[] expected={"6:1: " + getCheckMessage(MSG_KEY,4,0,"[AnotherInnerClass, HashMap, HashSet, int]"),"7:5: " + getCheckMessage(MSG_KEY,1,0,"[ArrayList]"),"27:1: " + getCheckMessage(MSG_KEY,2,0,"[HashMap, HashSet]")};
    verify(checkConfig,getPath("InputClassDataAbstractionCoupling.java"),expected);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.puppycrawl.tools.checkstyle.checks;
import static com.puppycrawl.tools.checkstyle.checks.ArrayTypeStyleCheck.MSG_KEY;
import static org.junit.Assert.assertArrayEquals;
import static org.junit.Assert.assertEquals;
import org.junit.Test;
import com.puppycrawl.tools.checkstyle.AbstractModuleTestSupport;
import com.puppycrawl.tools.checkstyle.DefaultConfiguration;
import com.puppycrawl.tools.checkstyle.api.TokenTypes;
public class ArrayTypeStyleCheckTest extends AbstractModuleTestSupport {
  @Override protected String getPackageLocation(){
    return "com/puppycrawl/tools/checkstyle/checks/arraytypestyle";
  }
  @Test public void testGetRequiredTokens(){
    final ArrayTypeStyleCheck checkObj=new ArrayTypeStyleCheck();
    final int[] expected={TokenTypes.ARRAY_DECLARATOR};
    assertArrayEquals("Required tokens differs from expected",expected,checkObj.getRequiredTokens());
  }
  @Test public void testJavaStyleOn() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(ArrayTypeStyleCheck.class);
    final String[] expected={"14:23: " + getCheckMessage(MSG_KEY),"15:18: " + getCheckMessage(MSG_KEY),"21:44: " + getCheckMessage(MSG_KEY)};
    verify(checkConfig,getPath("InputArrayTypeStyle.java"),expected);
  }
  @Test public void testJavaStyleOff() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(ArrayTypeStyleCheck.class);
    checkConfig.addAttribute("javaStyle","false");
    final String[] expected={"13:16: " + getCheckMessage(MSG_KEY),"17:39: " + getCheckMessage(MSG_KEY),"23:18: " + getCheckMessage(MSG_KEY),"31:20: " + getCheckMessage(MSG_KEY)};
    verify(checkConfig,getPath("InputArrayTypeStyle.java"),expected);
  }
  @Test public void testGetAcceptableTokens(){
    final int[] expected={TokenTypes.ARRAY_DECLARATOR};
    final ArrayTypeStyleCheck check=new ArrayTypeStyleCheck();
    final int[] actual=check.getAcceptableTokens();
    assertEquals("Amount of acceptable tokens differs from expected",1,actual.length);
    assertArrayEquals("Acceptable tokens differs from expected",expected,actual);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.puppycrawl.tools.checkstyle.checks.indentation;
import static org.junit.Assert.assertEquals;
import org.junit.Test;
public class LineSetTest {
  @Test public void testToStringShowingFirstAndLastLine(){
    final LineSet lineSet=new LineSet();
    lineSet.addLineAndCol(0,1);
    lineSet.addLineAndCol(2,3);
    final String result=lineSet.toString();
    assertEquals("Invalid toString result","LineSet[firstLine=0, lastLine=2]",result);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.puppycrawl.tools.checkstyle.checks.whitespace;
import static com.puppycrawl.tools.checkstyle.checks.whitespace.SeparatorWrapCheck.MSG_LINE_NEW;
import static com.puppycrawl.tools.checkstyle.checks.whitespace.SeparatorWrapCheck.MSG_LINE_PREVIOUS;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import org.junit.Assert;
import org.junit.Test;
import com.puppycrawl.tools.checkstyle.AbstractModuleTestSupport;
import com.puppycrawl.tools.checkstyle.DefaultConfiguration;
import com.puppycrawl.tools.checkstyle.api.CheckstyleException;
import com.puppycrawl.tools.checkstyle.api.TokenTypes;
import com.puppycrawl.tools.checkstyle.utils.CommonUtil;
public class SeparatorWrapCheckTest extends AbstractModuleTestSupport {
  @Override protected String getPackageLocation(){
    return "com/puppycrawl/tools/checkstyle/checks/whitespace/separatorwrap";
  }
  @Test public void testDot() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(SeparatorWrapCheck.class);
    checkConfig.addAttribute("option","NL");
    checkConfig.addAttribute("tokens","DOT");
    final String[] expected={"31:10: " + getCheckMessage(MSG_LINE_NEW,".")};
    verify(checkConfig,getPath("InputSeparatorWrapForTestDot.java"),expected);
  }
  @Test public void testComma() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(SeparatorWrapCheck.class);
    checkConfig.addAttribute("option","EOL");
    checkConfig.addAttribute("tokens","COMMA");
    final String[] expected={"39:17: " + getCheckMessage(MSG_LINE_PREVIOUS,",")};
    verify(checkConfig,getPath("InputSeparatorWrapForTestComma.java"),expected);
  }
  @Test public void testMethodRef() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(SeparatorWrapCheck.class);
    checkConfig.addAttribute("option","NL");
    checkConfig.addAttribute("tokens","METHOD_REF");
    final String[] expected={"17:56: " + getCheckMessage(MSG_LINE_NEW,"::")};
    verify(checkConfig,getPath("InputSeparatorWrapForTestMethodRef.java"),expected);
  }
  @Test public void testGetDefaultTokens(){
    final SeparatorWrapCheck separatorWrapCheckObj=new SeparatorWrapCheck();
    final int[] actual=separatorWrapCheckObj.getDefaultTokens();
    final int[] expected={TokenTypes.DOT,TokenTypes.COMMA};
    Assert.assertArrayEquals("Invalid default tokens",expected,actual);
  }
  @Test public void testInvalidOption() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(SeparatorWrapCheck.class);
    checkConfig.addAttribute("option","invalid_option");
    try {
      final String[] expected=CommonUtil.EMPTY_STRING_ARRAY;
      verify(checkConfig,getPath("InputSeparatorWrapForInvalidOption.java"),expected);
      fail("exception expected");
    }
 catch (    CheckstyleException ex) {
      final String messageStart="cannot initialize module " + "com.puppycrawl.tools.checkstyle.TreeWalker - Cannot set property 'option' to " + "'invalid_option' in module";
      assertTrue("Invalid exception message, should start with: " + messageStart,ex.getMessage().startsWith(messageStart));
    }
  }
  @Test public void testEllipsis() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(SeparatorWrapCheck.class);
    checkConfig.addAttribute("option","EOL");
    checkConfig.addAttribute("tokens","ELLIPSIS");
    final String[] expected={"11:13: " + getCheckMessage(MSG_LINE_PREVIOUS,"...")};
    verify(checkConfig,getPath("InputSeparatorWrapForEllipsis.java"),expected);
  }
  @Test public void testArrayDeclarator() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(SeparatorWrapCheck.class);
    checkConfig.addAttribute("option","EOL");
    checkConfig.addAttribute("tokens","ARRAY_DECLARATOR");
    final String[] expected={"9:13: " + getCheckMessage(MSG_LINE_PREVIOUS,"[")};
    verify(checkConfig,getPath("InputSeparatorWrapForArrayDeclarator.java"),expected);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.puppycrawl.tools.checkstyle.checks.whitespace;
import static com.puppycrawl.tools.checkstyle.checks.whitespace.EmptyForInitializerPadCheck.MSG_NOT_PRECEDED;
import static com.puppycrawl.tools.checkstyle.checks.whitespace.EmptyForInitializerPadCheck.MSG_PRECEDED;
import static org.junit.Assert.assertArrayEquals;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import org.junit.Test;
import com.puppycrawl.tools.checkstyle.AbstractModuleTestSupport;
import com.puppycrawl.tools.checkstyle.DefaultConfiguration;
import com.puppycrawl.tools.checkstyle.api.CheckstyleException;
import com.puppycrawl.tools.checkstyle.api.TokenTypes;
import com.puppycrawl.tools.checkstyle.utils.CommonUtil;
public class EmptyForInitializerPadCheckTest extends AbstractModuleTestSupport {
  @Override protected String getPackageLocation(){
    return "com/puppycrawl/tools/checkstyle/checks/whitespace/emptyforinitializerpad";
  }
  @Test public void testGetRequiredTokens(){
    final EmptyForInitializerPadCheck checkObj=new EmptyForInitializerPadCheck();
    final int[] expected={TokenTypes.FOR_INIT};
    assertArrayEquals("Default required tokens are invalid",expected,checkObj.getRequiredTokens());
  }
  @Test public void testDefault() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(EmptyForInitializerPadCheck.class);
    final String[] expected={"48:14: " + getCheckMessage(MSG_PRECEDED,";")};
    verify(checkConfig,getPath("InputEmptyForInitializerPadDefaultConfig.java"),expected);
  }
  @Test public void testSpaceOption() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(EmptyForInitializerPadCheck.class);
    checkConfig.addAttribute("option",PadOption.SPACE.toString());
    final String[] expected={"51:13: " + getCheckMessage(MSG_NOT_PRECEDED,";")};
    verify(checkConfig,getPath("InputEmptyForInitializerPad.java"),expected);
  }
  @Test public void testGetAcceptableTokens(){
    final EmptyForInitializerPadCheck emptyForInitializerPadCheckObj=new EmptyForInitializerPadCheck();
    final int[] actual=emptyForInitializerPadCheckObj.getAcceptableTokens();
    final int[] expected={TokenTypes.FOR_INIT};
    assertArrayEquals("Default acceptable tokens are invalid",expected,actual);
  }
  @Test public void testPadOptionValueOf(){
    final PadOption option=PadOption.valueOf("NOSPACE");
    assertEquals("Result of valueOf is invalid",PadOption.NOSPACE,option);
  }
  @Test public void testWrapOptionValueOf(){
    final WrapOption option=WrapOption.valueOf("EOL");
    assertEquals("Result of valueOf is invalid",WrapOption.EOL,option);
  }
  @Test public void testInvalidOption() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(EmptyForInitializerPadCheck.class);
    checkConfig.addAttribute("option","invalid_option");
    try {
      final String[] expected=CommonUtil.EMPTY_STRING_ARRAY;
      verify(checkConfig,getPath("InputEmptyForInitializerPad.java"),expected);
      fail("exception expected");
    }
 catch (    CheckstyleException ex) {
      final String messageStart="cannot initialize module " + "com.puppycrawl.tools.checkstyle.TreeWalker - Cannot set property 'option' to " + "'invalid_option' in module";
      assertTrue("Invalid exception message, should start with: ",ex.getMessage().startsWith(messageStart));
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.puppycrawl.tools.checkstyle.checks.coding;
import static com.puppycrawl.tools.checkstyle.checks.coding.IllegalInstantiationCheck.MSG_KEY;
import java.io.File;
import java.nio.charset.StandardCharsets;
import java.util.SortedSet;
import org.junit.Assert;
import org.junit.Test;
import com.puppycrawl.tools.checkstyle.AbstractModuleTestSupport;
import com.puppycrawl.tools.checkstyle.DefaultConfiguration;
import com.puppycrawl.tools.checkstyle.api.DetailAST;
import com.puppycrawl.tools.checkstyle.api.FileContents;
import com.puppycrawl.tools.checkstyle.api.FileText;
import com.puppycrawl.tools.checkstyle.api.LocalizedMessage;
import com.puppycrawl.tools.checkstyle.api.TokenTypes;
import com.puppycrawl.tools.checkstyle.utils.CommonUtil;
public class IllegalInstantiationCheckTest extends AbstractModuleTestSupport {
  @Override protected String getPackageLocation(){
    return "com/puppycrawl/tools/checkstyle/checks/coding/illegalinstantiation";
  }
  @Test public void testDefault() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(IllegalInstantiationCheck.class);
    checkConfig.addAttribute("classes","java.lang.Boolean," + "com.puppycrawl.tools.checkstyle.checks.coding." + "illegalinstantiation.InputModifier,"+ "java.io.File,"+ "java.awt.Color");
    final String[] expected={"19:21: " + getCheckMessage(MSG_KEY,"java.lang.Boolean"),"24:21: " + getCheckMessage(MSG_KEY,"java.lang.Boolean"),"31:16: " + getCheckMessage(MSG_KEY,"java.lang.Boolean"),"38:21: " + getCheckMessage(MSG_KEY,"com.puppycrawl.tools.checkstyle.checks.coding." + "illegalinstantiation.InputModifier"),"41:18: " + getCheckMessage(MSG_KEY,"java.io.File"),"44:21: " + getCheckMessage(MSG_KEY,"java.awt.Color")};
    verify(checkConfig,getPath("InputIllegalInstantiationSemantic.java"),expected);
  }
  @Test public void testJava8() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(IllegalInstantiationCheck.class);
    final String[] expected=CommonUtil.EMPTY_STRING_ARRAY;
    verify(checkConfig,getPath("InputIllegalInstantiation.java"),expected);
  }
  @Test public void testNoPackage() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(IllegalInstantiationCheck.class);
    checkConfig.addAttribute("classes","java.lang.Boolean");
    final String[] expected={"3:20: " + getCheckMessage(MSG_KEY,"java.lang.Boolean")};
    verify(checkConfig,getNonCompilablePath("InputIllegalInstantiationNoPackage.java"),expected);
  }
  @Test public void testJavaLangPackage() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(IllegalInstantiationCheck.class);
    checkConfig.addAttribute("classes","java.lang.Boolean,java.lang.String");
    final String[] expected={"5:19: " + getCheckMessage(MSG_KEY,"java.lang.Boolean"),"13:20: " + getCheckMessage(MSG_KEY,"java.lang.String")};
    verify(checkConfig,getNonCompilablePath("InputIllegalInstantiationLang.java"),expected);
  }
  @Test public void testWrongPackage() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(IllegalInstantiationCheck.class);
    checkConfig.addAttribute("classes","jjva.lang.Boolean,java.lang*Boolean");
    final String[] expected=CommonUtil.EMPTY_STRING_ARRAY;
    verify(checkConfig,getNonCompilablePath("InputIllegalInstantiationLang.java"),expected);
  }
  @Test public void testNullClassLoader() throws Exception {
    final DetailAST exprAst=new DetailAST();
    exprAst.setType(TokenTypes.EXPR);
    final DetailAST newAst=new DetailAST();
    newAst.setType(TokenTypes.LITERAL_NEW);
    newAst.setLineNo(1);
    newAst.setColumnNo(1);
    final DetailAST identAst=new DetailAST();
    identAst.setType(TokenTypes.IDENT);
    identAst.setText("Boolean");
    final DetailAST lparenAst=new DetailAST();
    lparenAst.setType(TokenTypes.LPAREN);
    final DetailAST elistAst=new DetailAST();
    elistAst.setType(TokenTypes.ELIST);
    final DetailAST rparenAst=new DetailAST();
    rparenAst.setType(TokenTypes.RPAREN);
    exprAst.addChild(newAst);
    newAst.addChild(identAst);
    identAst.setNextSibling(lparenAst);
    lparenAst.setNextSibling(elistAst);
    elistAst.setNextSibling(rparenAst);
    final IllegalInstantiationCheck check=new IllegalInstantiationCheck();
    final File inputFile=new File(getNonCompilablePath("InputIllegalInstantiationLang.java"));
    check.setFileContents(new FileContents(new FileText(inputFile,StandardCharsets.UTF_8.name())));
    check.configure(createModuleConfig(IllegalInstantiationCheck.class));
    check.setClasses("java.lang.Boolean");
    check.visitToken(newAst);
    final SortedSet<LocalizedMessage> messages1=check.getMessages();
    Assert.assertEquals("No exception messages expected",0,messages1.size());
    check.finishTree(newAst);
    final SortedSet<LocalizedMessage> messages2=check.getMessages();
    final LocalizedMessage addExceptionMessage=new LocalizedMessage(1,"com.puppycrawl.tools.checkstyle.checks.coding.messages","instantiation.avoid",new String[]{"java.lang.Boolean"},null,getClass(),null);
    Assert.assertEquals("Invalid exception message",addExceptionMessage.getMessage(),messages2.first().getMessage());
  }
  @Test public void testTokensNotNull(){
    final IllegalInstantiationCheck check=new IllegalInstantiationCheck();
    Assert.assertNotNull("Acceptable tokens should not be null",check.getAcceptableTokens());
    Assert.assertNotNull("Default tokens should not be null",check.getDefaultTokens());
    Assert.assertNotNull("Required tokens should not be null",check.getRequiredTokens());
  }
  @Test public void testImproperToken(){
    final IllegalInstantiationCheck check=new IllegalInstantiationCheck();
    final DetailAST lambdaAst=new DetailAST();
    lambdaAst.setType(TokenTypes.LAMBDA);
    try {
      check.visitToken(lambdaAst);
      Assert.fail("IllegalArgumentException is expected");
    }
 catch (    IllegalArgumentException ex) {
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.puppycrawl.tools.checkstyle.checks.coding;
import static com.puppycrawl.tools.checkstyle.checks.coding.IllegalTokenTextCheck.MSG_KEY;
import java.util.Arrays;
import java.util.List;
import java.util.regex.Pattern;
import org.junit.Assert;
import org.junit.Test;
import com.puppycrawl.tools.checkstyle.AbstractModuleTestSupport;
import com.puppycrawl.tools.checkstyle.DefaultConfiguration;
import com.puppycrawl.tools.checkstyle.api.TokenTypes;
import com.puppycrawl.tools.checkstyle.internal.utils.TestUtil;
import com.puppycrawl.tools.checkstyle.utils.TokenUtil;
public class IllegalTokenTextCheckTest extends AbstractModuleTestSupport {
  @Override protected String getPackageLocation(){
    return "com/puppycrawl/tools/checkstyle/checks/coding/illegaltokentext";
  }
  @Test public void testCaseSensitive() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(IllegalTokenTextCheck.class);
    checkConfig.addAttribute("tokens","STRING_LITERAL");
    checkConfig.addAttribute("format","a href");
    checkConfig.addAttribute("ignoreCase","false");
    final String[] expected={"24:28: " + getCheckMessage(MSG_KEY,"a href")};
    verify(checkConfig,getPath("InputIllegalTokenTextTokens.java"),expected);
  }
  @Test public void testCaseInSensitive() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(IllegalTokenTextCheck.class);
    checkConfig.addAttribute("tokens","STRING_LITERAL");
    checkConfig.addAttribute("format","a href");
    checkConfig.addAttribute("ignoreCase","true");
    final String[] expected={"24:28: " + getCheckMessage(MSG_KEY,"a href"),"25:32: " + getCheckMessage(MSG_KEY,"a href")};
    verify(checkConfig,getPath("InputIllegalTokenTextTokens.java"),expected);
  }
  @Test public void testCustomMessage() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(IllegalTokenTextCheck.class);
    checkConfig.addAttribute("tokens","STRING_LITERAL");
    checkConfig.addAttribute("format","a href");
    checkConfig.addAttribute("message","My custom message");
    final String[] expected={"24:28: " + "My custom message"};
    verify(checkConfig,getPath("InputIllegalTokenTextTokens.java"),expected);
  }
  @Test public void testNullCustomMessage() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(IllegalTokenTextCheck.class);
    checkConfig.addAttribute("tokens","STRING_LITERAL");
    checkConfig.addAttribute("format","a href");
    checkConfig.addAttribute("message",null);
    final String[] expected={"24:28: " + getCheckMessage(MSG_KEY,"a href")};
    verify(checkConfig,getPath("InputIllegalTokenTextTokens.java"),expected);
  }
  @Test public void testTokensNotNull(){
    final IllegalTokenTextCheck check=new IllegalTokenTextCheck();
    Assert.assertNotNull("Acceptable tokens should not be null",check.getAcceptableTokens());
    Assert.assertNotNull("Default tokens should not be null",check.getDefaultTokens());
    Assert.assertNotNull("Required tokens should not be null",check.getRequiredTokens());
    Assert.assertTrue("Comments are also TokenType token",check.isCommentNodesRequired());
  }
  @Test public void testCommentToken() throws Exception {
    final DefaultConfiguration checkConfig=createModuleConfig(IllegalTokenTextCheck.class);
    checkConfig.addAttribute("tokens","COMMENT_CONTENT");
    checkConfig.addAttribute("format","a href");
    checkConfig.addAttribute("message",null);
    final String[] expected={"35:28: " + getCheckMessage(MSG_KEY,"a href")};
    verify(checkConfig,getPath("InputIllegalTokenTextTokens.java"),expected);
  }
  @Test public void testOrderOfProperties() throws Exception {
    final IllegalTokenTextCheck check=new IllegalTokenTextCheck();
    check.setFormat("test");
    check.setIgnoreCase(true);
    final Pattern actual=(Pattern)TestUtil.getClassDeclaredField(IllegalTokenTextCheck.class,"format").get(check);
    Assert.assertEquals("should match",Pattern.CASE_INSENSITIVE,actual.flags());
    Assert.assertEquals("should match","test",actual.pattern());
  }
  @Test public void testAcceptableTokensMakeSense(){
    final int expectedTokenTypesTotalNumber=169;
    Assert.assertEquals("Total number of TokenTypes has changed, acceptable tokens in" + " IllegalTokenTextCheck need to be reconsidered.",expectedTokenTypesTotalNumber,TokenUtil.getTokenTypesTotalNumber());
    final IllegalTokenTextCheck check=new IllegalTokenTextCheck();
    final int[] allowedTokens=check.getAcceptableTokens();
    final List<Integer> tokenTypesWithMutableText=Arrays.asList(TokenTypes.NUM_DOUBLE,TokenTypes.NUM_FLOAT,TokenTypes.NUM_INT,TokenTypes.NUM_LONG,TokenTypes.IDENT,TokenTypes.COMMENT_CONTENT,TokenTypes.STRING_LITERAL,TokenTypes.CHAR_LITERAL);
    for (    int tokenType : allowedTokens) {
      Assert.assertTrue(TokenUtil.getTokenName(tokenType) + " should not be allowed" + " in this check as its text is a constant (IllegalTokenCheck should be used for"+ " such cases).",tokenTypesWithMutableText.contains(tokenType));
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.puppycrawl.tools.checkstyle.checks.javadoc;
import static org.junit.Assert.assertArrayEquals;
import static org.junit.Assert.assertEquals;
import org.junit.Test;
import com.puppycrawl.tools.checkstyle.utils.JavadocUtil;
public class JavadocTagTest {
  @Test public void testJavadocTagTypeValueOf(){
    final JavadocUtil.JavadocTagType enumConst=JavadocUtil.JavadocTagType.valueOf("ALL");
    assertEquals("Invalid enum valueOf result",JavadocUtil.JavadocTagType.ALL,enumConst);
  }
  @Test public void testJavadocTagTypeValues(){
    final JavadocUtil.JavadocTagType[] enumConstants=JavadocUtil.JavadocTagType.values();
    final JavadocUtil.JavadocTagType[] expected={JavadocUtil.JavadocTagType.BLOCK,JavadocUtil.JavadocTagType.INLINE,JavadocUtil.JavadocTagType.ALL};
    assertArrayEquals("Invalid enum constants",expected,enumConstants);
  }
  @Test public void testToString(){
    final JavadocTag javadocTag=new JavadocTag(0,1,"author","firstArg");
    final String result=javadocTag.toString();
    assertEquals("Invalid toString result","JavadocTag[tag='author' lineNo=0, columnNo=1, firstArg='firstArg']",result);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.google.checkstyle.test.chapter7javadoc.rule731selfexplanatory;
import org.junit.Test;
import com.google.checkstyle.test.base.AbstractModuleTestSupport;
import com.puppycrawl.tools.checkstyle.api.Configuration;
import com.puppycrawl.tools.checkstyle.checks.javadoc.JavadocMethodCheck;
public class JavadocMethodTest extends AbstractModuleTestSupport {
  @Override protected String getPackageLocation(){
    return "com/google/checkstyle/test/chapter7javadoc/rule731selfexplanatory";
  }
  @Test public void testJavadocMethod() throws Exception {
    final String msg=getCheckMessage(JavadocMethodCheck.class,"javadoc.missing");
    final String[] expected={"57:5: " + msg};
    final Configuration checkConfig=getModuleConfig("JavadocMethod");
    final String filePath=getPath("InputJavadocMethodCheck.java");
    final Integer[] warnList=getLinesWithWarn(filePath);
    verify(checkConfig,filePath,expected,warnList);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.google.checkstyle.test.chapter6programpractice.rule62donotignoreexceptions;
import org.junit.Test;
import com.google.checkstyle.test.base.AbstractModuleTestSupport;
import com.puppycrawl.tools.checkstyle.api.Configuration;
import com.puppycrawl.tools.checkstyle.checks.blocks.EmptyBlockCheck;
public class EmptyBlockTest extends AbstractModuleTestSupport {
  @Override protected String getPackageLocation(){
    return "com/google/checkstyle/test/chapter6programpractice/rule62donotignoreexceptions";
  }
  @Test public void testEmptyBlockCatch() throws Exception {
    final String[] expected={"29:17: " + getCheckMessage(EmptyBlockCheck.class,"block.empty","finally"),"50:21: " + getCheckMessage(EmptyBlockCheck.class,"block.empty","finally"),"72:21: " + getCheckMessage(EmptyBlockCheck.class,"block.empty","finally")};
    final Configuration checkConfig=getModuleConfig("EmptyBlock");
    final String filePath=getPath("InputEmptyBlockCatch.java");
    final Integer[] warnList=getLinesWithWarn(filePath);
    verify(checkConfig,filePath,expected,warnList);
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from checkstyle-checkstyle-8.15~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.google.common.collect.testing.testers;
import static com.google.common.collect.testing.features.CollectionFeature.ALLOWS_NULL_QUERIES;
import static com.google.common.collect.testing.features.CollectionFeature.ALLOWS_NULL_VALUES;
import static com.google.common.collect.testing.features.CollectionSize.ZERO;
import com.google.common.annotations.GwtCompatible;
import com.google.common.collect.testing.AbstractCollectionTester;
import com.google.common.collect.testing.WrongType;
import com.google.common.collect.testing.features.CollectionFeature;
import com.google.common.collect.testing.features.CollectionSize;
import org.junit.Ignore;
/** 
 * A generic JUnit test which tests  {@code contains()} operations on a collection. Can't be invokeddirectly; please see  {@link com.google.common.collect.testing.CollectionTestSuiteBuilder}.
 * @author Kevin Bourrillion
 * @author Chris Povirk
 */
@GwtCompatible @Ignore public class CollectionContainsTester<E> extends AbstractCollectionTester<E> {
  @CollectionSize.Require(absent=ZERO) public void testContains_yes(){
    assertTrue("contains(present) should return true",collection.contains(e0()));
  }
  public void testContains_no(){
    assertFalse("contains(notPresent) should return false",collection.contains(e3()));
  }
  @CollectionFeature.Require(ALLOWS_NULL_QUERIES) public void testContains_nullNotContainedButQueriesSupported(){
    assertFalse("contains(null) should return false",collection.contains(null));
  }
  @CollectionFeature.Require(absent=ALLOWS_NULL_QUERIES) public void testContains_nullNotContainedAndUnsupported(){
    expectNullMissingWhenNullUnsupported("contains(null) should return false or throw");
  }
  @CollectionFeature.Require(ALLOWS_NULL_VALUES) @CollectionSize.Require(absent=ZERO) public void testContains_nonNullWhenNullContained(){
    initCollectionWithNullElement();
    assertFalse("contains(notPresent) should return false",collection.contains(e3()));
  }
  @CollectionFeature.Require(ALLOWS_NULL_VALUES) @CollectionSize.Require(absent=ZERO) public void testContains_nullContained(){
    initCollectionWithNullElement();
    assertTrue("contains(null) should return true",collection.contains(null));
  }
  public void testContains_wrongType(){
    try {
      assertFalse("contains(wrongType) should return false or throw",collection.contains(WrongType.VALUE));
    }
 catch (    ClassCastException tolerated) {
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.google.common.collect.testing.google;
import static com.google.common.collect.testing.Helpers.assertContentsAnyOrder;
import static com.google.common.collect.testing.features.CollectionSize.ZERO;
import static com.google.common.collect.testing.features.MapFeature.ALLOWS_NULL_KEYS;
import static com.google.common.collect.testing.features.MapFeature.ALLOWS_NULL_VALUES;
import static com.google.common.collect.testing.features.MapFeature.SUPPORTS_PUT;
import static com.google.common.collect.testing.features.MapFeature.SUPPORTS_REMOVE;
import com.google.common.annotations.GwtCompatible;
import com.google.common.collect.Multimap;
import com.google.common.collect.testing.Helpers;
import com.google.common.collect.testing.features.CollectionSize;
import com.google.common.collect.testing.features.MapFeature;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.List;
import org.junit.Ignore;
/** 
 * Tests for  {@link Multimap#replaceValues(Object,Iterable)}.
 * @author Louis Wasserman
 */
@GwtCompatible @Ignore public class MultimapReplaceValuesTester<K,V> extends AbstractMultimapTester<K,V,Multimap<K,V>> {
  @MapFeature.Require({SUPPORTS_PUT,SUPPORTS_REMOVE,ALLOWS_NULL_VALUES}) public void testReplaceValuesWithNullValue(){
    @SuppressWarnings("unchecked") List<V> values=Arrays.asList(v0(),null,v3());
    multimap().replaceValues(k0(),values);
    assertGet(k0(),values);
  }
  @MapFeature.Require({SUPPORTS_PUT,SUPPORTS_REMOVE,ALLOWS_NULL_KEYS}) public void testReplaceValuesWithNullKey(){
    @SuppressWarnings("unchecked") List<V> values=Arrays.asList(v0(),v2(),v3());
    multimap().replaceValues(null,values);
    assertGet(null,values);
  }
  @MapFeature.Require({SUPPORTS_PUT,SUPPORTS_REMOVE}) public void testReplaceEmptyValues(){
    int size=multimap().size();
    @SuppressWarnings("unchecked") List<V> values=Arrays.asList(v0(),v2(),v3());
    multimap().replaceValues(k3(),values);
    assertGet(k3(),values);
    assertEquals(size + values.size(),multimap().size());
  }
  @MapFeature.Require({SUPPORTS_PUT,SUPPORTS_REMOVE}) public void testReplaceValuesWithEmpty(){
    int size=multimap().size();
    List<V> oldValues=new ArrayList<>(multimap().get(k0()));
    @SuppressWarnings("unchecked") List<V> values=Collections.emptyList();
    assertEquals(oldValues,new ArrayList<V>(multimap().replaceValues(k0(),values)));
    assertGet(k0());
    assertEquals(size - oldValues.size(),multimap().size());
  }
  @MapFeature.Require({SUPPORTS_PUT,SUPPORTS_REMOVE}) public void testReplaceValuesWithDuplicates(){
    int size=multimap().size();
    List<V> oldValues=new ArrayList<>(multimap().get(k0()));
    List<V> values=Arrays.asList(v0(),v3(),v0());
    assertEquals(oldValues,new ArrayList<V>(multimap().replaceValues(k0(),values)));
    assertEquals(size - oldValues.size() + multimap().get(k0()).size(),multimap().size());
    assertTrue(multimap().get(k0()).containsAll(values));
  }
  @CollectionSize.Require(absent=ZERO) @MapFeature.Require({SUPPORTS_PUT,SUPPORTS_REMOVE}) public void testReplaceNonEmptyValues(){
    List<K> keys=Helpers.copyToList(multimap().keySet());
    @SuppressWarnings("unchecked") List<V> values=Arrays.asList(v0(),v2(),v3());
    for (    K k : keys) {
      resetContainer();
      int size=multimap().size();
      Collection<V> oldKeyValues=Helpers.copyToList(multimap().get(k));
      multimap().replaceValues(k,values);
      assertGet(k,values);
      assertEquals(size + values.size() - oldKeyValues.size(),multimap().size());
    }
  }
  @MapFeature.Require({SUPPORTS_PUT,SUPPORTS_REMOVE}) public void testReplaceValuesPropagatesToGet(){
    Collection<V> getCollection=multimap().get(k0());
    @SuppressWarnings("unchecked") List<V> values=Arrays.asList(v0(),v2(),v3());
    multimap().replaceValues(k0(),values);
    assertContentsAnyOrder(getCollection,v0(),v2(),v3());
  }
  @MapFeature.Require(absent=SUPPORTS_REMOVE) @CollectionSize.Require(absent=ZERO) public void testReplaceValuesRemoveNotSupported(){
    List<V> values=Collections.singletonList(v3());
    try {
      multimap().replaceValues(k0(),values);
      fail("Expected UnsupportedOperationException");
    }
 catch (    UnsupportedOperationException expected) {
    }
  }
  @MapFeature.Require(absent=SUPPORTS_PUT) public void testReplaceValuesPutNotSupported(){
    List<V> values=Collections.singletonList(v3());
    try {
      multimap().replaceValues(k0(),values);
      fail("Expected UnsupportedOperationException");
    }
 catch (    UnsupportedOperationException expected) {
    }
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from guava-27.0.1~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.server.timelineservice.reader;
import static org.junit.Assert.assertEquals;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.service.Service.STATE;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
import org.apache.hadoop.yarn.server.timelineservice.storage.FileSystemTimelineReaderImpl;
import org.apache.hadoop.yarn.server.timelineservice.storage.TimelineReader;
import org.junit.Test;
public class TestTimelineReaderServer {
  @Test(timeout=60000) public void testStartStopServer() throws Exception {
    @SuppressWarnings("resource") TimelineReaderServer server=new TimelineReaderServer();
    Configuration config=new YarnConfiguration();
    config.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,true);
    config.setFloat(YarnConfiguration.TIMELINE_SERVICE_VERSION,2.0f);
    config.set(YarnConfiguration.TIMELINE_SERVICE_READER_WEBAPP_ADDRESS,"localhost:0");
    config.setClass(YarnConfiguration.TIMELINE_SERVICE_READER_CLASS,FileSystemTimelineReaderImpl.class,TimelineReader.class);
    try {
      server.init(config);
      assertEquals(STATE.INITED,server.getServiceState());
      assertEquals(2,server.getServices().size());
      server.start();
      assertEquals(STATE.STARTED,server.getServiceState());
      server.stop();
      assertEquals(STATE.STOPPED,server.getServiceState());
    }
  finally {
      server.stop();
    }
  }
  @Test(timeout=60000,expected=YarnRuntimeException.class) public void testTimelineReaderServerWithInvalidTimelineReader(){
    Configuration conf=new YarnConfiguration();
    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,true);
    conf.setFloat(YarnConfiguration.TIMELINE_SERVICE_VERSION,2.0f);
    conf.set(YarnConfiguration.TIMELINE_SERVICE_READER_WEBAPP_ADDRESS,"localhost:0");
    conf.set(YarnConfiguration.TIMELINE_SERVICE_READER_CLASS,Object.class.getName());
    runTimelineReaderServerWithConfig(conf);
  }
  @Test(timeout=60000,expected=YarnRuntimeException.class) public void testTimelineReaderServerWithNonexistentTimelineReader(){
    String nonexistentTimelineReaderClass="org.apache.org.yarn.server." + "timelineservice.storage.XXXXXXXX";
    Configuration conf=new YarnConfiguration();
    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED,true);
    conf.setFloat(YarnConfiguration.TIMELINE_SERVICE_VERSION,2.0f);
    conf.set(YarnConfiguration.TIMELINE_SERVICE_READER_WEBAPP_ADDRESS,"localhost:0");
    conf.set(YarnConfiguration.TIMELINE_SERVICE_READER_CLASS,nonexistentTimelineReaderClass);
    runTimelineReaderServerWithConfig(conf);
  }
  /** 
 * Run a TimelineReaderServer with a given configuration.
 * @param conf configuration to run TimelineReaderServer with
 */
  private static void runTimelineReaderServerWithConfig(  final Configuration conf){
    TimelineReaderServer server=new TimelineReaderServer();
    try {
      server.init(conf);
      server.start();
    }
  finally {
      server.stop();
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.webapp;
import com.google.inject.Guice;
import com.google.inject.servlet.ServletModule;
import com.sun.jersey.api.client.ClientResponse;
import com.sun.jersey.api.client.WebResource;
import com.sun.jersey.guice.spi.container.servlet.GuiceContainer;
import com.sun.jersey.test.framework.WebAppDescriptor;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.security.http.XFrameOptionsFilter;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
import org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler;
import org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices;
import org.junit.Before;
import org.junit.Test;
import java.util.HashMap;
import java.util.Map;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
/** 
 * Used TestRMWebServices as an example of web invocations of RM and added test for XFS Filter.
 */
public class TestRMWithXFSFilter extends JerseyTestBase {
  private static MockRM rm;
  @Before @Override public void setUp() throws Exception {
    super.setUp();
  }
  public TestRMWithXFSFilter(){
    super(new WebAppDescriptor.Builder("org.apache.hadoop.yarn.server.resourcemanager.webapp").contextListenerClass(GuiceServletConfig.class).filterClass(com.google.inject.servlet.GuiceFilter.class).contextPath("jersey-guice-filter").servletPath("/").build());
  }
  @Test public void testDefaultBehavior() throws Exception {
    createInjector();
    WebResource r=resource();
    ClientResponse response=r.path("ws").path("v1").path("cluster").path("info").accept("application/xml").get(ClientResponse.class);
    assertEquals("Should have received DENY x-frame options header","DENY",response.getHeaders().get(XFrameOptionsFilter.X_FRAME_OPTIONS).get(0));
  }
  protected void createInjector(  String headerValue){
    createInjector(headerValue,false);
  }
  protected void createInjector(){
    createInjector(null,false);
  }
  protected void createInjector(  final String headerValue,  final boolean explicitlyDisabled){
    GuiceServletConfig.setInjector(Guice.createInjector(new ServletModule(){
      @Override protected void configureServlets(){
        bind(JAXBContextResolver.class);
        bind(RMWebServices.class);
        bind(GenericExceptionHandler.class);
        Configuration conf=new Configuration();
        conf.setClass(YarnConfiguration.RM_SCHEDULER,FifoScheduler.class,ResourceScheduler.class);
        rm=new MockRM(conf);
        bind(ResourceManager.class).toInstance(rm);
        serve("/*").with(GuiceContainer.class);
        XFrameOptionsFilter xfsFilter=new XFrameOptionsFilter();
        Map<String,String> initParams=new HashMap<>();
        if (headerValue != null) {
          initParams.put(XFrameOptionsFilter.CUSTOM_HEADER_PARAM,headerValue);
        }
        if (explicitlyDisabled) {
          initParams.put("xframe-options-enabled","false");
        }
        filter("/*").through(xfsFilter,initParams);
      }
    }
));
  }
  @Test public void testSameOrigin() throws Exception {
    createInjector("SAMEORIGIN");
    WebResource r=resource();
    ClientResponse response=r.path("ws").path("v1").path("cluster").path("info").accept("application/xml").get(ClientResponse.class);
    assertEquals("Should have received SAMEORIGIN x-frame options header","SAMEORIGIN",response.getHeaders().get(XFrameOptionsFilter.X_FRAME_OPTIONS).get(0));
  }
  @Test public void testExplicitlyDisabled() throws Exception {
    createInjector(null,true);
    WebResource r=resource();
    ClientResponse response=r.path("ws").path("v1").path("cluster").path("info").accept("application/xml").get(ClientResponse.class);
    assertFalse("Should have not received x-frame options header",response.getHeaders().get(XFrameOptionsFilter.X_FRAME_OPTIONS) == null);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.server.resourcemanager.recovery;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.curator.test.TestingServer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.CommonConfigurationKeys;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
import org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreTestBase.TestDispatcher;
import org.apache.hadoop.util.ZKUtil;
import org.apache.zookeeper.server.auth.DigestAuthenticationProvider;
import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;
import java.security.NoSuchAlgorithmException;
import java.util.concurrent.atomic.AtomicBoolean;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
public class TestZKRMStateStoreZKClientConnections {
  private Log LOG=LogFactory.getLog(TestZKRMStateStoreZKClientConnections.class);
  private static final int ZK_TIMEOUT_MS=1000;
  private static final String DIGEST_USER_PASS="test-user:test-password";
  private static final String TEST_AUTH_GOOD="digest:" + DIGEST_USER_PASS;
  private static final String DIGEST_USER_HASH;
static {
    try {
      DIGEST_USER_HASH=DigestAuthenticationProvider.generateDigest(DIGEST_USER_PASS);
    }
 catch (    NoSuchAlgorithmException e) {
      throw new RuntimeException(e);
    }
  }
  private static final String TEST_ACL="digest:" + DIGEST_USER_HASH + ":rwcda";
  private TestingServer testingServer;
  @Before public void setupZKServer() throws Exception {
    testingServer=new TestingServer();
    testingServer.start();
  }
  @After public void cleanupZKServer() throws Exception {
    testingServer.stop();
  }
class TestZKClient {
    ZKRMStateStore store;
protected class TestZKRMStateStore extends ZKRMStateStore {
      public TestZKRMStateStore(      Configuration conf,      String workingZnode) throws Exception {
        setResourceManager(new ResourceManager());
        init(conf);
        start();
        assertTrue(znodeWorkingPath.equals(workingZnode));
      }
    }
    public RMStateStore getRMStateStore(    Configuration conf) throws Exception {
      String workingZnode="/Test";
      conf.set(CommonConfigurationKeys.ZK_ADDRESS,testingServer.getConnectString());
      conf.set(YarnConfiguration.ZK_RM_STATE_STORE_PARENT_PATH,workingZnode);
      this.store=new TestZKRMStateStore(conf,workingZnode);
      return this.store;
    }
  }
  @Test(timeout=20000) public void testZKClientRetry() throws Exception {
    TestZKClient zkClientTester=new TestZKClient();
    final String path="/test";
    YarnConfiguration conf=new YarnConfiguration();
    conf.setInt(CommonConfigurationKeys.ZK_TIMEOUT_MS,ZK_TIMEOUT_MS);
    conf.setLong(CommonConfigurationKeys.ZK_RETRY_INTERVAL_MS,100);
    final ZKRMStateStore store=(ZKRMStateStore)zkClientTester.getRMStateStore(conf);
    TestDispatcher dispatcher=new TestDispatcher();
    store.setRMDispatcher(dispatcher);
    final AtomicBoolean assertionFailedInThread=new AtomicBoolean(false);
    testingServer.stop();
    Thread clientThread=new Thread(){
      @Override public void run(){
        try {
          store.getData(path);
        }
 catch (        Exception e) {
          e.printStackTrace();
          assertionFailedInThread.set(true);
        }
      }
    }
;
    Thread.sleep(2000);
    testingServer.start();
    clientThread.join();
    Assert.assertFalse(assertionFailedInThread.get());
  }
  @Test(timeout=20000) public void testSetZKAcl(){
    TestZKClient zkClientTester=new TestZKClient();
    YarnConfiguration conf=new YarnConfiguration();
    conf.set(CommonConfigurationKeys.ZK_ACL,"world:anyone:rwca");
    try {
      zkClientTester.store.delete(zkClientTester.store.znodeWorkingPath);
      fail("Shouldn't be able to delete path");
    }
 catch (    Exception e) {
    }
  }
  @Test(timeout=20000) public void testInvalidZKAclConfiguration(){
    TestZKClient zkClientTester=new TestZKClient();
    YarnConfiguration conf=new YarnConfiguration();
    conf.set(CommonConfigurationKeys.ZK_ACL,"randomstring&*");
    try {
      zkClientTester.getRMStateStore(conf);
      fail("ZKRMStateStore created with bad ACL");
    }
 catch (    ZKUtil.BadAclFormatException bafe) {
    }
catch (    Exception e) {
      String error="Incorrect exception on BadAclFormat";
      LOG.error(error,e);
      fail(error);
    }
  }
  @Test public void testZKAuths() throws Exception {
    TestZKClient zkClientTester=new TestZKClient();
    YarnConfiguration conf=new YarnConfiguration();
    conf.setInt(CommonConfigurationKeys.ZK_NUM_RETRIES,1);
    conf.setInt(CommonConfigurationKeys.ZK_TIMEOUT_MS,ZK_TIMEOUT_MS);
    conf.set(CommonConfigurationKeys.ZK_ACL,TEST_ACL);
    conf.set(CommonConfigurationKeys.ZK_AUTH,TEST_AUTH_GOOD);
    zkClientTester.getRMStateStore(conf);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.server.resourcemanager.webapp;
import static org.apache.hadoop.yarn.webapp.WebServicesTestUtils.assertResponseStatusCode;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import static org.junit.Assume.assumeTrue;
import java.io.ByteArrayInputStream;
import java.io.DataInputStream;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.io.PrintWriter;
import java.io.StringReader;
import java.io.StringWriter;
import java.net.URI;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Enumeration;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.Set;
import javax.servlet.FilterConfig;
import javax.servlet.ServletException;
import javax.ws.rs.core.HttpHeaders;
import javax.ws.rs.core.MediaType;
import javax.xml.parsers.DocumentBuilder;
import javax.xml.parsers.DocumentBuilderFactory;
import javax.xml.parsers.ParserConfigurationException;
import org.apache.commons.codec.binary.Base64;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.http.JettyUtils;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.security.Credentials;
import org.apache.hadoop.security.authentication.server.AuthenticationFilter;
import org.apache.hadoop.security.authentication.server.PseudoAuthenticationHandler;
import org.apache.hadoop.yarn.api.records.ApplicationAccessType;
import org.apache.hadoop.yarn.api.records.ApplicationId;
import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
import org.apache.hadoop.yarn.api.records.ApplicationTimeoutType;
import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
import org.apache.hadoop.yarn.api.records.LocalResource;
import org.apache.hadoop.yarn.api.records.LocalResourceType;
import org.apache.hadoop.yarn.api.records.LocalResourceVisibility;
import org.apache.hadoop.yarn.api.records.LogAggregationContext;
import org.apache.hadoop.yarn.api.records.QueueACL;
import org.apache.hadoop.yarn.api.records.ReservationId;
import org.apache.hadoop.yarn.api.records.URL;
import org.apache.hadoop.yarn.api.records.YarnApplicationState;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.apache.hadoop.yarn.server.resourcemanager.MockNM;
import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
import org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMApp;
import org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppState;
import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler;
import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration;
import org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler;
import org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairSchedulerConfiguration;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CredentialsInfo;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LocalResourceInfo;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LogAggregationContextInfo;
import org.apache.hadoop.yarn.util.Times;
import org.apache.hadoop.yarn.webapp.GenericExceptionHandler;
import org.apache.hadoop.yarn.webapp.GuiceServletConfig;
import org.apache.hadoop.yarn.webapp.JerseyTestBase;
import org.apache.hadoop.yarn.webapp.WebServicesTestUtils;
import org.codehaus.jettison.json.JSONArray;
import org.codehaus.jettison.json.JSONException;
import org.codehaus.jettison.json.JSONObject;
import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.junit.runners.Parameterized;
import org.junit.runners.Parameterized.Parameters;
import org.w3c.dom.Document;
import org.w3c.dom.Element;
import org.w3c.dom.NodeList;
import org.xml.sax.InputSource;
import org.xml.sax.SAXException;
import com.google.inject.Guice;
import com.google.inject.Injector;
import com.google.inject.Singleton;
import com.google.inject.servlet.ServletModule;
import com.sun.jersey.api.client.Client;
import com.sun.jersey.api.client.ClientResponse;
import com.sun.jersey.api.client.ClientResponse.Status;
import com.sun.jersey.api.client.WebResource;
import com.sun.jersey.api.client.config.DefaultClientConfig;
import com.sun.jersey.api.client.filter.LoggingFilter;
import com.sun.jersey.api.json.JSONConfiguration;
import com.sun.jersey.api.json.JSONJAXBContext;
import com.sun.jersey.api.json.JSONMarshaller;
import com.sun.jersey.guice.spi.container.servlet.GuiceContainer;
import com.sun.jersey.test.framework.WebAppDescriptor;
@RunWith(Parameterized.class) public class TestRMWebServicesAppsModification extends JerseyTestBase {
  private static MockRM rm;
  private static final int CONTAINER_MB=1024;
  private String webserviceUserName="testuser";
  private boolean setAuthFilter=false;
  private static final String TEST_DIR=new File(System.getProperty("test.build.data","/tmp")).getAbsolutePath();
  private static final String FS_ALLOC_FILE=new File(TEST_DIR,"test-fs-queues.xml").getAbsolutePath();
@Singleton public static class TestRMCustomAuthFilter extends AuthenticationFilter {
    @Override protected Properties getConfiguration(    String configPrefix,    FilterConfig filterConfig) throws ServletException {
      Properties props=new Properties();
      Enumeration<?> names=filterConfig.getInitParameterNames();
      while (names.hasMoreElements()) {
        String name=(String)names.nextElement();
        if (name.startsWith(configPrefix)) {
          String value=filterConfig.getInitParameter(name);
          props.put(name.substring(configPrefix.length()),value);
        }
      }
      props.put(AuthenticationFilter.AUTH_TYPE,"simple");
      props.put(PseudoAuthenticationHandler.ANONYMOUS_ALLOWED,"false");
      return props;
    }
  }
private abstract class TestServletModule extends ServletModule {
    public Configuration conf=new Configuration();
    public abstract void configureScheduler();
    @Override protected void configureServlets(){
      configureScheduler();
      bind(JAXBContextResolver.class);
      bind(RMWebServices.class);
      bind(GenericExceptionHandler.class);
      conf.setInt(YarnConfiguration.RM_AM_MAX_ATTEMPTS,YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS);
      rm=new MockRM(conf);
      bind(ResourceManager.class).toInstance(rm);
      if (setAuthFilter) {
        filter("/*").through(TestRMCustomAuthFilter.class);
      }
      serve("/*").with(GuiceContainer.class);
    }
  }
private class CapTestServletModule extends TestServletModule {
    @Override public void configureScheduler(){
      conf.set(YarnConfiguration.RM_SCHEDULER,CapacityScheduler.class.getName());
    }
  }
private class FairTestServletModule extends TestServletModule {
    @Override public void configureScheduler(){
      try {
        PrintWriter out=new PrintWriter(new FileWriter(FS_ALLOC_FILE));
        out.println("<?xml version=\"1.0\"?>");
        out.println("<allocations>");
        out.println("<queue name=\"root\">");
        out.println("  <aclAdministerApps>someuser </aclAdministerApps>");
        out.println("  <queue name=\"default\">");
        out.println("    <aclAdministerApps>someuser </aclAdministerApps>");
        out.println("  </queue>");
        out.println("  <queue name=\"test\">");
        out.println("    <aclAdministerApps>someuser </aclAdministerApps>");
        out.println("  </queue>");
        out.println("</queue>");
        out.println("</allocations>");
        out.close();
      }
 catch (      IOException e) {
      }
      conf.set(FairSchedulerConfiguration.ALLOCATION_FILE,FS_ALLOC_FILE);
      conf.set(YarnConfiguration.RM_SCHEDULER,FairScheduler.class.getName());
    }
  }
  private Injector getNoAuthInjectorCap(){
    return Guice.createInjector(new CapTestServletModule(){
      @Override protected void configureServlets(){
        setAuthFilter=false;
        super.configureServlets();
      }
    }
);
  }
  private Injector getSimpleAuthInjectorCap(){
    return Guice.createInjector(new CapTestServletModule(){
      @Override protected void configureServlets(){
        setAuthFilter=true;
        conf.setBoolean(YarnConfiguration.YARN_ACL_ENABLE,true);
        conf.setStrings(YarnConfiguration.YARN_ADMIN_ACL,"testuser1");
        super.configureServlets();
      }
    }
);
  }
  private Injector getNoAuthInjectorFair(){
    return Guice.createInjector(new FairTestServletModule(){
      @Override protected void configureServlets(){
        setAuthFilter=false;
        super.configureServlets();
      }
    }
);
  }
  private Injector getSimpleAuthInjectorFair(){
    return Guice.createInjector(new FairTestServletModule(){
      @Override protected void configureServlets(){
        setAuthFilter=true;
        conf.setBoolean(YarnConfiguration.YARN_ACL_ENABLE,true);
        conf.setStrings(YarnConfiguration.YARN_ADMIN_ACL,"testuser1");
        super.configureServlets();
      }
    }
);
  }
  @Parameters public static Collection<Object[]> guiceConfigs(){
    return Arrays.asList(new Object[][]{{0},{1},{2},{3}});
  }
  @Before @Override public void setUp() throws Exception {
    super.setUp();
  }
  public TestRMWebServicesAppsModification(  int run){
    super(new WebAppDescriptor.Builder("org.apache.hadoop.yarn.server.resourcemanager.webapp").contextListenerClass(GuiceServletConfig.class).filterClass(com.google.inject.servlet.GuiceFilter.class).clientConfig(new DefaultClientConfig(JAXBContextResolver.class)).contextPath("jersey-guice-filter").servletPath("/").build());
switch (run) {
case 0:
default :
      GuiceServletConfig.setInjector(getNoAuthInjectorCap());
    break;
case 1:
  GuiceServletConfig.setInjector(getSimpleAuthInjectorCap());
break;
case 2:
GuiceServletConfig.setInjector(getNoAuthInjectorFair());
break;
case 3:
GuiceServletConfig.setInjector(getSimpleAuthInjectorFair());
break;
}
}
private boolean isAuthenticationEnabled(){
return setAuthFilter;
}
private WebResource constructWebResource(WebResource r,String... paths){
WebResource rt=r;
for (String path : paths) {
rt=rt.path(path);
}
if (isAuthenticationEnabled()) {
rt=rt.queryParam("user.name",webserviceUserName);
}
return rt;
}
private WebResource constructWebResource(String... paths){
WebResource r=resource();
WebResource ws=r.path("ws").path("v1").path("cluster");
return this.constructWebResource(ws,paths);
}
@Test public void testSingleAppState() throws Exception {
rm.start();
MockNM amNodeManager=rm.registerNode("127.0.0.1:1234",2048);
String[] mediaTypes={MediaType.APPLICATION_JSON,MediaType.APPLICATION_XML};
for (String mediaType : mediaTypes) {
RMApp app=rm.submitApp(CONTAINER_MB,"",webserviceUserName);
amNodeManager.nodeHeartbeat(true);
ClientResponse response=this.constructWebResource("apps",app.getApplicationId().toString(),"state").accept(mediaType).get(ClientResponse.class);
assertResponseStatusCode(Status.OK,response.getStatusInfo());
if (mediaType.contains(MediaType.APPLICATION_JSON)) {
verifyAppStateJson(response,RMAppState.ACCEPTED);
}
 else if (mediaType.contains(MediaType.APPLICATION_XML)) {
verifyAppStateXML(response,RMAppState.ACCEPTED);
}
}
rm.stop();
}
@Test(timeout=120000) public void testSingleAppKill() throws Exception {
rm.start();
MockNM amNodeManager=rm.registerNode("127.0.0.1:1234",2048);
String[] mediaTypes={MediaType.APPLICATION_JSON,MediaType.APPLICATION_XML};
MediaType[] contentTypes={MediaType.APPLICATION_JSON_TYPE,MediaType.APPLICATION_XML_TYPE};
String diagnostic="message1";
for (String mediaType : mediaTypes) {
for (MediaType contentType : contentTypes) {
RMApp app=rm.submitApp(CONTAINER_MB,"",webserviceUserName);
amNodeManager.nodeHeartbeat(true);
AppState targetState=new AppState(YarnApplicationState.KILLED.toString());
targetState.setDiagnostics(diagnostic);
Object entity;
if (contentType.equals(MediaType.APPLICATION_JSON_TYPE)) {
entity=appStateToJSON(targetState);
}
 else {
entity=targetState;
}
ClientResponse response=this.constructWebResource("apps",app.getApplicationId().toString(),"state").entity(entity,contentType).accept(mediaType).put(ClientResponse.class);
if (!isAuthenticationEnabled()) {
assertResponseStatusCode(Status.UNAUTHORIZED,response.getStatusInfo());
continue;
}
assertResponseStatusCode(Status.ACCEPTED,response.getStatusInfo());
if (mediaType.contains(MediaType.APPLICATION_JSON)) {
verifyAppStateJson(response,RMAppState.FINAL_SAVING,RMAppState.KILLED,RMAppState.KILLING,RMAppState.ACCEPTED);
}
 else {
verifyAppStateXML(response,RMAppState.FINAL_SAVING,RMAppState.KILLED,RMAppState.KILLING,RMAppState.ACCEPTED);
}
String locationHeaderValue=response.getHeaders().getFirst(HttpHeaders.LOCATION);
Client c=Client.create();
WebResource tmp=c.resource(locationHeaderValue);
if (isAuthenticationEnabled()) {
tmp=tmp.queryParam("user.name",webserviceUserName);
}
response=tmp.get(ClientResponse.class);
assertResponseStatusCode(Status.OK,response.getStatusInfo());
assertTrue(locationHeaderValue.endsWith("/ws/v1/cluster/apps/" + app.getApplicationId().toString() + "/state"));
while (true) {
Thread.sleep(100);
response=this.constructWebResource("apps",app.getApplicationId().toString(),"state").accept(mediaType).entity(entity,contentType).put(ClientResponse.class);
assertTrue((response.getStatusInfo().getStatusCode() == Status.ACCEPTED.getStatusCode()) || (response.getStatusInfo().getStatusCode() == Status.OK.getStatusCode()));
if (response.getStatusInfo().getStatusCode() == Status.OK.getStatusCode()) {
assertEquals(RMAppState.KILLED,app.getState());
if (mediaType.equals(MediaType.APPLICATION_JSON)) {
verifyAppStateJson(response,RMAppState.KILLED);
}
 else {
verifyAppStateXML(response,RMAppState.KILLED);
}
assertTrue("Diagnostic message is incorrect",app.getDiagnostics().toString().contains(diagnostic));
break;
}
}
}
}
rm.stop();
}
@Test public void testSingleAppKillInvalidState() throws Exception {
rm.start();
MockNM amNodeManager=rm.registerNode("127.0.0.1:1234",2048);
String[] mediaTypes={MediaType.APPLICATION_JSON,MediaType.APPLICATION_XML};
MediaType[] contentTypes={MediaType.APPLICATION_JSON_TYPE,MediaType.APPLICATION_XML_TYPE};
String[] targetStates={YarnApplicationState.FINISHED.toString(),"blah"};
for (String mediaType : mediaTypes) {
for (MediaType contentType : contentTypes) {
for (String targetStateString : targetStates) {
RMApp app=rm.submitApp(CONTAINER_MB,"",webserviceUserName);
amNodeManager.nodeHeartbeat(true);
ClientResponse response;
AppState targetState=new AppState(targetStateString);
Object entity;
if (contentType.equals(MediaType.APPLICATION_JSON_TYPE)) {
entity=appStateToJSON(targetState);
}
 else {
entity=targetState;
}
response=this.constructWebResource("apps",app.getApplicationId().toString(),"state").entity(entity,contentType).accept(mediaType).put(ClientResponse.class);
if (!isAuthenticationEnabled()) {
assertResponseStatusCode(Status.UNAUTHORIZED,response.getStatusInfo());
continue;
}
assertResponseStatusCode(Status.BAD_REQUEST,response.getStatusInfo());
}
}
}
rm.stop();
}
private static String appStateToJSON(AppState state) throws Exception {
StringWriter sw=new StringWriter();
JSONJAXBContext ctx=new JSONJAXBContext(AppState.class);
JSONMarshaller jm=ctx.createJSONMarshaller();
jm.marshallToJSON(state,sw);
return sw.toString();
}
protected static void verifyAppStateJson(ClientResponse response,RMAppState... states) throws JSONException {
assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
JSONObject json=response.getEntity(JSONObject.class);
assertEquals("incorrect number of elements",1,json.length());
String responseState=json.getString("state");
boolean valid=false;
for (RMAppState state : states) {
if (state.toString().equals(responseState)) {
valid=true;
}
}
String msg="app state incorrect, got " + responseState;
assertTrue(msg,valid);
}
protected static void verifyAppStateXML(ClientResponse response,RMAppState... appStates) throws ParserConfigurationException, IOException, SAXException {
assertEquals(MediaType.APPLICATION_XML_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
String xml=response.getEntity(String.class);
DocumentBuilderFactory dbf=DocumentBuilderFactory.newInstance();
DocumentBuilder db=dbf.newDocumentBuilder();
InputSource is=new InputSource();
is.setCharacterStream(new StringReader(xml));
Document dom=db.parse(is);
NodeList nodes=dom.getElementsByTagName("appstate");
assertEquals("incorrect number of elements",1,nodes.getLength());
Element element=(Element)nodes.item(0);
String state=WebServicesTestUtils.getXmlString(element,"state");
boolean valid=false;
for (RMAppState appState : appStates) {
if (appState.toString().equals(state)) {
valid=true;
}
}
String msg="app state incorrect, got " + state;
assertTrue(msg,valid);
}
@Test(timeout=60000) public void testSingleAppKillUnauthorized() throws Exception {
boolean isCapacityScheduler=rm.getResourceScheduler() instanceof CapacityScheduler;
boolean isFairScheduler=rm.getResourceScheduler() instanceof FairScheduler;
assumeTrue("This test is only supported on Capacity and Fair Scheduler",isCapacityScheduler || isFairScheduler);
if (isCapacityScheduler) {
CapacitySchedulerConfiguration csconf=new CapacitySchedulerConfiguration();
csconf.setAcl("root",QueueACL.ADMINISTER_QUEUE,"someuser");
csconf.setAcl("root.default",QueueACL.ADMINISTER_QUEUE,"someuser");
rm.getResourceScheduler().reinitialize(csconf,rm.getRMContext());
}
rm.start();
MockNM amNodeManager=rm.registerNode("127.0.0.1:1234",2048);
String[] mediaTypes={MediaType.APPLICATION_JSON,MediaType.APPLICATION_XML};
for (String mediaType : mediaTypes) {
RMApp app=rm.submitApp(CONTAINER_MB,"test","someuser");
amNodeManager.nodeHeartbeat(true);
ClientResponse response=this.constructWebResource("apps",app.getApplicationId().toString(),"state").accept(mediaType).get(ClientResponse.class);
AppState info=response.getEntity(AppState.class);
info.setState(YarnApplicationState.KILLED.toString());
response=this.constructWebResource("apps",app.getApplicationId().toString(),"state").accept(mediaType).entity(info,MediaType.APPLICATION_XML).put(ClientResponse.class);
validateResponseStatus(response,Status.FORBIDDEN);
}
rm.stop();
}
@Test public void testSingleAppKillInvalidId() throws Exception {
rm.start();
MockNM amNodeManager=rm.registerNode("127.0.0.1:1234",2048);
amNodeManager.nodeHeartbeat(true);
String[] testAppIds={"application_1391705042196_0001","random_string"};
for (int i=0; i < testAppIds.length; i++) {
AppState info=new AppState("KILLED");
ClientResponse response=this.constructWebResource("apps",testAppIds[i],"state").accept(MediaType.APPLICATION_XML).entity(info,MediaType.APPLICATION_XML).put(ClientResponse.class);
if (!isAuthenticationEnabled()) {
assertResponseStatusCode(Status.UNAUTHORIZED,response.getStatusInfo());
continue;
}
if (i == 0) {
assertResponseStatusCode(Status.NOT_FOUND,response.getStatusInfo());
}
 else {
assertResponseStatusCode(Status.BAD_REQUEST,response.getStatusInfo());
}
}
rm.stop();
}
@After @Override public void tearDown() throws Exception {
if (rm != null) {
rm.stop();
}
super.tearDown();
}
/** 
 * Helper function to wrap frequently used code. It checks the response status and checks if it UNAUTHORIZED if we are running with authorization turned off or the param passed if we are running with authorization turned on.
 * @param response the ClientResponse object to be checked
 * @param expectedAuthorizedMode the expected Status in authorized mode.
 */
public void validateResponseStatus(ClientResponse response,Status expectedAuthorizedMode){
validateResponseStatus(response,Status.UNAUTHORIZED,expectedAuthorizedMode);
}
/** 
 * Helper function to wrap frequently used code. It checks the response status and checks if it is the param expectedUnauthorizedMode if we are running with authorization turned off or the param expectedAuthorizedMode passed if we are running with authorization turned on.
 * @param response the ClientResponse object to be checked
 * @param expectedUnauthorizedMode the expected Status in unauthorized mode.
 * @param expectedAuthorizedMode the expected Status in authorized mode.
 */
public void validateResponseStatus(ClientResponse response,Status expectedUnauthorizedMode,Status expectedAuthorizedMode){
if (!isAuthenticationEnabled()) {
assertResponseStatusCode(expectedUnauthorizedMode,response.getStatusInfo());
}
 else {
assertResponseStatusCode(expectedAuthorizedMode,response.getStatusInfo());
}
}
@Test public void testGetNewApplication() throws Exception {
client().addFilter(new LoggingFilter(System.out));
rm.start();
String mediaTypes[]={MediaType.APPLICATION_JSON,MediaType.APPLICATION_XML};
for (String acceptMedia : mediaTypes) {
testGetNewApplication(acceptMedia);
}
rm.stop();
}
protected String testGetNewApplication(String mediaType) throws JSONException, ParserConfigurationException, IOException, SAXException {
ClientResponse response=this.constructWebResource("apps","new-application").accept(mediaType).post(ClientResponse.class);
validateResponseStatus(response,Status.OK);
if (!isAuthenticationEnabled()) {
return "";
}
return validateGetNewApplicationResponse(response);
}
protected String validateGetNewApplicationResponse(ClientResponse resp) throws JSONException, ParserConfigurationException, IOException, SAXException {
String ret="";
if (resp.getType().toString().contains(MediaType.APPLICATION_JSON)) {
JSONObject json=resp.getEntity(JSONObject.class);
ret=validateGetNewApplicationJsonResponse(json);
}
 else if (resp.getType().toString().contains(MediaType.APPLICATION_XML)) {
String xml=resp.getEntity(String.class);
ret=validateGetNewApplicationXMLResponse(xml);
}
 else {
assertTrue(false);
}
return ret;
}
protected String validateGetNewApplicationJsonResponse(JSONObject json) throws JSONException {
String appId=json.getString("application-id");
assertTrue(!appId.isEmpty());
JSONObject maxResources=json.getJSONObject("maximum-resource-capability");
long memory=maxResources.getLong("memory");
long vCores=maxResources.getLong("vCores");
assertTrue(memory != 0);
assertTrue(vCores != 0);
return appId;
}
protected String validateGetNewApplicationXMLResponse(String response) throws ParserConfigurationException, IOException, SAXException {
DocumentBuilderFactory dbf=DocumentBuilderFactory.newInstance();
DocumentBuilder db=dbf.newDocumentBuilder();
InputSource is=new InputSource();
is.setCharacterStream(new StringReader(response));
Document dom=db.parse(is);
NodeList nodes=dom.getElementsByTagName("NewApplication");
assertEquals("incorrect number of elements",1,nodes.getLength());
Element element=(Element)nodes.item(0);
String appId=WebServicesTestUtils.getXmlString(element,"application-id");
assertTrue(!appId.isEmpty());
NodeList maxResourceNodes=element.getElementsByTagName("maximum-resource-capability");
assertEquals(1,maxResourceNodes.getLength());
Element maxResourceCapability=(Element)maxResourceNodes.item(0);
long memory=WebServicesTestUtils.getXmlLong(maxResourceCapability,"memory");
long vCores=WebServicesTestUtils.getXmlLong(maxResourceCapability,"vCores");
assertTrue(memory != 0);
assertTrue(vCores != 0);
return appId;
}
@Test public void testGetNewApplicationAndSubmit() throws Exception {
rm.start();
MockNM amNodeManager=rm.registerNode("127.0.0.1:1234",2048);
amNodeManager.nodeHeartbeat(true);
String mediaTypes[]={MediaType.APPLICATION_JSON,MediaType.APPLICATION_XML};
for (String acceptMedia : mediaTypes) {
for (String contentMedia : mediaTypes) {
testAppSubmit(acceptMedia,contentMedia);
testAppSubmitErrors(acceptMedia,contentMedia);
}
}
rm.stop();
}
public void testAppSubmit(String acceptMedia,String contentMedia) throws Exception {
client().addFilter(new LoggingFilter(System.out));
String lrKey="example";
String queueName="testqueue";
String[] queues={"default","testqueue"};
CapacitySchedulerConfiguration csconf=new CapacitySchedulerConfiguration();
csconf.setQueues("root",queues);
csconf.setCapacity("root.default",50.0f);
csconf.setCapacity("root.testqueue",50.0f);
rm.getResourceScheduler().reinitialize(csconf,rm.getRMContext());
String appName="test";
String appType="test-type";
String urlPath="apps";
String appId=testGetNewApplication(acceptMedia);
List<String> commands=new ArrayList<>();
commands.add("/bin/sleep 5");
HashMap<String,String> environment=new HashMap<>();
environment.put("APP_VAR","ENV_SETTING");
HashMap<ApplicationAccessType,String> acls=new HashMap<>();
acls.put(ApplicationAccessType.MODIFY_APP,"testuser1, testuser2");
acls.put(ApplicationAccessType.VIEW_APP,"testuser3, testuser4");
Set<String> tags=new HashSet<>();
tags.add("tag1");
tags.add("tag 2");
CredentialsInfo credentials=new CredentialsInfo();
HashMap<String,String> tokens=new HashMap<>();
HashMap<String,String> secrets=new HashMap<>();
secrets.put("secret1",Base64.encodeBase64String("mysecret".getBytes("UTF8")));
credentials.setSecrets(secrets);
credentials.setTokens(tokens);
ApplicationSubmissionContextInfo appInfo=new ApplicationSubmissionContextInfo();
appInfo.setApplicationId(appId);
appInfo.setApplicationName(appName);
appInfo.setMaxAppAttempts(2);
appInfo.setQueue(queueName);
appInfo.setApplicationType(appType);
appInfo.setPriority(0);
HashMap<String,LocalResourceInfo> lr=new HashMap<>();
LocalResourceInfo y=new LocalResourceInfo();
y.setUrl(new URI("http://www.test.com/file.txt"));
y.setSize(100);
y.setTimestamp(System.currentTimeMillis());
y.setType(LocalResourceType.FILE);
y.setVisibility(LocalResourceVisibility.APPLICATION);
lr.put(lrKey,y);
appInfo.getContainerLaunchContextInfo().setResources(lr);
appInfo.getContainerLaunchContextInfo().setCommands(commands);
appInfo.getContainerLaunchContextInfo().setEnvironment(environment);
appInfo.getContainerLaunchContextInfo().setAcls(acls);
appInfo.getContainerLaunchContextInfo().getAuxillaryServiceData().put("test",Base64.encodeBase64URLSafeString("value12".getBytes("UTF8")));
appInfo.getContainerLaunchContextInfo().setCredentials(credentials);
appInfo.getResource().setMemory(1024);
appInfo.getResource().setvCores(1);
appInfo.setApplicationTags(tags);
String includePattern="file1";
String excludePattern="file2";
String rolledLogsIncludePattern="file3";
String rolledLogsExcludePattern="file4";
String className="policy_class";
String parameters="policy_parameter";
LogAggregationContextInfo logAggregationContextInfo=new LogAggregationContextInfo();
logAggregationContextInfo.setIncludePattern(includePattern);
logAggregationContextInfo.setExcludePattern(excludePattern);
logAggregationContextInfo.setRolledLogsIncludePattern(rolledLogsIncludePattern);
logAggregationContextInfo.setRolledLogsExcludePattern(rolledLogsExcludePattern);
logAggregationContextInfo.setLogAggregationPolicyClassName(className);
logAggregationContextInfo.setLogAggregationPolicyParameters(parameters);
appInfo.setLogAggregationContextInfo(logAggregationContextInfo);
long attemptFailuresValidityInterval=5000;
appInfo.setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);
String reservationId=ReservationId.newInstance(System.currentTimeMillis(),1).toString();
appInfo.setReservationId(reservationId);
ClientResponse response=this.constructWebResource(urlPath).accept(acceptMedia).entity(appInfo,contentMedia).post(ClientResponse.class);
if (!this.isAuthenticationEnabled()) {
assertResponseStatusCode(Status.UNAUTHORIZED,response.getStatusInfo());
return;
}
assertResponseStatusCode(Status.ACCEPTED,response.getStatusInfo());
assertTrue(!response.getHeaders().getFirst(HttpHeaders.LOCATION).isEmpty());
String locURL=response.getHeaders().getFirst(HttpHeaders.LOCATION);
assertTrue(locURL.contains("/apps/application"));
appId=locURL.substring(locURL.indexOf("/apps/") + "/apps/".length());
WebResource res=resource().uri(new URI(locURL));
res=res.queryParam("user.name",webserviceUserName);
response=res.get(ClientResponse.class);
assertResponseStatusCode(Status.OK,response.getStatusInfo());
RMApp app=rm.getRMContext().getRMApps().get(ApplicationId.fromString(appId));
assertEquals(appName,app.getName());
assertEquals(webserviceUserName,app.getUser());
assertEquals(2,app.getMaxAppAttempts());
if (app.getQueue().contains("root.")) {
queueName="root." + queueName;
}
assertEquals(queueName,app.getQueue());
assertEquals(appType,app.getApplicationType());
assertEquals(tags,app.getApplicationTags());
ContainerLaunchContext ctx=app.getApplicationSubmissionContext().getAMContainerSpec();
assertEquals(commands,ctx.getCommands());
assertEquals(environment,ctx.getEnvironment());
assertEquals(acls,ctx.getApplicationACLs());
Map<String,LocalResource> appLRs=ctx.getLocalResources();
assertTrue(appLRs.containsKey(lrKey));
LocalResource exampleLR=appLRs.get(lrKey);
assertEquals(URL.fromURI(y.getUrl()),exampleLR.getResource());
assertEquals(y.getSize(),exampleLR.getSize());
assertEquals(y.getTimestamp(),exampleLR.getTimestamp());
assertEquals(y.getType(),exampleLR.getType());
assertEquals(y.getPattern(),exampleLR.getPattern());
assertEquals(y.getVisibility(),exampleLR.getVisibility());
Credentials cs=new Credentials();
ByteArrayInputStream str=new ByteArrayInputStream(app.getApplicationSubmissionContext().getAMContainerSpec().getTokens().array());
DataInputStream di=new DataInputStream(str);
cs.readTokenStorageStream(di);
Text key=new Text("secret1");
assertTrue("Secrets missing from credentials object",cs.getAllSecretKeys().contains(key));
assertEquals("mysecret",new String(cs.getSecretKey(key),"UTF-8"));
ApplicationSubmissionContext asc=app.getApplicationSubmissionContext();
LogAggregationContext lac=asc.getLogAggregationContext();
assertEquals(includePattern,lac.getIncludePattern());
assertEquals(excludePattern,lac.getExcludePattern());
assertEquals(rolledLogsIncludePattern,lac.getRolledLogsIncludePattern());
assertEquals(rolledLogsExcludePattern,lac.getRolledLogsExcludePattern());
assertEquals(className,lac.getLogAggregationPolicyClassName());
assertEquals(parameters,lac.getLogAggregationPolicyParameters());
assertEquals(attemptFailuresValidityInterval,asc.getAttemptFailuresValidityInterval());
assertEquals(reservationId,app.getReservationId().toString());
response=this.constructWebResource("apps",appId).accept(acceptMedia).get(ClientResponse.class);
assertResponseStatusCode(Status.OK,response.getStatusInfo());
}
public void testAppSubmitErrors(String acceptMedia,String contentMedia) throws Exception {
String urlPath="apps";
ApplicationSubmissionContextInfo appInfo=new ApplicationSubmissionContextInfo();
ClientResponse response=this.constructWebResource(urlPath).accept(acceptMedia).entity(appInfo,contentMedia).post(ClientResponse.class);
validateResponseStatus(response,Status.BAD_REQUEST);
String appId="random";
appInfo.setApplicationId(appId);
response=this.constructWebResource(urlPath).accept(acceptMedia).entity(appInfo,contentMedia).post(ClientResponse.class);
validateResponseStatus(response,Status.BAD_REQUEST);
appId="random_junk";
appInfo.setApplicationId(appId);
response=this.constructWebResource(urlPath).accept(acceptMedia).entity(appInfo,contentMedia).post(ClientResponse.class);
validateResponseStatus(response,Status.BAD_REQUEST);
appInfo.getResource().setMemory(rm.getConfig().getInt(YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_MB,YarnConfiguration.DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_MB) + 1);
appInfo.getResource().setvCores(1);
response=this.constructWebResource(urlPath).accept(acceptMedia).entity(appInfo,contentMedia).post(ClientResponse.class);
validateResponseStatus(response,Status.BAD_REQUEST);
appInfo.getResource().setvCores(rm.getConfig().getInt(YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES,YarnConfiguration.DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES) + 1);
appInfo.getResource().setMemory(CONTAINER_MB);
response=this.constructWebResource(urlPath).accept(acceptMedia).entity(appInfo,contentMedia).post(ClientResponse.class);
validateResponseStatus(response,Status.BAD_REQUEST);
}
@Test public void testAppSubmitBadJsonAndXML() throws Exception {
String urlPath="apps";
rm.start();
MockNM amNodeManager=rm.registerNode("127.0.0.1:1234",2048);
amNodeManager.nodeHeartbeat(true);
ApplicationSubmissionContextInfo appInfo=new ApplicationSubmissionContextInfo();
appInfo.setApplicationName("test");
appInfo.setPriority(3);
appInfo.setMaxAppAttempts(2);
appInfo.setQueue("testqueue");
appInfo.setApplicationType("test-type");
HashMap<String,LocalResourceInfo> lr=new HashMap<>();
LocalResourceInfo y=new LocalResourceInfo();
y.setUrl(new URI("http://www.test.com/file.txt"));
y.setSize(100);
y.setTimestamp(System.currentTimeMillis());
y.setType(LocalResourceType.FILE);
y.setVisibility(LocalResourceVisibility.APPLICATION);
lr.put("example",y);
appInfo.getContainerLaunchContextInfo().setResources(lr);
appInfo.getResource().setMemory(1024);
appInfo.getResource().setvCores(1);
String body="<?xml version=\"1.0\" encoding=\"UTF-8\" " + "standalone=\"yes\"?><blah/>";
ClientResponse response=this.constructWebResource(urlPath).accept(MediaType.APPLICATION_XML).entity(body,MediaType.APPLICATION_XML).post(ClientResponse.class);
assertResponseStatusCode(Status.BAD_REQUEST,response.getStatusInfo());
body="{\"a\" : \"b\"}";
response=this.constructWebResource(urlPath).accept(MediaType.APPLICATION_XML).entity(body,MediaType.APPLICATION_JSON).post(ClientResponse.class);
validateResponseStatus(response,Status.BAD_REQUEST);
rm.stop();
}
@Test public void testGetAppQueue() throws Exception {
client().addFilter(new LoggingFilter(System.out));
boolean isCapacityScheduler=rm.getResourceScheduler() instanceof CapacityScheduler;
rm.start();
MockNM amNodeManager=rm.registerNode("127.0.0.1:1234",2048);
String[] contentTypes={MediaType.APPLICATION_JSON,MediaType.APPLICATION_XML};
for (String contentType : contentTypes) {
RMApp app=rm.submitApp(CONTAINER_MB,"",webserviceUserName);
amNodeManager.nodeHeartbeat(true);
ClientResponse response=this.constructWebResource("apps",app.getApplicationId().toString(),"queue").accept(contentType).get(ClientResponse.class);
assertResponseStatusCode(Status.OK,response.getStatusInfo());
String expectedQueue="default";
if (!isCapacityScheduler) {
expectedQueue="root." + webserviceUserName;
}
if (contentType.contains(MediaType.APPLICATION_JSON)) {
verifyAppQueueJson(response,expectedQueue);
}
 else {
verifyAppQueueXML(response,expectedQueue);
}
}
rm.stop();
}
@Test(timeout=90000) public void testUpdateAppPriority() throws Exception {
client().addFilter(new LoggingFilter(System.out));
if (!(rm.getResourceScheduler() instanceof CapacityScheduler)) {
return;
}
CapacityScheduler cs=(CapacityScheduler)rm.getResourceScheduler();
Configuration conf=new Configuration();
conf.setInt(YarnConfiguration.MAX_CLUSTER_LEVEL_APPLICATION_PRIORITY,10);
cs.setClusterMaxPriority(conf);
CapacitySchedulerConfiguration csconf=new CapacitySchedulerConfiguration();
String[] queues={"default","test"};
csconf.setQueues("root",queues);
csconf.setCapacity("root.default",50.0f);
csconf.setCapacity("root.test",50.0f);
csconf.setAcl("root",QueueACL.ADMINISTER_QUEUE,"someuser");
csconf.setAcl("root.default",QueueACL.ADMINISTER_QUEUE,"someuser");
csconf.setAcl("root.test",QueueACL.ADMINISTER_QUEUE,"someuser");
rm.getResourceScheduler().reinitialize(csconf,rm.getRMContext());
rm.start();
MockNM amNodeManager=rm.registerNode("127.0.0.1:1234",2048);
String[] mediaTypes={MediaType.APPLICATION_JSON,MediaType.APPLICATION_XML};
MediaType[] contentTypes={MediaType.APPLICATION_JSON_TYPE,MediaType.APPLICATION_XML_TYPE};
for (String mediaType : mediaTypes) {
for (MediaType contentType : contentTypes) {
RMApp app=rm.submitApp(CONTAINER_MB,"",webserviceUserName);
amNodeManager.nodeHeartbeat(true);
int modifiedPriority=8;
AppPriority priority=new AppPriority(modifiedPriority);
Object entity;
if (contentType.equals(MediaType.APPLICATION_JSON_TYPE)) {
entity=appPriorityToJSON(priority);
}
 else {
entity=priority;
}
ClientResponse response=this.constructWebResource("apps",app.getApplicationId().toString(),"priority").entity(entity,contentType).accept(mediaType).put(ClientResponse.class);
if (!isAuthenticationEnabled()) {
assertResponseStatusCode(Status.UNAUTHORIZED,response.getStatusInfo());
continue;
}
assertResponseStatusCode(Status.OK,response.getStatusInfo());
if (mediaType.contains(MediaType.APPLICATION_JSON)) {
verifyAppPriorityJson(response,modifiedPriority);
}
 else {
verifyAppPriorityXML(response,modifiedPriority);
}
response=this.constructWebResource("apps",app.getApplicationId().toString(),"priority").accept(mediaType).get(ClientResponse.class);
assertResponseStatusCode(Status.OK,response.getStatusInfo());
if (mediaType.contains(MediaType.APPLICATION_JSON)) {
verifyAppPriorityJson(response,modifiedPriority);
}
 else {
verifyAppPriorityXML(response,modifiedPriority);
}
app=rm.submitApp(CONTAINER_MB,"","someuser");
amNodeManager.nodeHeartbeat(true);
response=this.constructWebResource("apps",app.getApplicationId().toString(),"priority").entity(entity,contentType).accept(mediaType).put(ClientResponse.class);
assertResponseStatusCode(Status.FORBIDDEN,response.getStatusInfo());
}
}
rm.stop();
}
@Test(timeout=90000) public void testAppMove() throws Exception {
client().addFilter(new LoggingFilter(System.out));
boolean isCapacityScheduler=rm.getResourceScheduler() instanceof CapacityScheduler;
CapacitySchedulerConfiguration csconf=new CapacitySchedulerConfiguration();
String[] queues={"default","test"};
csconf.setQueues("root",queues);
csconf.setCapacity("root.default",50.0f);
csconf.setCapacity("root.test",50.0f);
csconf.setAcl("root",QueueACL.ADMINISTER_QUEUE,"someuser");
csconf.setAcl("root.default",QueueACL.ADMINISTER_QUEUE,"someuser");
csconf.setAcl("root.test",QueueACL.ADMINISTER_QUEUE,"someuser");
rm.getResourceScheduler().reinitialize(csconf,rm.getRMContext());
rm.start();
MockNM amNodeManager=rm.registerNode("127.0.0.1:1234",2048);
String[] mediaTypes={MediaType.APPLICATION_JSON,MediaType.APPLICATION_XML};
MediaType[] contentTypes={MediaType.APPLICATION_JSON_TYPE,MediaType.APPLICATION_XML_TYPE};
for (String mediaType : mediaTypes) {
for (MediaType contentType : contentTypes) {
RMApp app=rm.submitApp(CONTAINER_MB,"",webserviceUserName);
amNodeManager.nodeHeartbeat(true);
AppQueue targetQueue=new AppQueue("test");
Object entity;
if (contentType.equals(MediaType.APPLICATION_JSON_TYPE)) {
entity=appQueueToJSON(targetQueue);
}
 else {
entity=targetQueue;
}
ClientResponse response=this.constructWebResource("apps",app.getApplicationId().toString(),"queue").entity(entity,contentType).accept(mediaType).put(ClientResponse.class);
if (!isAuthenticationEnabled()) {
assertResponseStatusCode(Status.UNAUTHORIZED,response.getStatusInfo());
continue;
}
assertResponseStatusCode(Status.OK,response.getStatusInfo());
String expectedQueue="test";
if (!isCapacityScheduler) {
expectedQueue="root.test";
}
if (mediaType.contains(MediaType.APPLICATION_JSON)) {
verifyAppQueueJson(response,expectedQueue);
}
 else {
verifyAppQueueXML(response,expectedQueue);
}
Assert.assertEquals(expectedQueue,app.getQueue());
app=rm.submitApp(CONTAINER_MB,"","someuser");
amNodeManager.nodeHeartbeat(true);
response=this.constructWebResource("apps",app.getApplicationId().toString(),"queue").entity(entity,contentType).accept(mediaType).put(ClientResponse.class);
assertResponseStatusCode(Status.FORBIDDEN,response.getStatusInfo());
if (isCapacityScheduler) {
Assert.assertEquals("default",app.getQueue());
}
 else {
Assert.assertEquals("root.someuser",app.getQueue());
}
}
}
rm.stop();
}
protected static String appPriorityToJSON(AppPriority targetPriority) throws Exception {
StringWriter sw=new StringWriter();
JSONJAXBContext ctx=new JSONJAXBContext(AppPriority.class);
JSONMarshaller jm=ctx.createJSONMarshaller();
jm.marshallToJSON(targetPriority,sw);
return sw.toString();
}
protected static String appQueueToJSON(AppQueue targetQueue) throws Exception {
StringWriter sw=new StringWriter();
JSONJAXBContext ctx=new JSONJAXBContext(AppQueue.class);
JSONMarshaller jm=ctx.createJSONMarshaller();
jm.marshallToJSON(targetQueue,sw);
return sw.toString();
}
protected static void verifyAppPriorityJson(ClientResponse response,int expectedPriority) throws JSONException {
assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
JSONObject json=response.getEntity(JSONObject.class);
assertEquals("incorrect number of elements",1,json.length());
int responsePriority=json.getInt("priority");
assertEquals(expectedPriority,responsePriority);
}
protected static void verifyAppPriorityXML(ClientResponse response,int expectedPriority) throws ParserConfigurationException, IOException, SAXException {
assertEquals(MediaType.APPLICATION_XML_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
String xml=response.getEntity(String.class);
DocumentBuilderFactory dbf=DocumentBuilderFactory.newInstance();
DocumentBuilder db=dbf.newDocumentBuilder();
InputSource is=new InputSource();
is.setCharacterStream(new StringReader(xml));
Document dom=db.parse(is);
NodeList nodes=dom.getElementsByTagName("applicationpriority");
assertEquals("incorrect number of elements",1,nodes.getLength());
Element element=(Element)nodes.item(0);
int responsePriority=WebServicesTestUtils.getXmlInt(element,"priority");
assertEquals(expectedPriority,responsePriority);
}
protected static void verifyAppQueueJson(ClientResponse response,String queue) throws JSONException {
assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
JSONObject json=response.getEntity(JSONObject.class);
assertEquals("incorrect number of elements",1,json.length());
String responseQueue=json.getString("queue");
assertEquals(queue,responseQueue);
}
protected static void verifyAppQueueXML(ClientResponse response,String queue) throws ParserConfigurationException, IOException, SAXException {
assertEquals(MediaType.APPLICATION_XML_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
String xml=response.getEntity(String.class);
DocumentBuilderFactory dbf=DocumentBuilderFactory.newInstance();
DocumentBuilder db=dbf.newDocumentBuilder();
InputSource is=new InputSource();
is.setCharacterStream(new StringReader(xml));
Document dom=db.parse(is);
NodeList nodes=dom.getElementsByTagName("appqueue");
assertEquals("incorrect number of elements",1,nodes.getLength());
Element element=(Element)nodes.item(0);
String responseQueue=WebServicesTestUtils.getXmlString(element,"queue");
assertEquals(queue,responseQueue);
}
@Test(timeout=90000) public void testUpdateAppTimeout() throws Exception {
client().addFilter(new LoggingFilter(System.out));
rm.start();
rm.registerNode("127.0.0.1:1234",2048);
String[] mediaTypes={MediaType.APPLICATION_JSON,MediaType.APPLICATION_XML};
MediaType[] contentTypes={MediaType.APPLICATION_JSON_TYPE,MediaType.APPLICATION_XML_TYPE};
for (String mediaType : mediaTypes) {
for (MediaType contentType : contentTypes) {
RMApp app=rm.submitApp(CONTAINER_MB,"",webserviceUserName);
ClientResponse response=this.constructWebResource("apps",app.getApplicationId().toString(),"timeouts").accept(mediaType).get(ClientResponse.class);
if (mediaType.contains(MediaType.APPLICATION_JSON)) {
assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
JSONObject js=response.getEntity(JSONObject.class).getJSONObject("timeouts");
JSONArray entity=js.getJSONArray("timeout");
verifyAppTimeoutJson(entity.getJSONObject(0),ApplicationTimeoutType.LIFETIME,"UNLIMITED",-1);
}
long timeOutFromNow=60;
String expireTime=Times.formatISO8601(System.currentTimeMillis() + timeOutFromNow * 1000);
Object entity=getAppTimeoutInfoEntity(ApplicationTimeoutType.LIFETIME,contentType,expireTime);
response=this.constructWebResource("apps",app.getApplicationId().toString(),"timeout").entity(entity,contentType).accept(mediaType).put(ClientResponse.class);
if (!isAuthenticationEnabled()) {
assertResponseStatusCode(Status.UNAUTHORIZED,response.getStatusInfo());
continue;
}
assertResponseStatusCode(Status.OK,response.getStatusInfo());
if (mediaType.contains(MediaType.APPLICATION_JSON)) {
verifyAppTimeoutJson(response,ApplicationTimeoutType.LIFETIME,expireTime,timeOutFromNow);
}
 else {
verifyAppTimeoutXML(response,ApplicationTimeoutType.LIFETIME,expireTime,timeOutFromNow);
}
entity=getAppTimeoutInfoEntity(null,contentType,null);
response=this.constructWebResource("apps",app.getApplicationId().toString(),"timeout").entity(entity,contentType).accept(mediaType).put(ClientResponse.class);
assertResponseStatusCode(Status.BAD_REQUEST,response.getStatusInfo());
response=this.constructWebResource("apps",app.getApplicationId().toString(),"timeouts",ApplicationTimeoutType.LIFETIME.toString()).accept(mediaType).get(ClientResponse.class);
assertResponseStatusCode(Status.OK,response.getStatusInfo());
if (mediaType.contains(MediaType.APPLICATION_JSON)) {
verifyAppTimeoutJson(response,ApplicationTimeoutType.LIFETIME,expireTime,timeOutFromNow);
}
}
}
rm.stop();
}
private Object getAppTimeoutInfoEntity(ApplicationTimeoutType type,MediaType contentType,String expireTime) throws Exception {
AppTimeoutInfo timeoutUpdate=new AppTimeoutInfo();
timeoutUpdate.setTimeoutType(type);
timeoutUpdate.setExpiryTime(expireTime);
Object entity;
if (contentType.equals(MediaType.APPLICATION_JSON_TYPE)) {
entity=appTimeoutToJSON(timeoutUpdate);
}
 else {
entity=timeoutUpdate;
}
return entity;
}
protected static void verifyAppTimeoutJson(ClientResponse response,ApplicationTimeoutType type,String expireTime,long timeOutFromNow) throws JSONException {
assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
JSONObject jsonTimeout=response.getEntity(JSONObject.class);
assertEquals("incorrect number of elements",1,jsonTimeout.length());
JSONObject json=jsonTimeout.getJSONObject("timeout");
verifyAppTimeoutJson(json,type,expireTime,timeOutFromNow);
}
protected static void verifyAppTimeoutJson(JSONObject json,ApplicationTimeoutType type,String expireTime,long timeOutFromNow) throws JSONException {
assertEquals("incorrect number of elements",3,json.length());
assertEquals(type.toString(),json.getString("type"));
assertEquals(expireTime,json.getString("expiryTime"));
assertTrue(json.getLong("remainingTimeInSeconds") <= timeOutFromNow);
}
protected static void verifyAppTimeoutXML(ClientResponse response,ApplicationTimeoutType type,String expireTime,long timeOutFromNow) throws ParserConfigurationException, IOException, SAXException {
assertEquals(MediaType.APPLICATION_XML_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
String xml=response.getEntity(String.class);
DocumentBuilderFactory dbf=DocumentBuilderFactory.newInstance();
DocumentBuilder db=dbf.newDocumentBuilder();
InputSource is=new InputSource();
is.setCharacterStream(new StringReader(xml));
Document dom=db.parse(is);
NodeList nodes=dom.getElementsByTagName("timeout");
assertEquals("incorrect number of elements",1,nodes.getLength());
Element element=(Element)nodes.item(0);
assertEquals(type.toString(),WebServicesTestUtils.getXmlString(element,"type"));
assertEquals(expireTime,WebServicesTestUtils.getXmlString(element,"expiryTime"));
assertTrue(WebServicesTestUtils.getXmlLong(element,"remainingTimeInSeconds") < timeOutFromNow);
}
protected static String appTimeoutToJSON(AppTimeoutInfo timeout) throws Exception {
StringWriter sw=new StringWriter();
JSONJAXBContext ctx=new JSONJAXBContext(JSONConfiguration.natural().rootUnwrapping(false).build(),AppTimeoutInfo.class);
JSONMarshaller jm=ctx.createJSONMarshaller();
jm.marshallToJSON(timeout,sw);
jm.marshallToJSON(timeout,System.out);
return sw.toString();
}
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.server.resourcemanager.webapp;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import java.io.IOException;
import java.io.StringWriter;
import java.util.ArrayList;
import javax.ws.rs.core.MediaType;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.http.JettyUtils;
import org.apache.hadoop.security.UserGroupInformation;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelInfo;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntry;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
import org.apache.hadoop.yarn.webapp.GenericExceptionHandler;
import org.apache.hadoop.yarn.webapp.GuiceServletConfig;
import org.apache.hadoop.yarn.webapp.JerseyTestBase;
import org.apache.hadoop.yarn.webapp.WebServicesTestUtils;
import org.codehaus.jettison.json.JSONException;
import org.codehaus.jettison.json.JSONObject;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;
import com.google.inject.Guice;
import com.google.inject.servlet.ServletModule;
import com.sun.jersey.api.client.ClientResponse;
import com.sun.jersey.api.client.UniformInterfaceException;
import com.sun.jersey.api.client.WebResource;
import com.sun.jersey.api.json.JSONJAXBContext;
import com.sun.jersey.api.json.JSONMarshaller;
import com.sun.jersey.core.util.MultivaluedMapImpl;
import com.sun.jersey.guice.spi.container.servlet.GuiceContainer;
import com.sun.jersey.test.framework.WebAppDescriptor;
public class TestRMWebServicesNodeLabels extends JerseyTestBase {
  private static final int BAD_REQUEST_CODE=400;
  private static final Log LOG=LogFactory.getLog(TestRMWebServicesNodeLabels.class);
  private static MockRM rm;
  private static YarnConfiguration conf;
  private static String userName;
  private static String notUserName;
  private static RMWebServices rmWebService;
private static class WebServletModule extends ServletModule {
    @Override protected void configureServlets(){
      bind(JAXBContextResolver.class);
      try {
        userName=UserGroupInformation.getCurrentUser().getShortUserName();
      }
 catch (      IOException ioe) {
        throw new RuntimeException("Unable to get current user name " + ioe.getMessage(),ioe);
      }
      notUserName=userName + "abc123";
      conf=new YarnConfiguration();
      conf.set(YarnConfiguration.YARN_ADMIN_ACL,userName);
      rm=new MockRM(conf);
      rmWebService=new RMWebServices(rm,conf);
      bind(RMWebServices.class).toInstance(rmWebService);
      bind(GenericExceptionHandler.class);
      bind(ResourceManager.class).toInstance(rm);
      filter("/*").through(TestRMWebServicesAppsModification.TestRMCustomAuthFilter.class);
      serve("/*").with(GuiceContainer.class);
    }
  }
  @Override @Before public void setUp() throws Exception {
    super.setUp();
    GuiceServletConfig.setInjector(Guice.createInjector(new WebServletModule()));
  }
  public TestRMWebServicesNodeLabels(){
    super(new WebAppDescriptor.Builder("org.apache.hadoop.yarn.server.resourcemanager.webapp").contextListenerClass(GuiceServletConfig.class).filterClass(com.google.inject.servlet.GuiceFilter.class).contextPath("jersey-guice-filter").servletPath("/").build());
  }
  @Test public void testNodeLabels() throws JSONException, Exception {
    WebResource r=resource();
    ClientResponse response;
    NodeLabelsInfo nlsifo=new NodeLabelsInfo();
    nlsifo.getNodeLabelsInfo().add(new NodeLabelInfo("a"));
    response=r.path("ws").path("v1").path("cluster").path("add-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).entity(toJson(nlsifo,NodeLabelsInfo.class),MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("get-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertEquals(1,nlsifo.getNodeLabels().size());
    for (    NodeLabelInfo nl : nlsifo.getNodeLabelsInfo()) {
      assertEquals("a",nl.getName());
      assertTrue(nl.getExclusivity());
    }
    nlsifo=new NodeLabelsInfo();
    nlsifo.getNodeLabelsInfo().add(new NodeLabelInfo("b",false));
    response=r.path("ws").path("v1").path("cluster").path("add-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).entity(toJson(nlsifo,NodeLabelsInfo.class),MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("get-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertEquals(2,nlsifo.getNodeLabels().size());
    for (    NodeLabelInfo nl : nlsifo.getNodeLabelsInfo()) {
      if (nl.getName().equals("b")) {
        assertFalse(nl.getExclusivity());
      }
    }
    MultivaluedMapImpl params=new MultivaluedMapImpl();
    params.add("labels","a");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("replace-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    LOG.info("posted node nodelabel");
    params=new MultivaluedMapImpl();
    params.add("labels","b");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid1:0").path("replace-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    LOG.info("posted node nodelabel");
    params=new MultivaluedMapImpl();
    params.add("labels","b");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid2:0").path("replace-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    LOG.info("posted node nodelabel");
    response=r.path("ws").path("v1").path("cluster").path("label-mappings").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    LabelsToNodesInfo ltni=response.getEntity(LabelsToNodesInfo.class);
    assertEquals(2,ltni.getLabelsToNodes().size());
    NodeIDsInfo nodes=ltni.getLabelsToNodes().get(new NodeLabelInfo("b",false));
    assertTrue(nodes.getNodeIDs().contains("nid2:0"));
    assertTrue(nodes.getNodeIDs().contains("nid1:0"));
    nodes=ltni.getLabelsToNodes().get(new NodeLabelInfo("a"));
    assertTrue(nodes.getNodeIDs().contains("nid:0"));
    params=new MultivaluedMapImpl();
    params.add("labels","a");
    response=r.path("ws").path("v1").path("cluster").path("label-mappings").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    ltni=response.getEntity(LabelsToNodesInfo.class);
    assertEquals(1,ltni.getLabelsToNodes().size());
    nodes=ltni.getLabelsToNodes().get(new NodeLabelInfo("a"));
    assertTrue(nodes.getNodeIDs().contains("nid:0"));
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("get-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertTrue(nlsifo.getNodeLabelsInfo().contains(new NodeLabelInfo("a")));
    params=new MultivaluedMapImpl();
    params.add("labels","b");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("replace-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    LOG.info("posted node nodelabel");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("get-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertTrue(nlsifo.getNodeLabelsInfo().contains(new NodeLabelInfo("b",false)));
    NodeToLabelsEntryList ntli=new NodeToLabelsEntryList();
    ArrayList<String> labels=new ArrayList<String>();
    labels.add("a");
    NodeToLabelsEntry nli=new NodeToLabelsEntry("nid:0",labels);
    ntli.getNodeToLabels().add(nli);
    response=r.path("ws").path("v1").path("cluster").path("replace-node-to-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).entity(toJson(ntli,NodeToLabelsEntryList.class),MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("get-node-to-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    NodeToLabelsInfo ntlinfo=response.getEntity(NodeToLabelsInfo.class);
    NodeLabelsInfo nlinfo=ntlinfo.getNodeToLabels().get("nid:0");
    assertEquals(1,nlinfo.getNodeLabels().size());
    assertTrue(nlinfo.getNodeLabelsInfo().contains(new NodeLabelInfo("a")));
    params=new MultivaluedMapImpl();
    params.add("labels","");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("replace-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    LOG.info("posted node nodelabel");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("get-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertTrue(nlsifo.getNodeLabelsInfo().isEmpty());
    params=new MultivaluedMapImpl();
    params.add("labels","a");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("replace-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    LOG.info("posted node nodelabel");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("get-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertTrue(nlsifo.getNodeLabelsInfo().contains(new NodeLabelInfo("a")));
    params=new MultivaluedMapImpl();
    params.add("labels","b");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("replace-labels").queryParam("user.name",notUserName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("get-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertTrue(nlsifo.getNodeLabelsInfo().contains(new NodeLabelInfo("a")));
    response=r.path("ws").path("v1").path("cluster").path("add-node-labels").queryParam("user.name",notUserName).accept(MediaType.APPLICATION_JSON).entity("{\"nodeLabels\":\"c\"}",MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("get-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertEquals(2,nlsifo.getNodeLabels().size());
    params=new MultivaluedMapImpl();
    params.add("labels","b");
    response=r.path("ws").path("v1").path("cluster").path("remove-node-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("get-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertEquals(1,nlsifo.getNodeLabels().size());
    for (    NodeLabelInfo nl : nlsifo.getNodeLabelsInfo()) {
      assertEquals("a",nl.getName());
      assertTrue(nl.getExclusivity());
    }
    params=new MultivaluedMapImpl();
    params.add("labels","a");
    response=r.path("ws").path("v1").path("cluster").path("remove-node-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("get-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertEquals(0,nlsifo.getNodeLabels().size());
    nlsifo=new NodeLabelsInfo();
    nlsifo.getNodeLabelsInfo().add(new NodeLabelInfo("x",false));
    nlsifo.getNodeLabelsInfo().add(new NodeLabelInfo("y",false));
    response=r.path("ws").path("v1").path("cluster").path("add-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).entity(toJson(nlsifo,NodeLabelsInfo.class),MediaType.APPLICATION_JSON).post(ClientResponse.class);
    params=new MultivaluedMapImpl();
    params.add("labels","y");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("replace-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    LOG.info("posted node nodelabel");
    rmWebService.isCentralizedNodeLabelConfiguration=false;
    ntli=new NodeToLabelsEntryList();
    labels=new ArrayList<String>();
    labels.add("x");
    nli=new NodeToLabelsEntry("nid:0",labels);
    ntli.getNodeToLabels().add(nli);
    response=r.path("ws").path("v1").path("cluster").path("replace-node-to-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).entity(toJson(ntli,NodeToLabelsEntryList.class),MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("get-node-to-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    ntlinfo=response.getEntity(NodeToLabelsInfo.class);
    nlinfo=ntlinfo.getNodeToLabels().get("nid:0");
    assertEquals(1,nlinfo.getNodeLabels().size());
    assertFalse(nlinfo.getNodeLabelsInfo().contains(new NodeLabelInfo("x",false)));
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("replace-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).entity("{\"nodeLabelName\": [\"x\"]}",MediaType.APPLICATION_JSON).post(ClientResponse.class);
    LOG.info("posted node nodelabel");
    response=r.path("ws").path("v1").path("cluster").path("get-node-to-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    ntlinfo=response.getEntity(NodeToLabelsInfo.class);
    nlinfo=ntlinfo.getNodeToLabels().get("nid:0");
    assertEquals(1,nlinfo.getNodeLabels().size());
    assertFalse(nlinfo.getNodeLabelsInfo().contains(new NodeLabelInfo("x",false)));
    params=new MultivaluedMapImpl();
    params.add("labels","x");
    response=r.path("ws").path("v1").path("cluster").path("remove-node-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("get-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertEquals(new NodeLabelInfo("y",false),nlsifo.getNodeLabelsInfo().get(0));
    assertEquals("y",nlsifo.getNodeLabelsInfo().get(0).getName());
    assertFalse(nlsifo.getNodeLabelsInfo().get(0).getExclusivity());
    params=new MultivaluedMapImpl();
    params.add("labels","y");
    response=r.path("ws").path("v1").path("cluster").path("remove-node-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("get-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertTrue(nlsifo.getNodeLabelsInfo().isEmpty());
    nlsifo=new NodeLabelsInfo();
    nlsifo.getNodeLabelsInfo().add(new NodeLabelInfo("z",false));
    response=r.path("ws").path("v1").path("cluster").path("add-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).entity(toJson(nlsifo,NodeLabelsInfo.class),MediaType.APPLICATION_JSON).post(ClientResponse.class);
    response=r.path("ws").path("v1").path("cluster").path("get-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_JSON_TYPE + "; " + JettyUtils.UTF_8,response.getType().toString());
    nlsifo=response.getEntity(NodeLabelsInfo.class);
    assertEquals("z",nlsifo.getNodeLabelsInfo().get(0).getName());
    assertFalse(nlsifo.getNodeLabelsInfo().get(0).getExclusivity());
    assertEquals(1,nlsifo.getNodeLabels().size());
  }
  @Test public void testLabelInvalidAddition() throws UniformInterfaceException, Exception {
    WebResource r=resource();
    ClientResponse response;
    NodeLabelsInfo nlsifo=new NodeLabelsInfo();
    nlsifo.getNodeLabelsInfo().add(new NodeLabelInfo("a&"));
    response=r.path("ws").path("v1").path("cluster").path("add-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).entity(toJson(nlsifo,NodeLabelsInfo.class),MediaType.APPLICATION_JSON).post(ClientResponse.class);
    String expectedmessage="java.io.IOException: label name should only contains" + " {0-9, a-z, A-Z, -, _} and should not started with" + " {-,_}, now it is= a&";
    validateJsonExceptionContent(response,expectedmessage);
  }
  @Test public void testLabelChangeExclusivity() throws Exception, JSONException {
    WebResource r=resource();
    ClientResponse response;
    NodeLabelsInfo nlsifo=new NodeLabelsInfo();
    nlsifo.getNodeLabelsInfo().add(new NodeLabelInfo("newlabel",true));
    response=r.path("ws").path("v1").path("cluster").path("add-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).entity(toJson(nlsifo,NodeLabelsInfo.class),MediaType.APPLICATION_JSON).post(ClientResponse.class);
    NodeLabelsInfo nlsinfo2=new NodeLabelsInfo();
    nlsinfo2.getNodeLabelsInfo().add(new NodeLabelInfo("newlabel",false));
    response=r.path("ws").path("v1").path("cluster").path("add-node-labels").queryParam("user.name",userName).accept(MediaType.APPLICATION_JSON).entity(toJson(nlsinfo2,NodeLabelsInfo.class),MediaType.APPLICATION_JSON).post(ClientResponse.class);
    String expectedmessage="java.io.IOException: Exclusivity cannot be modified for an existing" + " label with : <newlabel:exclusivity=false>";
    validateJsonExceptionContent(response,expectedmessage);
  }
  private void validateJsonExceptionContent(  ClientResponse response,  String expectedmessage) throws JSONException {
    Assert.assertEquals(BAD_REQUEST_CODE,response.getStatus());
    JSONObject msg=response.getEntity(JSONObject.class);
    JSONObject exception=msg.getJSONObject("RemoteException");
    String message=exception.getString("message");
    assertEquals("incorrect number of elements",3,exception.length());
    String type=exception.getString("exception");
    String classname=exception.getString("javaClassName");
    WebServicesTestUtils.checkStringMatch("exception type","BadRequestException",type);
    WebServicesTestUtils.checkStringMatch("exception classname","org.apache.hadoop.yarn.webapp.BadRequestException",classname);
    WebServicesTestUtils.checkStringContains("exception message",expectedmessage,message);
  }
  @Test public void testLabelInvalidReplace() throws UniformInterfaceException, Exception {
    WebResource r=resource();
    ClientResponse response;
    MultivaluedMapImpl params=new MultivaluedMapImpl();
    params.add("labels","idontexist");
    response=r.path("ws").path("v1").path("cluster").path("nodes").path("nid:0").path("replace-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    String expectedmessage="Not all labels being replaced contained by known label" + " collections, please check, new labels=[idontexist]";
    validateJsonExceptionContent(response,expectedmessage);
  }
  @Test public void testLabelInvalidRemove() throws UniformInterfaceException, Exception {
    WebResource r=resource();
    ClientResponse response;
    MultivaluedMapImpl params=new MultivaluedMapImpl();
    params.add("labels","irealldontexist");
    response=r.path("ws").path("v1").path("cluster").path("remove-node-labels").queryParam("user.name",userName).queryParams(params).accept(MediaType.APPLICATION_JSON).post(ClientResponse.class);
    String expectedmessage="java.io.IOException: Node label=irealldontexist to be" + " removed doesn't existed in cluster node labels" + " collection.";
    validateJsonExceptionContent(response,expectedmessage);
  }
  @SuppressWarnings("rawtypes") private String toJson(  Object nsli,  Class klass) throws Exception {
    StringWriter sw=new StringWriter();
    JSONJAXBContext ctx=new JSONJAXBContext(klass);
    JSONMarshaller jm=ctx.createJSONMarshaller();
    jm.marshallToJSON(nsli,sw);
    return sw.toString();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at <p> http://www.apache.org/licenses/LICENSE-2.0 <p> Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity;
import org.junit.Before;
import org.junit.Test;
import static org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoCreatedQueueBase.C;
import static org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoCreatedQueueBase.D;
import static org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoCreatedQueueBase.E;
import static org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoCreatedQueueBase.USER0;
import static org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoCreatedQueueBase.USER1;
import static org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoCreatedQueueBase.USER2;
import static org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacitySchedulerAutoCreatedQueueBase.USER3;
/** 
 * Tests various preemption cases on auto-created leaf queues. All auto-created leaf queues will end up having same priority since they are set from template. Priority on ManagedParent Queues can be set however and priority based premption cases are based on that.
 */
public class TestCapacitySchedulerAutoCreatedQueuePreemption extends TestCapacitySchedulerSurgicalPreemption {
  @Override @Before public void setUp() throws Exception {
    super.setUp();
  }
  public static CapacitySchedulerConfiguration setupQueueConfigurationForSimpleSurgicalPreemption(  CapacitySchedulerConfiguration conf){
    TestCapacitySchedulerAutoCreatedQueueBase.setupQueueMappings(conf,"c",true,new int[]{1,2});
    conf.setQueues(CapacitySchedulerConfiguration.ROOT,new String[]{"c"});
    conf.setCapacity(C,100f);
    conf.setUserLimitFactor(C,1.0f);
    conf.setAutoCreateChildQueueEnabled(C,true);
    conf.setAutoCreatedLeafQueueConfigCapacity(C,30.0f);
    conf.setAutoCreatedLeafQueueConfigMaxCapacity(C,100.0f);
    conf.setAutoCreatedLeafQueueConfigUserLimit(C,100);
    conf.setAutoCreatedLeafQueueConfigUserLimitFactor(C,3.0f);
    return conf;
  }
  protected CapacitySchedulerConfiguration setupQueueConfigurationForPriorityBasedPreemption(  CapacitySchedulerConfiguration conf){
    TestCapacitySchedulerAutoCreatedQueueBase.setupQueueMappings(conf,"c",true,new int[]{1,2});
    TestCapacitySchedulerAutoCreatedQueueBase.setupQueueMappings(conf,"d",true,new int[]{3,4});
    TestCapacitySchedulerAutoCreatedQueueBase.setupQueueMappings(conf,"e",true,new int[]{0});
    conf.setQueues(CapacitySchedulerConfiguration.ROOT,new String[]{"c","d","e"});
    conf.setCapacity(C,45f);
    conf.setCapacity(D,45f);
    conf.setCapacity(E,10f);
    conf.setUserLimitFactor(E,3.0f);
    conf.setUserLimitFactor(C,3.0f);
    conf.setUserLimitFactor(D,3.0f);
    conf.setAutoCreateChildQueueEnabled(C,true);
    conf.setAutoCreateChildQueueEnabled(D,true);
    conf.setAutoCreateChildQueueEnabled(E,true);
    conf.setAutoCreatedLeafQueueConfigCapacity(C,100f);
    conf.setAutoCreatedLeafQueueConfigMaxCapacity(C,100.0f);
    conf.setAutoCreatedLeafQueueConfigUserLimit(C,100);
    conf.setAutoCreatedLeafQueueConfigUserLimitFactor(C,3.0f);
    conf.setAutoCreatedLeafQueueConfigCapacity(D,100.0f);
    conf.setAutoCreatedLeafQueueConfigMaxCapacity(D,100.0f);
    conf.setAutoCreatedLeafQueueConfigUserLimit(D,100);
    conf.setAutoCreatedLeafQueueConfigUserLimitFactor(D,3.0f);
    conf.setAutoCreatedLeafQueueConfigCapacity(E,100.0f);
    conf.setAutoCreatedLeafQueueConfigMaxCapacity(E,100.0f);
    conf.setAutoCreatedLeafQueueConfigUserLimit(E,100);
    conf.setAutoCreatedLeafQueueConfigUserLimitFactor(E,3.0f);
    conf.setQueuePriority(CapacitySchedulerConfiguration.ROOT + ".c",1);
    conf.setQueuePriority(CapacitySchedulerConfiguration.ROOT + ".d",2);
    return conf;
  }
  @Test(timeout=60000) public void testSimpleSurgicalPreemptionOnAutoCreatedLeafQueues() throws Exception {
    setupQueueConfigurationForSimpleSurgicalPreemption(conf);
    testSimpleSurgicalPreemption(USER1,USER2,USER1,USER2);
  }
  @Test(timeout=600000) public void testPreemptionFromHighestPriorityManagedParentQueueAndOldestContainer() throws Exception {
    setupQueueConfigurationForPriorityBasedPreemption(conf);
    testPriorityPreemptionFromHighestPriorityQueueAndOldestContainer(new String[]{USER1,USER3,USER0},new String[]{USER1,USER3,USER0});
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.server.resourcemanager.blacklist;
import java.util.Collections;
import java.util.List;
import org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest;
import org.junit.Assert;
import org.junit.Test;
public class TestBlacklistManager {
  @Test public void testSimpleBlacklistBelowFailureThreshold(){
    final int numberOfNodeManagerHosts=3;
    final double blacklistDisableFailureThreshold=0.8;
    BlacklistManager manager=new SimpleBlacklistManager(numberOfNodeManagerHosts,blacklistDisableFailureThreshold);
    String anyNode="foo";
    String anyNode2="bar";
    manager.addNode(anyNode);
    manager.addNode(anyNode2);
    ResourceBlacklistRequest blacklist=manager.getBlacklistUpdates();
    List<String> blacklistAdditions=blacklist.getBlacklistAdditions();
    Collections.sort(blacklistAdditions);
    List<String> blacklistRemovals=blacklist.getBlacklistRemovals();
    String[] expectedBlacklistAdditions=new String[]{anyNode2,anyNode};
    Assert.assertArrayEquals("Blacklist additions was not as expected",expectedBlacklistAdditions,blacklistAdditions.toArray());
    Assert.assertTrue("Blacklist removals should be empty but was " + blacklistRemovals,blacklistRemovals.isEmpty());
  }
  @Test public void testSimpleBlacklistAboveFailureThreshold(){
    BlacklistManager manager=new SimpleBlacklistManager(3,0.5);
    String anyNode="foo";
    String anyNode2="bar";
    manager.addNode(anyNode);
    ResourceBlacklistRequest blacklist=manager.getBlacklistUpdates();
    List<String> blacklistAdditions=blacklist.getBlacklistAdditions();
    Collections.sort(blacklistAdditions);
    List<String> blacklistRemovals=blacklist.getBlacklistRemovals();
    String[] expectedBlacklistAdditions=new String[]{anyNode};
    Assert.assertArrayEquals("Blacklist additions was not as expected",expectedBlacklistAdditions,blacklistAdditions.toArray());
    Assert.assertTrue("Blacklist removals should be empty but was " + blacklistRemovals,blacklistRemovals.isEmpty());
    manager.addNode(anyNode2);
    blacklist=manager.getBlacklistUpdates();
    blacklistAdditions=blacklist.getBlacklistAdditions();
    Collections.sort(blacklistAdditions);
    blacklistRemovals=blacklist.getBlacklistRemovals();
    Collections.sort(blacklistRemovals);
    String[] expectedBlacklistRemovals=new String[]{anyNode2,anyNode};
    Assert.assertTrue("Blacklist additions should be empty but was " + blacklistAdditions,blacklistAdditions.isEmpty());
    Assert.assertArrayEquals("Blacklist removals was not as expected",expectedBlacklistRemovals,blacklistRemovals.toArray());
  }
  @Test public void testDisabledBlacklist(){
    BlacklistManager disabled=new DisabledBlacklistManager();
    String anyNode="foo";
    disabled.addNode(anyNode);
    ResourceBlacklistRequest blacklist=disabled.getBlacklistUpdates();
    List<String> blacklistAdditions=blacklist.getBlacklistAdditions();
    List<String> blacklistRemovals=blacklist.getBlacklistRemovals();
    Assert.assertTrue("Blacklist additions should be empty but was " + blacklistAdditions,blacklistAdditions.isEmpty());
    Assert.assertTrue("Blacklist removals should be empty but was " + blacklistRemovals,blacklistRemovals.isEmpty());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.server.resourcemanager;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.when;
import java.io.IOException;
import java.security.PrivilegedExceptionAction;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.security.SaslRpcServer.AuthMethod;
import org.apache.hadoop.security.UserGroupInformation;
import org.apache.hadoop.security.UserGroupInformation.AuthenticationMethod;
import org.apache.hadoop.security.authentication.util.KerberosName;
import org.apache.hadoop.security.token.Token;
import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest;
import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest;
import org.apache.hadoop.yarn.exceptions.YarnException;
import org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier;
import org.apache.hadoop.yarn.server.resourcemanager.recovery.NullRMStateStore;
import org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager;
import org.apache.hadoop.yarn.server.utils.BuilderUtils;
import org.apache.hadoop.yarn.util.Records;
import org.junit.AfterClass;
import org.junit.Assert;
import org.junit.BeforeClass;
import org.junit.Test;
public class TestTokenClientRMService {
  private final static String kerberosRule="RULE:[1:$1@$0](.*@EXAMPLE.COM)s/@.*//\nDEFAULT";
  private static RMDelegationTokenSecretManager dtsm;
static {
    KerberosName.setRules(kerberosRule);
  }
  private static final UserGroupInformation owner=UserGroupInformation.createRemoteUser("owner",AuthMethod.KERBEROS);
  private static final UserGroupInformation other=UserGroupInformation.createRemoteUser("other",AuthMethod.KERBEROS);
  private static final UserGroupInformation tester=UserGroupInformation.createRemoteUser("tester",AuthMethod.KERBEROS);
  private static final String testerPrincipal="tester@EXAMPLE.COM";
  private static final String ownerPrincipal="owner@EXAMPLE.COM";
  private static final String otherPrincipal="other@EXAMPLE.COM";
  private static final UserGroupInformation testerKerb=UserGroupInformation.createRemoteUser(testerPrincipal,AuthMethod.KERBEROS);
  private static final UserGroupInformation ownerKerb=UserGroupInformation.createRemoteUser(ownerPrincipal,AuthMethod.KERBEROS);
  private static final UserGroupInformation otherKerb=UserGroupInformation.createRemoteUser(otherPrincipal,AuthMethod.KERBEROS);
  @BeforeClass public static void setupSecretManager() throws IOException {
    ResourceManager rm=mock(ResourceManager.class);
    RMContext rmContext=mock(RMContext.class);
    when(rmContext.getStateStore()).thenReturn(new NullRMStateStore());
    when(rm.getRMContext()).thenReturn(rmContext);
    when(rmContext.getResourceManager()).thenReturn(rm);
    dtsm=new RMDelegationTokenSecretManager(60000,60000,60000,60000,rmContext);
    dtsm.startThreads();
    Configuration conf=new Configuration();
    conf.set("hadoop.security.authentication","kerberos");
    conf.set("hadoop.security.auth_to_local",kerberosRule);
    UserGroupInformation.setConfiguration(conf);
    UserGroupInformation.getLoginUser().setAuthenticationMethod(AuthenticationMethod.KERBEROS);
  }
  @AfterClass public static void teardownSecretManager(){
    if (dtsm != null) {
      dtsm.stopThreads();
    }
  }
  @Test public void testTokenCancellationByOwner() throws Exception {
    RMContext rmContext=mock(RMContext.class);
    final ClientRMService rmService=new ClientRMService(rmContext,null,null,null,null,dtsm);
    testerKerb.doAs(new PrivilegedExceptionAction<Void>(){
      @Override public Void run() throws Exception {
        checkTokenCancellation(rmService,testerKerb,other);
        return null;
      }
    }
);
    owner.doAs(new PrivilegedExceptionAction<Void>(){
      @Override public Void run() throws Exception {
        checkTokenCancellation(owner,other);
        return null;
      }
    }
);
  }
  @Test public void testTokenRenewalWrongUser() throws Exception {
    try {
      owner.doAs(new PrivilegedExceptionAction<Void>(){
        @Override public Void run() throws Exception {
          try {
            checkTokenRenewal(owner,other);
            return null;
          }
 catch (          YarnException ex) {
            Assert.assertTrue(ex.getMessage().contains(owner.getUserName() + " tries to renew a token"));
            Assert.assertTrue(ex.getMessage().contains("with non-matching renewer " + other.getUserName()));
            throw ex;
          }
        }
      }
);
    }
 catch (    Exception e) {
      return;
    }
    Assert.fail("renew should have failed");
  }
  @Test public void testTokenRenewalByLoginUser() throws Exception {
    UserGroupInformation.getLoginUser().doAs(new PrivilegedExceptionAction<Void>(){
      @Override public Void run() throws Exception {
        checkTokenRenewal(owner,owner);
        checkTokenRenewal(owner,other);
        return null;
      }
    }
);
  }
  private void checkTokenRenewal(  UserGroupInformation owner,  UserGroupInformation renewer) throws IOException, YarnException {
    RMDelegationTokenIdentifier tokenIdentifier=new RMDelegationTokenIdentifier(new Text(owner.getUserName()),new Text(renewer.getUserName()),null);
    Token<?> token=new Token<RMDelegationTokenIdentifier>(tokenIdentifier,dtsm);
    org.apache.hadoop.yarn.api.records.Token dToken=BuilderUtils.newDelegationToken(token.getIdentifier(),token.getKind().toString(),token.getPassword(),token.getService().toString());
    RenewDelegationTokenRequest request=Records.newRecord(RenewDelegationTokenRequest.class);
    request.setDelegationToken(dToken);
    RMContext rmContext=mock(RMContext.class);
    ClientRMService rmService=new ClientRMService(rmContext,null,null,null,null,dtsm);
    rmService.renewDelegationToken(request);
  }
  @Test public void testTokenCancellationByRenewer() throws Exception {
    RMContext rmContext=mock(RMContext.class);
    final ClientRMService rmService=new ClientRMService(rmContext,null,null,null,null,dtsm);
    testerKerb.doAs(new PrivilegedExceptionAction<Void>(){
      @Override public Void run() throws Exception {
        checkTokenCancellation(rmService,owner,testerKerb);
        return null;
      }
    }
);
    other.doAs(new PrivilegedExceptionAction<Void>(){
      @Override public Void run() throws Exception {
        checkTokenCancellation(owner,other);
        return null;
      }
    }
);
  }
  @Test public void testTokenCancellationByWrongUser(){
    RMContext rmContext=mock(RMContext.class);
    final ClientRMService rmService=new ClientRMService(rmContext,null,null,null,null,dtsm);
    UserGroupInformation[] kerbTestOwners={owner,other,tester,ownerKerb,otherKerb};
    UserGroupInformation[] kerbTestRenewers={owner,other,ownerKerb,otherKerb};
    for (    final UserGroupInformation tokOwner : kerbTestOwners) {
      for (      final UserGroupInformation tokRenewer : kerbTestRenewers) {
        try {
          testerKerb.doAs(new PrivilegedExceptionAction<Void>(){
            @Override public Void run() throws Exception {
              try {
                checkTokenCancellation(rmService,tokOwner,tokRenewer);
                Assert.fail("We should not reach here; token owner = " + tokOwner.getUserName() + ", renewer = "+ tokRenewer.getUserName());
                return null;
              }
 catch (              YarnException e) {
                Assert.assertTrue(e.getMessage().contains(testerKerb.getUserName() + " is not authorized to cancel the token"));
                return null;
              }
            }
          }
);
        }
 catch (        Exception e) {
          Assert.fail("Unexpected exception; " + e.getMessage());
        }
      }
    }
    UserGroupInformation[] simpleTestOwners={owner,other,ownerKerb,otherKerb,testerKerb};
    UserGroupInformation[] simpleTestRenewers={owner,other,ownerKerb,otherKerb};
    for (    final UserGroupInformation tokOwner : simpleTestOwners) {
      for (      final UserGroupInformation tokRenewer : simpleTestRenewers) {
        try {
          tester.doAs(new PrivilegedExceptionAction<Void>(){
            @Override public Void run() throws Exception {
              try {
                checkTokenCancellation(tokOwner,tokRenewer);
                Assert.fail("We should not reach here; token owner = " + tokOwner.getUserName() + ", renewer = "+ tokRenewer.getUserName());
                return null;
              }
 catch (              YarnException ex) {
                Assert.assertTrue(ex.getMessage().contains(tester.getUserName() + " is not authorized to cancel the token"));
                return null;
              }
            }
          }
);
        }
 catch (        Exception e) {
          Assert.fail("Unexpected exception; " + e.getMessage());
        }
      }
    }
  }
  private void checkTokenCancellation(  UserGroupInformation owner,  UserGroupInformation renewer) throws IOException, YarnException {
    RMContext rmContext=mock(RMContext.class);
    final ClientRMService rmService=new ClientRMService(rmContext,null,null,null,null,dtsm);
    checkTokenCancellation(rmService,owner,renewer);
  }
  private void checkTokenCancellation(  ClientRMService rmService,  UserGroupInformation owner,  UserGroupInformation renewer) throws IOException, YarnException {
    RMDelegationTokenIdentifier tokenIdentifier=new RMDelegationTokenIdentifier(new Text(owner.getUserName()),new Text(renewer.getUserName()),null);
    Token<?> token=new Token<RMDelegationTokenIdentifier>(tokenIdentifier,dtsm);
    org.apache.hadoop.yarn.api.records.Token dToken=BuilderUtils.newDelegationToken(token.getIdentifier(),token.getKind().toString(),token.getPassword(),token.getService().toString());
    CancelDelegationTokenRequest request=Records.newRecord(CancelDelegationTokenRequest.class);
    request.setDelegationToken(dToken);
    rmService.cancelDelegationToken(request);
  }
  @Test public void testTokenRenewalByOwner() throws Exception {
    owner.doAs(new PrivilegedExceptionAction<Void>(){
      @Override public Void run() throws Exception {
        checkTokenRenewal(owner,owner);
        return null;
      }
    }
);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.server.nodemanager;
import static org.apache.hadoop.yarn.server.utils.YarnServerBuilderUtils.newNodeHeartbeatResponse;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.when;
import java.io.EOFException;
import java.io.File;
import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ConcurrentMap;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.CyclicBarrier;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileContext;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.DataOutputBuffer;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.retry.RetryPolicy;
import org.apache.hadoop.io.retry.RetryProxy;
import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
import org.apache.hadoop.net.NetUtils;
import org.apache.hadoop.net.ServerSocketUtil;
import org.apache.hadoop.security.Credentials;
import org.apache.hadoop.security.token.delegation.web.DelegationTokenIdentifier;
import org.apache.hadoop.service.Service.STATE;
import org.apache.hadoop.service.ServiceOperations;
import org.apache.hadoop.util.concurrent.HadoopExecutors;
import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest;
import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
import org.apache.hadoop.yarn.api.records.ApplicationId;
import org.apache.hadoop.yarn.api.records.ContainerId;
import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
import org.apache.hadoop.yarn.api.records.ContainerState;
import org.apache.hadoop.yarn.api.records.ContainerStatus;
import org.apache.hadoop.yarn.api.records.NodeId;
import org.apache.hadoop.yarn.api.records.Resource;
import org.apache.hadoop.yarn.api.records.SignalContainerCommand;
import org.apache.hadoop.yarn.api.records.Token;
import org.apache.hadoop.yarn.client.RMProxy;
import org.apache.hadoop.yarn.conf.HAUtil;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.apache.hadoop.yarn.event.Dispatcher;
import org.apache.hadoop.yarn.event.Event;
import org.apache.hadoop.yarn.event.EventHandler;
import org.apache.hadoop.yarn.exceptions.YarnException;
import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
import org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto;
import org.apache.hadoop.yarn.security.ContainerTokenIdentifier;
import org.apache.hadoop.yarn.server.api.ResourceTracker;
import org.apache.hadoop.yarn.server.api.protocolrecords.NodeHeartbeatRequest;
import org.apache.hadoop.yarn.server.api.protocolrecords.NodeHeartbeatResponse;
import org.apache.hadoop.yarn.server.api.protocolrecords.RegisterNodeManagerRequest;
import org.apache.hadoop.yarn.server.api.protocolrecords.RegisterNodeManagerResponse;
import org.apache.hadoop.yarn.server.api.protocolrecords.UnRegisterNodeManagerRequest;
import org.apache.hadoop.yarn.server.api.protocolrecords.UnRegisterNodeManagerResponse;
import org.apache.hadoop.yarn.server.api.protocolrecords.impl.pb.NodeHeartbeatResponsePBImpl;
import org.apache.hadoop.yarn.server.api.records.MasterKey;
import org.apache.hadoop.yarn.server.api.records.NodeAction;
import org.apache.hadoop.yarn.server.api.records.NodeStatus;
import org.apache.hadoop.yarn.server.api.records.impl.pb.MasterKeyPBImpl;
import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
import org.apache.hadoop.yarn.server.nodemanager.NodeManager.NMContext;
import org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl;
import org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application;
import org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationState;
import org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container;
import org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl;
import org.apache.hadoop.yarn.server.nodemanager.metrics.NodeManagerMetrics;
import org.apache.hadoop.yarn.server.nodemanager.recovery.NMNullStateStoreService;
import org.apache.hadoop.yarn.server.nodemanager.recovery.NMStateStoreService;
import org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager;
import org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM;
import org.apache.hadoop.yarn.server.security.ApplicationACLsManager;
import org.apache.hadoop.yarn.server.utils.BuilderUtils;
import org.apache.hadoop.yarn.server.utils.YarnServerBuilderUtils;
import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;
@SuppressWarnings("rawtypes") public class TestNodeStatusUpdater extends NodeManagerTestBase {
  volatile int heartBeatID=0;
  volatile Throwable nmStartError=null;
  private final List<NodeId> registeredNodes=new ArrayList<NodeId>();
  private boolean triggered=false;
  private NodeManager nm;
  private AtomicBoolean assertionFailedInThread=new AtomicBoolean(false);
  @After public void tearDown(){
    this.registeredNodes.clear();
    heartBeatID=0;
    ServiceOperations.stop(nm);
    assertionFailedInThread.set(false);
    DefaultMetricsSystem.shutdown();
  }
  public static MasterKey createMasterKey(){
    MasterKey masterKey=new MasterKeyPBImpl();
    masterKey.setKeyId(123);
    masterKey.setBytes(ByteBuffer.wrap(new byte[]{new Integer(123).byteValue()}));
    return masterKey;
  }
private class MyResourceTracker implements ResourceTracker {
    private final Context context;
    private boolean signalContainer;
    public MyResourceTracker(    Context context,    boolean signalContainer){
      this.context=context;
      this.signalContainer=signalContainer;
    }
    @Override public RegisterNodeManagerResponse registerNodeManager(    RegisterNodeManagerRequest request) throws YarnException, IOException {
      NodeId nodeId=request.getNodeId();
      Resource resource=request.getResource();
      LOG.info("Registering " + nodeId.toString());
      InetSocketAddress expected=NetUtils.getConnectAddress(conf.getSocketAddr(YarnConfiguration.NM_ADDRESS,null,-1));
      Assert.assertEquals(NetUtils.getHostPortString(expected),nodeId.toString());
      Assert.assertEquals(5 * 1024,resource.getMemorySize());
      registeredNodes.add(nodeId);
      RegisterNodeManagerResponse response=recordFactory.newRecordInstance(RegisterNodeManagerResponse.class);
      response.setContainerTokenMasterKey(createMasterKey());
      response.setNMTokenMasterKey(createMasterKey());
      return response;
    }
    private Map<ApplicationId,List<ContainerStatus>> getAppToContainerStatusMap(    List<ContainerStatus> containers){
      Map<ApplicationId,List<ContainerStatus>> map=new HashMap<ApplicationId,List<ContainerStatus>>();
      for (      ContainerStatus cs : containers) {
        ApplicationId applicationId=cs.getContainerId().getApplicationAttemptId().getApplicationId();
        List<ContainerStatus> appContainers=map.get(applicationId);
        if (appContainers == null) {
          appContainers=new ArrayList<ContainerStatus>();
          map.put(applicationId,appContainers);
        }
        appContainers.add(cs);
      }
      return map;
    }
    @Override public NodeHeartbeatResponse nodeHeartbeat(    NodeHeartbeatRequest request) throws YarnException, IOException {
      NodeStatus nodeStatus=request.getNodeStatus();
      LOG.info("Got heartbeat number " + heartBeatID);
      NodeManagerMetrics mockMetrics=mock(NodeManagerMetrics.class);
      Dispatcher mockDispatcher=mock(Dispatcher.class);
      @SuppressWarnings("unchecked") EventHandler<Event> mockEventHandler=mock(EventHandler.class);
      when(mockDispatcher.getEventHandler()).thenReturn(mockEventHandler);
      NMStateStoreService stateStore=new NMNullStateStoreService();
      nodeStatus.setResponseId(heartBeatID++);
      Map<ApplicationId,List<ContainerStatus>> appToContainers=getAppToContainerStatusMap(nodeStatus.getContainersStatuses());
      List<SignalContainerRequest> containersToSignal=null;
      ApplicationId appId1=ApplicationId.newInstance(0,1);
      ApplicationId appId2=ApplicationId.newInstance(0,2);
      ContainerId firstContainerID=null;
      if (heartBeatID == 1) {
        Assert.assertEquals(0,nodeStatus.getContainersStatuses().size());
        ApplicationAttemptId appAttemptID=ApplicationAttemptId.newInstance(appId1,0);
        firstContainerID=ContainerId.newContainerId(appAttemptID,heartBeatID);
        ContainerLaunchContext launchContext=recordFactory.newRecordInstance(ContainerLaunchContext.class);
        Resource resource=BuilderUtils.newResource(2,1);
        long currentTime=System.currentTimeMillis();
        String user="testUser";
        ContainerTokenIdentifier containerToken=BuilderUtils.newContainerTokenIdentifier(BuilderUtils.newContainerToken(firstContainerID,0,InetAddress.getByName("localhost").getCanonicalHostName(),1234,user,resource,currentTime + 10000,123,"password".getBytes(),currentTime));
        Context context=mock(Context.class);
        when(context.getNMStateStore()).thenReturn(stateStore);
        Container container=new ContainerImpl(conf,mockDispatcher,launchContext,null,mockMetrics,containerToken,context);
        this.context.getContainers().put(firstContainerID,container);
      }
 else       if (heartBeatID == 2) {
        Assert.assertEquals("Number of applications should only be one!",1,nodeStatus.getContainersStatuses().size());
        Assert.assertEquals("Number of container for the app should be one!",1,appToContainers.get(appId1).size());
        ConcurrentMap<ContainerId,Container> activeContainers=this.context.getContainers();
        Assert.assertEquals(1,activeContainers.size());
        if (this.signalContainer) {
          containersToSignal=new ArrayList<SignalContainerRequest>();
          SignalContainerRequest signalReq=recordFactory.newRecordInstance(SignalContainerRequest.class);
          signalReq.setContainerId(firstContainerID);
          signalReq.setCommand(SignalContainerCommand.OUTPUT_THREAD_DUMP);
          containersToSignal.add(signalReq);
        }
        ApplicationAttemptId appAttemptID=ApplicationAttemptId.newInstance(appId2,0);
        ContainerId secondContainerID=ContainerId.newContainerId(appAttemptID,heartBeatID);
        ContainerLaunchContext launchContext=recordFactory.newRecordInstance(ContainerLaunchContext.class);
        long currentTime=System.currentTimeMillis();
        String user="testUser";
        Resource resource=BuilderUtils.newResource(3,1);
        ContainerTokenIdentifier containerToken=BuilderUtils.newContainerTokenIdentifier(BuilderUtils.newContainerToken(secondContainerID,0,InetAddress.getByName("localhost").getCanonicalHostName(),1234,user,resource,currentTime + 10000,123,"password".getBytes(),currentTime));
        Context context=mock(Context.class);
        when(context.getNMStateStore()).thenReturn(stateStore);
        Container container=new ContainerImpl(conf,mockDispatcher,launchContext,null,mockMetrics,containerToken,context);
        this.context.getContainers().put(secondContainerID,container);
      }
 else       if (heartBeatID == 3) {
        Assert.assertEquals("Number of applications should have two!",2,appToContainers.size());
        Assert.assertEquals("Number of container for the app-1 should be only one!",1,appToContainers.get(appId1).size());
        Assert.assertEquals("Number of container for the app-2 should be only one!",1,appToContainers.get(appId2).size());
        ConcurrentMap<ContainerId,Container> activeContainers=this.context.getContainers();
        Assert.assertEquals(2,activeContainers.size());
      }
      NodeHeartbeatResponse nhResponse=YarnServerBuilderUtils.newNodeHeartbeatResponse(heartBeatID,null,null,null,null,null,1000L);
      if (containersToSignal != null) {
        nhResponse.addAllContainersToSignal(containersToSignal);
      }
      return nhResponse;
    }
    @Override public UnRegisterNodeManagerResponse unRegisterNodeManager(    UnRegisterNodeManagerRequest request) throws YarnException, IOException {
      return recordFactory.newRecordInstance(UnRegisterNodeManagerResponse.class);
    }
  }
private class MyNodeStatusUpdater extends BaseNodeStatusUpdaterForTest {
    public MyNodeStatusUpdater(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker,    NodeManagerMetrics metrics){
      this(context,dispatcher,healthChecker,metrics,false);
    }
    public MyNodeStatusUpdater(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker,    NodeManagerMetrics metrics,    boolean signalContainer){
      super(context,dispatcher,healthChecker,metrics,new MyResourceTracker(context,signalContainer));
    }
  }
private class MyNodeStatusUpdater2 extends NodeStatusUpdaterImpl {
    public ResourceTracker resourceTracker;
    public MyNodeStatusUpdater2(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker,    NodeManagerMetrics metrics){
      super(context,dispatcher,healthChecker,metrics);
      resourceTracker=new MyResourceTracker4(context);
    }
    @Override protected ResourceTracker getRMClient(){
      return resourceTracker;
    }
    @Override protected void stopRMProxy(){
      return;
    }
  }
private class MyNodeStatusUpdater3 extends NodeStatusUpdaterImpl {
    public ResourceTracker resourceTracker;
    private Context context;
    public MyNodeStatusUpdater3(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker,    NodeManagerMetrics metrics){
      super(context,dispatcher,healthChecker,metrics);
      this.context=context;
      this.resourceTracker=new MyResourceTracker3(this.context);
    }
    @Override protected ResourceTracker getRMClient(){
      return resourceTracker;
    }
    @Override protected void stopRMProxy(){
      return;
    }
    @Override protected boolean isTokenKeepAliveEnabled(    Configuration conf){
      return true;
    }
  }
private class MyNodeStatusUpdater4 extends NodeStatusUpdaterImpl {
    private final long rmStartIntervalMS;
    private final boolean rmNeverStart;
    public ResourceTracker resourceTracker;
    public MyNodeStatusUpdater4(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker,    NodeManagerMetrics metrics,    long rmStartIntervalMS,    boolean rmNeverStart){
      super(context,dispatcher,healthChecker,metrics);
      this.rmStartIntervalMS=rmStartIntervalMS;
      this.rmNeverStart=rmNeverStart;
    }
    @Override protected void serviceStart() throws Exception {
      super.serviceStart();
    }
    @Override protected ResourceTracker getRMClient() throws IOException {
      RetryPolicy retryPolicy=RMProxy.createRetryPolicy(conf,HAUtil.isHAEnabled(conf));
      resourceTracker=(ResourceTracker)RetryProxy.create(ResourceTracker.class,new MyResourceTracker6(rmStartIntervalMS,rmNeverStart),retryPolicy);
      return resourceTracker;
    }
    private boolean isTriggered(){
      return triggered;
    }
    @Override protected void stopRMProxy(){
      return;
    }
  }
private class MyNodeStatusUpdater5 extends NodeStatusUpdaterImpl {
    private ResourceTracker resourceTracker;
    private Configuration conf;
    public MyNodeStatusUpdater5(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker,    NodeManagerMetrics metrics,    Configuration conf){
      super(context,dispatcher,healthChecker,metrics);
      resourceTracker=new MyResourceTracker5();
      this.conf=conf;
    }
    @Override protected ResourceTracker getRMClient(){
      RetryPolicy retryPolicy=RMProxy.createRetryPolicy(conf,HAUtil.isHAEnabled(conf));
      return (ResourceTracker)RetryProxy.create(ResourceTracker.class,resourceTracker,retryPolicy);
    }
    @Override protected void stopRMProxy(){
      return;
    }
  }
private class MyNodeStatusUpdater6 extends NodeStatusUpdaterImpl {
    private final long rmStartIntervalMS;
    private final boolean rmNeverStart;
    public ResourceTracker resourceTracker;
    public MyNodeStatusUpdater6(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker,    NodeManagerMetrics metrics,    long rmStartIntervalMS,    boolean rmNeverStart){
      super(context,dispatcher,healthChecker,metrics);
      this.rmStartIntervalMS=rmStartIntervalMS;
      this.rmNeverStart=rmNeverStart;
    }
    @Override protected void serviceStart() throws Exception {
      super.serviceStart();
    }
    private boolean isTriggered(){
      return triggered;
    }
    @Override protected void stopRMProxy(){
      return;
    }
  }
private class MyNodeManager extends NodeManager {
    private MyNodeStatusUpdater3 nodeStatusUpdater;
    @Override protected NodeStatusUpdater createNodeStatusUpdater(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker){
      this.nodeStatusUpdater=new MyNodeStatusUpdater3(context,dispatcher,healthChecker,metrics);
      return this.nodeStatusUpdater;
    }
    public MyNodeStatusUpdater3 getNodeStatusUpdater(){
      return this.nodeStatusUpdater;
    }
  }
private class MyNodeManager2 extends NodeManager {
    public boolean isStopped=false;
    private NodeStatusUpdater nodeStatusUpdater;
    private CyclicBarrier syncBarrier;
    private Configuration conf;
    public MyNodeManager2(    CyclicBarrier syncBarrier,    Configuration conf){
      this.syncBarrier=syncBarrier;
      this.conf=conf;
    }
    @Override protected NodeStatusUpdater createNodeStatusUpdater(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker){
      nodeStatusUpdater=new MyNodeStatusUpdater5(context,dispatcher,healthChecker,metrics,conf);
      return nodeStatusUpdater;
    }
    @Override protected void serviceStop() throws Exception {
      syncBarrier.await(10000,TimeUnit.MILLISECONDS);
      System.out.println("Called stooppppp");
      super.serviceStop();
      isStopped=true;
      ConcurrentMap<ApplicationId,Application> applications=getNMContext().getApplications();
      if (!applications.isEmpty()) {
        assertionFailedInThread.set(true);
      }
      syncBarrier.await(10000,TimeUnit.MILLISECONDS);
    }
  }
private class MyResourceTracker2 implements ResourceTracker {
    public NodeAction heartBeatNodeAction=NodeAction.NORMAL;
    public NodeAction registerNodeAction=NodeAction.NORMAL;
    public String shutDownMessage="";
    public String rmVersion="3.0.1";
    @Override public RegisterNodeManagerResponse registerNodeManager(    RegisterNodeManagerRequest request) throws YarnException, IOException {
      RegisterNodeManagerResponse response=recordFactory.newRecordInstance(RegisterNodeManagerResponse.class);
      response.setNodeAction(registerNodeAction);
      response.setContainerTokenMasterKey(createMasterKey());
      response.setNMTokenMasterKey(createMasterKey());
      response.setDiagnosticsMessage(shutDownMessage);
      response.setRMVersion(rmVersion);
      return response;
    }
    @Override public NodeHeartbeatResponse nodeHeartbeat(    NodeHeartbeatRequest request) throws YarnException, IOException {
      NodeStatus nodeStatus=request.getNodeStatus();
      nodeStatus.setResponseId(heartBeatID++);
      NodeHeartbeatResponse nhResponse=YarnServerBuilderUtils.newNodeHeartbeatResponse(heartBeatID,heartBeatNodeAction,null,null,null,null,1000L);
      nhResponse.setDiagnosticsMessage(shutDownMessage);
      return nhResponse;
    }
    @Override public UnRegisterNodeManagerResponse unRegisterNodeManager(    UnRegisterNodeManagerRequest request) throws YarnException, IOException {
      return recordFactory.newRecordInstance(UnRegisterNodeManagerResponse.class);
    }
  }
private class MyResourceTracker3 implements ResourceTracker {
    public NodeAction heartBeatNodeAction=NodeAction.NORMAL;
    public NodeAction registerNodeAction=NodeAction.NORMAL;
    private Map<ApplicationId,List<Long>> keepAliveRequests=new HashMap<ApplicationId,List<Long>>();
    private ApplicationId appId=BuilderUtils.newApplicationId(1,1);
    private final Context context;
    MyResourceTracker3(    Context context){
      this.context=context;
    }
    @Override public RegisterNodeManagerResponse registerNodeManager(    RegisterNodeManagerRequest request) throws YarnException, IOException {
      RegisterNodeManagerResponse response=recordFactory.newRecordInstance(RegisterNodeManagerResponse.class);
      response.setNodeAction(registerNodeAction);
      response.setContainerTokenMasterKey(createMasterKey());
      response.setNMTokenMasterKey(createMasterKey());
      return response;
    }
    @Override public NodeHeartbeatResponse nodeHeartbeat(    NodeHeartbeatRequest request) throws YarnException, IOException {
      LOG.info("Got heartBeatId: [" + heartBeatID + "]");
      NodeStatus nodeStatus=request.getNodeStatus();
      nodeStatus.setResponseId(heartBeatID++);
      NodeHeartbeatResponse nhResponse=YarnServerBuilderUtils.newNodeHeartbeatResponse(heartBeatID,heartBeatNodeAction,null,null,null,null,1000L);
      if (nodeStatus.getKeepAliveApplications() != null && nodeStatus.getKeepAliveApplications().size() > 0) {
        for (        ApplicationId appId : nodeStatus.getKeepAliveApplications()) {
          List<Long> list=keepAliveRequests.get(appId);
          if (list == null) {
            list=new LinkedList<Long>();
            keepAliveRequests.put(appId,list);
          }
          list.add(System.currentTimeMillis());
        }
      }
      if (heartBeatID == 2) {
        LOG.info("Sending FINISH_APP for application: [" + appId + "]");
        this.context.getApplications().put(appId,mock(Application.class));
        nhResponse.addAllApplicationsToCleanup(Collections.singletonList(appId));
      }
      return nhResponse;
    }
    @Override public UnRegisterNodeManagerResponse unRegisterNodeManager(    UnRegisterNodeManagerRequest request) throws YarnException, IOException {
      return recordFactory.newRecordInstance(UnRegisterNodeManagerResponse.class);
    }
  }
  private Credentials expectedCredentials=new Credentials();
private class MyResourceTracker4 implements ResourceTracker {
    public NodeAction registerNodeAction=NodeAction.NORMAL;
    public NodeAction heartBeatNodeAction=NodeAction.NORMAL;
    private Context context;
    private final ContainerStatus containerStatus2=createContainerStatus(2,ContainerState.RUNNING);
    private final ContainerStatus containerStatus3=createContainerStatus(3,ContainerState.COMPLETE);
    private final ContainerStatus containerStatus4=createContainerStatus(4,ContainerState.RUNNING);
    private final ContainerStatus containerStatus5=createContainerStatus(5,ContainerState.COMPLETE);
    public MyResourceTracker4(    Context context){
      org.apache.hadoop.security.token.Token<DelegationTokenIdentifier> token1=new org.apache.hadoop.security.token.Token<DelegationTokenIdentifier>();
      token1.setKind(new Text("kind1"));
      expectedCredentials.addToken(new Text("token1"),token1);
      this.context=context;
    }
    @Override public RegisterNodeManagerResponse registerNodeManager(    RegisterNodeManagerRequest request) throws YarnException, IOException {
      RegisterNodeManagerResponse response=recordFactory.newRecordInstance(RegisterNodeManagerResponse.class);
      response.setNodeAction(registerNodeAction);
      response.setContainerTokenMasterKey(createMasterKey());
      response.setNMTokenMasterKey(createMasterKey());
      return response;
    }
    @Override public NodeHeartbeatResponse nodeHeartbeat(    NodeHeartbeatRequest request) throws YarnException, IOException {
      List<ContainerId> finishedContainersPulledByAM=new ArrayList<ContainerId>();
      try {
        if (heartBeatID == 0) {
          Assert.assertEquals(0,request.getNodeStatus().getContainersStatuses().size());
          Assert.assertEquals(0,context.getContainers().size());
        }
 else         if (heartBeatID == 1) {
          List<ContainerStatus> statuses=request.getNodeStatus().getContainersStatuses();
          Assert.assertEquals(2,statuses.size());
          Assert.assertEquals(2,context.getContainers().size());
          boolean container2Exist=false, container3Exist=false;
          for (          ContainerStatus status : statuses) {
            if (status.getContainerId().equals(containerStatus2.getContainerId())) {
              Assert.assertTrue(status.getState().equals(containerStatus2.getState()));
              container2Exist=true;
            }
            if (status.getContainerId().equals(containerStatus3.getContainerId())) {
              Assert.assertTrue(status.getState().equals(containerStatus3.getState()));
              container3Exist=true;
            }
          }
          Assert.assertTrue(container2Exist && container3Exist);
          throw new YarnRuntimeException("Lost the heartbeat response");
        }
 else         if (heartBeatID == 2 || heartBeatID == 3) {
          List<ContainerStatus> statuses=request.getNodeStatus().getContainersStatuses();
          if (heartBeatID == 2) {
            Assert.assertEquals(4,statuses.size());
          }
 else {
            Assert.assertEquals(2,statuses.size());
          }
          Assert.assertEquals(4,context.getContainers().size());
          boolean container2Exist=false, container3Exist=false, container4Exist=false, container5Exist=false;
          for (          ContainerStatus status : statuses) {
            if (status.getContainerId().equals(containerStatus2.getContainerId())) {
              Assert.assertTrue(status.getState().equals(containerStatus2.getState()));
              container2Exist=true;
            }
            if (status.getContainerId().equals(containerStatus3.getContainerId())) {
              Assert.assertTrue(status.getState().equals(containerStatus3.getState()));
              container3Exist=true;
            }
            if (status.getContainerId().equals(containerStatus4.getContainerId())) {
              Assert.assertTrue(status.getState().equals(containerStatus4.getState()));
              container4Exist=true;
            }
            if (status.getContainerId().equals(containerStatus5.getContainerId())) {
              Assert.assertTrue(status.getState().equals(containerStatus5.getState()));
              container5Exist=true;
            }
          }
          if (heartBeatID == 2) {
            Assert.assertTrue(container2Exist && container3Exist && container4Exist&& container5Exist);
          }
 else {
            Assert.assertTrue(container2Exist && !container3Exist && container4Exist&& !container5Exist);
          }
          if (heartBeatID == 3) {
            finishedContainersPulledByAM.add(containerStatus3.getContainerId());
          }
        }
 else         if (heartBeatID == 4) {
          List<ContainerStatus> statuses=request.getNodeStatus().getContainersStatuses();
          Assert.assertEquals(2,statuses.size());
          Assert.assertEquals(3,context.getContainers().size());
          boolean container3Exist=false;
          for (          ContainerStatus status : statuses) {
            if (status.getContainerId().equals(containerStatus3.getContainerId())) {
              container3Exist=true;
            }
          }
          Assert.assertFalse(container3Exist);
        }
      }
 catch (      AssertionError error) {
        error.printStackTrace();
        assertionFailedInThread.set(true);
      }
 finally {
        heartBeatID++;
      }
      NodeStatus nodeStatus=request.getNodeStatus();
      nodeStatus.setResponseId(heartBeatID);
      NodeHeartbeatResponse nhResponse=YarnServerBuilderUtils.newNodeHeartbeatResponse(heartBeatID,heartBeatNodeAction,null,null,null,null,1000L);
      nhResponse.addContainersToBeRemovedFromNM(finishedContainersPulledByAM);
      Map<ApplicationId,ByteBuffer> appCredentials=new HashMap<ApplicationId,ByteBuffer>();
      DataOutputBuffer dob=new DataOutputBuffer();
      expectedCredentials.writeTokenStorageToStream(dob);
      ByteBuffer byteBuffer1=ByteBuffer.wrap(dob.getData(),0,dob.getLength());
      appCredentials.put(ApplicationId.newInstance(1234,1),byteBuffer1);
      nhResponse.setSystemCredentialsForApps(appCredentials);
      return nhResponse;
    }
    @Override public UnRegisterNodeManagerResponse unRegisterNodeManager(    UnRegisterNodeManagerRequest request) throws YarnException, IOException {
      return recordFactory.newRecordInstance(UnRegisterNodeManagerResponse.class);
    }
  }
private class MyResourceTracker5 implements ResourceTracker {
    public NodeAction registerNodeAction=NodeAction.NORMAL;
    @Override public RegisterNodeManagerResponse registerNodeManager(    RegisterNodeManagerRequest request) throws YarnException, IOException {
      RegisterNodeManagerResponse response=recordFactory.newRecordInstance(RegisterNodeManagerResponse.class);
      response.setNodeAction(registerNodeAction);
      response.setContainerTokenMasterKey(createMasterKey());
      response.setNMTokenMasterKey(createMasterKey());
      return response;
    }
    @Override public NodeHeartbeatResponse nodeHeartbeat(    NodeHeartbeatRequest request) throws YarnException, IOException {
      heartBeatID++;
      if (heartBeatID == 1) {
        throw new EOFException("NodeHeartbeat exception");
      }
 else {
        throw new java.net.ConnectException("NodeHeartbeat exception");
      }
    }
    @Override public UnRegisterNodeManagerResponse unRegisterNodeManager(    UnRegisterNodeManagerRequest request) throws YarnException, IOException {
      return recordFactory.newRecordInstance(UnRegisterNodeManagerResponse.class);
    }
  }
private class MyResourceTracker6 implements ResourceTracker {
    private long rmStartIntervalMS;
    private boolean rmNeverStart;
    private final long waitStartTime;
    public MyResourceTracker6(    long rmStartIntervalMS,    boolean rmNeverStart){
      this.rmStartIntervalMS=rmStartIntervalMS;
      this.rmNeverStart=rmNeverStart;
      this.waitStartTime=System.currentTimeMillis();
    }
    @Override public RegisterNodeManagerResponse registerNodeManager(    RegisterNodeManagerRequest request) throws YarnException, IOException, IOException {
      if (System.currentTimeMillis() - waitStartTime <= rmStartIntervalMS || rmNeverStart) {
        throw new java.net.ConnectException("Faking RM start failure as start " + "delay timer has not expired.");
      }
 else {
        NodeId nodeId=request.getNodeId();
        Resource resource=request.getResource();
        LOG.info("Registering " + nodeId.toString());
        InetSocketAddress expected=NetUtils.getConnectAddress(conf.getSocketAddr(YarnConfiguration.NM_ADDRESS,null,-1));
        Assert.assertEquals(NetUtils.getHostPortString(expected),nodeId.toString());
        Assert.assertEquals(5 * 1024,resource.getMemorySize());
        registeredNodes.add(nodeId);
        RegisterNodeManagerResponse response=recordFactory.newRecordInstance(RegisterNodeManagerResponse.class);
        triggered=true;
        return response;
      }
    }
    @Override public NodeHeartbeatResponse nodeHeartbeat(    NodeHeartbeatRequest request) throws YarnException, IOException {
      NodeStatus nodeStatus=request.getNodeStatus();
      nodeStatus.setResponseId(heartBeatID++);
      NodeHeartbeatResponse nhResponse=YarnServerBuilderUtils.newNodeHeartbeatResponse(heartBeatID,NodeAction.NORMAL,null,null,null,null,1000L);
      return nhResponse;
    }
    @Override public UnRegisterNodeManagerResponse unRegisterNodeManager(    UnRegisterNodeManagerRequest request) throws YarnException, IOException {
      return recordFactory.newRecordInstance(UnRegisterNodeManagerResponse.class);
    }
  }
  @Before public void clearError(){
    nmStartError=null;
  }
  @After public void deleteBaseDir() throws IOException {
    FileContext lfs=FileContext.getLocalFSFileContext();
    lfs.delete(new Path(basedir.getPath()),true);
  }
  @Test(timeout=90000) public void testRecentlyFinishedContainers() throws Exception {
    NodeManager nm=new NodeManager();
    YarnConfiguration conf=new YarnConfiguration();
    conf.set(NodeStatusUpdaterImpl.YARN_NODEMANAGER_DURATION_TO_TRACK_STOPPED_CONTAINERS,"10000");
    nm.init(conf);
    NodeStatusUpdaterImpl nodeStatusUpdater=(NodeStatusUpdaterImpl)nm.getNodeStatusUpdater();
    ApplicationId appId=ApplicationId.newInstance(0,0);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    ContainerId cId=ContainerId.newContainerId(appAttemptId,0);
    nm.getNMContext().getApplications().putIfAbsent(appId,mock(Application.class));
    nm.getNMContext().getContainers().putIfAbsent(cId,mock(Container.class));
    nodeStatusUpdater.addCompletedContainer(cId);
    Assert.assertTrue(nodeStatusUpdater.isContainerRecentlyStopped(cId));
    nm.getNMContext().getContainers().remove(cId);
    long time1=System.currentTimeMillis();
    int waitInterval=15;
    while (waitInterval-- > 0 && nodeStatusUpdater.isContainerRecentlyStopped(cId)) {
      nodeStatusUpdater.removeVeryOldStoppedContainersFromCache();
      Thread.sleep(1000);
    }
    long time2=System.currentTimeMillis();
    Assert.assertFalse(nodeStatusUpdater.isContainerRecentlyStopped(cId));
    Assert.assertTrue((time2 - time1) >= 10000 && (time2 - time1) <= 250000);
  }
  @Test(timeout=90000) public void testRemovePreviousCompletedContainersFromContext() throws Exception {
    NodeManager nm=new NodeManager();
    YarnConfiguration conf=new YarnConfiguration();
    conf.set(NodeStatusUpdaterImpl.YARN_NODEMANAGER_DURATION_TO_TRACK_STOPPED_CONTAINERS,"10000");
    nm.init(conf);
    NodeStatusUpdaterImpl nodeStatusUpdater=(NodeStatusUpdaterImpl)nm.getNodeStatusUpdater();
    ApplicationId appId=ApplicationId.newInstance(0,0);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    ContainerId cId=ContainerId.newContainerId(appAttemptId,1);
    Token containerToken=BuilderUtils.newContainerToken(cId,0,"anyHost",1234,"anyUser",BuilderUtils.newResource(1024,1),0,123,"password".getBytes(),0);
    Container anyCompletedContainer=new ContainerImpl(conf,null,null,null,null,BuilderUtils.newContainerTokenIdentifier(containerToken),nm.getNMContext()){
      @Override public ContainerState getCurrentState(){
        return ContainerState.COMPLETE;
      }
      @Override public org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerState getContainerState(){
        return org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerState.DONE;
      }
    }
;
    ContainerId runningContainerId=ContainerId.newContainerId(appAttemptId,3);
    Token runningContainerToken=BuilderUtils.newContainerToken(runningContainerId,0,"anyHost",1234,"anyUser",BuilderUtils.newResource(1024,1),0,123,"password".getBytes(),0);
    Container runningContainer=new ContainerImpl(conf,null,null,null,null,BuilderUtils.newContainerTokenIdentifier(runningContainerToken),nm.getNMContext()){
      @Override public ContainerState getCurrentState(){
        return ContainerState.RUNNING;
      }
      @Override public org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerState getContainerState(){
        return org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerState.RUNNING;
      }
    }
;
    nm.getNMContext().getApplications().putIfAbsent(appId,mock(Application.class));
    nm.getNMContext().getContainers().put(cId,anyCompletedContainer);
    nm.getNMContext().getContainers().put(runningContainerId,runningContainer);
    Assert.assertEquals(2,nodeStatusUpdater.getContainerStatuses().size());
    List<ContainerId> ackedContainers=new ArrayList<ContainerId>();
    ackedContainers.add(cId);
    ackedContainers.add(runningContainerId);
    nodeStatusUpdater.removeOrTrackCompletedContainersFromContext(ackedContainers);
    Set<ContainerId> containerIdSet=new HashSet<ContainerId>();
    List<ContainerStatus> containerStatuses=nodeStatusUpdater.getContainerStatuses();
    for (    ContainerStatus status : containerStatuses) {
      containerIdSet.add(status.getContainerId());
    }
    Assert.assertEquals(1,containerStatuses.size());
    Assert.assertFalse(containerIdSet.contains(cId));
    Assert.assertTrue(containerIdSet.contains(runningContainerId));
  }
  @Test(timeout=10000) public void testCompletedContainersIsRecentlyStopped() throws Exception {
    NodeManager nm=new NodeManager();
    nm.init(conf);
    NodeStatusUpdaterImpl nodeStatusUpdater=(NodeStatusUpdaterImpl)nm.getNodeStatusUpdater();
    ApplicationId appId=ApplicationId.newInstance(0,0);
    Application completedApp=mock(Application.class);
    when(completedApp.getApplicationState()).thenReturn(ApplicationState.FINISHED);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    ContainerId containerId=ContainerId.newContainerId(appAttemptId,1);
    Token containerToken=BuilderUtils.newContainerToken(containerId,0,"host",1234,"user",BuilderUtils.newResource(1024,1),0,123,"password".getBytes(),0);
    Container completedContainer=new ContainerImpl(conf,null,null,null,null,BuilderUtils.newContainerTokenIdentifier(containerToken),nm.getNMContext()){
      @Override public ContainerState getCurrentState(){
        return ContainerState.COMPLETE;
      }
    }
;
    nm.getNMContext().getApplications().putIfAbsent(appId,completedApp);
    nm.getNMContext().getContainers().put(containerId,completedContainer);
    Assert.assertEquals(1,nodeStatusUpdater.getContainerStatuses().size());
    Assert.assertTrue(nodeStatusUpdater.isContainerRecentlyStopped(containerId));
  }
  @Test public void testCleanedupApplicationContainerCleanup() throws IOException {
    NodeManager nm=new NodeManager();
    YarnConfiguration conf=new YarnConfiguration();
    conf.set(NodeStatusUpdaterImpl.YARN_NODEMANAGER_DURATION_TO_TRACK_STOPPED_CONTAINERS,"1000000");
    nm.init(conf);
    NodeStatusUpdaterImpl nodeStatusUpdater=(NodeStatusUpdaterImpl)nm.getNodeStatusUpdater();
    ApplicationId appId=ApplicationId.newInstance(0,0);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    ContainerId cId=ContainerId.newContainerId(appAttemptId,1);
    Token containerToken=BuilderUtils.newContainerToken(cId,0,"anyHost",1234,"anyUser",BuilderUtils.newResource(1024,1),0,123,"password".getBytes(),0);
    Container anyCompletedContainer=new ContainerImpl(conf,null,null,null,null,BuilderUtils.newContainerTokenIdentifier(containerToken),nm.getNMContext()){
      @Override public ContainerState getCurrentState(){
        return ContainerState.COMPLETE;
      }
    }
;
    Application application=mock(Application.class);
    when(application.getApplicationState()).thenReturn(ApplicationState.RUNNING);
    nm.getNMContext().getApplications().putIfAbsent(appId,application);
    nm.getNMContext().getContainers().put(cId,anyCompletedContainer);
    Assert.assertEquals(1,nodeStatusUpdater.getContainerStatuses().size());
    when(application.getApplicationState()).thenReturn(ApplicationState.FINISHING_CONTAINERS_WAIT);
    Assert.assertEquals(1,nodeStatusUpdater.getContainerStatuses().size());
    Assert.assertEquals(1,nodeStatusUpdater.getContainerStatuses().size());
    nm.getNMContext().getContainers().put(cId,anyCompletedContainer);
    nm.getNMContext().getApplications().remove(appId);
    Assert.assertEquals(1,nodeStatusUpdater.getContainerStatuses().size());
    Assert.assertEquals(1,nodeStatusUpdater.getContainerStatuses().size());
  }
  @Test public void testNMRegistration() throws InterruptedException, IOException {
    nm=new NodeManager(){
      @Override protected NodeStatusUpdater createNodeStatusUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        return new MyNodeStatusUpdater(context,dispatcher,healthChecker,metrics);
      }
    }
;
    YarnConfiguration conf=createNMConfig();
    nm.init(conf);
    Object[] services=nm.getServices().toArray();
    Object lastService=services[services.length - 1];
    Assert.assertTrue("last service is NOT the node status updater",lastService instanceof NodeStatusUpdater);
    new Thread(){
      public void run(){
        try {
          nm.start();
        }
 catch (        Throwable e) {
          TestNodeStatusUpdater.this.nmStartError=e;
          throw new YarnRuntimeException(e);
        }
      }
    }
.start();
    System.out.println(" ----- thread already started.." + nm.getServiceState());
    int waitCount=0;
    while (nm.getServiceState() == STATE.INITED && waitCount++ != 50) {
      LOG.info("Waiting for NM to start..");
      if (nmStartError != null) {
        LOG.error("Error during startup. ",nmStartError);
        Assert.fail(nmStartError.getCause().getMessage());
      }
      Thread.sleep(2000);
    }
    if (nm.getServiceState() != STATE.STARTED) {
      Assert.fail("NodeManager failed to start");
    }
    waitCount=0;
    while (heartBeatID <= 3 && waitCount++ != 200) {
      Thread.sleep(1000);
    }
    Assert.assertFalse(heartBeatID <= 3);
    Assert.assertEquals("Number of registered NMs is wrong!!",1,this.registeredNodes.size());
    nm.stop();
  }
  @Test public void testStopReentrant() throws Exception {
    final AtomicInteger numCleanups=new AtomicInteger(0);
    nm=new NodeManager(){
      @Override protected NodeStatusUpdater createNodeStatusUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        MyNodeStatusUpdater myNodeStatusUpdater=new MyNodeStatusUpdater(context,dispatcher,healthChecker,metrics);
        MyResourceTracker2 myResourceTracker2=new MyResourceTracker2();
        myResourceTracker2.heartBeatNodeAction=NodeAction.SHUTDOWN;
        myNodeStatusUpdater.resourceTracker=myResourceTracker2;
        return myNodeStatusUpdater;
      }
      @Override protected ContainerManagerImpl createContainerManager(      Context context,      ContainerExecutor exec,      DeletionService del,      NodeStatusUpdater nodeStatusUpdater,      ApplicationACLsManager aclsManager,      LocalDirsHandlerService dirsHandler){
        return new ContainerManagerImpl(context,exec,del,nodeStatusUpdater,metrics,dirsHandler){
          @Override public void cleanUpApplicationsOnNMShutDown(){
            super.cleanUpApplicationsOnNMShutDown();
            numCleanups.incrementAndGet();
          }
        }
;
      }
    }
;
    YarnConfiguration conf=createNMConfig();
    nm.init(conf);
    nm.start();
    int waitCount=0;
    while (heartBeatID < 1 && waitCount++ != 200) {
      Thread.sleep(500);
    }
    Assert.assertFalse(heartBeatID < 1);
    nm.stop();
    waitCount=0;
    while (nm.getServiceState() != STATE.STOPPED && waitCount++ != 20) {
      LOG.info("Waiting for NM to stop..");
      Thread.sleep(1000);
    }
    Assert.assertEquals(STATE.STOPPED,nm.getServiceState());
    waitCount=0;
    while (numCleanups.get() == 0 && waitCount++ != 20) {
      LOG.info("Waiting for NM shutdown..");
      Thread.sleep(1000);
    }
    Assert.assertEquals(1,numCleanups.get());
  }
  @Test public void testNodeDecommision() throws Exception {
    nm=getNodeManager(NodeAction.SHUTDOWN);
    YarnConfiguration conf=createNMConfig();
    nm.init(conf);
    Assert.assertEquals(STATE.INITED,nm.getServiceState());
    nm.start();
    int waitCount=0;
    while (heartBeatID < 1 && waitCount++ != 200) {
      Thread.sleep(500);
    }
    Assert.assertFalse(heartBeatID < 1);
    Assert.assertTrue(nm.getNMContext().getDecommissioned());
    waitCount=0;
    while (nm.getServiceState() != STATE.STOPPED && waitCount++ != 20) {
      LOG.info("Waiting for NM to stop..");
      Thread.sleep(1000);
    }
    Assert.assertEquals(STATE.STOPPED,nm.getServiceState());
  }
private abstract class NodeManagerWithCustomNodeStatusUpdater extends NodeManager {
    private NodeStatusUpdater updater;
    private NodeManagerWithCustomNodeStatusUpdater(){
    }
    @Override protected NodeStatusUpdater createNodeStatusUpdater(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker){
      updater=createUpdater(context,dispatcher,healthChecker);
      return updater;
    }
    public NodeStatusUpdater getUpdater(){
      return updater;
    }
    abstract NodeStatusUpdater createUpdater(    Context context,    Dispatcher dispatcher,    NodeHealthCheckerService healthChecker);
  }
  @Test public void testNMShutdownForRegistrationFailure() throws Exception {
    nm=new NodeManagerWithCustomNodeStatusUpdater(){
      @Override protected NodeStatusUpdater createUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        MyNodeStatusUpdater nodeStatusUpdater=new MyNodeStatusUpdater(context,dispatcher,healthChecker,metrics);
        MyResourceTracker2 myResourceTracker2=new MyResourceTracker2();
        myResourceTracker2.registerNodeAction=NodeAction.SHUTDOWN;
        myResourceTracker2.shutDownMessage="RM Shutting Down Node";
        nodeStatusUpdater.resourceTracker=myResourceTracker2;
        return nodeStatusUpdater;
      }
    }
;
    verifyNodeStartFailure("Received SHUTDOWN signal from Resourcemanager, " + "Registration of NodeManager failed, " + "Message from ResourceManager: RM Shutting Down Node");
  }
  @Test(timeout=100000) public void testNMRMConnectionConf() throws Exception {
    final long delta=50000;
    final long nmRmConnectionWaitMs=100;
    final long nmRmRetryInterval=100;
    final long connectionWaitMs=-1;
    final long connectionRetryIntervalMs=1000;
    final long rmStartIntervalMS=2 * 1000;
    conf.setLong(YarnConfiguration.NM_RESOURCEMANAGER_CONNECT_MAX_WAIT_MS,nmRmConnectionWaitMs);
    conf.setLong(YarnConfiguration.NM_RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS,nmRmRetryInterval);
    conf.setLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_MAX_WAIT_MS,connectionWaitMs);
    conf.setLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS,connectionRetryIntervalMs);
    conf.setInt(CommonConfigurationKeysPublic.IPC_CLIENT_CONNECT_MAX_RETRIES_KEY,1);
    NodeManagerWithCustomNodeStatusUpdater nmWithUpdater;
    nm=nmWithUpdater=new NodeManagerWithCustomNodeStatusUpdater(){
      @Override protected NodeStatusUpdater createUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        NodeStatusUpdater nodeStatusUpdater=new MyNodeStatusUpdater6(context,dispatcher,healthChecker,metrics,rmStartIntervalMS,true);
        return nodeStatusUpdater;
      }
    }
;
    nm.init(conf);
    long waitStartTime=System.currentTimeMillis();
    try {
      nm.start();
      Assert.fail("NM should have failed to start due to RM connect failure");
    }
 catch (    Exception e) {
      long t=System.currentTimeMillis();
      long duration=t - waitStartTime;
      boolean waitTimeValid=(duration >= nmRmConnectionWaitMs) && (duration < (nmRmConnectionWaitMs + delta));
      if (!waitTimeValid) {
        throw new Exception("NM should have tried re-connecting to RM during " + "period of at least " + nmRmConnectionWaitMs + " ms, but "+ "stopped retrying within "+ (nmRmConnectionWaitMs + delta)+ " ms: "+ e,e);
      }
    }
  }
  @Test(timeout=150000) public void testNMConnectionToRM() throws Exception {
    final long delta=50000;
    final long connectionWaitMs=5000;
    final long connectionRetryIntervalMs=1000;
    final long rmStartIntervalMS=2 * 1000;
    conf.setLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_MAX_WAIT_MS,connectionWaitMs);
    conf.setLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS,connectionRetryIntervalMs);
    NodeManagerWithCustomNodeStatusUpdater nmWithUpdater;
    nm=nmWithUpdater=new NodeManagerWithCustomNodeStatusUpdater(){
      @Override protected NodeStatusUpdater createUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        NodeStatusUpdater nodeStatusUpdater=new MyNodeStatusUpdater4(context,dispatcher,healthChecker,metrics,rmStartIntervalMS,true);
        return nodeStatusUpdater;
      }
    }
;
    nm.init(conf);
    long waitStartTime=System.currentTimeMillis();
    try {
      nm.start();
      Assert.fail("NM should have failed to start due to RM connect failure");
    }
 catch (    Exception e) {
      long t=System.currentTimeMillis();
      long duration=t - waitStartTime;
      boolean waitTimeValid=(duration >= connectionWaitMs) && (duration < (connectionWaitMs + delta));
      if (!waitTimeValid) {
        throw new Exception("NM should have tried re-connecting to RM during " + "period of at least " + connectionWaitMs + " ms, but "+ "stopped retrying within "+ (connectionWaitMs + delta)+ " ms: "+ e,e);
      }
    }
    nm=nmWithUpdater=new NodeManagerWithCustomNodeStatusUpdater(){
      @Override protected NodeStatusUpdater createUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        NodeStatusUpdater nodeStatusUpdater=new MyNodeStatusUpdater4(context,dispatcher,healthChecker,metrics,rmStartIntervalMS,false);
        return nodeStatusUpdater;
      }
    }
;
    nm.init(conf);
    NodeStatusUpdater updater=nmWithUpdater.getUpdater();
    Assert.assertNotNull("Updater not yet created ",updater);
    waitStartTime=System.currentTimeMillis();
    try {
      nm.start();
    }
 catch (    Exception ex) {
      LOG.error("NM should have started successfully " + "after connecting to RM.",ex);
      throw ex;
    }
    long duration=System.currentTimeMillis() - waitStartTime;
    MyNodeStatusUpdater4 myUpdater=(MyNodeStatusUpdater4)updater;
    Assert.assertTrue("NM started before updater triggered",myUpdater.isTriggered());
    Assert.assertTrue("NM should have connected to RM after " + "the start interval of " + rmStartIntervalMS + ": actual "+ duration+ " "+ myUpdater,(duration >= rmStartIntervalMS));
    Assert.assertTrue("NM should have connected to RM less than " + (rmStartIntervalMS + delta) + " milliseconds of RM starting up: actual "+ duration+ " "+ myUpdater,(duration < (rmStartIntervalMS + delta)));
  }
  /** 
 * Verifies that if for some reason NM fails to start ContainerManager RPC server, RM is oblivious to NM's presence. The behaviour is like this because otherwise, NM will report to RM even if all its servers are not started properly, RM will think that the NM is alive and will retire the NM only after NM_EXPIRY interval. See MAPREDUCE-2749.
 */
  @Test public void testNoRegistrationWhenNMServicesFail() throws Exception {
    nm=new NodeManager(){
      @Override protected NodeStatusUpdater createNodeStatusUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        return new MyNodeStatusUpdater(context,dispatcher,healthChecker,metrics);
      }
      @Override protected ContainerManagerImpl createContainerManager(      Context context,      ContainerExecutor exec,      DeletionService del,      NodeStatusUpdater nodeStatusUpdater,      ApplicationACLsManager aclsManager,      LocalDirsHandlerService diskhandler){
        return new ContainerManagerImpl(context,exec,del,nodeStatusUpdater,metrics,diskhandler){
          @Override protected void serviceStart(){
            throw new YarnRuntimeException("Starting of RPC Server failed");
          }
        }
;
      }
    }
;
    verifyNodeStartFailure("Starting of RPC Server failed");
  }
  @Test public void testApplicationKeepAlive() throws Exception {
    MyNodeManager nm=new MyNodeManager();
    try {
      YarnConfiguration conf=createNMConfig();
      conf.setBoolean(YarnConfiguration.LOG_AGGREGATION_ENABLED,true);
      conf.setLong(YarnConfiguration.RM_NM_EXPIRY_INTERVAL_MS,4000l);
      nm.init(conf);
      nm.start();
      while (heartBeatID < 12) {
        Thread.sleep(1000l);
      }
      MyResourceTracker3 rt=(MyResourceTracker3)nm.getNodeStatusUpdater().getRMClient();
      rt.context.getApplications().remove(rt.appId);
      Assert.assertEquals(1,rt.keepAliveRequests.size());
      int numKeepAliveRequests=rt.keepAliveRequests.get(rt.appId).size();
      LOG.info("Number of Keep Alive Requests: [" + numKeepAliveRequests + "]");
      Assert.assertTrue(numKeepAliveRequests == 2 || numKeepAliveRequests == 3);
      while (heartBeatID < 20) {
        Thread.sleep(1000l);
      }
      int numKeepAliveRequests2=rt.keepAliveRequests.get(rt.appId).size();
      Assert.assertEquals(numKeepAliveRequests,numKeepAliveRequests2);
    }
  finally {
      if (nm.getServiceState() == STATE.STARTED)       nm.stop();
    }
  }
  /** 
 * Test completed containerStatus get back up when heart beat lost, and will be sent via next heart beat.
 */
  @Test(timeout=200000) public void testCompletedContainerStatusBackup() throws Exception {
    nm=new NodeManager(){
      @Override protected NodeStatusUpdater createNodeStatusUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        MyNodeStatusUpdater2 myNodeStatusUpdater=new MyNodeStatusUpdater2(context,dispatcher,healthChecker,metrics);
        return myNodeStatusUpdater;
      }
      @Override protected NMContext createNMContext(      NMContainerTokenSecretManager containerTokenSecretManager,      NMTokenSecretManagerInNM nmTokenSecretManager,      NMStateStoreService store,      boolean isDistributedSchedulingEnabled,      Configuration config){
        return new MyNMContext(containerTokenSecretManager,nmTokenSecretManager,config);
      }
    }
;
    YarnConfiguration conf=createNMConfig();
    nm.init(conf);
    nm.start();
    int waitCount=0;
    while (heartBeatID <= 4 && waitCount++ != 20) {
      Thread.sleep(500);
    }
    if (heartBeatID <= 4) {
      Assert.fail("Failed to get all heartbeats in time, " + "heartbeatID:" + heartBeatID);
    }
    if (assertionFailedInThread.get()) {
      Assert.fail("ContainerStatus Backup failed");
    }
    Assert.assertNotNull(nm.getNMContext().getSystemCredentialsForApps().get(ApplicationId.newInstance(1234,1)).getToken(new Text("token1")));
    nm.stop();
  }
  @Test(timeout=200000) public void testNodeStatusUpdaterRetryAndNMShutdown() throws Exception {
    final long connectionWaitSecs=1000;
    final long connectionRetryIntervalMs=1000;
    int port=ServerSocketUtil.getPort(49156,10);
    YarnConfiguration conf=createNMConfig(port);
    conf.setLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_MAX_WAIT_MS,connectionWaitSecs);
    conf.setLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS,connectionRetryIntervalMs);
    conf.setLong(YarnConfiguration.NM_SLEEP_DELAY_BEFORE_SIGKILL_MS,5000);
    conf.setLong(YarnConfiguration.NM_LOG_RETAIN_SECONDS,1);
    CyclicBarrier syncBarrier=new CyclicBarrier(2);
    nm=new MyNodeManager2(syncBarrier,conf);
    nm.init(conf);
    nm.start();
    ContainerId cId=TestNodeManagerShutdown.createContainerId();
    FileContext localFS=FileContext.getLocalFSFileContext();
    TestNodeManagerShutdown.startContainer(nm,cId,localFS,nmLocalDir,new File("start_file.txt"),port);
    try {
      syncBarrier.await(10000,TimeUnit.MILLISECONDS);
      syncBarrier.await(10000,TimeUnit.MILLISECONDS);
    }
 catch (    Exception e) {
    }
    Assert.assertFalse("Containers not cleaned up when NM stopped",assertionFailedInThread.get());
    Assert.assertTrue(((MyNodeManager2)nm).isStopped);
    Assert.assertTrue("calculate heartBeatCount based on" + " connectionWaitSecs and RetryIntervalSecs",heartBeatID == 2);
  }
  @Test public void testRMVersionLessThanMinimum() throws InterruptedException, IOException {
    final AtomicInteger numCleanups=new AtomicInteger(0);
    YarnConfiguration conf=createNMConfig();
    conf.set(YarnConfiguration.NM_RESOURCEMANAGER_MINIMUM_VERSION,"3.0.0");
    nm=new NodeManager(){
      @Override protected NodeStatusUpdater createNodeStatusUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        MyNodeStatusUpdater myNodeStatusUpdater=new MyNodeStatusUpdater(context,dispatcher,healthChecker,metrics);
        MyResourceTracker2 myResourceTracker2=new MyResourceTracker2();
        myResourceTracker2.heartBeatNodeAction=NodeAction.NORMAL;
        myResourceTracker2.rmVersion="3.0.0";
        myNodeStatusUpdater.resourceTracker=myResourceTracker2;
        return myNodeStatusUpdater;
      }
      @Override protected ContainerManagerImpl createContainerManager(      Context context,      ContainerExecutor exec,      DeletionService del,      NodeStatusUpdater nodeStatusUpdater,      ApplicationACLsManager aclsManager,      LocalDirsHandlerService dirsHandler){
        return new ContainerManagerImpl(context,exec,del,nodeStatusUpdater,metrics,dirsHandler){
          @Override public void cleanUpApplicationsOnNMShutDown(){
            super.cleanUpApplicationsOnNMShutDown();
            numCleanups.incrementAndGet();
          }
        }
;
      }
    }
;
    nm.init(conf);
    nm.start();
    int waitCount=0;
    while (nm.getServiceState() != STATE.STARTED && waitCount++ != 20) {
      LOG.info("Waiting for NM to stop..");
      Thread.sleep(1000);
    }
    Assert.assertTrue(nm.getServiceState() == STATE.STARTED);
    nm.stop();
  }
  @Test public void testSignalContainerToContainerManager() throws Exception {
    nm=new NodeManager(){
      @Override protected NodeStatusUpdater createNodeStatusUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        return new MyNodeStatusUpdater(context,dispatcher,healthChecker,metrics,true);
      }
      @Override protected ContainerManagerImpl createContainerManager(      Context context,      ContainerExecutor exec,      DeletionService del,      NodeStatusUpdater nodeStatusUpdater,      ApplicationACLsManager aclsManager,      LocalDirsHandlerService diskhandler){
        return new MyContainerManager(context,exec,del,nodeStatusUpdater,metrics,diskhandler);
      }
    }
;
    YarnConfiguration conf=createNMConfig();
    nm.init(conf);
    nm.start();
    System.out.println(" ----- thread already started.." + nm.getServiceState());
    int waitCount=0;
    while (nm.getServiceState() == STATE.INITED && waitCount++ != 20) {
      LOG.info("Waiting for NM to start..");
      if (nmStartError != null) {
        LOG.error("Error during startup. ",nmStartError);
        Assert.fail(nmStartError.getCause().getMessage());
      }
      Thread.sleep(1000);
    }
    if (nm.getServiceState() != STATE.STARTED) {
      Assert.fail("NodeManager failed to start");
    }
    waitCount=0;
    while (heartBeatID <= 3 && waitCount++ != 20) {
      Thread.sleep(500);
    }
    Assert.assertFalse(heartBeatID <= 3);
    Assert.assertEquals("Number of registered NMs is wrong!!",1,this.registeredNodes.size());
    MyContainerManager containerManager=(MyContainerManager)nm.getContainerManager();
    Assert.assertTrue(containerManager.signaled);
    nm.stop();
  }
  @Test public void testConcurrentAccessToSystemCredentials(){
    final Map<ApplicationId,ByteBuffer> testCredentials=new HashMap<>();
    ByteBuffer byteBuffer=ByteBuffer.wrap(new byte[300]);
    ApplicationId applicationId=ApplicationId.newInstance(123456,120);
    testCredentials.put(applicationId,byteBuffer);
    final List<Throwable> exceptions=Collections.synchronizedList(new ArrayList<Throwable>());
    final int NUM_THREADS=10;
    final CountDownLatch allDone=new CountDownLatch(NUM_THREADS);
    final ExecutorService threadPool=HadoopExecutors.newFixedThreadPool(NUM_THREADS);
    final AtomicBoolean stop=new AtomicBoolean(false);
    try {
      for (int i=0; i < NUM_THREADS; i++) {
        threadPool.submit(new Runnable(){
          @Override public void run(){
            try {
              for (int i=0; i < 100 && !stop.get(); i++) {
                NodeHeartbeatResponse nodeHeartBeatResponse=newNodeHeartbeatResponse(0,NodeAction.NORMAL,null,null,null,null,0);
                nodeHeartBeatResponse.setSystemCredentialsForApps(testCredentials);
                NodeHeartbeatResponseProto proto=((NodeHeartbeatResponsePBImpl)nodeHeartBeatResponse).getProto();
                Assert.assertNotNull(proto);
              }
            }
 catch (            Throwable t) {
              exceptions.add(t);
              stop.set(true);
            }
 finally {
              allDone.countDown();
            }
          }
        }
);
      }
      int testTimeout=2;
      Assert.assertTrue("Timeout waiting for more than " + testTimeout + " "+ "seconds",allDone.await(testTimeout,TimeUnit.SECONDS));
    }
 catch (    InterruptedException ie) {
      exceptions.add(ie);
    }
 finally {
      threadPool.shutdownNow();
    }
    Assert.assertTrue("Test failed with exception(s)" + exceptions,exceptions.isEmpty());
  }
private class MyNMContext extends NMContext {
    public MyNMContext(    NMContainerTokenSecretManager containerTokenSecretManager,    NMTokenSecretManagerInNM nmTokenSecretManager,    Configuration conf){
      super(containerTokenSecretManager,nmTokenSecretManager,null,null,new NMNullStateStoreService(),false,conf);
    }
    @Override public ConcurrentMap<ContainerId,Container> getContainers(){
      if (heartBeatID == 0) {
        return containers;
      }
 else       if (heartBeatID == 1) {
        ContainerStatus containerStatus2=createContainerStatus(2,ContainerState.RUNNING);
        putMockContainer(containerStatus2);
        ContainerStatus containerStatus3=createContainerStatus(3,ContainerState.COMPLETE);
        putMockContainer(containerStatus3);
        return containers;
      }
 else       if (heartBeatID == 2) {
        ContainerStatus containerStatus4=createContainerStatus(4,ContainerState.RUNNING);
        putMockContainer(containerStatus4);
        ContainerStatus containerStatus5=createContainerStatus(5,ContainerState.COMPLETE);
        putMockContainer(containerStatus5);
        return containers;
      }
 else       if (heartBeatID == 3 || heartBeatID == 4) {
        return containers;
      }
 else {
        containers.clear();
        return containers;
      }
    }
    private void putMockContainer(    ContainerStatus containerStatus){
      Container container=getMockContainer(containerStatus);
      containers.put(containerStatus.getContainerId(),container);
      applications.putIfAbsent(containerStatus.getContainerId().getApplicationAttemptId().getApplicationId(),mock(Application.class));
    }
  }
  public static ContainerStatus createContainerStatus(  int id,  ContainerState containerState){
    ApplicationId applicationId=ApplicationId.newInstance(0,1);
    ApplicationAttemptId applicationAttemptId=ApplicationAttemptId.newInstance(applicationId,1);
    ContainerId contaierId=ContainerId.newContainerId(applicationAttemptId,id);
    ContainerStatus containerStatus=BuilderUtils.newContainerStatus(contaierId,containerState,"test_containerStatus: id=" + id + ", containerState: "+ containerState,0,Resource.newInstance(1024,1));
    return containerStatus;
  }
  public static Container getMockContainer(  ContainerStatus containerStatus){
    ContainerImpl container=mock(ContainerImpl.class);
    when(container.cloneAndGetContainerStatus()).thenReturn(containerStatus);
    when(container.getCurrentState()).thenReturn(containerStatus.getState());
    when(container.getContainerId()).thenReturn(containerStatus.getContainerId());
    if (containerStatus.getState().equals(ContainerState.COMPLETE)) {
      when(container.getContainerState()).thenReturn(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerState.DONE);
    }
 else     if (containerStatus.getState().equals(ContainerState.RUNNING)) {
      when(container.getContainerState()).thenReturn(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerState.RUNNING);
    }
    return container;
  }
  private void verifyNodeStartFailure(  String errMessage) throws Exception {
    Assert.assertNotNull("nm is null",nm);
    YarnConfiguration conf=createNMConfig();
    nm.init(conf);
    try {
      nm.start();
      Assert.fail("NM should have failed to start. Didn't get exception!!");
    }
 catch (    Exception e) {
      if (!e.getMessage().contains(errMessage)) {
        throw e;
      }
    }
    Assert.assertEquals("NM state is wrong!",STATE.STOPPED,nm.getServiceState());
    Assert.assertEquals("Number of registered nodes is wrong!",0,this.registeredNodes.size());
  }
  private NodeManager getNodeManager(  final NodeAction nodeHeartBeatAction){
    return new NodeManager(){
      @Override protected NodeStatusUpdater createNodeStatusUpdater(      Context context,      Dispatcher dispatcher,      NodeHealthCheckerService healthChecker){
        MyNodeStatusUpdater myNodeStatusUpdater=new MyNodeStatusUpdater(context,dispatcher,healthChecker,metrics);
        MyResourceTracker2 myResourceTracker2=new MyResourceTracker2();
        myResourceTracker2.heartBeatNodeAction=nodeHeartBeatAction;
        myNodeStatusUpdater.resourceTracker=myResourceTracker2;
        return myNodeStatusUpdater;
      }
    }
;
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.server.nodemanager.nodelabels;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.PrintWriter;
import java.util.TimerTask;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileContext;
import org.apache.hadoop.fs.FileUtil;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.service.ServiceStateException;
import org.apache.hadoop.util.Shell;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.apache.hadoop.yarn.nodelabels.NodeLabelTestBase;
import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;
public class TestScriptBasedNodeLabelsProvider extends NodeLabelTestBase {
  protected static File testRootDir=new File("target",TestScriptBasedNodeLabelsProvider.class.getName() + "-localDir").getAbsoluteFile();
  private final File nodeLabelsScriptFile=new File(testRootDir,Shell.appendScriptExtension("failingscript"));
  private ScriptBasedNodeLabelsProvider nodeLabelsProvider;
  @Before public void setup(){
    testRootDir.mkdirs();
    nodeLabelsProvider=new ScriptBasedNodeLabelsProvider();
  }
  @After public void tearDown() throws Exception {
    if (testRootDir.exists()) {
      FileContext.getLocalFSFileContext().delete(new Path(testRootDir.getAbsolutePath()),true);
    }
    if (nodeLabelsProvider != null) {
      nodeLabelsProvider.stop();
    }
  }
  private Configuration getConfForNodeLabelScript(){
    Configuration conf=new Configuration();
    conf.set(YarnConfiguration.NM_SCRIPT_BASED_NODE_LABELS_PROVIDER_PATH,nodeLabelsScriptFile.getAbsolutePath());
    conf.setLong(YarnConfiguration.NM_NODE_LABELS_PROVIDER_FETCH_INTERVAL_MS,1 * 60 * 60* 1000l);
    conf.setLong(YarnConfiguration.NM_NODE_LABELS_PROVIDER_FETCH_TIMEOUT_MS,1000);
    return conf;
  }
  private void writeNodeLabelsScriptFile(  String scriptStr,  boolean setExecutable) throws IOException {
    PrintWriter pw=null;
    try {
      FileUtil.setWritable(nodeLabelsScriptFile,true);
      FileUtil.setReadable(nodeLabelsScriptFile,true);
      pw=new PrintWriter(new FileOutputStream(nodeLabelsScriptFile));
      pw.println(scriptStr);
      pw.flush();
    }
 catch (    Exception e) {
      e.printStackTrace();
      Assert.fail();
    }
 finally {
      if (null != pw) {
        pw.close();
      }
    }
    FileUtil.setExecutable(nodeLabelsScriptFile,setExecutable);
  }
  @Test public void testNodeLabelsScriptRunnerCreation() throws IOException {
    ScriptBasedNodeLabelsProvider nodeLabelsProvider=new ScriptBasedNodeLabelsProvider();
    initilizeServiceFailTest("Expected to fail fast when no script is configured and " + "ScriptBasedNodeLabelsProvider service is inited",nodeLabelsProvider);
    nodeLabelsProvider=new ScriptBasedNodeLabelsProvider();
    Configuration conf=new Configuration();
    conf.set(YarnConfiguration.NM_SCRIPT_BASED_NODE_LABELS_PROVIDER_PATH,"");
    initilizeServiceFailTest("Expected to fail fast when script path configuration is blank" + "and ScriptBasedNodeLabelsProvider service is inited.",nodeLabelsProvider);
    nodeLabelsProvider=new ScriptBasedNodeLabelsProvider();
    writeNodeLabelsScriptFile("",false);
    initilizeServiceFailTest("Expected to fail fast when script is not executable" + "and ScriptBasedNodeLabelsProvider service is inited.",nodeLabelsProvider);
    nodeLabelsProvider=new ScriptBasedNodeLabelsProvider();
    writeNodeLabelsScriptFile("",true);
    nodeLabelsProvider.init(getConfForNodeLabelScript());
    nodeLabelsProvider.start();
    Assert.assertNotNull("Node Label Script runner should be started when script" + " is executable",nodeLabelsProvider.getTimerTask());
    nodeLabelsProvider.stop();
  }
  private void initilizeServiceFailTest(  String message,  ScriptBasedNodeLabelsProvider nodeLabelsProvider){
    try {
      nodeLabelsProvider.init(new Configuration());
      Assert.fail(message);
    }
 catch (    ServiceStateException ex) {
      Assert.assertEquals("IOException was expected",IOException.class,ex.getCause().getClass());
    }
  }
  @Test public void testConfigForNoTimer() throws Exception {
    Configuration conf=getConfForNodeLabelScript();
    conf.setLong(YarnConfiguration.NM_NODE_LABELS_PROVIDER_FETCH_INTERVAL_MS,AbstractNodeDescriptorsProvider.DISABLE_NODE_DESCRIPTORS_PROVIDER_FETCH_TIMER);
    String normalScript="echo NODE_PARTITION:X86";
    writeNodeLabelsScriptFile(normalScript,true);
    nodeLabelsProvider.init(conf);
    nodeLabelsProvider.start();
    Assert.assertNull("Timer is not expected to be created when interval is configured as -1",nodeLabelsProvider.getScheduler());
    assertNLCollectionEquals(toNodeLabelSet("X86"),nodeLabelsProvider.getDescriptors());
  }
  @Test public void testNodeLabelsScript() throws Exception {
    String scriptWithoutLabels="";
    String normalScript="echo NODE_PARTITION:Windows";
    String scrptWithMultipleLinesHavingNodeLabels="echo NODE_PARTITION:RAM\n echo NODE_PARTITION:JDK1_6";
    String timeOutScript=Shell.WINDOWS ? "@echo off\nping -n 4 127.0.0.1 >nul\n" + "echo NODE_PARTITION:ALL" : "sleep 4\necho NODE_PARTITION:ALL";
    writeNodeLabelsScriptFile(scriptWithoutLabels,true);
    nodeLabelsProvider.init(getConfForNodeLabelScript());
    nodeLabelsProvider.start();
    Thread.sleep(500l);
    TimerTask timerTask=nodeLabelsProvider.getTimerTask();
    timerTask.run();
    Assert.assertNull("Node Label Script runner should return null when script doesnt " + "give any Labels output",nodeLabelsProvider.getDescriptors());
    writeNodeLabelsScriptFile(normalScript,true);
    timerTask.run();
    assertNLCollectionEquals(toNodeLabelSet("Windows"),nodeLabelsProvider.getDescriptors());
    writeNodeLabelsScriptFile(scrptWithMultipleLinesHavingNodeLabels,true);
    timerTask.run();
    assertNLCollectionEquals(toNodeLabelSet("JDK1_6"),nodeLabelsProvider.getDescriptors());
    writeNodeLabelsScriptFile(timeOutScript,true);
    timerTask.run();
    Assert.assertNotEquals("Node Labels should not be set after timeout ",toNodeLabelSet("ALL"),nodeLabelsProvider.getDescriptors());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.logaggregation;
import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileWriter;
import java.io.PrintWriter;
import java.io.Writer;
import java.net.URL;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import javax.servlet.http.HttpServletRequest;
import org.apache.commons.io.FileUtils;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileUtil;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.security.UserGroupInformation;
import org.apache.hadoop.yarn.api.records.ApplicationAccessType;
import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
import org.apache.hadoop.yarn.api.records.ApplicationId;
import org.apache.hadoop.yarn.api.records.ContainerId;
import org.apache.hadoop.yarn.api.records.NodeId;
import org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl;
import org.apache.hadoop.yarn.api.records.impl.pb.ApplicationIdPBImpl;
import org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileController;
import org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerContext;
import org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerFactory;
import org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.TFileAggregatedLogsBlock;
import org.apache.hadoop.yarn.webapp.YarnWebParams;
import org.apache.hadoop.yarn.webapp.View.ViewContext;
import org.apache.hadoop.yarn.webapp.log.AggregatedLogsBlockForTest;
import org.apache.hadoop.yarn.webapp.view.BlockForTest;
import org.apache.hadoop.yarn.webapp.view.HtmlBlock;
import org.apache.hadoop.yarn.webapp.view.HtmlBlockForTest;
import org.junit.Test;
import static org.mockito.Mockito.*;
import com.google.inject.Inject;
import static org.junit.Assert.*;
/** 
 * Test AggregatedLogsBlock. AggregatedLogsBlock should check user, aggregate a logs into one file and show this logs or errors into html code
 */
public class TestAggregatedLogsBlock {
  /** 
 * Bad user. User 'owner' is trying to read logs without access
 */
  @Test public void testAccessDenied() throws Exception {
    FileUtil.fullyDelete(new File("target/logs"));
    Configuration configuration=getConfiguration();
    writeLogs("target/logs/logs/application_0_0001/container_0_0001_01_000001");
    writeLog(configuration,"owner");
    ByteArrayOutputStream data=new ByteArrayOutputStream();
    PrintWriter printWriter=new PrintWriter(data);
    HtmlBlock html=new HtmlBlockForTest();
    HtmlBlock.Block block=new BlockForTest(html,printWriter,10,false);
    TFileAggregatedLogsBlockForTest aggregatedBlock=getTFileAggregatedLogsBlockForTest(configuration,"owner","container_0_0001_01_000001","localhost:1234");
    aggregatedBlock.render(block);
    block.getWriter().flush();
    String out=data.toString();
    assertTrue(out.contains("User [owner] is not authorized to view the logs for entity"));
  }
  @Test public void testBlockContainsPortNumForUnavailableAppLog(){
    FileUtil.fullyDelete(new File("target/logs"));
    Configuration configuration=getConfiguration();
    String nodeName=configuration.get(YarnConfiguration.NM_WEBAPP_ADDRESS,YarnConfiguration.DEFAULT_NM_WEBAPP_ADDRESS);
    AggregatedLogsBlockForTest aggregatedBlock=getAggregatedLogsBlockForTest(configuration,"admin","container_0_0001_01_000001",nodeName);
    ByteArrayOutputStream data=new ByteArrayOutputStream();
    PrintWriter printWriter=new PrintWriter(data);
    HtmlBlock html=new HtmlBlockForTest();
    HtmlBlock.Block block=new BlockForTest(html,printWriter,10,false);
    aggregatedBlock.render(block);
    block.getWriter().flush();
    String out=data.toString();
    assertTrue(out.contains(nodeName));
  }
  /** 
 * try to read bad logs
 * @throws Exception
 */
  @Test public void testBadLogs() throws Exception {
    FileUtil.fullyDelete(new File("target/logs"));
    Configuration configuration=getConfiguration();
    writeLogs("target/logs/logs/application_0_0001/container_0_0001_01_000001");
    writeLog(configuration,"owner");
    AggregatedLogsBlockForTest aggregatedBlock=getAggregatedLogsBlockForTest(configuration,"admin","container_0_0001_01_000001");
    ByteArrayOutputStream data=new ByteArrayOutputStream();
    PrintWriter printWriter=new PrintWriter(data);
    HtmlBlock html=new HtmlBlockForTest();
    HtmlBlock.Block block=new BlockForTest(html,printWriter,10,false);
    aggregatedBlock.render(block);
    block.getWriter().flush();
    String out=data.toString();
    assertTrue(out.contains("Logs not available for entity. Aggregation may not be complete, Check back later or try the nodemanager at localhost:1234"));
  }
  /** 
 * Reading from logs should succeed and they should be shown in the AggregatedLogsBlock html.
 * @throws Exception
 */
  @Test public void testAggregatedLogsBlock() throws Exception {
    FileUtil.fullyDelete(new File("target/logs"));
    Configuration configuration=getConfiguration();
    writeLogs("target/logs/logs/application_0_0001/container_0_0001_01_000001");
    writeLog(configuration,"admin");
    ByteArrayOutputStream data=new ByteArrayOutputStream();
    PrintWriter printWriter=new PrintWriter(data);
    HtmlBlock html=new HtmlBlockForTest();
    HtmlBlock.Block block=new BlockForTest(html,printWriter,10,false);
    TFileAggregatedLogsBlockForTest aggregatedBlock=getTFileAggregatedLogsBlockForTest(configuration,"admin","container_0_0001_01_000001","localhost:1234");
    aggregatedBlock.render(block);
    block.getWriter().flush();
    String out=data.toString();
    assertTrue(out.contains("test log1"));
    assertTrue(out.contains("test log2"));
    assertTrue(out.contains("test log3"));
  }
  /** 
 * Reading from logs should succeed (from a HAR archive) and they should be shown in the AggregatedLogsBlock html.
 * @throws Exception
 */
  @Test public void testAggregatedLogsBlockHar() throws Exception {
    FileUtil.fullyDelete(new File("target/logs"));
    Configuration configuration=getConfiguration();
    URL harUrl=ClassLoader.getSystemClassLoader().getResource("application_1440536969523_0001.har");
    assertNotNull(harUrl);
    String path="target/logs/admin/logs/application_1440536969523_0001" + "/application_1440536969523_0001.har";
    FileUtils.copyDirectory(new File(harUrl.getPath()),new File(path));
    ByteArrayOutputStream data=new ByteArrayOutputStream();
    PrintWriter printWriter=new PrintWriter(data);
    HtmlBlock html=new HtmlBlockForTest();
    HtmlBlock.Block block=new BlockForTest(html,printWriter,10,false);
    TFileAggregatedLogsBlockForTest aggregatedBlock=getTFileAggregatedLogsBlockForTest(configuration,"admin","container_1440536969523_0001_01_000001","host1:1111");
    aggregatedBlock.render(block);
    block.getWriter().flush();
    String out=data.toString();
    assertTrue(out.contains("Hello stderr"));
    assertTrue(out.contains("Hello stdout"));
    assertTrue(out.contains("Hello syslog"));
    aggregatedBlock=getTFileAggregatedLogsBlockForTest(configuration,"admin","container_1440536969523_0001_01_000002","host2:2222");
    data=new ByteArrayOutputStream();
    printWriter=new PrintWriter(data);
    html=new HtmlBlockForTest();
    block=new BlockForTest(html,printWriter,10,false);
    aggregatedBlock.render(block);
    block.getWriter().flush();
    out=data.toString();
    assertTrue(out.contains("Goodbye stderr"));
    assertTrue(out.contains("Goodbye stdout"));
    assertTrue(out.contains("Goodbye syslog"));
  }
  /** 
 * Log files was deleted.
 * @throws Exception
 */
  @Test public void testNoLogs() throws Exception {
    FileUtil.fullyDelete(new File("target/logs"));
    Configuration configuration=getConfiguration();
    File f=new File("target/logs/logs/application_0_0001/container_0_0001_01_000001");
    if (!f.exists()) {
      assertTrue(f.mkdirs());
    }
    writeLog(configuration,"admin");
    ByteArrayOutputStream data=new ByteArrayOutputStream();
    PrintWriter printWriter=new PrintWriter(data);
    HtmlBlock html=new HtmlBlockForTest();
    HtmlBlock.Block block=new BlockForTest(html,printWriter,10,false);
    TFileAggregatedLogsBlockForTest aggregatedBlock=getTFileAggregatedLogsBlockForTest(configuration,"admin","container_0_0001_01_000001","localhost:1234");
    aggregatedBlock.render(block);
    block.getWriter().flush();
    String out=data.toString();
    assertTrue(out.contains("No logs available for container container_0_0001_01_000001"));
  }
  private Configuration getConfiguration(){
    Configuration configuration=new YarnConfiguration();
    configuration.setBoolean(YarnConfiguration.LOG_AGGREGATION_ENABLED,true);
    configuration.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,"target/logs");
    configuration.setBoolean(YarnConfiguration.YARN_ACL_ENABLE,true);
    configuration.set(YarnConfiguration.YARN_ADMIN_ACL,"admin");
    return configuration;
  }
  private AggregatedLogsBlockForTest getAggregatedLogsBlockForTest(  Configuration configuration,  String user,  String containerId){
    return getAggregatedLogsBlockForTest(configuration,user,containerId,"localhost:1234");
  }
  private TFileAggregatedLogsBlockForTest getTFileAggregatedLogsBlockForTest(  Configuration configuration,  String user,  String containerId,  String nodeName){
    HttpServletRequest request=mock(HttpServletRequest.class);
    when(request.getRemoteUser()).thenReturn(user);
    ViewContext mockContext=mock(ViewContext.class);
    TFileAggregatedLogsBlockForTest aggregatedBlock=new TFileAggregatedLogsBlockForTest(mockContext,configuration);
    aggregatedBlock.setRequest(request);
    aggregatedBlock.moreParams().put(YarnWebParams.CONTAINER_ID,containerId);
    aggregatedBlock.moreParams().put(YarnWebParams.NM_NODENAME,nodeName);
    aggregatedBlock.moreParams().put(YarnWebParams.APP_OWNER,user);
    aggregatedBlock.moreParams().put("start","");
    aggregatedBlock.moreParams().put("end","");
    aggregatedBlock.moreParams().put(YarnWebParams.ENTITY_STRING,"entity");
    return aggregatedBlock;
  }
  private AggregatedLogsBlockForTest getAggregatedLogsBlockForTest(  Configuration configuration,  String user,  String containerId,  String nodeName){
    HttpServletRequest request=mock(HttpServletRequest.class);
    when(request.getRemoteUser()).thenReturn(user);
    AggregatedLogsBlockForTest aggregatedBlock=new AggregatedLogsBlockForTest(configuration);
    aggregatedBlock.setRequest(request);
    aggregatedBlock.moreParams().put(YarnWebParams.CONTAINER_ID,containerId);
    aggregatedBlock.moreParams().put(YarnWebParams.NM_NODENAME,nodeName);
    aggregatedBlock.moreParams().put(YarnWebParams.APP_OWNER,user);
    aggregatedBlock.moreParams().put("start","");
    aggregatedBlock.moreParams().put("end","");
    aggregatedBlock.moreParams().put(YarnWebParams.ENTITY_STRING,"entity");
    return aggregatedBlock;
  }
  private void writeLog(  Configuration configuration,  String user) throws Exception {
    ApplicationId appId=ApplicationIdPBImpl.newInstance(0,1);
    ApplicationAttemptId appAttemptId=ApplicationAttemptIdPBImpl.newInstance(appId,1);
    ContainerId containerId=ContainerIdPBImpl.newContainerId(appAttemptId,1);
    String path="target/logs/" + user + "/logs/application_0_0001/localhost_1234";
    File f=new File(path);
    if (!f.getParentFile().exists()) {
      assertTrue(f.getParentFile().mkdirs());
    }
    List<String> rootLogDirs=Arrays.asList("target/logs/logs");
    UserGroupInformation ugi=UserGroupInformation.getCurrentUser();
    LogAggregationFileControllerFactory factory=new LogAggregationFileControllerFactory(configuration);
    LogAggregationFileController fileController=factory.getFileControllerForWrite();
    try {
      Map<ApplicationAccessType,String> appAcls=new HashMap<>();
      appAcls.put(ApplicationAccessType.VIEW_APP,ugi.getUserName());
      NodeId nodeId=NodeId.newInstance("localhost",1234);
      LogAggregationFileControllerContext context=new LogAggregationFileControllerContext(new Path(path),new Path(path),false,3600,appId,appAcls,nodeId,ugi);
      fileController.initializeWriter(context);
      fileController.write(new AggregatedLogFormat.LogKey("container_0_0001_01_000001"),new AggregatedLogFormat.LogValue(rootLogDirs,containerId,UserGroupInformation.getCurrentUser().getShortUserName()));
    }
  finally {
      fileController.closeWriter();
    }
  }
  private void writeLogs(  String dirName) throws Exception {
    File f=new File(dirName + File.separator + "log1");
    if (!f.getParentFile().exists()) {
      assertTrue(f.getParentFile().mkdirs());
    }
    writeLog(dirName + File.separator + "log1","test log1");
    writeLog(dirName + File.separator + "log2","test log2");
    writeLog(dirName + File.separator + "log3","test log3");
  }
  private void writeLog(  String fileName,  String text) throws Exception {
    File f=new File(fileName);
    Writer writer=new FileWriter(f);
    writer.write(text);
    writer.flush();
    writer.close();
  }
private static class TFileAggregatedLogsBlockForTest extends TFileAggregatedLogsBlock {
    private Map<String,String> params=new HashMap<String,String>();
    private HttpServletRequest request;
    @Inject TFileAggregatedLogsBlockForTest(    ViewContext ctx,    Configuration conf){
      super(ctx,conf);
    }
    public void render(    Block html){
      super.render(html);
    }
    @Override public Map<String,String> moreParams(){
      return params;
    }
    public HttpServletRequest request(){
      return request;
    }
    public void setRequest(    HttpServletRequest request){
      this.request=request;
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.yarn.client;
import java.util.List;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.yarn.api.ApplicationClientProtocol;
import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest;
import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest;
import org.apache.hadoop.yarn.api.records.ApplicationAttemptReport;
import org.apache.hadoop.yarn.api.records.ApplicationId;
import org.apache.hadoop.yarn.api.records.ApplicationReport;
import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
import org.apache.hadoop.yarn.api.records.ContainerReport;
import org.apache.hadoop.yarn.api.records.NodeReport;
import org.apache.hadoop.yarn.api.records.NodeState;
import org.apache.hadoop.yarn.api.records.QueueInfo;
import org.apache.hadoop.yarn.api.records.QueueUserACLInfo;
import org.apache.hadoop.yarn.api.records.Resource;
import org.apache.hadoop.yarn.api.records.Token;
import org.apache.hadoop.yarn.api.records.YarnClusterMetrics;
import org.apache.hadoop.yarn.client.api.YarnClient;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.apache.hadoop.yarn.util.Records;
import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;
public class TestApplicationClientProtocolOnHA extends ProtocolHATestBase {
  private YarnClient client=null;
  @Before public void initiate() throws Exception {
    startHACluster(1,true,false,false);
    Configuration conf=new YarnConfiguration(this.conf);
    client=createAndStartYarnClient(conf);
  }
  @After public void shutDown(){
    if (client != null) {
      client.stop();
    }
  }
  @Test(timeout=15000) public void testGetApplicationReportOnHA() throws Exception {
    ApplicationReport report=client.getApplicationReport(cluster.createFakeAppId());
    Assert.assertTrue(report != null);
    Assert.assertEquals(cluster.createFakeAppReport(),report);
  }
  @Test(timeout=15000) public void testGetNewApplicationOnHA() throws Exception {
    ApplicationId appId=client.createApplication().getApplicationSubmissionContext().getApplicationId();
    Assert.assertTrue(appId != null);
    Assert.assertEquals(cluster.createFakeAppId(),appId);
  }
  @Test(timeout=15000) public void testGetClusterMetricsOnHA() throws Exception {
    YarnClusterMetrics clusterMetrics=client.getYarnClusterMetrics();
    Assert.assertTrue(clusterMetrics != null);
    Assert.assertEquals(cluster.createFakeYarnClusterMetrics(),clusterMetrics);
  }
  @Test(timeout=15000) public void testGetApplicationsOnHA() throws Exception {
    List<ApplicationReport> reports=client.getApplications();
    Assert.assertTrue(reports != null);
    Assert.assertFalse(reports.isEmpty());
    Assert.assertEquals(cluster.createFakeAppReports(),reports);
  }
  @Test(timeout=15000) public void testGetClusterNodesOnHA() throws Exception {
    List<NodeReport> reports=client.getNodeReports(NodeState.RUNNING);
    Assert.assertTrue(reports != null);
    Assert.assertFalse(reports.isEmpty());
    Assert.assertEquals(cluster.createFakeNodeReports(),reports);
  }
  @Test(timeout=15000) public void testGetQueueInfoOnHA() throws Exception {
    QueueInfo queueInfo=client.getQueueInfo("root");
    Assert.assertTrue(queueInfo != null);
    Assert.assertEquals(cluster.createFakeQueueInfo(),queueInfo);
  }
  @Test(timeout=15000) public void testGetQueueUserAclsOnHA() throws Exception {
    List<QueueUserACLInfo> queueUserAclsList=client.getQueueAclsInfo();
    Assert.assertTrue(queueUserAclsList != null);
    Assert.assertFalse(queueUserAclsList.isEmpty());
    Assert.assertEquals(cluster.createFakeQueueUserACLInfoList(),queueUserAclsList);
  }
  @Test(timeout=15000) public void testGetApplicationAttemptReportOnHA() throws Exception {
    ApplicationAttemptReport report=client.getApplicationAttemptReport(cluster.createFakeApplicationAttemptId());
    Assert.assertTrue(report != null);
    Assert.assertEquals(cluster.createFakeApplicationAttemptReport(),report);
  }
  @Test(timeout=15000) public void testGetApplicationAttemptsOnHA() throws Exception {
    List<ApplicationAttemptReport> reports=client.getApplicationAttempts(cluster.createFakeAppId());
    Assert.assertTrue(reports != null);
    Assert.assertFalse(reports.isEmpty());
    Assert.assertEquals(cluster.createFakeApplicationAttemptReports(),reports);
  }
  @Test(timeout=15000) public void testGetContainerReportOnHA() throws Exception {
    ContainerReport report=client.getContainerReport(cluster.createFakeContainerId());
    Assert.assertTrue(report != null);
    Assert.assertEquals(cluster.createFakeContainerReport(),report);
  }
  @Test(timeout=15000) public void testGetContainersOnHA() throws Exception {
    List<ContainerReport> reports=client.getContainers(cluster.createFakeApplicationAttemptId());
    Assert.assertTrue(reports != null);
    Assert.assertFalse(reports.isEmpty());
    Assert.assertEquals(cluster.createFakeContainerReports(),reports);
  }
  @Test(timeout=15000) public void testSubmitApplicationOnHA() throws Exception {
    ApplicationSubmissionContext appContext=Records.newRecord(ApplicationSubmissionContext.class);
    appContext.setApplicationId(cluster.createFakeAppId());
    ContainerLaunchContext amContainer=Records.newRecord(ContainerLaunchContext.class);
    appContext.setAMContainerSpec(amContainer);
    Resource capability=Records.newRecord(Resource.class);
    capability.setMemorySize(10);
    capability.setVirtualCores(1);
    appContext.setResource(capability);
    ApplicationId appId=client.submitApplication(appContext);
    Assert.assertTrue(getActiveRM().getRMContext().getRMApps().containsKey(appId));
  }
  @Test(timeout=15000) public void testMoveApplicationAcrossQueuesOnHA() throws Exception {
    client.moveApplicationAcrossQueues(cluster.createFakeAppId(),"root");
  }
  @Test(timeout=15000) public void testForceKillApplicationOnHA() throws Exception {
    client.killApplication(cluster.createFakeAppId());
  }
  @Test(timeout=15000) public void testGetDelegationTokenOnHA() throws Exception {
    Token token=client.getRMDelegationToken(new Text(" "));
    Assert.assertEquals(token,cluster.createFakeToken());
  }
  @Test(timeout=15000) public void testRenewDelegationTokenOnHA() throws Exception {
    RenewDelegationTokenRequest request=RenewDelegationTokenRequest.newInstance(cluster.createFakeToken());
    long newExpirationTime=ClientRMProxy.createRMProxy(this.conf,ApplicationClientProtocol.class).renewDelegationToken(request).getNextExpirationTime();
    Assert.assertEquals(newExpirationTime,cluster.createNextExpirationTime());
  }
  @Test(timeout=15000) public void testCancelDelegationTokenOnHA() throws Exception {
    CancelDelegationTokenRequest request=CancelDelegationTokenRequest.newInstance(cluster.createFakeToken());
    ClientRMProxy.createRMProxy(this.conf,ApplicationClientProtocol.class).cancelDelegationToken(request);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.hadoop.registry.client.binding;
import org.apache.hadoop.registry.RegistryTestHelper;
import org.apache.hadoop.registry.client.exceptions.InvalidRecordException;
import org.apache.hadoop.registry.client.exceptions.NoRecordException;
import org.apache.hadoop.registry.client.types.ServiceRecord;
import org.apache.hadoop.registry.client.types.yarn.PersistencePolicies;
import org.junit.BeforeClass;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.TestName;
import org.junit.rules.Timeout;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
/** 
 * Test record marshalling
 */
public class TestMarshalling extends RegistryTestHelper {
  private static final Logger LOG=LoggerFactory.getLogger(TestMarshalling.class);
  @Rule public final Timeout testTimeout=new Timeout(10000);
  @Rule public TestName methodName=new TestName();
  private static RegistryUtils.ServiceRecordMarshal marshal;
  @BeforeClass public static void setupClass(){
    marshal=new RegistryUtils.ServiceRecordMarshal();
  }
  @Test public void testRoundTrip() throws Throwable {
    String persistence=PersistencePolicies.PERMANENT;
    ServiceRecord record=createRecord(persistence);
    record.set("customkey","customvalue");
    record.set("customkey2","customvalue2");
    RegistryTypeUtils.validateServiceRecord("",record);
    LOG.info(marshal.toJson(record));
    byte[] bytes=marshal.toBytes(record);
    ServiceRecord r2=marshal.fromBytes("",bytes);
    assertMatches(record,r2);
    RegistryTypeUtils.validateServiceRecord("",r2);
  }
  @Test(expected=NoRecordException.class) public void testUnmarshallNoData() throws Throwable {
    marshal.fromBytes("src",new byte[]{});
  }
  @Test(expected=NoRecordException.class) public void testUnmarshallNotEnoughData() throws Throwable {
    marshal.fromBytes("src",new byte[]{'{','}'},ServiceRecord.RECORD_TYPE);
  }
  @Test(expected=InvalidRecordException.class) public void testUnmarshallNoBody() throws Throwable {
    byte[] bytes="this is not valid JSON at all and should fail".getBytes();
    marshal.fromBytes("src",bytes);
  }
  @Test(expected=InvalidRecordException.class) public void testUnmarshallWrongType() throws Throwable {
    byte[] bytes="{'type':''}".getBytes();
    ServiceRecord serviceRecord=marshal.fromBytes("marshalling",bytes);
    RegistryTypeUtils.validateServiceRecord("validating",serviceRecord);
  }
  @Test(expected=NoRecordException.class) public void testUnmarshallWrongLongType() throws Throwable {
    ServiceRecord record=new ServiceRecord();
    record.type="ThisRecordHasALongButNonMatchingType";
    byte[] bytes=marshal.toBytes(record);
    ServiceRecord serviceRecord=marshal.fromBytes("marshalling",bytes,ServiceRecord.RECORD_TYPE);
  }
  @Test(expected=NoRecordException.class) public void testUnmarshallNoType() throws Throwable {
    ServiceRecord record=new ServiceRecord();
    record.type="NoRecord";
    byte[] bytes=marshal.toBytes(record);
    ServiceRecord serviceRecord=marshal.fromBytes("marshalling",bytes,ServiceRecord.RECORD_TYPE);
  }
  @Test(expected=InvalidRecordException.class) public void testRecordValidationWrongType() throws Throwable {
    ServiceRecord record=new ServiceRecord();
    record.type="NotAServiceRecordType";
    RegistryTypeUtils.validateServiceRecord("validating",record);
  }
  @Test public void testUnknownFieldsRoundTrip() throws Throwable {
    ServiceRecord record=createRecord(PersistencePolicies.APPLICATION_ATTEMPT);
    record.set("key","value");
    record.set("intval","2");
    assertEquals("value",record.get("key"));
    assertEquals("2",record.get("intval"));
    assertNull(record.get("null"));
    assertEquals("defval",record.get("null","defval"));
    byte[] bytes=marshal.toBytes(record);
    ServiceRecord r2=marshal.fromBytes("",bytes);
    assertEquals("value",r2.get("key"));
    assertEquals("2",r2.get("intval"));
  }
  @Test public void testFieldPropagationInCopy() throws Throwable {
    ServiceRecord record=createRecord(PersistencePolicies.APPLICATION_ATTEMPT);
    record.set("key","value");
    record.set("intval","2");
    ServiceRecord that=new ServiceRecord(record);
    assertMatches(record,that);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.hadoop.metrics2.lib;
import org.junit.Test;
import static org.junit.Assert.*;
import static org.mockito.Mockito.*;
import org.apache.hadoop.metrics2.MetricsCollector;
import org.apache.hadoop.metrics2.MetricsException;
import org.apache.hadoop.metrics2.MetricsRecordBuilder;
import org.apache.hadoop.metrics2.MetricsSource;
import org.apache.hadoop.metrics2.annotation.Metric;
import org.apache.hadoop.metrics2.annotation.Metric.*;
import org.apache.hadoop.metrics2.annotation.Metrics;
import org.apache.hadoop.metrics2.impl.MsInfo;
import static org.apache.hadoop.metrics2.lib.Interns.*;
import static org.apache.hadoop.test.MetricsAsserts.*;
public class TestMetricsAnnotations {
static class MyMetrics {
    @Metric MutableCounterInt c1;
    @Metric({"Counter2","Counter2 desc"}) MutableCounterLong c2;
    @Metric MutableGaugeInt g1, g2;
    @Metric("g3 desc") MutableGaugeLong g3;
    @Metric("g4 desc") MutableGaugeFloat g4;
    @Metric MutableRate r1;
    @Metric MutableStat s1;
    @Metric MutableRates rs1;
  }
  @Test public void testFields(){
    MyMetrics metrics=new MyMetrics();
    MetricsSource source=MetricsAnnotations.makeSource(metrics);
    metrics.c1.incr();
    metrics.c2.incr();
    metrics.g1.incr();
    metrics.g2.incr();
    metrics.g3.incr();
    metrics.g4.incr();
    metrics.r1.add(1);
    metrics.s1.add(1);
    metrics.rs1.add("rs1",1);
    MetricsRecordBuilder rb=getMetrics(source);
    verify(rb).addCounter(info("C1","C1"),1);
    verify(rb).addCounter(info("Counter2","Counter2 desc"),1L);
    verify(rb).addGauge(info("G1","G1"),1);
    verify(rb).addGauge(info("G2","G2"),1);
    verify(rb).addGauge(info("G3","g3 desc"),1L);
    verify(rb).addGauge(info("G4","g4 desc"),1f);
    verify(rb).addCounter(info("R1NumOps","Number of ops for r1"),1L);
    verify(rb).addGauge(info("R1AvgTime","Average time for r1"),1.0);
    verify(rb).addCounter(info("S1NumOps","Number of ops for s1"),1L);
    verify(rb).addGauge(info("S1AvgTime","Average time for s1"),1.0);
    verify(rb).addCounter(info("Rs1NumOps","Number of ops for rs1"),1L);
    verify(rb).addGauge(info("Rs1AvgTime","Average time for rs1"),1.0);
  }
static class BadMetrics {
    @Metric Integer i0;
  }
  @Test(expected=MetricsException.class) public void testBadFields(){
    MetricsAnnotations.makeSource(new BadMetrics());
  }
static class MyMetrics2 {
    @Metric int getG1(){
      return 1;
    }
    @Metric long getG2(){
      return 2;
    }
    @Metric float getG3(){
      return 3;
    }
    @Metric double getG4(){
      return 4;
    }
    @Metric(type=Type.COUNTER) int getC1(){
      return 1;
    }
    @Metric(type=Type.COUNTER) long getC2(){
      return 2;
    }
    @Metric(type=Type.TAG) String getT1(){
      return "t1";
    }
  }
  @Test public void testMethods(){
    MyMetrics2 metrics=new MyMetrics2();
    MetricsSource source=MetricsAnnotations.makeSource(metrics);
    MetricsRecordBuilder rb=getMetrics(source);
    verify(rb).addGauge(info("G1","G1"),1);
    verify(rb).addGauge(info("G2","G2"),2L);
    verify(rb).addGauge(info("G3","G3"),3.0f);
    verify(rb).addGauge(info("G4","G4"),4.0);
    verify(rb).addCounter(info("C1","C1"),1);
    verify(rb).addCounter(info("C2","C2"),2L);
    verify(rb).tag(info("T1","T1"),"t1");
  }
static class BadMetrics2 {
    @Metric int foo(    int i){
      return i;
    }
  }
  @Test(expected=IllegalArgumentException.class) public void testBadMethodWithArgs(){
    MetricsAnnotations.makeSource(new BadMetrics2());
  }
static class BadMetrics3 {
    @Metric boolean foo(){
      return true;
    }
  }
  @Test(expected=MetricsException.class) public void testBadMethodReturnType(){
    MetricsAnnotations.makeSource(new BadMetrics3());
  }
@Metrics(about="My metrics",context="foo") static class MyMetrics3 {
    @Metric int getG1(){
      return 1;
    }
  }
  @Test public void testClasses(){
    MetricsRecordBuilder rb=getMetrics(MetricsAnnotations.makeSource(new MyMetrics3()));
    MetricsCollector collector=rb.parent();
    verify(collector).addRecord(info("MyMetrics3","My metrics"));
    verify(rb).add(tag(MsInfo.Context,"foo"));
  }
static class HybridMetrics implements MetricsSource {
    final MetricsRegistry registry=new MetricsRegistry("HybridMetrics").setContext("hybrid");
    @Metric("C0 desc") MutableCounterInt C0;
    @Metric int getG0(){
      return 0;
    }
    @Override public void getMetrics(    MetricsCollector collector,    boolean all){
      collector.addRecord("foo").setContext("foocontext").addCounter(info("C1","C1 desc"),1).endRecord().addRecord("bar").setContext("barcontext").addGauge(info("G1","G1 desc"),1);
      registry.snapshot(collector.addRecord(registry.info()),all);
    }
  }
  @Test public void testHybrid(){
    HybridMetrics metrics=new HybridMetrics();
    MetricsSource source=MetricsAnnotations.makeSource(metrics);
    assertSame(metrics,source);
    metrics.C0.incr();
    MetricsRecordBuilder rb=getMetrics(source);
    MetricsCollector collector=rb.parent();
    verify(collector).addRecord("foo");
    verify(collector).addRecord("bar");
    verify(collector).addRecord(info("HybridMetrics","HybridMetrics"));
    verify(rb).setContext("foocontext");
    verify(rb).addCounter(info("C1","C1 desc"),1);
    verify(rb).setContext("barcontext");
    verify(rb).addGauge(info("G1","G1 desc"),1);
    verify(rb).add(tag(MsInfo.Context,"hybrid"));
    verify(rb).addCounter(info("C0","C0 desc"),1);
    verify(rb).addGauge(info("G0","G0"),0);
  }
@Metrics(context="hybrid") static class BadHybridMetrics implements MetricsSource {
    @Metric MutableCounterInt c1;
    @Override public void getMetrics(    MetricsCollector collector,    boolean all){
      collector.addRecord("foo");
    }
  }
  @Test(expected=MetricsException.class) public void testBadHybrid(){
    MetricsAnnotations.makeSource(new BadHybridMetrics());
  }
static class EmptyMetrics {
    int foo;
  }
  @Test(expected=MetricsException.class) public void testEmptyMetrics(){
    MetricsAnnotations.makeSource(new EmptyMetrics());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.crypto.key;
import java.io.IOException;
import java.util.Queue;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.apache.hadoop.crypto.key.kms.ValueQueue;
import org.apache.hadoop.crypto.key.kms.ValueQueue.QueueRefiller;
import org.apache.hadoop.crypto.key.kms.ValueQueue.SyncGenerationPolicy;
import org.apache.hadoop.test.GenericTestUtils;
import org.junit.Assert;
import org.junit.Test;
import com.google.common.base.Supplier;
import com.google.common.collect.Sets;
public class TestValueQueue {
  Logger LOG=LoggerFactory.getLogger(TestValueQueue.class);
private static class FillInfo {
    final int num;
    final String key;
    FillInfo(    int num,    String key){
      this.num=num;
      this.key=key;
    }
  }
private static class MockFiller implements QueueRefiller<String> {
    final LinkedBlockingQueue<FillInfo> fillCalls=new LinkedBlockingQueue<FillInfo>();
    @Override public void fillQueueForKey(    String keyName,    Queue<String> keyQueue,    int numValues) throws IOException {
      fillCalls.add(new FillInfo(numValues,keyName));
      for (int i=0; i < numValues; i++) {
        keyQueue.add("test");
      }
    }
    public FillInfo getTop() throws InterruptedException {
      return fillCalls.poll(500,TimeUnit.MILLISECONDS);
    }
  }
  /** 
 * Verifies that Queue is initially filled to "numInitValues"
 */
  @Test(timeout=30000) public void testInitFill() throws Exception {
    MockFiller filler=new MockFiller();
    ValueQueue<String> vq=new ValueQueue<String>(10,0.1f,300,1,SyncGenerationPolicy.ALL,filler);
    Assert.assertEquals("test",vq.getNext("k1"));
    Assert.assertEquals(1,filler.getTop().num);
    vq.shutdown();
  }
  /** 
 * Verifies that Queue is initialized (Warmed-up) for provided keys
 */
  @Test(timeout=30000) public void testWarmUp() throws Exception {
    MockFiller filler=new MockFiller();
    ValueQueue<String> vq=new ValueQueue<String>(10,0.5f,300,1,SyncGenerationPolicy.ALL,filler);
    vq.initializeQueuesForKeys("k1","k2","k3");
    FillInfo[] fillInfos={filler.getTop(),filler.getTop(),filler.getTop()};
    Assert.assertEquals(5,fillInfos[0].num);
    Assert.assertEquals(5,fillInfos[1].num);
    Assert.assertEquals(5,fillInfos[2].num);
    Assert.assertEquals(Sets.newHashSet("k1","k2","k3"),Sets.newHashSet(fillInfos[0].key,fillInfos[1].key,fillInfos[2].key));
    vq.shutdown();
  }
  /** 
 * Verifies that the refill task is executed after "checkInterval" if num values below "lowWatermark"
 */
  @Test(timeout=30000) public void testRefill() throws Exception {
    MockFiller filler=new MockFiller();
    ValueQueue<String> vq=new ValueQueue<String>(10,0.1f,300,1,SyncGenerationPolicy.ALL,filler);
    Assert.assertEquals("test",vq.getNext("k1"));
    Assert.assertEquals(1,filler.getTop().num);
    vq.getNext("k1");
    Assert.assertEquals(1,filler.getTop().num);
    Assert.assertEquals(10,filler.getTop().num);
    vq.shutdown();
  }
  /** 
 * Verifies that the No refill Happens after "checkInterval" if num values above "lowWatermark"
 */
  @Test(timeout=30000) public void testNoRefill() throws Exception {
    MockFiller filler=new MockFiller();
    ValueQueue<String> vq=new ValueQueue<String>(10,0.5f,300,1,SyncGenerationPolicy.ALL,filler);
    Assert.assertEquals("test",vq.getNext("k1"));
    Assert.assertEquals(5,filler.getTop().num);
    Assert.assertEquals(null,filler.getTop());
    vq.shutdown();
  }
  /** 
 * Verify getAtMost when SyncGeneration Policy = ALL
 */
  @Test(timeout=30000) public void testgetAtMostPolicyALL() throws Exception {
    MockFiller filler=new MockFiller();
    final ValueQueue<String> vq=new ValueQueue<String>(10,0.1f,300,1,SyncGenerationPolicy.ALL,filler);
    Assert.assertEquals("test",vq.getNext("k1"));
    Assert.assertEquals(1,filler.getTop().num);
    Assert.assertEquals("Failed in sync call.",10,vq.getAtMost("k1",10).size());
    Assert.assertEquals("Sync call filler got wrong number.",10,filler.getTop().num);
    GenericTestUtils.waitFor(new Supplier<Boolean>(){
      @Override public Boolean get(){
        int size=vq.getSize("k1");
        if (size != 10) {
          LOG.info("Current ValueQueue size is " + size);
          return false;
        }
        return true;
      }
    }
,100,3000);
    Assert.assertEquals("Failed in async call.",10,filler.getTop().num);
    Assert.assertEquals("Failed to drain completely after async.",10,vq.getAtMost("k1",10).size());
    Assert.assertEquals("Failed to get all 19.",19,vq.getAtMost("k1",19).size());
    Assert.assertEquals("Failed in sync call.",19,filler.getTop().num);
    vq.shutdown();
  }
  /** 
 * Verify getAtMost when SyncGeneration Policy = ALL
 */
  @Test(timeout=30000) public void testgetAtMostPolicyATLEAST_ONE() throws Exception {
    MockFiller filler=new MockFiller();
    ValueQueue<String> vq=new ValueQueue<String>(10,0.3f,300,1,SyncGenerationPolicy.ATLEAST_ONE,filler);
    Assert.assertEquals("test",vq.getNext("k1"));
    Assert.assertEquals(3,filler.getTop().num);
    Assert.assertEquals(2,vq.getAtMost("k1",10).size());
    Assert.assertEquals(10,filler.getTop().num);
    vq.shutdown();
  }
  /** 
 * Verify getAtMost when SyncGeneration Policy = LOW_WATERMARK
 */
  @Test(timeout=30000) public void testgetAtMostPolicyLOW_WATERMARK() throws Exception {
    MockFiller filler=new MockFiller();
    ValueQueue<String> vq=new ValueQueue<String>(10,0.3f,300,1,SyncGenerationPolicy.LOW_WATERMARK,filler);
    Assert.assertEquals("test",vq.getNext("k1"));
    Assert.assertEquals(3,filler.getTop().num);
    Assert.assertEquals(3,vq.getAtMost("k1",10).size());
    Assert.assertEquals(1,filler.getTop().num);
    Assert.assertEquals(10,filler.getTop().num);
    vq.shutdown();
  }
  @Test(timeout=30000) public void testDrain() throws Exception {
    MockFiller filler=new MockFiller();
    ValueQueue<String> vq=new ValueQueue<String>(10,0.1f,300,1,SyncGenerationPolicy.ALL,filler);
    Assert.assertEquals("test",vq.getNext("k1"));
    Assert.assertEquals(1,filler.getTop().num);
    vq.drain("k1");
    Assert.assertNull(filler.getTop());
    vq.shutdown();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.crypto.random;
import java.util.Arrays;
import org.junit.Test;
public class TestOpensslSecureRandom {
  @Test(timeout=120000) public void testRandomBytes() throws Exception {
    OpensslSecureRandom random=new OpensslSecureRandom();
    checkRandomBytes(random,16);
    checkRandomBytes(random,32);
    checkRandomBytes(random,128);
    checkRandomBytes(random,256);
  }
  /** 
 * Test will timeout if secure random implementation always returns a  constant value.
 */
  private void checkRandomBytes(  OpensslSecureRandom random,  int len){
    byte[] bytes=new byte[len];
    byte[] bytes1=new byte[len];
    random.nextBytes(bytes);
    random.nextBytes(bytes1);
    while (Arrays.equals(bytes,bytes1)) {
      random.nextBytes(bytes1);
    }
  }
  /** 
 * Test will timeout if secure random implementation always returns a  constant value.
 */
  @Test(timeout=120000) public void testRandomInt() throws Exception {
    OpensslSecureRandom random=new OpensslSecureRandom();
    int rand1=random.nextInt();
    int rand2=random.nextInt();
    while (rand1 == rand2) {
      rand2=random.nextInt();
    }
  }
  /** 
 * Test will timeout if secure random implementation always returns a  constant value.
 */
  @Test(timeout=120000) public void testRandomLong() throws Exception {
    OpensslSecureRandom random=new OpensslSecureRandom();
    long rand1=random.nextLong();
    long rand2=random.nextLong();
    while (rand1 == rand2) {
      rand2=random.nextLong();
    }
  }
  /** 
 * Test will timeout if secure random implementation always returns a  constant value.
 */
  @Test(timeout=120000) public void testRandomFloat() throws Exception {
    OpensslSecureRandom random=new OpensslSecureRandom();
    float rand1=random.nextFloat();
    float rand2=random.nextFloat();
    while (rand1 == rand2) {
      rand2=random.nextFloat();
    }
  }
  /** 
 * Test will timeout if secure random implementation always returns a  constant value.
 */
  @Test(timeout=120000) public void testRandomDouble() throws Exception {
    OpensslSecureRandom random=new OpensslSecureRandom();
    double rand1=random.nextDouble();
    double rand2=random.nextDouble();
    while (rand1 == rand2) {
      rand2=random.nextDouble();
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.hadoop.test;
import org.junit.Assert;
import org.junit.Before;
import org.junit.BeforeClass;
import org.junit.Rule;
import org.junit.rules.TestName;
import org.junit.rules.Timeout;
/** 
 * A base class for JUnit4 tests that sets a default timeout for all tests that subclass this test. Threads are named to the method being executed, for ease of diagnostics in logs and thread dumps.
 */
public abstract class HadoopTestBase extends Assert {
  /** 
 * System property name to set the test timeout:  {@value}.
 */
  public static final String PROPERTY_TEST_DEFAULT_TIMEOUT="test.default.timeout";
  /** 
 * The default timeout (in milliseconds) if the system property {@link #PROPERTY_TEST_DEFAULT_TIMEOUT}is not set:  {@value}.
 */
  public static final int TEST_DEFAULT_TIMEOUT_VALUE=100000;
  /** 
 * The JUnit rule that sets the default timeout for tests.
 */
  @Rule public Timeout defaultTimeout=retrieveTestTimeout();
  /** 
 * Retrieve the test timeout from the system property {@link #PROPERTY_TEST_DEFAULT_TIMEOUT}, falling back to the value in  {@link #TEST_DEFAULT_TIMEOUT_VALUE} if theproperty is not defined.
 * @return the recommended timeout for tests
 */
  public static Timeout retrieveTestTimeout(){
    String propval=System.getProperty(PROPERTY_TEST_DEFAULT_TIMEOUT,Integer.toString(TEST_DEFAULT_TIMEOUT_VALUE));
    int millis;
    try {
      millis=Integer.parseInt(propval);
    }
 catch (    NumberFormatException e) {
      millis=TEST_DEFAULT_TIMEOUT_VALUE;
    }
    return new Timeout(millis);
  }
  /** 
 * The method name.
 */
  @Rule public TestName methodName=new TestName();
  /** 
 * Get the method name; defaults to the value of  {@link #methodName}. Subclasses may wish to override it, which will tune the thread naming.
 * @return the name of the method.
 */
  protected String getMethodName(){
    return methodName.getMethodName();
  }
  /** 
 * Static initializer names this thread "JUnit".
 */
  @BeforeClass public static void nameTestThread(){
    Thread.currentThread().setName("JUnit");
  }
  /** 
 * Before each method, the thread is renamed to match the method name.
 */
  @Before public void nameThreadToMethod(){
    Thread.currentThread().setName("JUnit-" + getMethodName());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.hadoop.util;
import java.io.ByteArrayOutputStream;
import java.io.PrintStream;
import org.junit.Assert;
import org.apache.hadoop.util.FindClass;
import org.apache.hadoop.util.ToolRunner;
import org.junit.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
/** 
 * Test the find class logic
 */
public class TestFindClass extends Assert {
  private static final Logger LOG=LoggerFactory.getLogger(TestFindClass.class);
  public static final String LOG4J_PROPERTIES="log4j.properties";
  /** 
 * Run the tool runner instance
 * @param expected expected return code
 * @param args a list of arguments
 * @throws Exception on any falure that is not handled earlier
 */
  private void run(  int expected,  String... args) throws Exception {
    int result=ToolRunner.run(new FindClass(),args);
    assertEquals(expected,result);
  }
  @Test public void testUsage() throws Throwable {
    run(FindClass.E_USAGE,"org.apache.hadoop.util.TestFindClass");
  }
  @Test public void testFindsResource() throws Throwable {
    run(FindClass.SUCCESS,FindClass.A_RESOURCE,"org/apache/hadoop/util/TestFindClass.class");
  }
  @Test public void testFailsNoSuchResource() throws Throwable {
    run(FindClass.E_NOT_FOUND,FindClass.A_RESOURCE,"org/apache/hadoop/util/ThereIsNoSuchClass.class");
  }
  @Test public void testLoadFindsSelf() throws Throwable {
    run(FindClass.SUCCESS,FindClass.A_LOAD,"org.apache.hadoop.util.TestFindClass");
  }
  @Test public void testLoadFailsNoSuchClass() throws Throwable {
    run(FindClass.E_NOT_FOUND,FindClass.A_LOAD,"org.apache.hadoop.util.ThereIsNoSuchClass");
  }
  @Test public void testLoadWithErrorInStaticInit() throws Throwable {
    run(FindClass.E_LOAD_FAILED,FindClass.A_LOAD,"org.apache.hadoop.util.TestFindClass$FailInStaticInit");
  }
  @Test public void testCreateHandlesBadToString() throws Throwable {
    run(FindClass.SUCCESS,FindClass.A_CREATE,"org.apache.hadoop.util.TestFindClass$BadToStringClass");
  }
  @Test public void testCreatesClass() throws Throwable {
    run(FindClass.SUCCESS,FindClass.A_CREATE,"org.apache.hadoop.util.TestFindClass");
  }
  @Test public void testCreateFailsInStaticInit() throws Throwable {
    run(FindClass.E_LOAD_FAILED,FindClass.A_CREATE,"org.apache.hadoop.util.TestFindClass$FailInStaticInit");
  }
  @Test public void testCreateFailsInConstructor() throws Throwable {
    run(FindClass.E_CREATE_FAILED,FindClass.A_CREATE,"org.apache.hadoop.util.TestFindClass$FailInConstructor");
  }
  @Test public void testCreateFailsNoEmptyConstructor() throws Throwable {
    run(FindClass.E_CREATE_FAILED,FindClass.A_CREATE,"org.apache.hadoop.util.TestFindClass$NoEmptyConstructor");
  }
  @Test public void testLoadPrivateClass() throws Throwable {
    run(FindClass.SUCCESS,FindClass.A_LOAD,"org.apache.hadoop.util.TestFindClass$PrivateClass");
  }
  @Test public void testCreateFailsPrivateClass() throws Throwable {
    run(FindClass.E_CREATE_FAILED,FindClass.A_CREATE,"org.apache.hadoop.util.TestFindClass$PrivateClass");
  }
  @Test public void testCreateFailsInPrivateConstructor() throws Throwable {
    run(FindClass.E_CREATE_FAILED,FindClass.A_CREATE,"org.apache.hadoop.util.TestFindClass$PrivateConstructor");
  }
  @Test public void testLoadFindsLog4J() throws Throwable {
    run(FindClass.SUCCESS,FindClass.A_RESOURCE,LOG4J_PROPERTIES);
  }
  @SuppressWarnings("UseOfSystemOutOrSystemErr") @Test public void testPrintLog4J() throws Throwable {
    ByteArrayOutputStream baos=new ByteArrayOutputStream();
    PrintStream out=new PrintStream(baos);
    FindClass.setOutputStreams(out,System.err);
    run(FindClass.SUCCESS,FindClass.A_PRINTRESOURCE,LOG4J_PROPERTIES);
    out.flush();
    String body=baos.toString("UTF8");
    LOG.info(LOG4J_PROPERTIES + " =\n" + body);
    assertTrue(body.contains("Apache"));
  }
  /** 
 * trigger a divide by zero fault in the static init
 */
public static class FailInStaticInit {
static {
      int x=0;
      int y=1 / x;
    }
  }
  /** 
 * trigger a divide by zero fault in the constructor
 */
public static class FailInConstructor {
    public FailInConstructor(){
      int x=0;
      int y=1 / x;
    }
  }
  /** 
 * A class with no parameterless constructor -expect creation to fail
 */
public static class NoEmptyConstructor {
    public NoEmptyConstructor(    String text){
    }
  }
  /** 
 * This has triggers an NPE in the toString() method; checks the logging code handles this.
 */
public static class BadToStringClass {
    public BadToStringClass(){
    }
    @Override public String toString(){
      throw new NullPointerException("oops");
    }
  }
  /** 
 * This has a private constructor -creating it will trigger an IllegalAccessException
 */
public static class PrivateClass {
    private PrivateClass(){
    }
  }
  /** 
 * This has a private constructor -creating it will trigger an IllegalAccessException
 */
public static class PrivateConstructor {
    private PrivateConstructor(){
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.io.compress;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.util.Arrays;
import java.util.Random;
import java.util.zip.GZIPInputStream;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.DataInputBuffer;
import org.apache.hadoop.io.DataOutputBuffer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.junit.Before;
import org.junit.Test;
import static org.junit.Assert.assertArrayEquals;
import static org.junit.Assert.assertEquals;
/** 
 * Verify resettable compressor.
 */
public class TestGzipCodec {
  private static final Logger LOG=LoggerFactory.getLogger(TestGzipCodec.class);
  private static final String DATA1="Dogs don't know it's not bacon!\n";
  private static final String DATA2="It's baconnnn!!\n";
  private GzipCodec codec=new GzipCodec();
  @Before public void setUp(){
    codec.setConf(new Configuration(false));
  }
  @Test public void testSingleCompress() throws IOException {
    ByteArrayOutputStream baos=new ByteArrayOutputStream();
    CompressionOutputStream cmpOut=codec.createOutputStream(baos);
    cmpOut.write(DATA1.getBytes(StandardCharsets.UTF_8));
    cmpOut.finish();
    cmpOut.close();
    ByteArrayInputStream bais=new ByteArrayInputStream(baos.toByteArray());
    GZIPInputStream cmpIn=new GZIPInputStream(bais);
    byte[] buf=new byte[1024];
    int len=cmpIn.read(buf);
    String result=new String(buf,0,len,StandardCharsets.UTF_8);
    assertEquals("Input must match output",DATA1,result);
  }
  @Test public void testResetCompress() throws IOException {
    DataOutputBuffer dob=new DataOutputBuffer();
    CompressionOutputStream cmpOut=codec.createOutputStream(dob);
    cmpOut.write(DATA1.getBytes(StandardCharsets.UTF_8));
    cmpOut.finish();
    cmpOut.resetState();
    cmpOut.write(DATA2.getBytes(StandardCharsets.UTF_8));
    cmpOut.finish();
    cmpOut.close();
    dob.close();
    DataInputBuffer dib=new DataInputBuffer();
    dib.reset(dob.getData(),0,dob.getLength());
    CompressionInputStream cmpIn=codec.createInputStream(dib);
    byte[] buf=new byte[1024];
    StringBuilder result=new StringBuilder();
    int len=0;
    while (true) {
      len=cmpIn.read(buf);
      if (len < 0) {
        break;
      }
      result.append(new String(buf,0,len,StandardCharsets.UTF_8));
    }
    assertEquals("Output must match input",DATA1 + DATA2,result.toString());
  }
  @Test public void testWriteOverride() throws IOException {
    Random r=new Random();
    long seed=r.nextLong();
    LOG.info("seed: " + seed);
    r.setSeed(seed);
    byte[] buf=new byte[128];
    r.nextBytes(buf);
    DataOutputBuffer dob=new DataOutputBuffer();
    CompressionOutputStream cmpOut=codec.createOutputStream(dob);
    cmpOut.write(buf);
    int i=r.nextInt(128 - 10);
    int l=r.nextInt(128 - i);
    cmpOut.write(buf,i,l);
    cmpOut.write((byte)(r.nextInt() & 0xFF));
    cmpOut.close();
    r.setSeed(seed);
    DataInputBuffer dib=new DataInputBuffer();
    dib.reset(dob.getData(),0,dob.getLength());
    CompressionInputStream cmpIn=codec.createInputStream(dib);
    byte[] vbuf=new byte[128];
    assertEquals(128,cmpIn.read(vbuf));
    assertArrayEquals(buf,vbuf);
    r.nextBytes(vbuf);
    int vi=r.nextInt(128 - 10);
    int vl=r.nextInt(128 - vi);
    assertEquals(vl,cmpIn.read(vbuf,0,vl));
    assertArrayEquals(Arrays.copyOfRange(buf,i,i + l),Arrays.copyOf(vbuf,vl));
    assertEquals(r.nextInt() & 0xFF,cmpIn.read());
    assertEquals(-1,cmpIn.read());
  }
  @Test public void testIdempotentResetState() throws IOException {
    DataOutputBuffer dob=new DataOutputBuffer();
    CompressionOutputStream cmpOut=codec.createOutputStream(dob);
    cmpOut.write(DATA1.getBytes(StandardCharsets.UTF_8));
    cmpOut.finish();
    cmpOut.finish();
    cmpOut.finish();
    cmpOut.resetState();
    cmpOut.resetState();
    cmpOut.finish();
    cmpOut.resetState();
    cmpOut.close();
    dob.close();
    DataInputBuffer dib=new DataInputBuffer();
    dib.reset(dob.getData(),0,dob.getLength());
    CompressionInputStream cmpIn=codec.createInputStream(dib);
    byte[] buf=new byte[1024];
    StringBuilder result=new StringBuilder();
    int len=0;
    while (true) {
      len=cmpIn.read(buf);
      if (len < 0) {
        break;
      }
      result.append(new String(buf,0,len,StandardCharsets.UTF_8));
    }
    assertEquals("Output must match input",DATA1,result.toString());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.io.compress;
import static org.hamcrest.CoreMatchers.is;
import static org.junit.Assert.assertThat;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import java.io.ByteArrayInputStream;
import java.io.EOFException;
import java.io.IOException;
import org.junit.Before;
import org.junit.Test;
public class TestDecompressorStream {
  private static final String TEST_STRING="0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";
  private ByteArrayInputStream bytesIn;
  private Decompressor decompressor;
  private DecompressorStream decompressorStream;
  @Before public void setUp() throws IOException {
    bytesIn=new ByteArrayInputStream(TEST_STRING.getBytes());
    decompressor=new FakeDecompressor();
    decompressorStream=new DecompressorStream(bytesIn,decompressor,20,13);
  }
  @Test public void testReadOneByte() throws IOException {
    for (int i=0; i < TEST_STRING.length(); ++i) {
      assertThat(decompressorStream.read(),is((int)TEST_STRING.charAt(i)));
    }
    try {
      int ret=decompressorStream.read();
      fail("Not reachable but got ret " + ret);
    }
 catch (    EOFException e) {
    }
  }
  @Test public void testReadBuffer() throws IOException {
    byte[] buf=new byte[32];
    int bytesToRead=TEST_STRING.length();
    int i=0;
    while (bytesToRead > 0) {
      int n=Math.min(bytesToRead,buf.length);
      int bytesRead=decompressorStream.read(buf,0,n);
      assertTrue(bytesRead > 0 && bytesRead <= n);
      assertThat(new String(buf,0,bytesRead),is(TEST_STRING.substring(i,i + bytesRead)));
      bytesToRead=bytesToRead - bytesRead;
      i=i + bytesRead;
    }
    try {
      int ret=decompressorStream.read(buf,0,buf.length);
      fail("Not reachable but got ret " + ret);
    }
 catch (    EOFException e) {
    }
  }
  @Test public void testSkip() throws IOException {
    assertThat(decompressorStream.skip(12),is(12L));
    assertThat(decompressorStream.read(),is((int)TEST_STRING.charAt(12)));
    assertThat(decompressorStream.read(),is((int)TEST_STRING.charAt(13)));
    assertThat(decompressorStream.read(),is((int)TEST_STRING.charAt(14)));
    assertThat(decompressorStream.skip(10),is(10L));
    assertThat(decompressorStream.read(),is((int)TEST_STRING.charAt(25)));
    try {
      long ret=decompressorStream.skip(1000);
      fail("Not reachable but got ret " + ret);
    }
 catch (    EOFException e) {
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.io;
import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;
import java.util.Random;
import org.apache.hadoop.conf.Configuration;
import org.junit.Test;
import static org.junit.Assert.assertTrue;
/** 
 * Unit tests for WritableName. 
 */
public class TestWritableName {
  /** 
 * Example class used in test cases below. 
 */
public static class SimpleWritable implements Writable {
    private static final Random RANDOM=new Random();
    int state=RANDOM.nextInt();
    @Override public void write(    DataOutput out) throws IOException {
      out.writeInt(state);
    }
    @Override public void readFields(    DataInput in) throws IOException {
      this.state=in.readInt();
    }
    public static SimpleWritable read(    DataInput in) throws IOException {
      SimpleWritable result=new SimpleWritable();
      result.readFields(in);
      return result;
    }
    /** 
 * Required by test code, below. 
 */
    @Override public boolean equals(    Object o){
      if (!(o instanceof SimpleWritable))       return false;
      SimpleWritable other=(SimpleWritable)o;
      return this.state == other.state;
    }
  }
  private static final String testName="mystring";
  @Test public void testGoodName() throws Exception {
    Configuration conf=new Configuration();
    Class<?> test=WritableName.getClass("long",conf);
    assertTrue(test != null);
  }
  @Test public void testSetName() throws Exception {
    Configuration conf=new Configuration();
    WritableName.setName(SimpleWritable.class,testName);
    Class<?> test=WritableName.getClass(testName,conf);
    assertTrue(test.equals(SimpleWritable.class));
  }
  @Test public void testAddName() throws Exception {
    Configuration conf=new Configuration();
    String altName=testName + ".alt";
    WritableName.setName(SimpleWritable.class,testName);
    WritableName.addName(SimpleWritable.class,altName);
    Class<?> test=WritableName.getClass(altName,conf);
    assertTrue(test.equals(SimpleWritable.class));
    test=WritableName.getClass(testName,conf);
    assertTrue(test.equals(SimpleWritable.class));
  }
  @Test public void testBadName() throws Exception {
    Configuration conf=new Configuration();
    try {
      WritableName.getClass("unknown_junk",conf);
      assertTrue(false);
    }
 catch (    IOException e) {
      assertTrue(e.getMessage().matches(".*unknown_junk.*"));
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.io.erasurecode;
import org.apache.hadoop.io.erasurecode.rawcoder.NativeRSRawErasureCoderFactory;
import org.apache.hadoop.io.erasurecode.rawcoder.NativeXORRawErasureCoderFactory;
import org.apache.hadoop.io.erasurecode.rawcoder.RSLegacyRawErasureCoderFactory;
import org.apache.hadoop.io.erasurecode.rawcoder.RSRawErasureCoderFactory;
import org.apache.hadoop.io.erasurecode.rawcoder.RawErasureCoderFactory;
import org.apache.hadoop.io.erasurecode.rawcoder.RawErasureDecoder;
import org.apache.hadoop.io.erasurecode.rawcoder.RawErasureEncoder;
import org.apache.hadoop.io.erasurecode.rawcoder.XORRawErasureCoderFactory;
import org.junit.Test;
import java.util.ArrayList;
import java.util.List;
import java.util.Set;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
/** 
 * Test CodecRegistry.
 */
public class TestCodecRegistry {
  @Test public void testGetCodecs(){
    Set<String> codecs=CodecRegistry.getInstance().getCodecNames();
    assertEquals(3,codecs.size());
    assertTrue(codecs.contains(ErasureCodeConstants.RS_CODEC_NAME));
    assertTrue(codecs.contains(ErasureCodeConstants.RS_LEGACY_CODEC_NAME));
    assertTrue(codecs.contains(ErasureCodeConstants.XOR_CODEC_NAME));
  }
  @Test public void testGetCoders(){
    List<RawErasureCoderFactory> coders=CodecRegistry.getInstance().getCoders(ErasureCodeConstants.RS_CODEC_NAME);
    assertEquals(2,coders.size());
    assertTrue(coders.get(0) instanceof NativeRSRawErasureCoderFactory);
    assertTrue(coders.get(1) instanceof RSRawErasureCoderFactory);
    coders=CodecRegistry.getInstance().getCoders(ErasureCodeConstants.RS_LEGACY_CODEC_NAME);
    assertEquals(1,coders.size());
    assertTrue(coders.get(0) instanceof RSLegacyRawErasureCoderFactory);
    coders=CodecRegistry.getInstance().getCoders(ErasureCodeConstants.XOR_CODEC_NAME);
    assertEquals(2,coders.size());
    assertTrue(coders.get(0) instanceof NativeXORRawErasureCoderFactory);
    assertTrue(coders.get(1) instanceof XORRawErasureCoderFactory);
  }
  @Test public void testGetCodersWrong(){
    List<RawErasureCoderFactory> coders=CodecRegistry.getInstance().getCoders("WRONG_CODEC");
    assertNull(coders);
  }
  @Test public void testGetCoderNames(){
    String[] coderNames=CodecRegistry.getInstance().getCoderNames(ErasureCodeConstants.RS_CODEC_NAME);
    assertEquals(2,coderNames.length);
    assertEquals(NativeRSRawErasureCoderFactory.CODER_NAME,coderNames[0]);
    assertEquals(RSRawErasureCoderFactory.CODER_NAME,coderNames[1]);
    coderNames=CodecRegistry.getInstance().getCoderNames(ErasureCodeConstants.RS_LEGACY_CODEC_NAME);
    assertEquals(1,coderNames.length);
    assertEquals(RSLegacyRawErasureCoderFactory.CODER_NAME,coderNames[0]);
    coderNames=CodecRegistry.getInstance().getCoderNames(ErasureCodeConstants.XOR_CODEC_NAME);
    assertEquals(2,coderNames.length);
    assertEquals(NativeXORRawErasureCoderFactory.CODER_NAME,coderNames[0]);
    assertEquals(XORRawErasureCoderFactory.CODER_NAME,coderNames[1]);
  }
  @Test public void testGetCoderByName(){
    RawErasureCoderFactory coder=CodecRegistry.getInstance().getCoderByName(ErasureCodeConstants.RS_CODEC_NAME,RSRawErasureCoderFactory.CODER_NAME);
    assertTrue(coder instanceof RSRawErasureCoderFactory);
    coder=CodecRegistry.getInstance().getCoderByName(ErasureCodeConstants.RS_CODEC_NAME,NativeRSRawErasureCoderFactory.CODER_NAME);
    assertTrue(coder instanceof NativeRSRawErasureCoderFactory);
    coder=CodecRegistry.getInstance().getCoderByName(ErasureCodeConstants.RS_LEGACY_CODEC_NAME,RSLegacyRawErasureCoderFactory.CODER_NAME);
    assertTrue(coder instanceof RSLegacyRawErasureCoderFactory);
    coder=CodecRegistry.getInstance().getCoderByName(ErasureCodeConstants.XOR_CODEC_NAME,XORRawErasureCoderFactory.CODER_NAME);
    assertTrue(coder instanceof XORRawErasureCoderFactory);
    coder=CodecRegistry.getInstance().getCoderByName(ErasureCodeConstants.XOR_CODEC_NAME,NativeXORRawErasureCoderFactory.CODER_NAME);
    assertTrue(coder instanceof NativeXORRawErasureCoderFactory);
  }
  @Test public void testGetCoderByNameWrong(){
    RawErasureCoderFactory coder=CodecRegistry.getInstance().getCoderByName(ErasureCodeConstants.RS_CODEC_NAME,"WRONG_RS");
    assertNull(coder);
  }
  @Test public void testUpdateCoders(){
class RSUserDefinedIncorrectFactory implements RawErasureCoderFactory {
      public RawErasureEncoder createEncoder(      ErasureCoderOptions coderOptions){
        return null;
      }
      public RawErasureDecoder createDecoder(      ErasureCoderOptions coderOptions){
        return null;
      }
      public String getCoderName(){
        return "rs_java";
      }
      public String getCodecName(){
        return ErasureCodeConstants.RS_CODEC_NAME;
      }
    }
    List<RawErasureCoderFactory> userDefinedFactories=new ArrayList<>();
    userDefinedFactories.add(new RSUserDefinedIncorrectFactory());
    CodecRegistry.getInstance().updateCoders(userDefinedFactories);
    List<RawErasureCoderFactory> rsCoders=CodecRegistry.getInstance().getCoders(ErasureCodeConstants.RS_CODEC_NAME);
    assertEquals(2,rsCoders.size());
    assertTrue(rsCoders.get(0) instanceof NativeRSRawErasureCoderFactory);
    assertTrue(rsCoders.get(1) instanceof RSRawErasureCoderFactory);
    String[] rsCoderNames=CodecRegistry.getInstance().getCoderNames(ErasureCodeConstants.RS_CODEC_NAME);
    assertEquals(2,rsCoderNames.length);
    assertEquals(NativeRSRawErasureCoderFactory.CODER_NAME,rsCoderNames[0]);
    assertEquals(RSRawErasureCoderFactory.CODER_NAME,rsCoderNames[1]);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.io.erasurecode.rawcoder;
import org.junit.Before;
/** 
 * Test the legacy raw Reed-solomon coder implemented in Java.
 */
public class TestRSLegacyRawCoder extends TestRSRawCoderBase {
  @Before public void setup(){
    this.encoderFactoryClass=RSLegacyRawErasureCoderFactory.class;
    this.decoderFactoryClass=RSLegacyRawErasureCoderFactory.class;
    setAllowDump(false);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.io;
import java.io.*;
import java.util.*;
import org.apache.hadoop.fs.*;
import org.apache.hadoop.io.SequenceFile.CompressionType;
import org.apache.hadoop.io.SequenceFile.Metadata;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.io.compress.DefaultCodec;
import org.apache.hadoop.io.serializer.avro.AvroReflectSerialization;
import org.apache.hadoop.test.GenericTestUtils;
import org.apache.hadoop.util.ReflectionUtils;
import org.apache.hadoop.conf.*;
import org.junit.Test;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.fail;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
import org.mockito.Mockito;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
/** 
 * Support for flat files of binary key/value pairs. 
 */
public class TestSequenceFile {
  private static final Logger LOG=LoggerFactory.getLogger(TestSequenceFile.class);
  private Configuration conf=new Configuration();
  /** 
 * Unit tests for SequenceFile. 
 */
  @Test public void testZlibSequenceFile() throws Exception {
    LOG.info("Testing SequenceFile with DefaultCodec");
    compressedSeqFileTest(new DefaultCodec());
    LOG.info("Successfully tested SequenceFile with DefaultCodec");
  }
  @SuppressWarnings("deprecation") public void testSorterProperties() throws IOException {
    Configuration config=new Configuration();
    assertNull("The deprecated sort memory property " + CommonConfigurationKeys.IO_SORT_MB_KEY + " must not exist in any core-*.xml files.",config.get(CommonConfigurationKeys.IO_SORT_MB_KEY));
    assertNull("The deprecated sort factor property " + CommonConfigurationKeys.IO_SORT_FACTOR_KEY + " must not exist in any core-*.xml files.",config.get(CommonConfigurationKeys.IO_SORT_FACTOR_KEY));
    config=new Configuration();
    FileSystem fs=FileSystem.get(config);
    config.setInt(CommonConfigurationKeys.IO_SORT_MB_KEY,10);
    config.setInt(CommonConfigurationKeys.IO_SORT_FACTOR_KEY,10);
    config.setInt(CommonConfigurationKeys.SEQ_IO_SORT_MB_KEY,20);
    config.setInt(CommonConfigurationKeys.SEQ_IO_SORT_FACTOR_KEY,20);
    SequenceFile.Sorter sorter=new SequenceFile.Sorter(fs,Text.class,Text.class,config);
    assertEquals("Deprecated memory conf must be honored over newer property",10 * 1024 * 1024,sorter.getMemory());
    assertEquals("Deprecated factor conf must be honored over newer property",10,sorter.getFactor());
    config=new Configuration();
    fs=FileSystem.get(config);
    config.setInt(CommonConfigurationKeys.IO_SORT_MB_KEY,10);
    config.setInt(CommonConfigurationKeys.IO_SORT_FACTOR_KEY,10);
    sorter=new SequenceFile.Sorter(fs,Text.class,Text.class,config);
    assertEquals("Deprecated memory property " + CommonConfigurationKeys.IO_SORT_MB_KEY + " must get properly applied.",10 * 1024 * 1024,sorter.getMemory());
    assertEquals("Deprecated sort factor property " + CommonConfigurationKeys.IO_SORT_FACTOR_KEY + " must get properly applied.",10,sorter.getFactor());
    config=new Configuration();
    fs=FileSystem.get(config);
    config.setInt(CommonConfigurationKeys.SEQ_IO_SORT_MB_KEY,20);
    config.setInt(CommonConfigurationKeys.SEQ_IO_SORT_FACTOR_KEY,20);
    sorter=new SequenceFile.Sorter(fs,Text.class,Text.class,config);
    assertEquals("Memory property " + CommonConfigurationKeys.SEQ_IO_SORT_MB_KEY + " must get properly applied if present.",20 * 1024 * 1024,sorter.getMemory());
    assertEquals("Merge factor property " + CommonConfigurationKeys.SEQ_IO_SORT_FACTOR_KEY + " must get properly applied if present.",20,sorter.getFactor());
  }
  public void compressedSeqFileTest(  CompressionCodec codec) throws Exception {
    int count=1024 * 10;
    int megabytes=1;
    int factor=5;
    Path file=new Path(GenericTestUtils.getTempPath("test.seq"));
    Path recordCompressedFile=new Path(GenericTestUtils.getTempPath("test.rc.seq"));
    Path blockCompressedFile=new Path(GenericTestUtils.getTempPath("test.bc.seq"));
    int seed=new Random().nextInt();
    LOG.info("Seed = " + seed);
    FileSystem fs=FileSystem.getLocal(conf);
    try {
      writeTest(fs,count,seed,file,CompressionType.NONE,null);
      readTest(fs,count,seed,file);
      sortTest(fs,count,megabytes,factor,false,file);
      checkSort(fs,count,seed,file);
      sortTest(fs,count,megabytes,factor,true,file);
      checkSort(fs,count,seed,file);
      mergeTest(fs,count,seed,file,CompressionType.NONE,false,factor,megabytes);
      checkSort(fs,count,seed,file);
      mergeTest(fs,count,seed,file,CompressionType.NONE,true,factor,megabytes);
      checkSort(fs,count,seed,file);
      writeTest(fs,count,seed,recordCompressedFile,CompressionType.RECORD,codec);
      readTest(fs,count,seed,recordCompressedFile);
      sortTest(fs,count,megabytes,factor,false,recordCompressedFile);
      checkSort(fs,count,seed,recordCompressedFile);
      sortTest(fs,count,megabytes,factor,true,recordCompressedFile);
      checkSort(fs,count,seed,recordCompressedFile);
      mergeTest(fs,count,seed,recordCompressedFile,CompressionType.RECORD,false,factor,megabytes);
      checkSort(fs,count,seed,recordCompressedFile);
      mergeTest(fs,count,seed,recordCompressedFile,CompressionType.RECORD,true,factor,megabytes);
      checkSort(fs,count,seed,recordCompressedFile);
      writeTest(fs,count,seed,blockCompressedFile,CompressionType.BLOCK,codec);
      readTest(fs,count,seed,blockCompressedFile);
      sortTest(fs,count,megabytes,factor,false,blockCompressedFile);
      checkSort(fs,count,seed,blockCompressedFile);
      sortTest(fs,count,megabytes,factor,true,blockCompressedFile);
      checkSort(fs,count,seed,blockCompressedFile);
      mergeTest(fs,count,seed,blockCompressedFile,CompressionType.BLOCK,false,factor,megabytes);
      checkSort(fs,count,seed,blockCompressedFile);
      mergeTest(fs,count,seed,blockCompressedFile,CompressionType.BLOCK,true,factor,megabytes);
      checkSort(fs,count,seed,blockCompressedFile);
    }
  finally {
      fs.close();
    }
  }
  @SuppressWarnings("deprecation") private void writeTest(  FileSystem fs,  int count,  int seed,  Path file,  CompressionType compressionType,  CompressionCodec codec) throws IOException {
    fs.delete(file,true);
    LOG.info("creating " + count + " records with "+ compressionType+ " compression");
    SequenceFile.Writer writer=SequenceFile.createWriter(fs,conf,file,RandomDatum.class,RandomDatum.class,compressionType,codec);
    RandomDatum.Generator generator=new RandomDatum.Generator(seed);
    for (int i=0; i < count; i++) {
      generator.next();
      RandomDatum key=generator.getKey();
      RandomDatum value=generator.getValue();
      writer.append(key,value);
    }
    writer.close();
  }
  @SuppressWarnings("deprecation") private void readTest(  FileSystem fs,  int count,  int seed,  Path file) throws IOException {
    LOG.debug("reading " + count + " records");
    SequenceFile.Reader reader=new SequenceFile.Reader(fs,file,conf);
    RandomDatum.Generator generator=new RandomDatum.Generator(seed);
    RandomDatum k=new RandomDatum();
    RandomDatum v=new RandomDatum();
    DataOutputBuffer rawKey=new DataOutputBuffer();
    SequenceFile.ValueBytes rawValue=reader.createValueBytes();
    for (int i=0; i < count; i++) {
      generator.next();
      RandomDatum key=generator.getKey();
      RandomDatum value=generator.getValue();
      try {
        if ((i % 5) == 0) {
          rawKey.reset();
          reader.nextRaw(rawKey,rawValue);
        }
 else {
          if ((i % 2) == 0) {
            reader.next(k);
            reader.getCurrentValue(v);
          }
 else {
            reader.next(k,v);
          }
          if (!k.equals(key))           throw new RuntimeException("wrong key at " + i);
          if (!v.equals(value))           throw new RuntimeException("wrong value at " + i);
        }
      }
 catch (      IOException ioe) {
        LOG.info("Problem on row " + i);
        LOG.info("Expected key = " + key);
        LOG.info("Expected len = " + key.getLength());
        LOG.info("Actual key = " + k);
        LOG.info("Actual len = " + k.getLength());
        LOG.info("Expected value = " + value);
        LOG.info("Expected len = " + value.getLength());
        LOG.info("Actual value = " + v);
        LOG.info("Actual len = " + v.getLength());
        LOG.info("Key equals: " + k.equals(key));
        LOG.info("value equals: " + v.equals(value));
        throw ioe;
      }
    }
    reader.close();
  }
  private void sortTest(  FileSystem fs,  int count,  int megabytes,  int factor,  boolean fast,  Path file) throws IOException {
    fs.delete(new Path(file + ".sorted"),true);
    SequenceFile.Sorter sorter=newSorter(fs,fast,megabytes,factor);
    LOG.debug("sorting " + count + " records");
    sorter.sort(file,file.suffix(".sorted"));
    LOG.info("done sorting " + count + " debug");
  }
  @SuppressWarnings("deprecation") private void checkSort(  FileSystem fs,  int count,  int seed,  Path file) throws IOException {
    LOG.info("sorting " + count + " records in memory for debug");
    RandomDatum.Generator generator=new RandomDatum.Generator(seed);
    SortedMap<RandomDatum,RandomDatum> map=new TreeMap<RandomDatum,RandomDatum>();
    for (int i=0; i < count; i++) {
      generator.next();
      RandomDatum key=generator.getKey();
      RandomDatum value=generator.getValue();
      map.put(key,value);
    }
    LOG.debug("checking order of " + count + " records");
    RandomDatum k=new RandomDatum();
    RandomDatum v=new RandomDatum();
    Iterator<Map.Entry<RandomDatum,RandomDatum>> iterator=map.entrySet().iterator();
    SequenceFile.Reader reader=new SequenceFile.Reader(fs,file.suffix(".sorted"),conf);
    for (int i=0; i < count; i++) {
      Map.Entry<RandomDatum,RandomDatum> entry=iterator.next();
      RandomDatum key=entry.getKey();
      RandomDatum value=entry.getValue();
      reader.next(k,v);
      if (!k.equals(key))       throw new RuntimeException("wrong key at " + i);
      if (!v.equals(value))       throw new RuntimeException("wrong value at " + i);
    }
    reader.close();
    LOG.debug("sucessfully checked " + count + " records");
  }
  @SuppressWarnings("deprecation") private void mergeTest(  FileSystem fs,  int count,  int seed,  Path file,  CompressionType compressionType,  boolean fast,  int factor,  int megabytes) throws IOException {
    LOG.debug("creating " + factor + " files with "+ count / factor + " records");
    SequenceFile.Writer[] writers=new SequenceFile.Writer[factor];
    Path[] names=new Path[factor];
    Path[] sortedNames=new Path[factor];
    for (int i=0; i < factor; i++) {
      names[i]=file.suffix("." + i);
      sortedNames[i]=names[i].suffix(".sorted");
      fs.delete(names[i],true);
      fs.delete(sortedNames[i],true);
      writers[i]=SequenceFile.createWriter(fs,conf,names[i],RandomDatum.class,RandomDatum.class,compressionType);
    }
    RandomDatum.Generator generator=new RandomDatum.Generator(seed);
    for (int i=0; i < count; i++) {
      generator.next();
      RandomDatum key=generator.getKey();
      RandomDatum value=generator.getValue();
      writers[i % factor].append(key,value);
    }
    for (int i=0; i < factor; i++)     writers[i].close();
    for (int i=0; i < factor; i++) {
      LOG.debug("sorting file " + i + " with "+ count / factor + " records");
      newSorter(fs,fast,megabytes,factor).sort(names[i],sortedNames[i]);
    }
    LOG.info("merging " + factor + " files with "+ count / factor + " debug");
    fs.delete(new Path(file + ".sorted"),true);
    newSorter(fs,fast,megabytes,factor).merge(sortedNames,file.suffix(".sorted"));
  }
  private SequenceFile.Sorter newSorter(  FileSystem fs,  boolean fast,  int megabytes,  int factor){
    SequenceFile.Sorter sorter=fast ? new SequenceFile.Sorter(fs,new RandomDatum.Comparator(),RandomDatum.class,RandomDatum.class,conf) : new SequenceFile.Sorter(fs,RandomDatum.class,RandomDatum.class,conf);
    sorter.setMemory(megabytes * 1024 * 1024);
    sorter.setFactor(factor);
    return sorter;
  }
  /** 
 * Unit tests for SequenceFile metadata. 
 */
  @Test public void testSequenceFileMetadata() throws Exception {
    LOG.info("Testing SequenceFile with metadata");
    int count=1024 * 10;
    CompressionCodec codec=new DefaultCodec();
    Path file=new Path(GenericTestUtils.getTempPath("test.seq.metadata"));
    Path sortedFile=new Path(GenericTestUtils.getTempPath("test.sorted.seq.metadata"));
    Path recordCompressedFile=new Path(GenericTestUtils.getTempPath("test.rc.seq.metadata"));
    Path blockCompressedFile=new Path(GenericTestUtils.getTempPath("test.bc.seq.metadata"));
    FileSystem fs=FileSystem.getLocal(conf);
    SequenceFile.Metadata theMetadata=new SequenceFile.Metadata();
    theMetadata.set(new Text("name_1"),new Text("value_1"));
    theMetadata.set(new Text("name_2"),new Text("value_2"));
    theMetadata.set(new Text("name_3"),new Text("value_3"));
    theMetadata.set(new Text("name_4"),new Text("value_4"));
    int seed=new Random().nextInt();
    try {
      writeMetadataTest(fs,count,seed,file,CompressionType.NONE,null,theMetadata);
      SequenceFile.Metadata aMetadata=readMetadata(fs,file);
      if (!theMetadata.equals(aMetadata)) {
        LOG.info("The original metadata:\n" + theMetadata.toString());
        LOG.info("The retrieved metadata:\n" + aMetadata.toString());
        throw new RuntimeException("metadata not match:  " + 1);
      }
      writeMetadataTest(fs,count,seed,recordCompressedFile,CompressionType.RECORD,codec,theMetadata);
      aMetadata=readMetadata(fs,recordCompressedFile);
      if (!theMetadata.equals(aMetadata)) {
        LOG.info("The original metadata:\n" + theMetadata.toString());
        LOG.info("The retrieved metadata:\n" + aMetadata.toString());
        throw new RuntimeException("metadata not match:  " + 2);
      }
      writeMetadataTest(fs,count,seed,blockCompressedFile,CompressionType.BLOCK,codec,theMetadata);
      aMetadata=readMetadata(fs,blockCompressedFile);
      if (!theMetadata.equals(aMetadata)) {
        LOG.info("The original metadata:\n" + theMetadata.toString());
        LOG.info("The retrieved metadata:\n" + aMetadata.toString());
        throw new RuntimeException("metadata not match:  " + 3);
      }
      sortMetadataTest(fs,file,sortedFile,theMetadata);
      aMetadata=readMetadata(fs,recordCompressedFile);
      if (!theMetadata.equals(aMetadata)) {
        LOG.info("The original metadata:\n" + theMetadata.toString());
        LOG.info("The retrieved metadata:\n" + aMetadata.toString());
        throw new RuntimeException("metadata not match:  " + 4);
      }
    }
  finally {
      fs.close();
    }
    LOG.info("Successfully tested SequenceFile with metadata");
  }
  @SuppressWarnings("deprecation") private SequenceFile.Metadata readMetadata(  FileSystem fs,  Path file) throws IOException {
    LOG.info("reading file: " + file.toString());
    SequenceFile.Reader reader=new SequenceFile.Reader(fs,file,conf);
    SequenceFile.Metadata meta=reader.getMetadata();
    reader.close();
    return meta;
  }
  @SuppressWarnings("deprecation") private void writeMetadataTest(  FileSystem fs,  int count,  int seed,  Path file,  CompressionType compressionType,  CompressionCodec codec,  SequenceFile.Metadata metadata) throws IOException {
    fs.delete(file,true);
    LOG.info("creating " + count + " records with metadata and with "+ compressionType+ " compression");
    SequenceFile.Writer writer=SequenceFile.createWriter(fs,conf,file,RandomDatum.class,RandomDatum.class,compressionType,codec,null,metadata);
    RandomDatum.Generator generator=new RandomDatum.Generator(seed);
    for (int i=0; i < count; i++) {
      generator.next();
      RandomDatum key=generator.getKey();
      RandomDatum value=generator.getValue();
      writer.append(key,value);
    }
    writer.close();
  }
  private void sortMetadataTest(  FileSystem fs,  Path unsortedFile,  Path sortedFile,  SequenceFile.Metadata metadata) throws IOException {
    fs.delete(sortedFile,true);
    LOG.info("sorting: " + unsortedFile + " to: "+ sortedFile);
    final WritableComparator comparator=WritableComparator.get(RandomDatum.class);
    SequenceFile.Sorter sorter=new SequenceFile.Sorter(fs,comparator,RandomDatum.class,RandomDatum.class,conf,metadata);
    sorter.sort(new Path[]{unsortedFile},sortedFile,false);
  }
  @SuppressWarnings("deprecation") @Test public void testClose() throws IOException {
    Configuration conf=new Configuration();
    LocalFileSystem fs=FileSystem.getLocal(conf);
    Path path1=new Path(GenericTestUtils.getTempPath("test1.seq"));
    SequenceFile.Writer writer=SequenceFile.createWriter(fs,conf,path1,Text.class,NullWritable.class,CompressionType.BLOCK);
    writer.append(new Text("file1-1"),NullWritable.get());
    writer.append(new Text("file1-2"),NullWritable.get());
    writer.close();
    Path path2=new Path(GenericTestUtils.getTempPath("test2.seq"));
    writer=SequenceFile.createWriter(fs,conf,path2,Text.class,NullWritable.class,CompressionType.BLOCK);
    writer.append(new Text("file2-1"),NullWritable.get());
    writer.append(new Text("file2-2"),NullWritable.get());
    writer.close();
    SequenceFile.Reader reader=new SequenceFile.Reader(fs,path1,conf);
    reader.close();
    reader.close();
    SequenceFile.Reader reader1=new SequenceFile.Reader(fs,path1,conf);
    Text text=new Text();
    reader1.next(text);
    assertEquals("file1-1",text.toString());
    SequenceFile.Reader reader2=new SequenceFile.Reader(fs,path2,conf);
    reader2.next(text);
    assertEquals("file2-1",text.toString());
    reader1.next(text);
    assertEquals("file1-2",text.toString());
    reader2.next(text);
    assertEquals("file2-2",text.toString());
    assertFalse(reader1.next(text));
    assertFalse(reader2.next(text));
  }
  /** 
 * Test that makes sure the FileSystem passed to createWriter
 * @throws Exception
 */
  @SuppressWarnings("deprecation") @Test public void testCreateUsesFsArg() throws Exception {
    FileSystem fs=FileSystem.getLocal(conf);
    FileSystem spyFs=Mockito.spy(fs);
    Path p=new Path(GenericTestUtils.getTempPath("testCreateUsesFSArg.seq"));
    SequenceFile.Writer writer=SequenceFile.createWriter(spyFs,conf,p,NullWritable.class,NullWritable.class);
    writer.close();
    Mockito.verify(spyFs).getDefaultReplication(p);
  }
private static class TestFSDataInputStream extends FSDataInputStream {
    private boolean closed=false;
    private TestFSDataInputStream(    InputStream in) throws IOException {
      super(in);
    }
    @Override public void close() throws IOException {
      closed=true;
      super.close();
    }
    public boolean isClosed(){
      return closed;
    }
  }
  @SuppressWarnings("deprecation") @Test public void testCloseForErroneousSequenceFile() throws IOException {
    Configuration conf=new Configuration();
    LocalFileSystem fs=FileSystem.getLocal(conf);
    Path path=new Path(GenericTestUtils.getTempPath("broken.seq"));
    fs.create(path).close();
    final TestFSDataInputStream[] openedFile=new TestFSDataInputStream[1];
    try {
      new SequenceFile.Reader(fs,path,conf){
        @Override protected FSDataInputStream openFile(        FileSystem fs,        Path file,        int bufferSize,        long length) throws IOException {
          final InputStream in=super.openFile(fs,file,bufferSize,length);
          openedFile[0]=new TestFSDataInputStream(in);
          return openedFile[0];
        }
      }
;
      fail("IOException expected.");
    }
 catch (    IOException expected) {
    }
    assertNotNull(path + " should have been opened.",openedFile[0]);
    assertTrue("InputStream for " + path + " should have been closed.",openedFile[0].isClosed());
  }
  /** 
 * Test to makes sure zero length sequence file is handled properly while initializing.
 */
  @Test public void testInitZeroLengthSequenceFile() throws IOException {
    Configuration conf=new Configuration();
    LocalFileSystem fs=FileSystem.getLocal(conf);
    Path path=new Path(GenericTestUtils.getTempPath("zerolength.seq"));
    fs.create(path).close();
    try {
      new SequenceFile.Reader(conf,SequenceFile.Reader.file(path));
      fail("IOException expected.");
    }
 catch (    IOException expected) {
      assertTrue(expected instanceof EOFException);
    }
  }
  /** 
 * Test that makes sure createWriter succeeds on a file that was  already created
 * @throws IOException
 */
  @SuppressWarnings("deprecation") @Test public void testCreateWriterOnExistingFile() throws IOException {
    Configuration conf=new Configuration();
    FileSystem fs=FileSystem.getLocal(conf);
    Path name=new Path(new Path(GenericTestUtils.getTempPath("createWriterOnExistingFile")),"file");
    fs.create(name);
    SequenceFile.createWriter(fs,conf,name,RandomDatum.class,RandomDatum.class,512,(short)1,4096,false,CompressionType.NONE,null,new Metadata());
  }
  @SuppressWarnings("deprecation") @Test public void testRecursiveSeqFileCreate() throws IOException {
    FileSystem fs=FileSystem.getLocal(conf);
    Path name=new Path(new Path(GenericTestUtils.getTempPath("recursiveCreateDir")),"file");
    boolean createParent=false;
    try {
      SequenceFile.createWriter(fs,conf,name,RandomDatum.class,RandomDatum.class,512,(short)1,4096,createParent,CompressionType.NONE,null,new Metadata());
      fail("Expected an IOException due to missing parent");
    }
 catch (    IOException ioe) {
    }
    createParent=true;
    SequenceFile.createWriter(fs,conf,name,RandomDatum.class,RandomDatum.class,512,(short)1,4096,createParent,CompressionType.NONE,null,new Metadata());
  }
  @Test public void testSerializationAvailability() throws IOException {
    Configuration conf=new Configuration();
    Path path=new Path(GenericTestUtils.getTempPath("serializationAvailability"));
    try {
      SequenceFile.createWriter(conf,SequenceFile.Writer.file(path),SequenceFile.Writer.keyClass(String.class),SequenceFile.Writer.valueClass(NullWritable.class));
      fail("Must throw IOException for missing serializer for the Key class");
    }
 catch (    IOException e) {
      assertTrue(e.getMessage().startsWith("Could not find a serializer for the Key class: '" + String.class.getName() + "'."));
    }
    try {
      SequenceFile.createWriter(conf,SequenceFile.Writer.file(path),SequenceFile.Writer.keyClass(NullWritable.class),SequenceFile.Writer.valueClass(String.class));
      fail("Must throw IOException for missing serializer for the Value class");
    }
 catch (    IOException e) {
      assertTrue(e.getMessage().startsWith("Could not find a serializer for the Value class: '" + String.class.getName() + "'."));
    }
    writeTest(FileSystem.get(conf),1,1,path,CompressionType.NONE,null);
    conf.setStrings(CommonConfigurationKeys.IO_SERIALIZATIONS_KEY,AvroReflectSerialization.class.getName());
    try {
      new SequenceFile.Reader(conf,SequenceFile.Reader.file(path));
      fail("Must throw IOException for missing deserializer for the Key class");
    }
 catch (    IOException e) {
      assertTrue(e.getMessage().startsWith("Could not find a deserializer for the Key class: '" + RandomDatum.class.getName() + "'."));
    }
  }
  /** 
 * For debugging and testing. 
 */
  public static void main(  String[] args) throws Exception {
    int count=1024 * 1024;
    int megabytes=1;
    int factor=10;
    boolean create=true;
    boolean rwonly=false;
    boolean check=false;
    boolean fast=false;
    boolean merge=false;
    String compressType="NONE";
    String compressionCodec="org.apache.hadoop.io.compress.DefaultCodec";
    Path file=null;
    int seed=new Random().nextInt();
    String usage="Usage: testsequencefile " + "[-count N] " + "[-seed #] [-check] [-compressType <NONE|RECORD|BLOCK>] "+ "-codec <compressionCodec> "+ "[[-rwonly] | {[-megabytes M] [-factor F] [-nocreate] [-fast] [-merge]}] "+ " file";
    if (args.length == 0) {
      System.err.println(usage);
      System.exit(-1);
    }
    FileSystem fs=null;
    try {
      for (int i=0; i < args.length; ++i) {
        if (args[i] == null) {
          continue;
        }
 else         if (args[i].equals("-count")) {
          count=Integer.parseInt(args[++i]);
        }
 else         if (args[i].equals("-megabytes")) {
          megabytes=Integer.parseInt(args[++i]);
        }
 else         if (args[i].equals("-factor")) {
          factor=Integer.parseInt(args[++i]);
        }
 else         if (args[i].equals("-seed")) {
          seed=Integer.parseInt(args[++i]);
        }
 else         if (args[i].equals("-rwonly")) {
          rwonly=true;
        }
 else         if (args[i].equals("-nocreate")) {
          create=false;
        }
 else         if (args[i].equals("-check")) {
          check=true;
        }
 else         if (args[i].equals("-fast")) {
          fast=true;
        }
 else         if (args[i].equals("-merge")) {
          merge=true;
        }
 else         if (args[i].equals("-compressType")) {
          compressType=args[++i];
        }
 else         if (args[i].equals("-codec")) {
          compressionCodec=args[++i];
        }
 else {
          file=new Path(args[i]);
        }
      }
      TestSequenceFile test=new TestSequenceFile();
      fs=file.getFileSystem(test.conf);
      LOG.info("count = " + count);
      LOG.info("megabytes = " + megabytes);
      LOG.info("factor = " + factor);
      LOG.info("create = " + create);
      LOG.info("seed = " + seed);
      LOG.info("rwonly = " + rwonly);
      LOG.info("check = " + check);
      LOG.info("fast = " + fast);
      LOG.info("merge = " + merge);
      LOG.info("compressType = " + compressType);
      LOG.info("compressionCodec = " + compressionCodec);
      LOG.info("file = " + file);
      if (rwonly && (!create || merge || fast)) {
        System.err.println(usage);
        System.exit(-1);
      }
      CompressionType compressionType=CompressionType.valueOf(compressType);
      CompressionCodec codec=(CompressionCodec)ReflectionUtils.newInstance(test.conf.getClassByName(compressionCodec),test.conf);
      if (rwonly || (create && !merge)) {
        test.writeTest(fs,count,seed,file,compressionType,codec);
        test.readTest(fs,count,seed,file);
      }
      if (!rwonly) {
        if (merge) {
          test.mergeTest(fs,count,seed,file,compressionType,fast,factor,megabytes);
        }
 else {
          test.sortTest(fs,count,megabytes,factor,fast,file);
        }
      }
      if (check) {
        test.checkSort(fs,count,seed,file);
      }
    }
  finally {
      if (fs != null) {
        fs.close();
      }
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.fs;
import static org.apache.hadoop.test.PlatformAssumptions.assumeNotWindows;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotEquals;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.when;
import java.io.BufferedInputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.OutputStream;
import java.io.PrintWriter;
import java.net.InetAddress;
import java.net.URI;
import java.net.URISyntaxException;
import java.net.URL;
import java.net.UnknownHostException;
import java.nio.charset.StandardCharsets;
import java.nio.file.FileSystems;
import java.nio.file.Files;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.jar.Attributes;
import java.util.jar.JarFile;
import java.util.jar.Manifest;
import java.util.zip.ZipEntry;
import java.util.zip.ZipOutputStream;
import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
import org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;
import org.apache.commons.io.FileUtils;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.test.GenericTestUtils;
import org.apache.hadoop.util.StringUtils;
import org.apache.tools.tar.TarEntry;
import org.apache.tools.tar.TarOutputStream;
import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Ignore;
import org.junit.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
public class TestFileUtil {
  private static final Logger LOG=LoggerFactory.getLogger(TestFileUtil.class);
  private static final File TEST_DIR=GenericTestUtils.getTestDir("fu");
  private static final String FILE="x";
  private static final String LINK="y";
  private static final String DIR="dir";
  private final File del=new File(TEST_DIR,"del");
  private final File tmp=new File(TEST_DIR,"tmp");
  private final File dir1=new File(del,DIR + "1");
  private final File dir2=new File(del,DIR + "2");
  private final File partitioned=new File(TEST_DIR,"partitioned");
  private InetAddress inet1;
  private InetAddress inet2;
  private InetAddress inet3;
  private InetAddress inet4;
  private InetAddress inet5;
  private InetAddress inet6;
  private URI uri1;
  private URI uri2;
  private URI uri3;
  private URI uri4;
  private URI uri5;
  private URI uri6;
  private FileSystem fs1;
  private FileSystem fs2;
  private FileSystem fs3;
  private FileSystem fs4;
  private FileSystem fs5;
  private FileSystem fs6;
  /** 
 * Creates multiple directories for testing. Contents of them are dir:tmp:  file: x dir:del: file: x dir: dir1 : file:x dir: dir2 : file:x link: y to tmp/x link: tmpDir to tmp dir:partitioned: file: part-r-00000, contents: "foo" file: part-r-00001, contents: "bar"
 */
  @Ignore private void setupDirs() throws IOException {
    Assert.assertFalse(del.exists());
    Assert.assertFalse(tmp.exists());
    Assert.assertFalse(partitioned.exists());
    del.mkdirs();
    tmp.mkdirs();
    partitioned.mkdirs();
    new File(del,FILE).createNewFile();
    File tmpFile=new File(tmp,FILE);
    tmpFile.createNewFile();
    dir1.mkdirs();
    dir2.mkdirs();
    new File(dir1,FILE).createNewFile();
    new File(dir2,FILE).createNewFile();
    File link=new File(del,LINK);
    FileUtil.symLink(tmpFile.toString(),link.toString());
    File linkDir=new File(del,"tmpDir");
    FileUtil.symLink(tmp.toString(),linkDir.toString());
    Assert.assertEquals(5,del.listFiles().length);
    createFile(partitioned,"part-r-00000","foo");
    createFile(partitioned,"part-r-00001","bar");
    FileUtil.symLink(del.toString(),dir1.toString() + "/cycle");
  }
  /** 
 * Creates a new file in the specified directory, with the specified name and the specified file contents.  This method will add a newline terminator to the end of the contents string in the destination file.
 * @param directory File non-null destination directory.
 * @param name String non-null file name.
 * @param contents String non-null file contents.
 * @throws IOException if an I/O error occurs.
 */
  private File createFile(  File directory,  String name,  String contents) throws IOException {
    File newFile=new File(directory,name);
    PrintWriter pw=new PrintWriter(newFile);
    try {
      pw.println(contents);
    }
  finally {
      pw.close();
    }
    return newFile;
  }
  @Test(timeout=30000) public void testListFiles() throws IOException {
    setupDirs();
    File[] files=FileUtil.listFiles(partitioned);
    Assert.assertEquals(2,files.length);
    File newDir=new File(tmp.getPath(),"test");
    newDir.mkdir();
    Assert.assertTrue("Failed to create test dir",newDir.exists());
    files=FileUtil.listFiles(newDir);
    Assert.assertEquals(0,files.length);
    newDir.delete();
    Assert.assertFalse("Failed to delete test dir",newDir.exists());
    try {
      files=FileUtil.listFiles(newDir);
      Assert.fail("IOException expected on listFiles() for non-existent dir " + newDir.toString());
    }
 catch (    IOException ioe) {
    }
  }
  @Test(timeout=30000) public void testListAPI() throws IOException {
    setupDirs();
    String[] files=FileUtil.list(partitioned);
    Assert.assertEquals("Unexpected number of pre-existing files",2,files.length);
    File newDir=new File(tmp.getPath(),"test");
    newDir.mkdir();
    Assert.assertTrue("Failed to create test dir",newDir.exists());
    files=FileUtil.list(newDir);
    Assert.assertEquals("New directory unexpectedly contains files",0,files.length);
    newDir.delete();
    Assert.assertFalse("Failed to delete test dir",newDir.exists());
    try {
      files=FileUtil.list(newDir);
      Assert.fail("IOException expected on list() for non-existent dir " + newDir.toString());
    }
 catch (    IOException ioe) {
    }
  }
  @Before public void before() throws IOException {
    cleanupImpl();
  }
  @After public void tearDown() throws IOException {
    cleanupImpl();
  }
  private void cleanupImpl() throws IOException {
    FileUtil.fullyDelete(del,true);
    Assert.assertTrue(!del.exists());
    FileUtil.fullyDelete(tmp,true);
    Assert.assertTrue(!tmp.exists());
    FileUtil.fullyDelete(partitioned,true);
    Assert.assertTrue(!partitioned.exists());
  }
  @Test(timeout=30000) public void testFullyDelete() throws IOException {
    setupDirs();
    boolean ret=FileUtil.fullyDelete(del);
    Assert.assertTrue(ret);
    Assert.assertFalse(del.exists());
    validateTmpDir();
  }
  /** 
 * Tests if fullyDelete deletes (a) symlink to file only and not the file pointed to by symlink. (b) symlink to dir only and not the dir pointed to by symlink.
 * @throws IOException
 */
  @Test(timeout=30000) public void testFullyDeleteSymlinks() throws IOException {
    setupDirs();
    File link=new File(del,LINK);
    Assert.assertEquals(5,del.list().length);
    boolean ret=FileUtil.fullyDelete(link);
    Assert.assertTrue(ret);
    Assert.assertFalse(link.exists());
    Assert.assertEquals(4,del.list().length);
    validateTmpDir();
    File linkDir=new File(del,"tmpDir");
    ret=FileUtil.fullyDelete(linkDir);
    Assert.assertTrue(ret);
    Assert.assertFalse(linkDir.exists());
    Assert.assertEquals(3,del.list().length);
    validateTmpDir();
  }
  /** 
 * Tests if fullyDelete deletes (a) dangling symlink to file properly (b) dangling symlink to directory properly
 * @throws IOException
 */
  @Test(timeout=30000) public void testFullyDeleteDanglingSymlinks() throws IOException {
    setupDirs();
    boolean ret=FileUtil.fullyDelete(tmp);
    Assert.assertTrue(ret);
    Assert.assertFalse(tmp.exists());
    File link=new File(del,LINK);
    Assert.assertEquals(5,del.list().length);
    ret=FileUtil.fullyDelete(link);
    Assert.assertTrue(ret);
    Assert.assertEquals(4,del.list().length);
    File linkDir=new File(del,"tmpDir");
    ret=FileUtil.fullyDelete(linkDir);
    Assert.assertTrue(ret);
    Assert.assertEquals(3,del.list().length);
  }
  @Test(timeout=30000) public void testFullyDeleteContents() throws IOException {
    setupDirs();
    boolean ret=FileUtil.fullyDeleteContents(del);
    Assert.assertTrue(ret);
    Assert.assertTrue(del.exists());
    Assert.assertEquals(0,del.listFiles().length);
    validateTmpDir();
  }
  private void validateTmpDir(){
    Assert.assertTrue(tmp.exists());
    Assert.assertEquals(1,tmp.listFiles().length);
    Assert.assertTrue(new File(tmp,FILE).exists());
  }
  private final File xSubDir=new File(del,"xSubDir");
  private final File xSubSubDir=new File(xSubDir,"xSubSubDir");
  private final File ySubDir=new File(del,"ySubDir");
  private static final String file1Name="file1";
  private final File file2=new File(xSubDir,"file2");
  private final File file22=new File(xSubSubDir,"file22");
  private final File file3=new File(ySubDir,"file3");
  private final File zlink=new File(del,"zlink");
  /** 
 * Creates a directory which can not be deleted completely. Directory structure. The naming is important in that  {@link MyFile}is used to return them in alphabetical order when listed. del(+w) | .---------------------------------------, |            |              |           | file1(!w)   xSubDir(-rwx)   ySubDir(+w)   zlink |  |              | | file2(-rwx)   file3 | xSubSubDir(-rwx)  | file22(-rwx)
 * @throws IOException
 */
  private void setupDirsAndNonWritablePermissions() throws IOException {
    Assert.assertFalse("The directory del should not have existed!",del.exists());
    del.mkdirs();
    new MyFile(del,file1Name).createNewFile();
    xSubDir.mkdirs();
    file2.createNewFile();
    xSubSubDir.mkdirs();
    file22.createNewFile();
    revokePermissions(file22);
    revokePermissions(xSubSubDir);
    revokePermissions(file2);
    revokePermissions(xSubDir);
    ySubDir.mkdirs();
    file3.createNewFile();
    Assert.assertFalse("The directory tmp should not have existed!",tmp.exists());
    tmp.mkdirs();
    File tmpFile=new File(tmp,FILE);
    tmpFile.createNewFile();
    FileUtil.symLink(tmpFile.toString(),zlink.toString());
  }
  private static void grantPermissions(  final File f){
    FileUtil.setReadable(f,true);
    FileUtil.setWritable(f,true);
    FileUtil.setExecutable(f,true);
  }
  private static void revokePermissions(  final File f){
    FileUtil.setWritable(f,false);
    FileUtil.setExecutable(f,false);
    FileUtil.setReadable(f,false);
  }
  private void validateAndSetWritablePermissions(  final boolean expectedRevokedPermissionDirsExist,  final boolean ret){
    grantPermissions(xSubDir);
    grantPermissions(xSubSubDir);
    Assert.assertFalse("The return value should have been false.",ret);
    Assert.assertTrue("The file file1 should not have been deleted.",new File(del,file1Name).exists());
    Assert.assertEquals("The directory xSubDir *should* not have been deleted.",expectedRevokedPermissionDirsExist,xSubDir.exists());
    Assert.assertEquals("The file file2 *should* not have been deleted.",expectedRevokedPermissionDirsExist,file2.exists());
    Assert.assertEquals("The directory xSubSubDir *should* not have been deleted.",expectedRevokedPermissionDirsExist,xSubSubDir.exists());
    Assert.assertEquals("The file file22 *should* not have been deleted.",expectedRevokedPermissionDirsExist,file22.exists());
    Assert.assertFalse("The directory ySubDir should have been deleted.",ySubDir.exists());
    Assert.assertFalse("The link zlink should have been deleted.",zlink.exists());
  }
  @Test(timeout=30000) public void testFailFullyDelete() throws IOException {
    assumeNotWindows();
    LOG.info("Running test to verify failure of fullyDelete()");
    setupDirsAndNonWritablePermissions();
    boolean ret=FileUtil.fullyDelete(new MyFile(del));
    validateAndSetWritablePermissions(true,ret);
  }
  @Test(timeout=30000) public void testFailFullyDeleteGrantPermissions() throws IOException {
    setupDirsAndNonWritablePermissions();
    boolean ret=FileUtil.fullyDelete(new MyFile(del),true);
    validateAndSetWritablePermissions(false,ret);
  }
  /** 
 * Extend  {@link File}. Same as  {@link File} except for two things: (1) Thistreats file1Name as a very special file which is not delete-able irrespective of it's parent-dir's permissions, a peculiar file instance for testing. (2) It returns the files in alphabetically sorted order when listed.
 */
public static class MyFile extends File {
    private static final long serialVersionUID=1L;
    public MyFile(    File f){
      super(f.getAbsolutePath());
    }
    public MyFile(    File parent,    String child){
      super(parent,child);
    }
    /** 
 * Same as  {@link File#delete()} except for file1Name which will never bedeleted (hard-coded)
 */
    @Override public boolean delete(){
      LOG.info("Trying to delete myFile " + getAbsolutePath());
      boolean bool=false;
      if (getName().equals(file1Name)) {
        bool=false;
      }
 else {
        bool=super.delete();
      }
      if (bool) {
        LOG.info("Deleted " + getAbsolutePath() + " successfully");
      }
 else {
        LOG.info("Cannot delete " + getAbsolutePath());
      }
      return bool;
    }
    /** 
 * Return the list of files in an alphabetically sorted order
 */
    @Override public File[] listFiles(){
      final File[] files=super.listFiles();
      if (files == null) {
        return null;
      }
      List<File> filesList=Arrays.asList(files);
      Collections.sort(filesList);
      File[] myFiles=new MyFile[files.length];
      int i=0;
      for (      File f : filesList) {
        myFiles[i++]=new MyFile(f);
      }
      return myFiles;
    }
  }
  @Test(timeout=30000) public void testFailFullyDeleteContents() throws IOException {
    assumeNotWindows();
    LOG.info("Running test to verify failure of fullyDeleteContents()");
    setupDirsAndNonWritablePermissions();
    boolean ret=FileUtil.fullyDeleteContents(new MyFile(del));
    validateAndSetWritablePermissions(true,ret);
  }
  @Test(timeout=30000) public void testFailFullyDeleteContentsGrantPermissions() throws IOException {
    setupDirsAndNonWritablePermissions();
    boolean ret=FileUtil.fullyDeleteContents(new MyFile(del),true);
    validateAndSetWritablePermissions(false,ret);
  }
  /** 
 * Test that getDU is able to handle cycles caused due to symbolic links and that directory sizes are not added to the final calculated size
 * @throws IOException
 */
  @Test(timeout=30000) public void testGetDU() throws Exception {
    setupDirs();
    long du=FileUtil.getDU(TEST_DIR);
    final long expected=2 * (3 + System.getProperty("line.separator").length());
    Assert.assertEquals(expected,du);
    final File doesNotExist=new File(tmp,"QuickBrownFoxJumpsOverTheLazyDog");
    long duDoesNotExist=FileUtil.getDU(doesNotExist);
    assertEquals(0,duDoesNotExist);
    File notADirectory=new File(partitioned,"part-r-00000");
    long duNotADirectoryActual=FileUtil.getDU(notADirectory);
    long duNotADirectoryExpected=3 + System.getProperty("line.separator").length();
    assertEquals(duNotADirectoryExpected,duNotADirectoryActual);
    try {
      try {
        FileUtil.chmod(notADirectory.getAbsolutePath(),"0000");
      }
 catch (      InterruptedException ie) {
        assertNull(ie);
      }
      assertFalse(FileUtil.canRead(notADirectory));
      final long du3=FileUtil.getDU(partitioned);
      assertEquals(expected,du3);
      try {
        FileUtil.chmod(partitioned.getAbsolutePath(),"0000");
      }
 catch (      InterruptedException ie) {
        assertNull(ie);
      }
      assertFalse(FileUtil.canRead(partitioned));
      final long du4=FileUtil.getDU(partitioned);
      assertEquals(0,du4);
    }
  finally {
      FileUtil.chmod(partitioned.getAbsolutePath(),"0777",true);
    }
  }
  @Test(timeout=30000) public void testUnTar() throws IOException {
    setupDirs();
    final File simpleTar=new File(del,FILE);
    OutputStream os=new FileOutputStream(simpleTar);
    TarOutputStream tos=new TarOutputStream(os);
    try {
      TarEntry te=new TarEntry("/bar/foo");
      byte[] data="some-content".getBytes("UTF-8");
      te.setSize(data.length);
      tos.putNextEntry(te);
      tos.write(data);
      tos.closeEntry();
      tos.flush();
      tos.finish();
    }
  finally {
      tos.close();
    }
    FileUtil.unTar(simpleTar,tmp);
    assertTrue(new File(tmp,"/bar/foo").exists());
    assertEquals(12,new File(tmp,"/bar/foo").length());
    final File regularFile=new File(tmp,"QuickBrownFoxJumpsOverTheLazyDog");
    regularFile.createNewFile();
    assertTrue(regularFile.exists());
    try {
      FileUtil.unTar(simpleTar,regularFile);
      assertTrue("An IOException expected.",false);
    }
 catch (    IOException ioe) {
    }
  }
  @Test(timeout=30000) public void testReplaceFile() throws IOException {
    setupDirs();
    final File srcFile=new File(tmp,"src");
    srcFile.createNewFile();
    assertTrue(srcFile.exists());
    final File targetFile=new File(tmp,"target");
    assertTrue(!targetFile.exists());
    FileUtil.replaceFile(srcFile,targetFile);
    assertTrue(!srcFile.exists());
    assertTrue(targetFile.exists());
    srcFile.createNewFile();
    assertTrue(srcFile.exists());
    FileUtil.replaceFile(srcFile,targetFile);
    assertTrue(!srcFile.exists());
    assertTrue(targetFile.exists());
    srcFile.createNewFile();
    assertTrue(srcFile.exists());
    targetFile.delete();
    targetFile.mkdirs();
    File obstacle=new File(targetFile,"obstacle");
    obstacle.createNewFile();
    assertTrue(obstacle.exists());
    assertTrue(targetFile.exists() && targetFile.isDirectory());
    try {
      FileUtil.replaceFile(srcFile,targetFile);
      assertTrue(false);
    }
 catch (    IOException ioe) {
    }
    assertTrue(srcFile.exists());
    assertTrue(targetFile.exists() && targetFile.isDirectory());
    assertTrue(obstacle.exists());
  }
  @Test(timeout=30000) public void testCreateLocalTempFile() throws IOException {
    setupDirs();
    final File baseFile=new File(tmp,"base");
    File tmp1=FileUtil.createLocalTempFile(baseFile,"foo",false);
    File tmp2=FileUtil.createLocalTempFile(baseFile,"foo",true);
    assertFalse(tmp1.getAbsolutePath().equals(baseFile.getAbsolutePath()));
    assertFalse(tmp2.getAbsolutePath().equals(baseFile.getAbsolutePath()));
    assertTrue(tmp1.exists() && tmp2.exists());
    assertTrue(tmp1.canWrite() && tmp2.canWrite());
    assertTrue(tmp1.canRead() && tmp2.canRead());
    tmp1.delete();
    tmp2.delete();
    assertTrue(!tmp1.exists() && !tmp2.exists());
  }
  @Test(timeout=30000) public void testUnZip() throws IOException {
    setupDirs();
    final File simpleZip=new File(del,FILE);
    OutputStream os=new FileOutputStream(simpleZip);
    ZipOutputStream tos=new ZipOutputStream(os);
    try {
      ZipEntry ze=new ZipEntry("foo");
      byte[] data="some-content".getBytes("UTF-8");
      ze.setSize(data.length);
      tos.putNextEntry(ze);
      tos.write(data);
      tos.closeEntry();
      tos.flush();
      tos.finish();
    }
  finally {
      tos.close();
    }
    FileUtil.unZip(simpleZip,tmp);
    assertTrue(new File(tmp,"foo").exists());
    assertEquals(12,new File(tmp,"foo").length());
    final File regularFile=new File(tmp,"QuickBrownFoxJumpsOverTheLazyDog");
    regularFile.createNewFile();
    assertTrue(regularFile.exists());
    try {
      FileUtil.unZip(simpleZip,regularFile);
      assertTrue("An IOException expected.",false);
    }
 catch (    IOException ioe) {
    }
  }
  @Test(timeout=30000) public void testUnZip2() throws IOException {
    setupDirs();
    final File simpleZip=new File(del,FILE);
    OutputStream os=new FileOutputStream(simpleZip);
    try (ZipOutputStream tos=new ZipOutputStream(os)){
      ZipEntry ze=new ZipEntry("../foo");
      byte[] data="some-content".getBytes(StandardCharsets.UTF_8);
      ze.setSize(data.length);
      tos.putNextEntry(ze);
      tos.write(data);
      tos.closeEntry();
      tos.flush();
      tos.finish();
    }
     try {
      FileUtil.unZip(simpleZip,tmp);
      fail("unZip should throw IOException.");
    }
 catch (    IOException e) {
      GenericTestUtils.assertExceptionContains("would create file outside of",e);
    }
  }
  @Test(timeout=30000) public void testCopy5() throws IOException {
    setupDirs();
    URI uri=tmp.toURI();
    Configuration conf=new Configuration();
    FileSystem fs=FileSystem.newInstance(uri,conf);
    final String content="some-content";
    File srcFile=createFile(tmp,"src",content);
    Path srcPath=new Path(srcFile.toURI());
    final File dest=new File(del,"dest");
    boolean result=FileUtil.copy(fs,srcPath,dest,false,conf);
    assertTrue(result);
    assertTrue(dest.exists());
    assertEquals(content.getBytes().length + System.getProperty("line.separator").getBytes().length,dest.length());
    assertTrue(srcFile.exists());
    dest.delete();
    assertTrue(!dest.exists());
    result=FileUtil.copy(fs,srcPath,dest,true,conf);
    assertTrue(result);
    assertTrue(dest.exists());
    assertEquals(content.getBytes().length + System.getProperty("line.separator").getBytes().length,dest.length());
    assertTrue(!srcFile.exists());
    dest.delete();
    assertTrue(!dest.exists());
    srcPath=new Path(partitioned.toURI());
    result=FileUtil.copy(fs,srcPath,dest,true,conf);
    assertTrue(result);
    assertTrue(dest.exists() && dest.isDirectory());
    File[] files=dest.listFiles();
    assertTrue(files != null);
    assertEquals(2,files.length);
    for (    File f : files) {
      assertEquals(3 + System.getProperty("line.separator").getBytes().length,f.length());
    }
    assertTrue(!partitioned.exists());
  }
  @Test(timeout=30000) public void testStat2Paths1(){
    assertNull(FileUtil.stat2Paths(null));
    FileStatus[] fileStatuses=new FileStatus[0];
    Path[] paths=FileUtil.stat2Paths(fileStatuses);
    assertEquals(0,paths.length);
    Path path1=new Path("file://foo");
    Path path2=new Path("file://moo");
    fileStatuses=new FileStatus[]{new FileStatus(3,false,0,0,0,path1),new FileStatus(3,false,0,0,0,path2)};
    paths=FileUtil.stat2Paths(fileStatuses);
    assertEquals(2,paths.length);
    assertEquals(paths[0],path1);
    assertEquals(paths[1],path2);
  }
  @Test(timeout=30000) public void testStat2Paths2(){
    Path defaultPath=new Path("file://default");
    Path[] paths=FileUtil.stat2Paths(null,defaultPath);
    assertEquals(1,paths.length);
    assertEquals(defaultPath,paths[0]);
    paths=FileUtil.stat2Paths(null,null);
    assertTrue(paths != null);
    assertEquals(1,paths.length);
    assertEquals(null,paths[0]);
    Path path1=new Path("file://foo");
    Path path2=new Path("file://moo");
    FileStatus[] fileStatuses=new FileStatus[]{new FileStatus(3,false,0,0,0,path1),new FileStatus(3,false,0,0,0,path2)};
    paths=FileUtil.stat2Paths(fileStatuses,defaultPath);
    assertEquals(2,paths.length);
    assertEquals(paths[0],path1);
    assertEquals(paths[1],path2);
  }
  @Test(timeout=30000) public void testSymlink() throws Exception {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    byte[] data="testSymLink".getBytes();
    File file=new File(del,FILE);
    File link=new File(del,"_link");
    FileOutputStream os=new FileOutputStream(file);
    os.write(data);
    os.close();
    FileUtil.symLink(file.getAbsolutePath(),link.getAbsolutePath());
    Assert.assertEquals(data.length,file.length());
    Assert.assertEquals(data.length,link.length());
    FileInputStream in=new FileInputStream(link);
    long len=0;
    while (in.read() > 0) {
      len++;
    }
    in.close();
    Assert.assertEquals(data.length,len);
  }
  /** 
 * Test that rename on a symlink works as expected.
 */
  @Test(timeout=30000) public void testSymlinkRenameTo() throws Exception {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    File file=new File(del,FILE);
    file.createNewFile();
    File link=new File(del,"_link");
    FileUtil.symLink(file.getAbsolutePath(),link.getAbsolutePath());
    Assert.assertTrue(file.exists());
    Assert.assertTrue(link.exists());
    File link2=new File(del,"_link2");
    Assert.assertTrue(link.renameTo(link2));
    Assert.assertTrue(file.exists());
    Assert.assertTrue(link2.exists());
    Assert.assertFalse(link.exists());
  }
  /** 
 * Test that deletion of a symlink works as expected.
 */
  @Test(timeout=30000) public void testSymlinkDelete() throws Exception {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    File file=new File(del,FILE);
    file.createNewFile();
    File link=new File(del,"_link");
    FileUtil.symLink(file.getAbsolutePath(),link.getAbsolutePath());
    Assert.assertTrue(file.exists());
    Assert.assertTrue(link.exists());
    Assert.assertTrue(link.delete());
    Assert.assertFalse(link.exists());
    Assert.assertTrue(file.exists());
  }
  /** 
 * Test that length on a symlink works as expected.
 */
  @Test(timeout=30000) public void testSymlinkLength() throws Exception {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    byte[] data="testSymLinkData".getBytes();
    File file=new File(del,FILE);
    File link=new File(del,"_link");
    FileOutputStream os=new FileOutputStream(file);
    os.write(data);
    os.close();
    Assert.assertEquals(0,link.length());
    FileUtil.symLink(file.getAbsolutePath(),link.getAbsolutePath());
    Assert.assertEquals(data.length,file.length());
    Assert.assertEquals(data.length,link.length());
    file.delete();
    Assert.assertFalse(file.exists());
    Assert.assertEquals(0,link.length());
    link.delete();
    Assert.assertFalse(link.exists());
  }
  /** 
 * This test validates the correctness of {@link FileUtil#symLink(String,String)} in case of null pointer inputs.
 * @throws IOException
 */
  @Test public void testSymlinkWithNullInput() throws IOException {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    File file=new File(del,FILE);
    File link=new File(del,"_link");
    int result=FileUtil.symLink(null,null);
    Assert.assertEquals(1,result);
    result=FileUtil.symLink(file.getAbsolutePath(),null);
    Assert.assertEquals(1,result);
    result=FileUtil.symLink(null,link.getAbsolutePath());
    Assert.assertEquals(1,result);
    file.delete();
    link.delete();
  }
  /** 
 * This test validates the correctness of {@link FileUtil#symLink(String,String)} in case the file already exists.
 * @throws IOException
 */
  @Test public void testSymlinkFileAlreadyExists() throws IOException {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    File file=new File(del,FILE);
    File link=new File(del,"_link");
    int result1=FileUtil.symLink(file.getAbsolutePath(),link.getAbsolutePath());
    Assert.assertEquals(0,result1);
    result1=FileUtil.symLink(file.getAbsolutePath(),link.getAbsolutePath());
    Assert.assertEquals(1,result1);
    file.delete();
    link.delete();
  }
  /** 
 * This test validates the correctness of {@link FileUtil#symLink(String,String)} in case the file and the link arethe same file.
 * @throws IOException
 */
  @Test public void testSymlinkSameFile() throws IOException {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    File file=new File(del,FILE);
    int result=FileUtil.symLink(file.getAbsolutePath(),file.getAbsolutePath());
    Assert.assertEquals(0,result);
    file.delete();
  }
  /** 
 * This test validates the correctness of {@link FileUtil#symLink(String,String)} in case we want to use a link for2 different files.
 * @throws IOException
 */
  @Test public void testSymlink2DifferentFile() throws IOException {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    File file=new File(del,FILE);
    File fileSecond=new File(del,FILE + "_1");
    File link=new File(del,"_link");
    int result=FileUtil.symLink(file.getAbsolutePath(),link.getAbsolutePath());
    Assert.assertEquals(0,result);
    result=FileUtil.symLink(fileSecond.getAbsolutePath(),link.getAbsolutePath());
    Assert.assertEquals(1,result);
    file.delete();
    fileSecond.delete();
    link.delete();
  }
  /** 
 * This test validates the correctness of {@link FileUtil#symLink(String,String)} in case we want to use a 2different links for the same file.
 * @throws IOException
 */
  @Test public void testSymlink2DifferentLinks() throws IOException {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    File file=new File(del,FILE);
    File link=new File(del,"_link");
    File linkSecond=new File(del,"_link_1");
    int result=FileUtil.symLink(file.getAbsolutePath(),link.getAbsolutePath());
    Assert.assertEquals(0,result);
    result=FileUtil.symLink(file.getAbsolutePath(),linkSecond.getAbsolutePath());
    Assert.assertEquals(0,result);
    file.delete();
    link.delete();
    linkSecond.delete();
  }
  private void doUntarAndVerify(  File tarFile,  File untarDir) throws IOException {
    if (untarDir.exists() && !FileUtil.fullyDelete(untarDir)) {
      throw new IOException("Could not delete directory '" + untarDir + "'");
    }
    FileUtil.unTar(tarFile,untarDir);
    String parentDir=untarDir.getCanonicalPath() + Path.SEPARATOR + "name";
    File testFile=new File(parentDir + Path.SEPARATOR + "version");
    Assert.assertTrue(testFile.exists());
    Assert.assertTrue(testFile.length() == 0);
    String imageDir=parentDir + Path.SEPARATOR + "image";
    testFile=new File(imageDir + Path.SEPARATOR + "fsimage");
    Assert.assertTrue(testFile.exists());
    Assert.assertTrue(testFile.length() == 157);
    String currentDir=parentDir + Path.SEPARATOR + "current";
    testFile=new File(currentDir + Path.SEPARATOR + "fsimage");
    Assert.assertTrue(testFile.exists());
    Assert.assertTrue(testFile.length() == 4331);
    testFile=new File(currentDir + Path.SEPARATOR + "edits");
    Assert.assertTrue(testFile.exists());
    Assert.assertTrue(testFile.length() == 1033);
    testFile=new File(currentDir + Path.SEPARATOR + "fstime");
    Assert.assertTrue(testFile.exists());
    Assert.assertTrue(testFile.length() == 8);
  }
  @Test(timeout=30000) public void testUntar() throws IOException {
    String tarGzFileName=System.getProperty("test.cache.data","target/test/cache") + "/test-untar.tgz";
    String tarFileName=System.getProperty("test.cache.data","build/test/cache") + "/test-untar.tar";
    File dataDir=GenericTestUtils.getTestDir();
    File untarDir=new File(dataDir,"untarDir");
    doUntarAndVerify(new File(tarGzFileName),untarDir);
    doUntarAndVerify(new File(tarFileName),untarDir);
  }
  @Test(timeout=30000) public void testCreateJarWithClassPath() throws Exception {
    Assert.assertFalse(tmp.exists());
    Assert.assertTrue(tmp.mkdirs());
    List<File> wildcardMatches=Arrays.asList(new File(tmp,"wildcard1.jar"),new File(tmp,"wildcard2.jar"),new File(tmp,"wildcard3.JAR"),new File(tmp,"wildcard4.JAR"));
    for (    File wildcardMatch : wildcardMatches) {
      Assert.assertTrue("failure creating file: " + wildcardMatch,wildcardMatch.createNewFile());
    }
    Assert.assertTrue(new File(tmp,"text.txt").createNewFile());
    Assert.assertTrue(new File(tmp,"executable.exe").createNewFile());
    Assert.assertTrue(new File(tmp,"README").createNewFile());
    String wildcardPath=tmp.getCanonicalPath() + File.separator + "*";
    String nonExistentSubdir=tmp.getCanonicalPath() + Path.SEPARATOR + "subdir"+ Path.SEPARATOR;
    List<String> classPaths=Arrays.asList("","cp1.jar","cp2.jar",wildcardPath,"cp3.jar",nonExistentSubdir);
    String inputClassPath=StringUtils.join(File.pathSeparator,classPaths);
    String[] jarCp=FileUtil.createJarWithClassPath(inputClassPath + File.pathSeparator + "unexpandedwildcard/*",new Path(tmp.getCanonicalPath()),System.getenv());
    String classPathJar=jarCp[0];
    assertNotEquals("Unexpanded wildcard was not placed in extra classpath",jarCp[1].indexOf("unexpanded"),-1);
    JarFile jarFile=null;
    try {
      jarFile=new JarFile(classPathJar);
      Manifest jarManifest=jarFile.getManifest();
      Assert.assertNotNull(jarManifest);
      Attributes mainAttributes=jarManifest.getMainAttributes();
      Assert.assertNotNull(mainAttributes);
      Assert.assertTrue(mainAttributes.containsKey(Attributes.Name.CLASS_PATH));
      String classPathAttr=mainAttributes.getValue(Attributes.Name.CLASS_PATH);
      Assert.assertNotNull(classPathAttr);
      List<String> expectedClassPaths=new ArrayList<String>();
      for (      String classPath : classPaths) {
        if (classPath.length() == 0) {
          continue;
        }
        if (wildcardPath.equals(classPath)) {
          for (          File wildcardMatch : wildcardMatches) {
            expectedClassPaths.add(wildcardMatch.toURI().toURL().toExternalForm());
          }
        }
 else {
          File fileCp=null;
          if (!new Path(classPath).isAbsolute()) {
            fileCp=new File(tmp,classPath);
          }
 else {
            fileCp=new File(classPath);
          }
          if (nonExistentSubdir.equals(classPath)) {
            expectedClassPaths.add(fileCp.toURI().toURL().toExternalForm() + Path.SEPARATOR);
          }
 else {
            expectedClassPaths.add(fileCp.toURI().toURL().toExternalForm());
          }
        }
      }
      List<String> actualClassPaths=Arrays.asList(classPathAttr.split(" "));
      Collections.sort(expectedClassPaths);
      Collections.sort(actualClassPaths);
      Assert.assertEquals(expectedClassPaths,actualClassPaths);
    }
  finally {
      if (jarFile != null) {
        try {
          jarFile.close();
        }
 catch (        IOException e) {
          LOG.warn("exception closing jarFile: " + classPathJar,e);
        }
      }
    }
  }
  @Test public void testGetJarsInDirectory() throws Exception {
    List<Path> jars=FileUtil.getJarsInDirectory("/foo/bar/bogus/");
    assertTrue("no jars should be returned for a bogus path",jars.isEmpty());
    assertFalse(tmp.exists());
    assertTrue(tmp.mkdirs());
    File jar1=new File(tmp,"wildcard1.jar");
    File jar2=new File(tmp,"wildcard2.JAR");
    List<File> matches=Arrays.asList(jar1,jar2);
    for (    File match : matches) {
      assertTrue("failure creating file: " + match,match.createNewFile());
    }
    assertTrue(new File(tmp,"text.txt").createNewFile());
    assertTrue(new File(tmp,"executable.exe").createNewFile());
    assertTrue(new File(tmp,"README").createNewFile());
    String directory=tmp.getCanonicalPath();
    jars=FileUtil.getJarsInDirectory(directory);
    assertEquals("there should be 2 jars",2,jars.size());
    for (    Path jar : jars) {
      URL url=jar.toUri().toURL();
      assertTrue("the jar should match either of the jars",url.equals(jar1.toURI().toURL()) || url.equals(jar2.toURI().toURL()));
    }
  }
  @Ignore public void setupCompareFs(){
    String host1="1.2.3.4";
    String host2="2.3.4.5";
    int port1=7000;
    int port2=7001;
    String uris1="hdfs://" + host1 + ":"+ Integer.toString(port1)+ "/tmp/foo";
    String uris2="hdfs://" + host1 + ":"+ Integer.toString(port2)+ "/tmp/foo";
    String uris3="hdfs://" + host2 + ":"+ Integer.toString(port2)+ "/tmp/foo";
    String uris4="hdfs://" + host2 + ":"+ Integer.toString(port2)+ "/tmp/foo";
    String uris5="file:///" + host1 + ":"+ Integer.toString(port1)+ "/tmp/foo";
    String uris6="hdfs:///" + host1 + "/tmp/foo";
    try {
      uri1=new URI(uris1);
      uri2=new URI(uris2);
      uri3=new URI(uris3);
      uri4=new URI(uris4);
      uri5=new URI(uris5);
      uri6=new URI(uris6);
    }
 catch (    URISyntaxException use) {
    }
    inet1=mock(InetAddress.class);
    when(inet1.getCanonicalHostName()).thenReturn(host1);
    inet2=mock(InetAddress.class);
    when(inet2.getCanonicalHostName()).thenReturn(host1);
    inet3=mock(InetAddress.class);
    when(inet3.getCanonicalHostName()).thenReturn(host2);
    inet4=mock(InetAddress.class);
    when(inet4.getCanonicalHostName()).thenReturn(host2);
    inet5=mock(InetAddress.class);
    when(inet5.getCanonicalHostName()).thenReturn(host1);
    inet6=mock(InetAddress.class);
    when(inet6.getCanonicalHostName()).thenReturn(host1);
    try {
      when(InetAddress.getByName(uris1)).thenReturn(inet1);
      when(InetAddress.getByName(uris2)).thenReturn(inet2);
      when(InetAddress.getByName(uris3)).thenReturn(inet3);
      when(InetAddress.getByName(uris4)).thenReturn(inet4);
      when(InetAddress.getByName(uris5)).thenReturn(inet5);
    }
 catch (    UnknownHostException ue) {
    }
    fs1=mock(FileSystem.class);
    when(fs1.getUri()).thenReturn(uri1);
    fs2=mock(FileSystem.class);
    when(fs2.getUri()).thenReturn(uri2);
    fs3=mock(FileSystem.class);
    when(fs3.getUri()).thenReturn(uri3);
    fs4=mock(FileSystem.class);
    when(fs4.getUri()).thenReturn(uri4);
    fs5=mock(FileSystem.class);
    when(fs5.getUri()).thenReturn(uri5);
    fs6=mock(FileSystem.class);
    when(fs6.getUri()).thenReturn(uri6);
  }
  @Test public void testCompareFsNull() throws Exception {
    setupCompareFs();
    assertEquals(FileUtil.compareFs(null,fs1),false);
    assertEquals(FileUtil.compareFs(fs1,null),false);
  }
  @Test public void testCompareFsDirectories() throws Exception {
    setupCompareFs();
    assertEquals(FileUtil.compareFs(fs1,fs1),true);
    assertEquals(FileUtil.compareFs(fs1,fs2),false);
    assertEquals(FileUtil.compareFs(fs1,fs5),false);
    assertEquals(FileUtil.compareFs(fs3,fs4),true);
    assertEquals(FileUtil.compareFs(fs1,fs6),false);
  }
  @Test(timeout=8000) public void testCreateSymbolicLinkUsingJava() throws IOException {
    setupDirs();
    final File simpleTar=new File(del,FILE);
    OutputStream os=new FileOutputStream(simpleTar);
    TarArchiveOutputStream tos=new TarArchiveOutputStream(os);
    File untarFile=null;
    try {
      final String tmpDir="tmp/test";
      File tmpDir1=new File(tmpDir,"dir1/");
      File tmpDir2=new File(tmpDir,"dir2/");
      tmpDir1.mkdirs();
      tmpDir2.mkdirs();
      java.nio.file.Path symLink=FileSystems.getDefault().getPath(tmpDir1.getPath() + "/sl");
      Files.createSymbolicLink(symLink,FileSystems.getDefault().getPath(tmpDir2.getPath())).toString();
      assertTrue(Files.isSymbolicLink(symLink.toAbsolutePath()));
      putEntriesInTar(tos,tmpDir1.getParentFile());
      tos.close();
      untarFile=new File(tmpDir,"2");
      FileUtil.unTarUsingJava(simpleTar,untarFile,false);
      assertTrue(Files.exists(untarFile.toPath()));
      assertTrue(Files.exists(FileSystems.getDefault().getPath(untarFile.getPath(),tmpDir)));
      assertTrue(Files.isSymbolicLink(FileSystems.getDefault().getPath(untarFile.getPath().toString(),symLink.toString())));
    }
  finally {
      FileUtils.deleteDirectory(new File("tmp"));
      tos.close();
    }
  }
  private void putEntriesInTar(  TarArchiveOutputStream tos,  File f) throws IOException {
    if (Files.isSymbolicLink(f.toPath())) {
      TarArchiveEntry tarEntry=new TarArchiveEntry(f.getPath(),TarArchiveEntry.LF_SYMLINK);
      tarEntry.setLinkName(Files.readSymbolicLink(f.toPath()).toString());
      tos.putArchiveEntry(tarEntry);
      tos.closeArchiveEntry();
      return;
    }
    if (f.isDirectory()) {
      tos.putArchiveEntry(new TarArchiveEntry(f));
      tos.closeArchiveEntry();
      for (      File child : f.listFiles()) {
        putEntriesInTar(tos,child);
      }
    }
    if (f.isFile()) {
      tos.putArchiveEntry(new TarArchiveEntry(f));
      BufferedInputStream origin=new BufferedInputStream(new FileInputStream(f));
      int count;
      byte[] data=new byte[2048];
      while ((count=origin.read(data)) != -1) {
        tos.write(data,0,count);
      }
      tos.flush();
      tos.closeArchiveEntry();
      origin.close();
    }
  }
  /** 
 * This test validates the correctness of  {@link FileUtil#readLink(File)} incase of null pointer inputs.
 */
  @Test public void testReadSymlinkWithNullInput(){
    String result=FileUtil.readLink(null);
    Assert.assertEquals("",result);
  }
  /** 
 * This test validates the correctness of  {@link FileUtil#readLink(File)}.
 * @throws IOException
 */
  @Test public void testReadSymlink() throws IOException {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    File file=new File(del,FILE);
    File link=new File(del,"_link");
    FileUtil.symLink(file.getAbsolutePath(),link.getAbsolutePath());
    String result=FileUtil.readLink(link);
    Assert.assertEquals(file.getAbsolutePath(),result);
    file.delete();
    link.delete();
  }
  /** 
 * This test validates the correctness of  {@link FileUtil#readLink(File)} whenit gets a file in input.
 * @throws IOException
 */
  @Test public void testReadSymlinkWithAFileAsInput() throws IOException {
    Assert.assertFalse(del.exists());
    del.mkdirs();
    File file=new File(del,FILE);
    String result=FileUtil.readLink(file);
    Assert.assertEquals("",result);
    file.delete();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.crypto.key.kms.server;
import java.io.ByteArrayOutputStream;
import java.io.FilterOutputStream;
import java.io.InputStream;
import java.io.IOException;
import java.io.OutputStream;
import java.io.PrintStream;
import java.util.List;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.crypto.key.kms.server.KMS.KMSOp;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.security.UserGroupInformation;
import org.apache.hadoop.test.GenericTestUtils;
import org.apache.hadoop.test.Whitebox;
import org.apache.hadoop.util.ThreadUtil;
import org.apache.log4j.LogManager;
import org.apache.log4j.PropertyConfigurator;
import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.Timeout;
import org.mockito.Mockito;
public class TestKMSAudit {
  private PrintStream originalOut;
  private ByteArrayOutputStream memOut;
  private FilterOut filterOut;
  private PrintStream capturedOut;
  private KMSAudit kmsAudit;
private static class FilterOut extends FilterOutputStream {
    public FilterOut(    OutputStream out){
      super(out);
    }
    public void setOutputStream(    OutputStream out){
      this.out=out;
    }
  }
  @Rule public final Timeout testTimeout=new Timeout(180000);
  @Before public void setUp() throws IOException {
    originalOut=System.err;
    memOut=new ByteArrayOutputStream();
    filterOut=new FilterOut(memOut);
    capturedOut=new PrintStream(filterOut);
    System.setErr(capturedOut);
    InputStream is=ThreadUtil.getResourceAsStream("log4j-kmsaudit.properties");
    PropertyConfigurator.configure(is);
    IOUtils.closeStream(is);
    Configuration conf=new Configuration();
    this.kmsAudit=new KMSAudit(conf);
  }
  @After public void cleanUp(){
    System.setErr(originalOut);
    LogManager.resetConfiguration();
    kmsAudit.shutdown();
  }
  private String getAndResetLogOutput(){
    capturedOut.flush();
    String logOutput=new String(memOut.toByteArray());
    memOut=new ByteArrayOutputStream();
    filterOut.setOutputStream(memOut);
    return logOutput;
  }
  @Test @SuppressWarnings("checkstyle:linelength") public void testAggregation() throws Exception {
    UserGroupInformation luser=Mockito.mock(UserGroupInformation.class);
    Mockito.when(luser.getShortUserName()).thenReturn("luser");
    kmsAudit.ok(luser,KMSOp.DECRYPT_EEK,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.DECRYPT_EEK,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.DECRYPT_EEK,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.DELETE_KEY,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.ROLL_NEW_VERSION,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.INVALIDATE_CACHE,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.DECRYPT_EEK,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.DECRYPT_EEK,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.DECRYPT_EEK,"k1","testmsg");
    kmsAudit.evictCacheForTesting();
    kmsAudit.ok(luser,KMSOp.DECRYPT_EEK,"k1","testmsg");
    kmsAudit.evictCacheForTesting();
    kmsAudit.ok(luser,KMSOp.REENCRYPT_EEK,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.REENCRYPT_EEK,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.REENCRYPT_EEK,"k1","testmsg");
    kmsAudit.evictCacheForTesting();
    kmsAudit.ok(luser,KMSOp.REENCRYPT_EEK_BATCH,"k1","testmsg");
    kmsAudit.ok(luser,KMSOp.REENCRYPT_EEK_BATCH,"k1","testmsg");
    kmsAudit.evictCacheForTesting();
    String out=getAndResetLogOutput();
    System.out.println(out);
    Assert.assertTrue(out.matches("OK\\[op=DECRYPT_EEK, key=k1, user=luser, accessCount=1, interval=[^m]{1,4}ms\\] testmsg" + "OK\\[op=DELETE_KEY, key=k1, user=luser\\] testmsg" + "OK\\[op=ROLL_NEW_VERSION, key=k1, user=luser\\] testmsg"+ "OK\\[op=INVALIDATE_CACHE, key=k1, user=luser\\] testmsg"+ "OK\\[op=DECRYPT_EEK, key=k1, user=luser, accessCount=6, interval=[^m]{1,4}ms\\] testmsg"+ "OK\\[op=DECRYPT_EEK, key=k1, user=luser, accessCount=1, interval=[^m]{1,4}ms\\] testmsg"+ "OK\\[op=REENCRYPT_EEK, key=k1, user=luser, accessCount=1, interval=[^m]{1,4}ms\\] testmsg"+ "OK\\[op=REENCRYPT_EEK, key=k1, user=luser, accessCount=3, interval=[^m]{1,4}ms\\] testmsg"+ "OK\\[op=REENCRYPT_EEK_BATCH, key=k1, user=luser\\] testmsg"+ "OK\\[op=REENCRYPT_EEK_BATCH, key=k1, user=luser\\] testmsg"));
  }
  @Test @SuppressWarnings("checkstyle:linelength") public void testAggregationUnauth() throws Exception {
    UserGroupInformation luser=Mockito.mock(UserGroupInformation.class);
    Mockito.when(luser.getShortUserName()).thenReturn("luser");
    kmsAudit.unauthorized(luser,KMSOp.GENERATE_EEK,"k2");
    kmsAudit.evictCacheForTesting();
    kmsAudit.ok(luser,KMSOp.GENERATE_EEK,"k3","testmsg");
    kmsAudit.ok(luser,KMSOp.GENERATE_EEK,"k3","testmsg");
    kmsAudit.ok(luser,KMSOp.GENERATE_EEK,"k3","testmsg");
    kmsAudit.ok(luser,KMSOp.GENERATE_EEK,"k3","testmsg");
    kmsAudit.ok(luser,KMSOp.GENERATE_EEK,"k3","testmsg");
    kmsAudit.unauthorized(luser,KMSOp.GENERATE_EEK,"k3");
    Thread.sleep(1000);
    kmsAudit.ok(luser,KMSOp.GENERATE_EEK,"k3","testmsg");
    kmsAudit.evictCacheForTesting();
    String out=getAndResetLogOutput();
    System.out.println(out);
    Assert.assertTrue(out.matches("UNAUTHORIZED\\[op=GENERATE_EEK, key=k2, user=luser\\] " + "OK\\[op=GENERATE_EEK, key=k3, user=luser, accessCount=1, interval=[^m]{1,4}ms\\] testmsg" + "OK\\[op=GENERATE_EEK, key=k3, user=luser, accessCount=5, interval=[^m]{1,4}ms\\] testmsg"+ "UNAUTHORIZED\\[op=GENERATE_EEK, key=k3, user=luser\\] "+ "OK\\[op=GENERATE_EEK, key=k3, user=luser, accessCount=1, interval=[^m]{1,4}ms\\] testmsg") || out.matches("UNAUTHORIZED\\[op=GENERATE_EEK, key=k2, user=luser\\] " + "OK\\[op=GENERATE_EEK, key=k3, user=luser, accessCount=1, interval=[^m]{1,4}ms\\] testmsg" + "UNAUTHORIZED\\[op=GENERATE_EEK, key=k3, user=luser\\] "+ "OK\\[op=GENERATE_EEK, key=k3, user=luser, accessCount=5, interval=[^m]{1,4}ms\\] testmsg"+ "OK\\[op=GENERATE_EEK, key=k3, user=luser, accessCount=1, interval=[^m]{1,4}ms\\] testmsg"));
  }
  @Test @SuppressWarnings("checkstyle:linelength") public void testAuditLogFormat() throws Exception {
    UserGroupInformation luser=Mockito.mock(UserGroupInformation.class);
    Mockito.when(luser.getShortUserName()).thenReturn("luser");
    kmsAudit.ok(luser,KMSOp.GENERATE_EEK,"k4","testmsg");
    kmsAudit.ok(luser,KMSOp.GENERATE_EEK,"testmsg");
    kmsAudit.evictCacheForTesting();
    kmsAudit.unauthorized(luser,KMSOp.DECRYPT_EEK,"k4");
    kmsAudit.error(luser,"method","url","testmsg");
    kmsAudit.unauthenticated("remotehost","method","url","testmsg");
    String out=getAndResetLogOutput();
    System.out.println(out);
    Assert.assertTrue(out.matches("OK\\[op=GENERATE_EEK, key=k4, user=luser, accessCount=1, interval=[^m]{1,4}ms\\] testmsg" + "OK\\[op=GENERATE_EEK, user=luser\\] testmsg" + "OK\\[op=GENERATE_EEK, key=k4, user=luser, accessCount=1, interval=[^m]{1,4}ms\\] testmsg"+ "UNAUTHORIZED\\[op=DECRYPT_EEK, key=k4, user=luser\\] "+ "ERROR\\[user=luser\\] Method:'method' Exception:'testmsg'"+ "UNAUTHENTICATED RemoteHost:remotehost Method:method URL:url ErrorMsg:'testmsg'"));
  }
  @SuppressWarnings("unchecked") @Test public void testInitAuditLoggers() throws Exception {
    List<KMSAuditLogger> loggers=(List<KMSAuditLogger>)Whitebox.getInternalState(kmsAudit,"auditLoggers");
    Assert.assertEquals(1,loggers.size());
    Assert.assertEquals(SimpleKMSAuditLogger.class,loggers.get(0).getClass());
    final Configuration conf=new Configuration();
    conf.set(KMSConfiguration.KMS_AUDIT_LOGGER_KEY,SimpleKMSAuditLogger.class.getName() + ", " + SimpleKMSAuditLogger.class.getName());
    final KMSAudit audit=new KMSAudit(conf);
    loggers=(List<KMSAuditLogger>)Whitebox.getInternalState(audit,"auditLoggers");
    Assert.assertEquals(1,loggers.size());
    Assert.assertEquals(SimpleKMSAuditLogger.class,loggers.get(0).getClass());
    conf.set(KMSConfiguration.KMS_AUDIT_LOGGER_KEY,SimpleKMSAuditLogger.class.getName() + ",unknown");
    try {
      new KMSAudit(conf);
      Assert.fail("loggers configured but invalid, init should fail.");
    }
 catch (    Exception ex) {
      GenericTestUtils.assertExceptionContains(KMSConfiguration.KMS_AUDIT_LOGGER_KEY,ex);
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapreduce.v2.hs.webapp;
import static org.junit.Assert.assertEquals;
import java.net.URI;
import java.net.URISyntaxException;
import org.apache.hadoop.http.HttpConfig;
import org.apache.hadoop.mapreduce.v2.jobhistory.JHAdminConfig;
import org.apache.hadoop.yarn.api.records.ApplicationId;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.junit.Test;
public class TestMapReduceTrackingUriPlugin {
  @Test public void testProducesHistoryServerUriForAppId() throws URISyntaxException {
    final String historyAddress="example.net:424242";
    YarnConfiguration conf=new YarnConfiguration();
    conf.set(JHAdminConfig.MR_HS_HTTP_POLICY,HttpConfig.Policy.HTTP_ONLY.name());
    conf.set(JHAdminConfig.MR_HISTORY_WEBAPP_ADDRESS,historyAddress);
    MapReduceTrackingUriPlugin plugin=new MapReduceTrackingUriPlugin();
    plugin.setConf(conf);
    ApplicationId id=ApplicationId.newInstance(6384623L,5);
    String jobSuffix=id.toString().replaceFirst("^application_","job_");
    URI expected=new URI("http://" + historyAddress + "/jobhistory/job/"+ jobSuffix);
    URI actual=plugin.getTrackingUri(id);
    assertEquals(expected,actual);
  }
  @Test public void testProducesHistoryServerUriWithHTTPS() throws URISyntaxException {
    final String historyAddress="example.net:404040";
    YarnConfiguration conf=new YarnConfiguration();
    conf.set(JHAdminConfig.MR_HS_HTTP_POLICY,HttpConfig.Policy.HTTPS_ONLY.name());
    conf.set(JHAdminConfig.MR_HISTORY_WEBAPP_HTTPS_ADDRESS,historyAddress);
    MapReduceTrackingUriPlugin plugin=new MapReduceTrackingUriPlugin();
    plugin.setConf(conf);
    ApplicationId id=ApplicationId.newInstance(6384623L,5);
    String jobSuffix=id.toString().replaceFirst("^application_","job_");
    URI expected=new URI("https://" + historyAddress + "/jobhistory/job/"+ jobSuffix);
    URI actual=plugin.getTrackingUri(id);
    assertEquals(expected,actual);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapreduce.lib.partition;
import static org.junit.Assert.*;
import java.util.Arrays;
import java.util.Collections;
import org.apache.commons.lang3.ArrayUtils;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.NullWritable;
import org.junit.*;
public class TestRehashPartitioner {
  /** 
 * number of partitions 
 */
  private static final int PARTITIONS=32;
  /** 
 * step in sequence 
 */
  private static final int STEP=3;
  /** 
 * end of test sequence 
 */
  private static final int END=100000;
  /** 
 * maximum error for considering too big/small bucket 
 */
  private static final double MAX_ERROR=0.20;
  /** 
 * maximum number of oddly sized buckets 
 */
  private static final double MAX_BADBUCKETS=0.10;
  /** 
 * test partitioner for patterns 
 */
  @Test public void testPatterns(){
    int results[]=new int[PARTITIONS];
    RehashPartitioner<IntWritable,NullWritable> p=new RehashPartitioner<IntWritable,NullWritable>();
    for (int i=0; i < END; i+=STEP) {
      results[p.getPartition(new IntWritable(i),null,PARTITIONS)]++;
    }
    int badbuckets=0;
    Integer min=Collections.min(Arrays.asList(ArrayUtils.toObject(results)));
    Integer max=Collections.max(Arrays.asList(ArrayUtils.toObject(results)));
    Integer avg=(int)Math.round((max + min) / 2.0);
    System.out.println("Dumping buckets distribution: min=" + min + " avg="+ avg+ " max="+ max);
    for (int i=0; i < PARTITIONS; i++) {
      double var=(results[i] - avg) / (double)(avg);
      System.out.println("bucket " + i + " "+ results[i]+ " items, variance "+ var);
      if (Math.abs(var) > MAX_ERROR)       badbuckets++;
    }
    System.out.println(badbuckets + " of " + PARTITIONS+ " are too small or large buckets");
    assertTrue("too many overflow buckets",badbuckets < PARTITIONS * MAX_BADBUCKETS);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapreduce.v2.app;
import java.util.Iterator;
import java.util.List;
import org.junit.Assert;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.mapreduce.MRJobConfig;
import org.apache.hadoop.mapreduce.v2.api.records.AMInfo;
import org.apache.hadoop.mapreduce.v2.api.records.JobState;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptState;
import org.apache.hadoop.mapreduce.v2.api.records.TaskState;
import org.apache.hadoop.mapreduce.v2.app.TestRecovery.MRAppWithHistory;
import org.apache.hadoop.mapreduce.v2.app.job.Job;
import org.apache.hadoop.mapreduce.v2.app.job.Task;
import org.apache.hadoop.mapreduce.v2.app.job.TaskAttempt;
import org.junit.Test;
public class TestAMInfos {
  @Test public void testAMInfosWithoutRecoveryEnabled() throws Exception {
    int runCount=0;
    MRApp app=new MRAppWithHistory(1,0,false,this.getClass().getName(),true,++runCount);
    Configuration conf=new Configuration();
    conf.setBoolean(MRJobConfig.JOB_UBERTASK_ENABLE,false);
    Job job=app.submit(conf);
    app.waitForState(job,JobState.RUNNING);
    long am1StartTime=app.getAllAMInfos().get(0).getStartTime();
    Assert.assertEquals("No of tasks not correct",1,job.getTasks().size());
    Iterator<Task> it=job.getTasks().values().iterator();
    Task mapTask=it.next();
    app.waitForState(mapTask,TaskState.RUNNING);
    TaskAttempt taskAttempt=mapTask.getAttempts().values().iterator().next();
    app.waitForState(taskAttempt,TaskAttemptState.RUNNING);
    app.stop();
    app=new MRAppWithHistory(1,0,false,this.getClass().getName(),false,++runCount);
    conf=new Configuration();
    conf.setBoolean(MRJobConfig.MR_AM_JOB_RECOVERY_ENABLE,false);
    conf.setBoolean(MRJobConfig.JOB_UBERTASK_ENABLE,false);
    job=app.submit(conf);
    app.waitForState(job,JobState.RUNNING);
    Assert.assertEquals("No of tasks not correct",1,job.getTasks().size());
    it=job.getTasks().values().iterator();
    mapTask=it.next();
    List<AMInfo> amInfos=app.getAllAMInfos();
    Assert.assertEquals(2,amInfos.size());
    AMInfo amInfoOne=amInfos.get(0);
    Assert.assertEquals(am1StartTime,amInfoOne.getStartTime());
    app.stop();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapreduce.v2.app.job.impl;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.when;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.Task;
import org.apache.hadoop.mapred.TaskUmbilicalProtocol;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.Counters;
import org.apache.hadoop.mapreduce.TaskCounter;
import org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier;
import org.apache.hadoop.mapreduce.split.JobSplit.TaskSplitMetaInfo;
import org.apache.hadoop.mapreduce.v2.api.records.Avataar;
import org.apache.hadoop.mapreduce.v2.api.records.JobId;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptState;
import org.apache.hadoop.mapreduce.v2.api.records.TaskId;
import org.apache.hadoop.mapreduce.v2.api.records.TaskState;
import org.apache.hadoop.mapreduce.v2.api.records.TaskType;
import org.apache.hadoop.mapreduce.v2.app.AppContext;
import org.apache.hadoop.mapreduce.v2.app.TaskAttemptListener;
import org.apache.hadoop.mapreduce.v2.app.job.TaskAttempt;
import org.apache.hadoop.mapreduce.v2.app.job.TaskStateInternal;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskTAttemptEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskTAttemptFailedEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskTAttemptKilledEvent;
import org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics;
import org.apache.hadoop.security.Credentials;
import org.apache.hadoop.security.token.Token;
import org.apache.hadoop.yarn.api.records.ApplicationId;
import org.apache.hadoop.yarn.event.Event;
import org.apache.hadoop.yarn.event.EventHandler;
import org.apache.hadoop.yarn.event.InlineDispatcher;
import org.apache.hadoop.yarn.util.Clock;
import org.apache.hadoop.yarn.util.Records;
import org.apache.hadoop.yarn.util.SystemClock;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
@SuppressWarnings("rawtypes") public class TestTaskImpl {
  private static final Logger LOG=LoggerFactory.getLogger(TestTaskImpl.class);
  private JobConf conf;
  private TaskAttemptListener taskAttemptListener;
  private Token<JobTokenIdentifier> jobToken;
  private JobId jobId;
  private Path remoteJobConfFile;
  private Credentials credentials;
  private Clock clock;
  private MRAppMetrics metrics;
  private TaskImpl mockTask;
  private ApplicationId appId;
  private TaskSplitMetaInfo taskSplitMetaInfo;
  private String[] dataLocations=new String[0];
  private AppContext appContext;
  private int startCount=0;
  private int taskCounter=0;
  private final int partition=1;
  private InlineDispatcher dispatcher;
  private MockTaskAttemptEventHandler taskAttemptEventHandler;
  private List<MockTaskAttemptImpl> taskAttempts;
private class MockTaskImpl extends TaskImpl {
    private int taskAttemptCounter=0;
    TaskType taskType;
    public MockTaskImpl(    JobId jobId,    int partition,    EventHandler eventHandler,    Path remoteJobConfFile,    JobConf conf,    TaskAttemptListener taskAttemptListener,    Token<JobTokenIdentifier> jobToken,    Credentials credentials,    Clock clock,    int startCount,    MRAppMetrics metrics,    AppContext appContext,    TaskType taskType){
      super(jobId,taskType,partition,eventHandler,remoteJobConfFile,conf,taskAttemptListener,jobToken,credentials,clock,startCount,metrics,appContext);
      this.taskType=taskType;
    }
    @Override public TaskType getType(){
      return taskType;
    }
    @Override protected TaskAttemptImpl createAttempt(){
      MockTaskAttemptImpl attempt=new MockTaskAttemptImpl(getID(),++taskAttemptCounter,eventHandler,taskAttemptListener,remoteJobConfFile,partition,conf,jobToken,credentials,clock,appContext,taskType);
      taskAttempts.add(attempt);
      return attempt;
    }
    @Override protected int getMaxAttempts(){
      return 100;
    }
    @Override protected void internalError(    TaskEventType type){
      super.internalError(type);
      fail("Internal error: " + type);
    }
  }
private class MockTaskAttemptImpl extends TaskAttemptImpl {
    private float progress=0;
    private TaskAttemptState state=TaskAttemptState.NEW;
    boolean rescheduled=false;
    boolean containerAssigned=false;
    private TaskType taskType;
    private Counters attemptCounters=TaskAttemptImpl.EMPTY_COUNTERS;
    public MockTaskAttemptImpl(    TaskId taskId,    int id,    EventHandler eventHandler,    TaskAttemptListener taskAttemptListener,    Path jobFile,    int partition,    JobConf conf,    Token<JobTokenIdentifier> jobToken,    Credentials credentials,    Clock clock,    AppContext appContext,    TaskType taskType){
      super(taskId,id,eventHandler,taskAttemptListener,jobFile,partition,conf,dataLocations,jobToken,credentials,clock,appContext);
      this.taskType=taskType;
    }
    public void assignContainer(){
      containerAssigned=true;
    }
    @Override boolean isContainerAssigned(){
      return containerAssigned;
    }
    public TaskAttemptId getAttemptId(){
      return getID();
    }
    @Override protected Task createRemoteTask(){
      return new MockTask(taskType);
    }
    public float getProgress(){
      return progress;
    }
    public void setProgress(    float progress){
      this.progress=progress;
    }
    public void setState(    TaskAttemptState state){
      this.state=state;
    }
    @Override public TaskAttemptState getState(){
      return state;
    }
    public boolean getRescheduled(){
      return this.rescheduled;
    }
    public void setRescheduled(    boolean rescheduled){
      this.rescheduled=rescheduled;
    }
    @Override public Counters getCounters(){
      return attemptCounters;
    }
    public void setCounters(    Counters counters){
      attemptCounters=counters;
    }
  }
private class MockTask extends Task {
    private TaskType taskType;
    MockTask(    TaskType taskType){
      this.taskType=taskType;
    }
    @Override public void run(    JobConf job,    TaskUmbilicalProtocol umbilical) throws IOException, ClassNotFoundException, InterruptedException {
      return;
    }
    @Override public boolean isMapTask(){
      return (taskType == TaskType.MAP);
    }
  }
  @Before @SuppressWarnings("unchecked") public void setup(){
    dispatcher=new InlineDispatcher();
    ++startCount;
    conf=new JobConf();
    taskAttemptListener=mock(TaskAttemptListener.class);
    jobToken=(Token<JobTokenIdentifier>)mock(Token.class);
    remoteJobConfFile=mock(Path.class);
    credentials=null;
    clock=SystemClock.getInstance();
    metrics=mock(MRAppMetrics.class);
    dataLocations=new String[1];
    appId=ApplicationId.newInstance(System.currentTimeMillis(),1);
    jobId=Records.newRecord(JobId.class);
    jobId.setId(1);
    jobId.setAppId(appId);
    appContext=mock(AppContext.class);
    taskSplitMetaInfo=mock(TaskSplitMetaInfo.class);
    when(taskSplitMetaInfo.getLocations()).thenReturn(dataLocations);
    taskAttempts=new ArrayList<MockTaskAttemptImpl>();
    taskAttemptEventHandler=new MockTaskAttemptEventHandler();
    dispatcher.register(TaskAttemptEventType.class,taskAttemptEventHandler);
  }
  private MockTaskImpl createMockTask(  TaskType taskType){
    return new MockTaskImpl(jobId,partition,dispatcher.getEventHandler(),remoteJobConfFile,conf,taskAttemptListener,jobToken,credentials,clock,startCount,metrics,appContext,taskType);
  }
  @After public void teardown(){
    taskAttempts.clear();
  }
  private TaskId getNewTaskID(){
    TaskId taskId=Records.newRecord(TaskId.class);
    taskId.setId(++taskCounter);
    taskId.setJobId(jobId);
    taskId.setTaskType(mockTask.getType());
    return taskId;
  }
  private void scheduleTaskAttempt(  TaskId taskId){
    mockTask.handle(new TaskEvent(taskId,TaskEventType.T_SCHEDULE));
    assertTaskScheduledState();
    assertTaskAttemptAvataar(Avataar.VIRGIN);
  }
  private void killTask(  TaskId taskId){
    mockTask.handle(new TaskEvent(taskId,TaskEventType.T_KILL));
    assertTaskKillWaitState();
  }
  private void killScheduledTaskAttempt(  TaskAttemptId attemptId){
    killScheduledTaskAttempt(attemptId,false);
  }
  private void killScheduledTaskAttempt(  TaskAttemptId attemptId,  boolean reschedule){
    mockTask.handle(new TaskTAttemptKilledEvent(attemptId,reschedule));
    assertTaskScheduledState();
  }
  private void launchTaskAttempt(  TaskAttemptId attemptId){
    mockTask.handle(new TaskTAttemptEvent(attemptId,TaskEventType.T_ATTEMPT_LAUNCHED));
    ((MockTaskAttemptImpl)(mockTask.getAttempt(attemptId))).assignContainer();
    assertTaskRunningState();
  }
  private void commitTaskAttempt(  TaskAttemptId attemptId){
    mockTask.handle(new TaskTAttemptEvent(attemptId,TaskEventType.T_ATTEMPT_COMMIT_PENDING));
    assertTaskRunningState();
  }
  private MockTaskAttemptImpl getLastAttempt(){
    return taskAttempts.get(taskAttempts.size() - 1);
  }
  private void updateLastAttemptProgress(  float p){
    getLastAttempt().setProgress(p);
  }
  private void updateLastAttemptState(  TaskAttemptState s){
    getLastAttempt().setState(s);
  }
  private void killRunningTaskAttempt(  TaskAttemptId attemptId){
    killRunningTaskAttempt(attemptId,false);
  }
  private void killRunningTaskAttempt(  TaskAttemptId attemptId,  boolean reschedule){
    mockTask.handle(new TaskTAttemptKilledEvent(attemptId,reschedule));
    assertTaskRunningState();
  }
  private void failRunningTaskAttempt(  TaskAttemptId attemptId){
    mockTask.handle(new TaskTAttemptFailedEvent(attemptId));
    assertTaskRunningState();
  }
  /** 
 * {@link TaskState#NEW}
 */
  private void assertTaskNewState(){
    assertEquals(TaskState.NEW,mockTask.getState());
  }
  /** 
 * {@link TaskState#SCHEDULED}
 */
  private void assertTaskScheduledState(){
    assertEquals(TaskState.SCHEDULED,mockTask.getState());
  }
  /** 
 * {@link TaskState#RUNNING}
 */
  private void assertTaskRunningState(){
    assertEquals(TaskState.RUNNING,mockTask.getState());
  }
  /** 
 * {@link TaskState#KILL_WAIT}
 */
  private void assertTaskKillWaitState(){
    assertEquals(TaskStateInternal.KILL_WAIT,mockTask.getInternalState());
  }
  /** 
 * {@link TaskState#SUCCEEDED}
 */
  private void assertTaskSucceededState(){
    assertEquals(TaskState.SUCCEEDED,mockTask.getState());
  }
  /** 
 * {@link Avataar}
 */
  private void assertTaskAttemptAvataar(  Avataar avataar){
    for (    TaskAttempt taskAttempt : mockTask.getAttempts().values()) {
      if (((TaskAttemptImpl)taskAttempt).getAvataar() == avataar) {
        return;
      }
    }
    fail("There is no " + (avataar == Avataar.VIRGIN ? "virgin" : "speculative") + "task attempt");
  }
  @Test public void testInit(){
    LOG.info("--- START: testInit ---");
    mockTask=createMockTask(TaskType.MAP);
    assertTaskNewState();
    assert (taskAttempts.size() == 0);
  }
  @Test public void testScheduleTask(){
    LOG.info("--- START: testScheduleTask ---");
    mockTask=createMockTask(TaskType.MAP);
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
  }
  @Test public void testKillScheduledTask(){
    LOG.info("--- START: testKillScheduledTask ---");
    mockTask=createMockTask(TaskType.MAP);
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    killTask(taskId);
  }
  @Test public void testKillScheduledTaskAttempt(){
    LOG.info("--- START: testKillScheduledTaskAttempt ---");
    mockTask=createMockTask(TaskType.MAP);
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    killScheduledTaskAttempt(getLastAttempt().getAttemptId(),true);
    assertEquals(TaskAttemptEventType.TA_RESCHEDULE,taskAttemptEventHandler.lastTaskAttemptEvent.getType());
  }
  @Test public void testLaunchTaskAttempt(){
    LOG.info("--- START: testLaunchTaskAttempt ---");
    mockTask=createMockTask(TaskType.MAP);
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    launchTaskAttempt(getLastAttempt().getAttemptId());
  }
  @Test public void testKillRunningTaskAttempt(){
    LOG.info("--- START: testKillRunningTaskAttempt ---");
    mockTask=createMockTask(TaskType.MAP);
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    killRunningTaskAttempt(getLastAttempt().getAttemptId(),true);
    assertEquals(TaskAttemptEventType.TA_RESCHEDULE,taskAttemptEventHandler.lastTaskAttemptEvent.getType());
  }
  @Test public void testKillSuccessfulTask(){
    LOG.info("--- START: testKillSuccesfulTask ---");
    mockTask=createMockTask(TaskType.MAP);
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    commitTaskAttempt(getLastAttempt().getAttemptId());
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ATTEMPT_SUCCEEDED));
    assertTaskSucceededState();
    mockTask.handle(new TaskEvent(taskId,TaskEventType.T_KILL));
    assertTaskSucceededState();
  }
  @Test public void testKillAttemptForSuccessfulTask(){
    LOG.info("--- START: testKillAttemptForSuccessfulTask ---");
    mockTask=createMockTask(TaskType.MAP);
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    commitTaskAttempt(getLastAttempt().getAttemptId());
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ATTEMPT_SUCCEEDED));
    assertTaskSucceededState();
    mockTask.handle(new TaskTAttemptKilledEvent(getLastAttempt().getAttemptId(),true));
    assertEquals(TaskAttemptEventType.TA_RESCHEDULE,taskAttemptEventHandler.lastTaskAttemptEvent.getType());
    assertTaskScheduledState();
  }
  @Test public void testTaskProgress(){
    LOG.info("--- START: testTaskProgress ---");
    mockTask=createMockTask(TaskType.MAP);
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    float progress=0f;
    assert (mockTask.getProgress() == progress);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    progress=50f;
    updateLastAttemptProgress(progress);
    assert (mockTask.getProgress() == progress);
    progress=100f;
    updateLastAttemptProgress(progress);
    assert (mockTask.getProgress() == progress);
    progress=0f;
    updateLastAttemptState(TaskAttemptState.KILLED);
    assert (mockTask.getProgress() == progress);
    killRunningTaskAttempt(getLastAttempt().getAttemptId());
    assert (taskAttempts.size() == 2);
    assert (mockTask.getProgress() == 0f);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    progress=50f;
    updateLastAttemptProgress(progress);
    assert (mockTask.getProgress() == progress);
  }
  @Test public void testKillDuringTaskAttemptCommit(){
    mockTask=createMockTask(TaskType.REDUCE);
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    updateLastAttemptState(TaskAttemptState.COMMIT_PENDING);
    commitTaskAttempt(getLastAttempt().getAttemptId());
    TaskAttemptId commitAttempt=getLastAttempt().getAttemptId();
    updateLastAttemptState(TaskAttemptState.KILLED);
    killRunningTaskAttempt(commitAttempt);
    assertFalse(mockTask.canCommit(commitAttempt));
  }
  @Test public void testFailureDuringTaskAttemptCommit(){
    mockTask=createMockTask(TaskType.MAP);
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    updateLastAttemptState(TaskAttemptState.COMMIT_PENDING);
    commitTaskAttempt(getLastAttempt().getAttemptId());
    updateLastAttemptState(TaskAttemptState.FAILED);
    failRunningTaskAttempt(getLastAttempt().getAttemptId());
    assertEquals(2,taskAttempts.size());
    updateLastAttemptState(TaskAttemptState.SUCCEEDED);
    commitTaskAttempt(getLastAttempt().getAttemptId());
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ATTEMPT_SUCCEEDED));
    assertFalse("First attempt should not commit",mockTask.canCommit(taskAttempts.get(0).getAttemptId()));
    assertTrue("Second attempt should commit",mockTask.canCommit(getLastAttempt().getAttemptId()));
    assertTaskSucceededState();
  }
  private void runSpeculativeTaskAttemptSucceeds(  TaskEventType firstAttemptFinishEvent){
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    updateLastAttemptState(TaskAttemptState.RUNNING);
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ADD_SPEC_ATTEMPT));
    launchTaskAttempt(getLastAttempt().getAttemptId());
    commitTaskAttempt(getLastAttempt().getAttemptId());
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ATTEMPT_SUCCEEDED));
    assertTaskSucceededState();
    if (firstAttemptFinishEvent.equals(TaskEventType.T_ATTEMPT_FAILED)) {
      mockTask.handle(new TaskTAttemptFailedEvent(taskAttempts.get(0).getAttemptId()));
    }
 else {
      mockTask.handle(new TaskTAttemptEvent(taskAttempts.get(0).getAttemptId(),firstAttemptFinishEvent));
    }
    assertTaskSucceededState();
    assertTaskAttemptAvataar(Avataar.SPECULATIVE);
  }
  @Test public void testMapSpeculativeTaskAttemptSucceedsEvenIfFirstFails(){
    mockTask=createMockTask(TaskType.MAP);
    runSpeculativeTaskAttemptSucceeds(TaskEventType.T_ATTEMPT_FAILED);
  }
  @Test public void testReduceSpeculativeTaskAttemptSucceedsEvenIfFirstFails(){
    mockTask=createMockTask(TaskType.REDUCE);
    runSpeculativeTaskAttemptSucceeds(TaskEventType.T_ATTEMPT_FAILED);
  }
  @Test public void testMapSpeculativeTaskAttemptSucceedsEvenIfFirstIsKilled(){
    mockTask=createMockTask(TaskType.MAP);
    runSpeculativeTaskAttemptSucceeds(TaskEventType.T_ATTEMPT_KILLED);
  }
  @Test public void testReduceSpeculativeTaskAttemptSucceedsEvenIfFirstIsKilled(){
    mockTask=createMockTask(TaskType.REDUCE);
    runSpeculativeTaskAttemptSucceeds(TaskEventType.T_ATTEMPT_KILLED);
  }
  @Test public void testMultipleTaskAttemptsSucceed(){
    mockTask=createMockTask(TaskType.MAP);
    runSpeculativeTaskAttemptSucceeds(TaskEventType.T_ATTEMPT_SUCCEEDED);
  }
  @Test public void testCommitAfterSucceeds(){
    mockTask=createMockTask(TaskType.REDUCE);
    runSpeculativeTaskAttemptSucceeds(TaskEventType.T_ATTEMPT_COMMIT_PENDING);
  }
  @Test public void testSpeculativeMapFetchFailure(){
    mockTask=createMockTask(TaskType.MAP);
    runSpeculativeTaskAttemptSucceeds(TaskEventType.T_ATTEMPT_KILLED);
    assertEquals(2,taskAttempts.size());
    mockTask.handle(new TaskTAttemptFailedEvent(taskAttempts.get(1).getAttemptId()));
    assertTaskScheduledState();
    assertEquals(3,taskAttempts.size());
  }
  @Test public void testSpeculativeMapMultipleSucceedFetchFailure(){
    mockTask=createMockTask(TaskType.MAP);
    runSpeculativeTaskAttemptSucceeds(TaskEventType.T_ATTEMPT_SUCCEEDED);
    assertEquals(2,taskAttempts.size());
    mockTask.handle(new TaskTAttemptFailedEvent(taskAttempts.get(1).getAttemptId()));
    assertTaskScheduledState();
    assertEquals(3,taskAttempts.size());
  }
  @Test public void testSpeculativeMapFailedFetchFailure(){
    mockTask=createMockTask(TaskType.MAP);
    runSpeculativeTaskAttemptSucceeds(TaskEventType.T_ATTEMPT_FAILED);
    assertEquals(2,taskAttempts.size());
    mockTask.handle(new TaskTAttemptFailedEvent(taskAttempts.get(1).getAttemptId()));
    assertTaskScheduledState();
    assertEquals(3,taskAttempts.size());
  }
  @Test public void testFailedTransitions(){
    mockTask=new MockTaskImpl(jobId,partition,dispatcher.getEventHandler(),remoteJobConfFile,conf,taskAttemptListener,jobToken,credentials,clock,startCount,metrics,appContext,TaskType.MAP){
      @Override protected int getMaxAttempts(){
        return 1;
      }
    }
;
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ADD_SPEC_ATTEMPT));
    launchTaskAttempt(getLastAttempt().getAttemptId());
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ADD_SPEC_ATTEMPT));
    launchTaskAttempt(getLastAttempt().getAttemptId());
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ADD_SPEC_ATTEMPT));
    launchTaskAttempt(getLastAttempt().getAttemptId());
    assertEquals(4,taskAttempts.size());
    MockTaskAttemptImpl taskAttempt=taskAttempts.get(0);
    taskAttempt.setState(TaskAttemptState.FAILED);
    mockTask.handle(new TaskTAttemptFailedEvent(taskAttempt.getAttemptId()));
    assertEquals(TaskState.FAILED,mockTask.getState());
    mockTask.handle(new TaskEvent(taskId,TaskEventType.T_KILL));
    assertEquals(TaskState.FAILED,mockTask.getState());
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ADD_SPEC_ATTEMPT));
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ATTEMPT_LAUNCHED));
    assertEquals(TaskState.FAILED,mockTask.getState());
    assertEquals(4,taskAttempts.size());
    taskAttempt=taskAttempts.get(1);
    taskAttempt.setState(TaskAttemptState.COMMIT_PENDING);
    mockTask.handle(new TaskTAttemptEvent(taskAttempt.getAttemptId(),TaskEventType.T_ATTEMPT_COMMIT_PENDING));
    assertEquals(TaskState.FAILED,mockTask.getState());
    taskAttempt.setState(TaskAttemptState.FAILED);
    mockTask.handle(new TaskTAttemptFailedEvent(taskAttempt.getAttemptId()));
    assertEquals(TaskState.FAILED,mockTask.getState());
    taskAttempt=taskAttempts.get(2);
    taskAttempt.setState(TaskAttemptState.SUCCEEDED);
    mockTask.handle(new TaskTAttemptEvent(taskAttempt.getAttemptId(),TaskEventType.T_ATTEMPT_SUCCEEDED));
    assertEquals(TaskState.FAILED,mockTask.getState());
    taskAttempt=taskAttempts.get(3);
    taskAttempt.setState(TaskAttemptState.KILLED);
    mockTask.handle(new TaskTAttemptKilledEvent(taskAttempt.getAttemptId(),false));
    assertEquals(TaskState.FAILED,mockTask.getState());
  }
private class PartialAttemptEventHandler implements EventHandler {
    @Override public void handle(    Event event){
      if (event instanceof TaskAttemptEvent)       if (event.getType() == TaskAttemptEventType.TA_RESCHEDULE) {
        TaskAttempt attempt=mockTask.getAttempt(((TaskAttemptEvent)event).getTaskAttemptID());
        ((MockTaskAttemptImpl)attempt).setRescheduled(true);
      }
    }
  }
  @Test public void testFailedTransitionWithHangingSpeculativeMap(){
    mockTask=new MockTaskImpl(jobId,partition,new PartialAttemptEventHandler(),remoteJobConfFile,conf,taskAttemptListener,jobToken,credentials,clock,startCount,metrics,appContext,TaskType.MAP){
      @Override protected int getMaxAttempts(){
        return 4;
      }
    }
;
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ADD_SPEC_ATTEMPT));
    MockTaskAttemptImpl taskAttempt=taskAttempts.get(0);
    taskAttempt.setState(TaskAttemptState.FAILED);
    mockTask.handle(new TaskTAttemptFailedEvent(taskAttempt.getAttemptId()));
    assertEquals(TaskState.RUNNING,mockTask.getState());
    assertEquals(3,taskAttempts.size());
    assertEquals(false,taskAttempts.get(1).getRescheduled());
    assertEquals(true,taskAttempts.get(2).getRescheduled());
    launchTaskAttempt(getLastAttempt().getAttemptId());
    MockTaskAttemptImpl taskAttempt1=taskAttempts.get(1);
    taskAttempt1.setState(TaskAttemptState.FAILED);
    mockTask.handle(new TaskTAttemptFailedEvent(taskAttempt1.getAttemptId()));
    assertEquals(TaskState.RUNNING,mockTask.getState());
    assertEquals(3,taskAttempts.size());
  }
  @Test public void testCountersWithSpeculation(){
    mockTask=new MockTaskImpl(jobId,partition,dispatcher.getEventHandler(),remoteJobConfFile,conf,taskAttemptListener,jobToken,credentials,clock,startCount,metrics,appContext,TaskType.MAP){
      @Override protected int getMaxAttempts(){
        return 1;
      }
    }
;
    TaskId taskId=getNewTaskID();
    scheduleTaskAttempt(taskId);
    launchTaskAttempt(getLastAttempt().getAttemptId());
    updateLastAttemptState(TaskAttemptState.RUNNING);
    MockTaskAttemptImpl baseAttempt=getLastAttempt();
    mockTask.handle(new TaskTAttemptEvent(getLastAttempt().getAttemptId(),TaskEventType.T_ADD_SPEC_ATTEMPT));
    launchTaskAttempt(getLastAttempt().getAttemptId());
    updateLastAttemptState(TaskAttemptState.RUNNING);
    MockTaskAttemptImpl specAttempt=getLastAttempt();
    assertEquals(2,taskAttempts.size());
    Counters specAttemptCounters=new Counters();
    Counter cpuCounter=specAttemptCounters.findCounter(TaskCounter.CPU_MILLISECONDS);
    cpuCounter.setValue(1000);
    specAttempt.setCounters(specAttemptCounters);
    commitTaskAttempt(specAttempt.getAttemptId());
    specAttempt.setProgress(1.0f);
    specAttempt.setState(TaskAttemptState.SUCCEEDED);
    mockTask.handle(new TaskTAttemptEvent(specAttempt.getAttemptId(),TaskEventType.T_ATTEMPT_SUCCEEDED));
    assertEquals(TaskState.SUCCEEDED,mockTask.getState());
    baseAttempt.setProgress(1.0f);
    Counters taskCounters=mockTask.getCounters();
    assertEquals("wrong counters for task",specAttemptCounters,taskCounters);
  }
public static class MockTaskAttemptEventHandler implements EventHandler {
    public TaskAttemptEvent lastTaskAttemptEvent;
    @Override public void handle(    Event event){
      if (event instanceof TaskAttemptEvent) {
        lastTaskAttemptEvent=(TaskAttemptEvent)event;
      }
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapreduce.v2.app.job.impl;
import static org.apache.hadoop.test.GenericTestUtils.waitFor;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.spy;
import static org.mockito.Mockito.times;
import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.when;
import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.net.InetSocketAddress;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.concurrent.CopyOnWriteArrayList;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptFailEvent;
import org.junit.After;
import org.junit.Assert;
import org.junit.BeforeClass;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.RawLocalFileSystem;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.MapTaskAttemptImpl;
import org.apache.hadoop.mapred.ReduceTaskAttemptImpl;
import org.apache.hadoop.mapreduce.Counters;
import org.apache.hadoop.mapreduce.JobCounter;
import org.apache.hadoop.mapreduce.MRJobConfig;
import org.apache.hadoop.mapreduce.jobhistory.JobHistoryEvent;
import org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion;
import org.apache.hadoop.mapreduce.split.JobSplit.TaskSplitMetaInfo;
import org.apache.hadoop.mapreduce.v2.api.records.JobId;
import org.apache.hadoop.mapreduce.v2.api.records.JobState;
import org.apache.hadoop.mapreduce.v2.api.records.Locality;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptReport;
import org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptState;
import org.apache.hadoop.mapreduce.v2.api.records.TaskId;
import org.apache.hadoop.mapreduce.v2.api.records.TaskState;
import org.apache.hadoop.mapreduce.v2.api.records.TaskType;
import org.apache.hadoop.mapreduce.v2.app.AppContext;
import org.apache.hadoop.mapreduce.v2.app.ClusterInfo;
import org.apache.hadoop.mapreduce.v2.app.MRApp;
import org.apache.hadoop.mapreduce.v2.app.TaskAttemptFinishingMonitor;
import org.apache.hadoop.mapreduce.v2.app.TaskAttemptListener;
import org.apache.hadoop.mapreduce.v2.app.job.Job;
import org.apache.hadoop.mapreduce.v2.app.job.Task;
import org.apache.hadoop.mapreduce.v2.app.job.TaskAttempt;
import org.apache.hadoop.mapreduce.v2.app.job.TaskAttemptStateInternal;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptContainerAssignedEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptContainerLaunchedEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptDiagnosticsUpdateEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptKillEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptTooManyFetchFailureEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskEvent;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType;
import org.apache.hadoop.mapreduce.v2.app.job.event.TaskTAttemptKilledEvent;
import org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent;
import org.apache.hadoop.mapreduce.v2.util.MRBuilderUtils;
import org.apache.hadoop.security.Credentials;
import org.apache.hadoop.security.token.Token;
import org.apache.hadoop.yarn.LocalConfigurationProvider;
import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
import org.apache.hadoop.yarn.api.records.ApplicationId;
import org.apache.hadoop.yarn.api.records.Container;
import org.apache.hadoop.yarn.api.records.ContainerId;
import org.apache.hadoop.yarn.api.records.NodeId;
import org.apache.hadoop.yarn.api.records.Resource;
import org.apache.hadoop.yarn.api.records.ResourceInformation;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.apache.hadoop.yarn.event.Event;
import org.apache.hadoop.yarn.event.EventHandler;
import org.apache.hadoop.yarn.exceptions.YarnException;
import org.apache.hadoop.yarn.util.Clock;
import org.apache.hadoop.yarn.util.ControlledClock;
import org.apache.hadoop.yarn.util.SystemClock;
import org.apache.hadoop.yarn.util.resource.ResourceUtils;
import org.apache.log4j.AppenderSkeleton;
import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.log4j.spi.LoggingEvent;
import org.junit.Test;
import org.mockito.ArgumentCaptor;
import com.google.common.collect.ImmutableList;
@SuppressWarnings({"unchecked","rawtypes"}) public class TestTaskAttempt {
  private static final String CUSTOM_RESOURCE_NAME="a-custom-resource";
static public class StubbedFS extends RawLocalFileSystem {
    @Override public FileStatus getFileStatus(    Path f) throws IOException {
      return new FileStatus(1,false,1,1,1,f);
    }
  }
private static class CustomResourceTypesConfigurationProvider extends LocalConfigurationProvider {
    @Override public InputStream getConfigurationInputStream(    Configuration bootstrapConf,    String name) throws YarnException, IOException {
      if (YarnConfiguration.RESOURCE_TYPES_CONFIGURATION_FILE.equals(name)) {
        return new ByteArrayInputStream(("<configuration>\n" + " <property>\n" + "   <name>yarn.resource-types</name>\n"+ "   <value>a-custom-resource</value>\n"+ " </property>\n"+ " <property>\n"+ "   <name>yarn.resource-types.a-custom-resource.units</name>\n"+ "   <value>G</value>\n"+ " </property>\n"+ "</configuration>\n").getBytes());
      }
 else {
        return super.getConfigurationInputStream(bootstrapConf,name);
      }
    }
  }
private static class TestAppender extends AppenderSkeleton {
    private final List<LoggingEvent> logEvents=new CopyOnWriteArrayList<>();
    @Override public boolean requiresLayout(){
      return false;
    }
    @Override public void close(){
    }
    @Override protected void append(    LoggingEvent arg0){
      logEvents.add(arg0);
    }
    private List<LoggingEvent> getLogEvents(){
      return logEvents;
    }
  }
  @BeforeClass public static void setupBeforeClass(){
    ResourceUtils.resetResourceTypes(new Configuration());
  }
  @After public void tearDown(){
    ResourceUtils.resetResourceTypes(new Configuration());
  }
  @Test public void testMRAppHistoryForMap() throws Exception {
    MRApp app=null;
    try {
      app=new FailingAttemptsMRApp(1,0);
      testMRAppHistory(app);
    }
  finally {
      app.close();
    }
  }
  @Test public void testMRAppHistoryForReduce() throws Exception {
    MRApp app=null;
    try {
      app=new FailingAttemptsMRApp(0,1);
      testMRAppHistory(app);
    }
  finally {
      app.close();
    }
  }
  @Test public void testMRAppHistoryForTAFailedInAssigned() throws Exception {
    FailingAttemptsDuringAssignedMRApp app=null;
    try {
      app=new FailingAttemptsDuringAssignedMRApp(1,0,TaskAttemptEventType.TA_CONTAINER_LAUNCH_FAILED);
      testTaskAttemptAssignedFailHistory(app);
      app.close();
      app=new FailingAttemptsDuringAssignedMRApp(0,1,TaskAttemptEventType.TA_CONTAINER_LAUNCH_FAILED);
      testTaskAttemptAssignedFailHistory(app);
      app.close();
      app=new FailingAttemptsDuringAssignedMRApp(1,0,TaskAttemptEventType.TA_CONTAINER_COMPLETED);
      testTaskAttemptAssignedFailHistory(app);
      app.close();
      app=new FailingAttemptsDuringAssignedMRApp(0,1,TaskAttemptEventType.TA_CONTAINER_COMPLETED);
      testTaskAttemptAssignedFailHistory(app);
      app.close();
      app=new FailingAttemptsDuringAssignedMRApp(1,0,TaskAttemptEventType.TA_FAILMSG);
      testTaskAttemptAssignedFailHistory(app);
      app.close();
      app=new FailingAttemptsDuringAssignedMRApp(0,1,TaskAttemptEventType.TA_FAILMSG);
      testTaskAttemptAssignedFailHistory(app);
      app.close();
      app=new FailingAttemptsDuringAssignedMRApp(1,0,TaskAttemptEventType.TA_FAILMSG_BY_CLIENT);
      testTaskAttemptAssignedFailHistory(app);
      app.close();
      app=new FailingAttemptsDuringAssignedMRApp(0,1,TaskAttemptEventType.TA_FAILMSG_BY_CLIENT);
      testTaskAttemptAssignedFailHistory(app);
      app.close();
      app=new FailingAttemptsDuringAssignedMRApp(1,0,TaskAttemptEventType.TA_KILL);
      testTaskAttemptAssignedKilledHistory(app);
      app.close();
      app=new FailingAttemptsDuringAssignedMRApp(0,1,TaskAttemptEventType.TA_KILL);
      testTaskAttemptAssignedKilledHistory(app);
      app.close();
    }
  finally {
      app.close();
    }
  }
  @Test public void testSingleRackRequest() throws Exception {
    TaskAttemptImpl.RequestContainerTransition rct=new TaskAttemptImpl.RequestContainerTransition(false);
    EventHandler eventHandler=mock(EventHandler.class);
    String[] hosts=new String[3];
    hosts[0]="host1";
    hosts[1]="host2";
    hosts[2]="host3";
    TaskSplitMetaInfo splitInfo=new TaskSplitMetaInfo(hosts,0,128 * 1024 * 1024l);
    TaskAttemptImpl mockTaskAttempt=createMapTaskAttemptImplForTest(eventHandler,splitInfo);
    TaskAttemptEvent mockTAEvent=mock(TaskAttemptEvent.class);
    rct.transition(mockTaskAttempt,mockTAEvent);
    ArgumentCaptor<Event> arg=ArgumentCaptor.forClass(Event.class);
    verify(eventHandler,times(2)).handle(arg.capture());
    if (!(arg.getAllValues().get(1) instanceof ContainerRequestEvent)) {
      Assert.fail("Second Event not of type ContainerRequestEvent");
    }
    ContainerRequestEvent cre=(ContainerRequestEvent)arg.getAllValues().get(1);
    String[] requestedRacks=cre.getRacks();
    assertEquals(1,requestedRacks.length);
  }
  @Test public void testHostResolveAttempt() throws Exception {
    TaskAttemptImpl.RequestContainerTransition rct=new TaskAttemptImpl.RequestContainerTransition(false);
    EventHandler eventHandler=mock(EventHandler.class);
    String[] hosts=new String[3];
    hosts[0]="192.168.1.1";
    hosts[1]="host2";
    hosts[2]="host3";
    TaskSplitMetaInfo splitInfo=new TaskSplitMetaInfo(hosts,0,128 * 1024 * 1024l);
    TaskAttemptImpl mockTaskAttempt=createMapTaskAttemptImplForTest(eventHandler,splitInfo);
    TaskAttemptImpl spyTa=spy(mockTaskAttempt);
    when(spyTa.resolveHost(hosts[0])).thenReturn("host1");
    spyTa.dataLocalHosts=spyTa.resolveHosts(splitInfo.getLocations());
    TaskAttemptEvent mockTAEvent=mock(TaskAttemptEvent.class);
    rct.transition(spyTa,mockTAEvent);
    verify(spyTa).resolveHost(hosts[0]);
    ArgumentCaptor<Event> arg=ArgumentCaptor.forClass(Event.class);
    verify(eventHandler,times(2)).handle(arg.capture());
    if (!(arg.getAllValues().get(1) instanceof ContainerRequestEvent)) {
      Assert.fail("Second Event not of type ContainerRequestEvent");
    }
    Map<String,Boolean> expected=new HashMap<String,Boolean>();
    expected.put("host1",true);
    expected.put("host2",true);
    expected.put("host3",true);
    ContainerRequestEvent cre=(ContainerRequestEvent)arg.getAllValues().get(1);
    String[] requestedHosts=cre.getHosts();
    for (    String h : requestedHosts) {
      expected.remove(h);
    }
    assertEquals(0,expected.size());
  }
  @Test public void testMillisCountersUpdate() throws Exception {
    verifyMillisCounters(Resource.newInstance(1024,1),512);
    verifyMillisCounters(Resource.newInstance(2048,4),1024);
    verifyMillisCounters(Resource.newInstance(10240,8),2048);
  }
  public void verifyMillisCounters(  Resource containerResource,  int minContainerSize) throws Exception {
    Clock actualClock=SystemClock.getInstance();
    ControlledClock clock=new ControlledClock(actualClock);
    clock.setTime(10);
    MRApp app=new MRApp(1,1,false,"testSlotMillisCounterUpdate",true,clock);
    app.setAllocatedContainerResource(containerResource);
    Configuration conf=new Configuration();
    conf.setInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB,minContainerSize);
    app.setClusterInfo(new ClusterInfo(Resource.newInstance(10240,1)));
    Job job=app.submit(conf);
    app.waitForState(job,JobState.RUNNING);
    Map<TaskId,Task> tasks=job.getTasks();
    Assert.assertEquals("Num tasks is not correct",2,tasks.size());
    Iterator<Task> taskIter=tasks.values().iterator();
    Task mTask=taskIter.next();
    app.waitForState(mTask,TaskState.RUNNING);
    Task rTask=taskIter.next();
    app.waitForState(rTask,TaskState.RUNNING);
    Map<TaskAttemptId,TaskAttempt> mAttempts=mTask.getAttempts();
    Assert.assertEquals("Num attempts is not correct",1,mAttempts.size());
    Map<TaskAttemptId,TaskAttempt> rAttempts=rTask.getAttempts();
    Assert.assertEquals("Num attempts is not correct",1,rAttempts.size());
    TaskAttempt mta=mAttempts.values().iterator().next();
    TaskAttempt rta=rAttempts.values().iterator().next();
    app.waitForState(mta,TaskAttemptState.RUNNING);
    app.waitForState(rta,TaskAttemptState.RUNNING);
    clock.setTime(11);
    app.getContext().getEventHandler().handle(new TaskAttemptEvent(mta.getID(),TaskAttemptEventType.TA_DONE));
    app.getContext().getEventHandler().handle(new TaskAttemptEvent(rta.getID(),TaskAttemptEventType.TA_DONE));
    app.waitForState(job,JobState.SUCCEEDED);
    Assert.assertEquals(mta.getFinishTime(),11);
    Assert.assertEquals(mta.getLaunchTime(),10);
    Assert.assertEquals(rta.getFinishTime(),11);
    Assert.assertEquals(rta.getLaunchTime(),10);
    Counters counters=job.getAllCounters();
    int memoryMb=(int)containerResource.getMemorySize();
    int vcores=containerResource.getVirtualCores();
    Assert.assertEquals((int)Math.ceil((float)memoryMb / minContainerSize),counters.findCounter(JobCounter.SLOTS_MILLIS_MAPS).getValue());
    Assert.assertEquals((int)Math.ceil((float)memoryMb / minContainerSize),counters.findCounter(JobCounter.SLOTS_MILLIS_REDUCES).getValue());
    Assert.assertEquals(1,counters.findCounter(JobCounter.MILLIS_MAPS).getValue());
    Assert.assertEquals(1,counters.findCounter(JobCounter.MILLIS_REDUCES).getValue());
    Assert.assertEquals(memoryMb,counters.findCounter(JobCounter.MB_MILLIS_MAPS).getValue());
    Assert.assertEquals(memoryMb,counters.findCounter(JobCounter.MB_MILLIS_REDUCES).getValue());
    Assert.assertEquals(vcores,counters.findCounter(JobCounter.VCORES_MILLIS_MAPS).getValue());
    Assert.assertEquals(vcores,counters.findCounter(JobCounter.VCORES_MILLIS_REDUCES).getValue());
  }
  private TaskAttemptImpl createMapTaskAttemptImplForTest(  EventHandler eventHandler,  TaskSplitMetaInfo taskSplitMetaInfo){
    Clock clock=SystemClock.getInstance();
    return createMapTaskAttemptImplForTest(eventHandler,taskSplitMetaInfo,clock,new JobConf());
  }
  private TaskAttemptImpl createMapTaskAttemptImplForTest(  EventHandler eventHandler,  TaskSplitMetaInfo taskSplitMetaInfo,  Clock clock,  JobConf jobConf){
    ApplicationId appId=ApplicationId.newInstance(1,1);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    Path jobFile=mock(Path.class);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,taskSplitMetaInfo,jobConf,taListener,null,null,clock,null);
    return taImpl;
  }
  private TaskAttemptImpl createReduceTaskAttemptImplForTest(  EventHandler eventHandler,  Clock clock,  JobConf jobConf){
    ApplicationId appId=ApplicationId.newInstance(1,1);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.REDUCE);
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    Path jobFile=mock(Path.class);
    TaskAttemptImpl taImpl=new ReduceTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,1,jobConf,taListener,null,null,clock,null);
    return taImpl;
  }
  private void testMRAppHistory(  MRApp app) throws Exception {
    Configuration conf=new Configuration();
    Job job=app.submit(conf);
    app.waitForState(job,JobState.FAILED);
    Map<TaskId,Task> tasks=job.getTasks();
    Assert.assertEquals("Num tasks is not correct",1,tasks.size());
    Task task=tasks.values().iterator().next();
    Assert.assertEquals("Task state not correct",TaskState.FAILED,task.getReport().getTaskState());
    Map<TaskAttemptId,TaskAttempt> attempts=tasks.values().iterator().next().getAttempts();
    Assert.assertEquals("Num attempts is not correct",4,attempts.size());
    Iterator<TaskAttempt> it=attempts.values().iterator();
    TaskAttemptReport report=it.next().getReport();
    Assert.assertEquals("Attempt state not correct",TaskAttemptState.FAILED,report.getTaskAttemptState());
    Assert.assertEquals("Diagnostic Information is not Correct","Test Diagnostic Event",report.getDiagnosticInfo());
    report=it.next().getReport();
    Assert.assertEquals("Attempt state not correct",TaskAttemptState.FAILED,report.getTaskAttemptState());
  }
  private void testTaskAttemptAssignedFailHistory(  FailingAttemptsDuringAssignedMRApp app) throws Exception {
    Configuration conf=new Configuration();
    Job job=app.submit(conf);
    app.waitForState(job,JobState.FAILED);
    Map<TaskId,Task> tasks=job.getTasks();
    Assert.assertTrue("No Ta Started JH Event",app.getTaStartJHEvent());
    Assert.assertTrue("No Ta Failed JH Event",app.getTaFailedJHEvent());
  }
  private void testTaskAttemptAssignedKilledHistory(  FailingAttemptsDuringAssignedMRApp app) throws Exception {
    Configuration conf=new Configuration();
    Job job=app.submit(conf);
    app.waitForState(job,JobState.RUNNING);
    Map<TaskId,Task> tasks=job.getTasks();
    Task task=tasks.values().iterator().next();
    app.waitForState(task,TaskState.SCHEDULED);
    Map<TaskAttemptId,TaskAttempt> attempts=task.getAttempts();
    TaskAttempt attempt=attempts.values().iterator().next();
    app.waitForState(attempt,TaskAttemptState.KILLED);
    waitFor(app::getTaStartJHEvent,100,800);
    waitFor(app::getTaKilledJHEvent,100,800);
  }
static class FailingAttemptsMRApp extends MRApp {
    FailingAttemptsMRApp(    int maps,    int reduces){
      super(maps,reduces,true,"FailingAttemptsMRApp",true);
    }
    @Override protected void attemptLaunched(    TaskAttemptId attemptID){
      getContext().getEventHandler().handle(new TaskAttemptDiagnosticsUpdateEvent(attemptID,"Test Diagnostic Event"));
      getContext().getEventHandler().handle(new TaskAttemptFailEvent(attemptID));
    }
    protected EventHandler<JobHistoryEvent> createJobHistoryHandler(    AppContext context){
      return new EventHandler<JobHistoryEvent>(){
        @Override public void handle(        JobHistoryEvent event){
          if (event.getType() == org.apache.hadoop.mapreduce.jobhistory.EventType.MAP_ATTEMPT_FAILED) {
            TaskAttemptUnsuccessfulCompletion datum=(TaskAttemptUnsuccessfulCompletion)event.getHistoryEvent().getDatum();
            Assert.assertEquals("Diagnostic Information is not Correct","Test Diagnostic Event",datum.get(8).toString());
          }
        }
      }
;
    }
  }
static class FailingAttemptsDuringAssignedMRApp extends MRApp {
    FailingAttemptsDuringAssignedMRApp(    int maps,    int reduces,    TaskAttemptEventType event){
      super(maps,reduces,true,"FailingAttemptsMRApp",true);
      sendFailEvent=event;
    }
    TaskAttemptEventType sendFailEvent;
    @Override protected void containerLaunched(    TaskAttemptId attemptID,    int shufflePort){
    }
    @Override protected void attemptLaunched(    TaskAttemptId attemptID){
      getContext().getEventHandler().handle(new TaskAttemptEvent(attemptID,sendFailEvent));
    }
    private boolean receiveTaStartJHEvent=false;
    private boolean receiveTaFailedJHEvent=false;
    private boolean receiveTaKilledJHEvent=false;
    public boolean getTaStartJHEvent(){
      return receiveTaStartJHEvent;
    }
    public boolean getTaFailedJHEvent(){
      return receiveTaFailedJHEvent;
    }
    public boolean getTaKilledJHEvent(){
      return receiveTaKilledJHEvent;
    }
    protected EventHandler<JobHistoryEvent> createJobHistoryHandler(    AppContext context){
      return new EventHandler<JobHistoryEvent>(){
        @Override public void handle(        JobHistoryEvent event){
          if (event.getType() == org.apache.hadoop.mapreduce.jobhistory.EventType.MAP_ATTEMPT_FAILED) {
            receiveTaFailedJHEvent=true;
          }
 else           if (event.getType() == org.apache.hadoop.mapreduce.jobhistory.EventType.MAP_ATTEMPT_KILLED) {
            receiveTaKilledJHEvent=true;
          }
 else           if (event.getType() == org.apache.hadoop.mapreduce.jobhistory.EventType.MAP_ATTEMPT_STARTED) {
            receiveTaStartJHEvent=true;
          }
 else           if (event.getType() == org.apache.hadoop.mapreduce.jobhistory.EventType.REDUCE_ATTEMPT_FAILED) {
            receiveTaFailedJHEvent=true;
          }
 else           if (event.getType() == org.apache.hadoop.mapreduce.jobhistory.EventType.REDUCE_ATTEMPT_KILLED) {
            receiveTaKilledJHEvent=true;
          }
 else           if (event.getType() == org.apache.hadoop.mapreduce.jobhistory.EventType.REDUCE_ATTEMPT_STARTED) {
            receiveTaStartJHEvent=true;
          }
        }
      }
;
    }
  }
  @Test public void testLaunchFailedWhileKilling() throws Exception {
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,new Token(),new Credentials(),SystemClock.getInstance(),null);
    NodeId nid=NodeId.newInstance("127.0.0.1",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,container,mock(Map.class)));
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_KILL));
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_CONTAINER_CLEANED));
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_CONTAINER_LAUNCH_FAILED));
    assertFalse(eventHandler.internalError);
    assertEquals("Task attempt is not assigned on the local node",Locality.NODE_LOCAL,taImpl.getLocality());
  }
  @Test public void testContainerCleanedWhileRunning() throws Exception {
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    Resource resource=mock(Resource.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    when(resource.getMemorySize()).thenReturn(1024L);
    setupTaskAttemptFinishingMonitor(eventHandler,jobConf,appCtx);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,new Token(),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.2",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,container,mock(Map.class)));
    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId,0));
    assertEquals("Task attempt is not in running state",taImpl.getState(),TaskAttemptState.RUNNING);
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_CONTAINER_CLEANED));
    assertFalse("InternalError occurred trying to handle TA_CONTAINER_CLEANED",eventHandler.internalError);
    assertEquals("Task attempt is not assigned on the local rack",Locality.RACK_LOCAL,taImpl.getLocality());
  }
  @Test public void testContainerCleanedWhileCommitting() throws Exception {
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    Resource resource=mock(Resource.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    when(resource.getMemorySize()).thenReturn(1024L);
    setupTaskAttemptFinishingMonitor(eventHandler,jobConf,appCtx);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,new Token(),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.1",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,container,mock(Map.class)));
    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId,0));
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_COMMIT_PENDING));
    assertEquals("Task attempt is not in commit pending state",taImpl.getState(),TaskAttemptState.COMMIT_PENDING);
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_CONTAINER_CLEANED));
    assertFalse("InternalError occurred trying to handle TA_CONTAINER_CLEANED",eventHandler.internalError);
    assertEquals("Task attempt is assigned locally",Locality.OFF_SWITCH,taImpl.getLocality());
  }
  @Test public void testDoubleTooManyFetchFailure() throws Exception {
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    TaskId reduceTaskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.REDUCE);
    TaskAttemptId reduceTAId=MRBuilderUtils.newTaskAttemptId(reduceTaskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    Resource resource=mock(Resource.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    when(resource.getMemorySize()).thenReturn(1024L);
    setupTaskAttemptFinishingMonitor(eventHandler,jobConf,appCtx);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,new Token(),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.1",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,container,mock(Map.class)));
    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId,0));
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_DONE));
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_CONTAINER_COMPLETED));
    assertEquals("Task attempt is not in succeeded state",taImpl.getState(),TaskAttemptState.SUCCEEDED);
    taImpl.handle(new TaskAttemptTooManyFetchFailureEvent(attemptId,reduceTAId,"Host"));
    assertEquals("Task attempt is not in FAILED state",taImpl.getState(),TaskAttemptState.FAILED);
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));
    assertEquals("Task attempt is not in FAILED state, still",taImpl.getState(),TaskAttemptState.FAILED);
    assertFalse("InternalError occurred trying to handle TA_CONTAINER_CLEANED",eventHandler.internalError);
  }
  @Test public void testAppDiagnosticEventOnUnassignedTask(){
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    Resource resource=mock(Resource.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    when(resource.getMemorySize()).thenReturn(1024L);
    setupTaskAttemptFinishingMonitor(eventHandler,jobConf,appCtx);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,new Token(),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.1",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptId,"Task got killed"));
    assertFalse("InternalError occurred trying to handle TA_DIAGNOSTICS_UPDATE on assigned task",eventHandler.internalError);
    try {
      taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_KILL));
      Assert.assertTrue("No exception on UNASSIGNED STATE KILL event",true);
    }
 catch (    Exception e) {
      Assert.assertFalse("Exception not expected for UNASSIGNED STATE KILL event",true);
    }
  }
  @Test public void testTooManyFetchFailureAfterKill() throws Exception {
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    Resource resource=mock(Resource.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    when(resource.getMemorySize()).thenReturn(1024L);
    setupTaskAttemptFinishingMonitor(eventHandler,jobConf,appCtx);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,mock(Token.class),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.1",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,container,mock(Map.class)));
    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId,0));
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_DONE));
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_CONTAINER_COMPLETED));
    assertEquals("Task attempt is not in succeeded state",taImpl.getState(),TaskAttemptState.SUCCEEDED);
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_KILL));
    assertEquals("Task attempt is not in KILLED state",taImpl.getState(),TaskAttemptState.KILLED);
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_TOO_MANY_FETCH_FAILURE));
    assertEquals("Task attempt is not in KILLED state, still",taImpl.getState(),TaskAttemptState.KILLED);
    assertFalse("InternalError occurred trying to handle TA_CONTAINER_CLEANED",eventHandler.internalError);
  }
  @Test public void testAppDiagnosticEventOnNewTask(){
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    Resource resource=mock(Resource.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    when(resource.getMemorySize()).thenReturn(1024L);
    setupTaskAttemptFinishingMonitor(eventHandler,jobConf,appCtx);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,new Token(),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.1",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptDiagnosticsUpdateEvent(attemptId,"Task got killed"));
    assertFalse("InternalError occurred trying to handle TA_DIAGNOSTICS_UPDATE on assigned task",eventHandler.internalError);
  }
  @Test public void testFetchFailureAttemptFinishTime() throws Exception {
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    TaskId reducetaskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.REDUCE);
    TaskAttemptId reduceTAId=MRBuilderUtils.newTaskAttemptId(reducetaskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    setupTaskAttemptFinishingMonitor(eventHandler,jobConf,appCtx);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,mock(Token.class),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.1",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,container,mock(Map.class)));
    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId,0));
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_DONE));
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_CONTAINER_COMPLETED));
    assertEquals("Task attempt is not in succeeded state",taImpl.getState(),TaskAttemptState.SUCCEEDED);
    assertTrue("Task Attempt finish time is not greater than 0",taImpl.getFinishTime() > 0);
    Long finishTime=taImpl.getFinishTime();
    Thread.sleep(5);
    taImpl.handle(new TaskAttemptTooManyFetchFailureEvent(attemptId,reduceTAId,"Host"));
    assertEquals("Task attempt is not in Too Many Fetch Failure state",taImpl.getState(),TaskAttemptState.FAILED);
    assertEquals("After TA_TOO_MANY_FETCH_FAILURE," + " Task attempt finish time is not the same ",finishTime,Long.valueOf(taImpl.getFinishTime()));
  }
  private void containerKillBeforeAssignment(  boolean scheduleAttempt) throws Exception {
    MockEventHandler eventHandler=new MockEventHandler();
    ApplicationId appId=ApplicationId.newInstance(1,2);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,mock(Path.class),1,mock(TaskSplitMetaInfo.class),new JobConf(),mock(TaskAttemptListener.class),mock(Token.class),new Credentials(),SystemClock.getInstance(),mock(AppContext.class));
    if (scheduleAttempt) {
      taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_SCHEDULE));
    }
    taImpl.handle(new TaskAttemptKillEvent(taImpl.getID(),"",true));
    assertEquals("Task attempt is not in KILLED state",taImpl.getState(),TaskAttemptState.KILLED);
    assertEquals("Task attempt's internal state is not KILLED",taImpl.getInternalState(),TaskAttemptStateInternal.KILLED);
    assertFalse("InternalError occurred",eventHandler.internalError);
    TaskEvent event=eventHandler.lastTaskEvent;
    assertEquals(TaskEventType.T_ATTEMPT_KILLED,event.getType());
    assertFalse(((TaskTAttemptKilledEvent)event).getRescheduleAttempt());
  }
  @Test public void testContainerKillOnNew() throws Exception {
    containerKillBeforeAssignment(false);
  }
  @Test public void testContainerKillOnUnassigned() throws Exception {
    containerKillBeforeAssignment(true);
  }
  @Test public void testContainerKillAfterAssigned() throws Exception {
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    Resource resource=mock(Resource.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    when(resource.getMemorySize()).thenReturn(1024L);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,new Token(),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.2",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,container,mock(Map.class)));
    assertEquals("Task attempt is not in assinged state",taImpl.getInternalState(),TaskAttemptStateInternal.ASSIGNED);
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_KILL));
    assertEquals("Task should be in KILL_CONTAINER_CLEANUP state",TaskAttemptStateInternal.KILL_CONTAINER_CLEANUP,taImpl.getInternalState());
  }
  @Test public void testContainerKillWhileRunning() throws Exception {
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    Resource resource=mock(Resource.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    when(resource.getMemorySize()).thenReturn(1024L);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,new Token(),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.2",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,container,mock(Map.class)));
    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId,0));
    assertEquals("Task attempt is not in running state",taImpl.getState(),TaskAttemptState.RUNNING);
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_KILL));
    assertFalse("InternalError occurred trying to handle TA_KILL",eventHandler.internalError);
    assertEquals("Task should be in KILL_CONTAINER_CLEANUP state",TaskAttemptStateInternal.KILL_CONTAINER_CLEANUP,taImpl.getInternalState());
  }
  @Test public void testContainerKillWhileCommitPending() throws Exception {
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    Path jobFile=mock(Path.class);
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    Resource resource=mock(Resource.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    when(resource.getMemorySize()).thenReturn(1024L);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,new Token(),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.2",0);
    ContainerId contId=ContainerId.newContainerId(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,container,mock(Map.class)));
    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId,0));
    assertEquals("Task attempt is not in running state",taImpl.getState(),TaskAttemptState.RUNNING);
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_COMMIT_PENDING));
    assertEquals("Task should be in COMMIT_PENDING state",TaskAttemptStateInternal.COMMIT_PENDING,taImpl.getInternalState());
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_KILL));
    assertFalse("InternalError occurred trying to handle TA_KILL",eventHandler.internalError);
    assertEquals("Task should be in KILL_CONTAINER_CLEANUP state",TaskAttemptStateInternal.KILL_CONTAINER_CLEANUP,taImpl.getInternalState());
  }
  @Test public void testKillMapTaskWhileSuccessFinishing() throws Exception {
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptImpl taImpl=createTaskAttemptImpl(eventHandler);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_DONE));
    assertEquals("Task attempt is not in SUCCEEDED state",taImpl.getState(),TaskAttemptState.SUCCEEDED);
    assertEquals("Task attempt's internal state is not " + "SUCCESS_FINISHING_CONTAINER",taImpl.getInternalState(),TaskAttemptStateInternal.SUCCESS_FINISHING_CONTAINER);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_KILL));
    assertEquals("Task attempt is not in KILLED state",taImpl.getState(),TaskAttemptState.KILLED);
    assertEquals("Task attempt's internal state is not KILL_CONTAINER_CLEANUP",taImpl.getInternalState(),TaskAttemptStateInternal.KILL_CONTAINER_CLEANUP);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_CONTAINER_CLEANED));
    assertEquals("Task attempt's internal state is not KILL_TASK_CLEANUP",taImpl.getInternalState(),TaskAttemptStateInternal.KILL_TASK_CLEANUP);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_CLEANUP_DONE));
    assertEquals("Task attempt is not in KILLED state",taImpl.getState(),TaskAttemptState.KILLED);
    assertFalse("InternalError occurred",eventHandler.internalError);
  }
  @Test public void testKillMapTaskAfterSuccess() throws Exception {
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptImpl taImpl=createTaskAttemptImpl(eventHandler);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_DONE));
    assertEquals("Task attempt is not in SUCCEEDED state",taImpl.getState(),TaskAttemptState.SUCCEEDED);
    assertEquals("Task attempt's internal state is not " + "SUCCESS_FINISHING_CONTAINER",taImpl.getInternalState(),TaskAttemptStateInternal.SUCCESS_FINISHING_CONTAINER);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_CONTAINER_CLEANED));
    taImpl.handle(new TaskAttemptKillEvent(taImpl.getID(),"",true));
    assertEquals("Task attempt is not in KILLED state",taImpl.getState(),TaskAttemptState.KILLED);
    assertEquals("Task attempt's internal state is not KILLED",taImpl.getInternalState(),TaskAttemptStateInternal.KILLED);
    assertFalse("InternalError occurred",eventHandler.internalError);
    TaskEvent event=eventHandler.lastTaskEvent;
    assertEquals(TaskEventType.T_ATTEMPT_KILLED,event.getType());
    assertTrue(((TaskTAttemptKilledEvent)event).getRescheduleAttempt());
  }
  @Test public void testKillMapTaskWhileFailFinishing() throws Exception {
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptImpl taImpl=createTaskAttemptImpl(eventHandler);
    taImpl.handle(new TaskAttemptFailEvent(taImpl.getID()));
    assertEquals("Task attempt is not in FAILED state",taImpl.getState(),TaskAttemptState.FAILED);
    assertEquals("Task attempt's internal state is not " + "FAIL_FINISHING_CONTAINER",taImpl.getInternalState(),TaskAttemptStateInternal.FAIL_FINISHING_CONTAINER);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_KILL));
    assertEquals("Task attempt is not in RUNNING state",taImpl.getState(),TaskAttemptState.FAILED);
    assertEquals("Task attempt's internal state is not " + "FAIL_FINISHING_CONTAINER",taImpl.getInternalState(),TaskAttemptStateInternal.FAIL_FINISHING_CONTAINER);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_TIMED_OUT));
    assertEquals("Task attempt's internal state is not FAIL_CONTAINER_CLEANUP",taImpl.getInternalState(),TaskAttemptStateInternal.FAIL_CONTAINER_CLEANUP);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_CONTAINER_CLEANED));
    assertEquals("Task attempt's internal state is not FAIL_TASK_CLEANUP",taImpl.getInternalState(),TaskAttemptStateInternal.FAIL_TASK_CLEANUP);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_CLEANUP_DONE));
    assertEquals("Task attempt is not in KILLED state",taImpl.getState(),TaskAttemptState.FAILED);
    assertFalse("InternalError occurred",eventHandler.internalError);
  }
  @Test public void testFailMapTaskByClient() throws Exception {
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptImpl taImpl=createTaskAttemptImpl(eventHandler);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_FAILMSG_BY_CLIENT));
    assertEquals("Task attempt is not in RUNNING state",taImpl.getState(),TaskAttemptState.FAILED);
    assertEquals("Task attempt's internal state is not " + "FAIL_CONTAINER_CLEANUP",taImpl.getInternalState(),TaskAttemptStateInternal.FAIL_CONTAINER_CLEANUP);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_CONTAINER_CLEANED));
    assertEquals("Task attempt's internal state is not FAIL_TASK_CLEANUP",taImpl.getInternalState(),TaskAttemptStateInternal.FAIL_TASK_CLEANUP);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_CLEANUP_DONE));
    assertEquals("Task attempt is not in KILLED state",taImpl.getState(),TaskAttemptState.FAILED);
    assertFalse("InternalError occurred",eventHandler.internalError);
  }
  @Test public void testTaskAttemptDiagnosticEventOnFinishing() throws Exception {
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptImpl taImpl=createTaskAttemptImpl(eventHandler);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_DONE));
    assertEquals("Task attempt is not in RUNNING state",taImpl.getState(),TaskAttemptState.SUCCEEDED);
    assertEquals("Task attempt's internal state is not " + "SUCCESS_FINISHING_CONTAINER",taImpl.getInternalState(),TaskAttemptStateInternal.SUCCESS_FINISHING_CONTAINER);
    taImpl.handle(new TaskAttemptDiagnosticsUpdateEvent(taImpl.getID(),"Task got updated"));
    assertEquals("Task attempt is not in RUNNING state",taImpl.getState(),TaskAttemptState.SUCCEEDED);
    assertEquals("Task attempt's internal state is not " + "SUCCESS_FINISHING_CONTAINER",taImpl.getInternalState(),TaskAttemptStateInternal.SUCCESS_FINISHING_CONTAINER);
    assertFalse("InternalError occurred",eventHandler.internalError);
  }
  @Test public void testTimeoutWhileSuccessFinishing() throws Exception {
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptImpl taImpl=createTaskAttemptImpl(eventHandler);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_DONE));
    assertEquals("Task attempt is not in RUNNING state",taImpl.getState(),TaskAttemptState.SUCCEEDED);
    assertEquals("Task attempt's internal state is not " + "SUCCESS_FINISHING_CONTAINER",taImpl.getInternalState(),TaskAttemptStateInternal.SUCCESS_FINISHING_CONTAINER);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_TIMED_OUT));
    assertEquals("Task attempt is not in RUNNING state",taImpl.getState(),TaskAttemptState.SUCCEEDED);
    assertEquals("Task attempt's internal state is not " + "SUCCESS_CONTAINER_CLEANUP",taImpl.getInternalState(),TaskAttemptStateInternal.SUCCESS_CONTAINER_CLEANUP);
    assertFalse("InternalError occurred",eventHandler.internalError);
  }
  @Test public void testTimeoutWhileFailFinishing() throws Exception {
    MockEventHandler eventHandler=new MockEventHandler();
    TaskAttemptImpl taImpl=createTaskAttemptImpl(eventHandler);
    taImpl.handle(new TaskAttemptFailEvent(taImpl.getID()));
    assertEquals("Task attempt is not in RUNNING state",taImpl.getState(),TaskAttemptState.FAILED);
    assertEquals("Task attempt's internal state is not " + "FAIL_FINISHING_CONTAINER",taImpl.getInternalState(),TaskAttemptStateInternal.FAIL_FINISHING_CONTAINER);
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_TIMED_OUT));
    assertEquals("Task attempt's internal state is not FAIL_CONTAINER_CLEANUP",taImpl.getInternalState(),TaskAttemptStateInternal.FAIL_CONTAINER_CLEANUP);
    assertFalse("InternalError occurred",eventHandler.internalError);
  }
  @Test public void testMapperCustomResourceTypes(){
    initResourceTypes();
    EventHandler eventHandler=mock(EventHandler.class);
    TaskSplitMetaInfo taskSplitMetaInfo=new TaskSplitMetaInfo();
    Clock clock=SystemClock.getInstance();
    JobConf jobConf=new JobConf();
    jobConf.setLong(MRJobConfig.MAP_RESOURCE_TYPE_PREFIX + CUSTOM_RESOURCE_NAME,7L);
    TaskAttemptImpl taImpl=createMapTaskAttemptImplForTest(eventHandler,taskSplitMetaInfo,clock,jobConf);
    ResourceInformation resourceInfo=getResourceInfoFromContainerRequest(taImpl,eventHandler).getResourceInformation(CUSTOM_RESOURCE_NAME);
    assertEquals("Expecting the default unit (G)","G",resourceInfo.getUnits());
    assertEquals(7L,resourceInfo.getValue());
  }
  @Test public void testReducerCustomResourceTypes(){
    initResourceTypes();
    EventHandler eventHandler=mock(EventHandler.class);
    Clock clock=SystemClock.getInstance();
    JobConf jobConf=new JobConf();
    jobConf.set(MRJobConfig.REDUCE_RESOURCE_TYPE_PREFIX + CUSTOM_RESOURCE_NAME,"3m");
    TaskAttemptImpl taImpl=createReduceTaskAttemptImplForTest(eventHandler,clock,jobConf);
    ResourceInformation resourceInfo=getResourceInfoFromContainerRequest(taImpl,eventHandler).getResourceInformation(CUSTOM_RESOURCE_NAME);
    assertEquals("Expecting the specified unit (m)","m",resourceInfo.getUnits());
    assertEquals(3L,resourceInfo.getValue());
  }
  @Test public void testReducerMemoryRequestViaMapreduceReduceMemoryMb(){
    EventHandler eventHandler=mock(EventHandler.class);
    Clock clock=SystemClock.getInstance();
    JobConf jobConf=new JobConf();
    jobConf.setInt(MRJobConfig.REDUCE_MEMORY_MB,2048);
    TaskAttemptImpl taImpl=createReduceTaskAttemptImplForTest(eventHandler,clock,jobConf);
    long memorySize=getResourceInfoFromContainerRequest(taImpl,eventHandler).getMemorySize();
    assertEquals(2048,memorySize);
  }
  @Test public void testReducerMemoryRequestViaMapreduceReduceResourceMemory(){
    EventHandler eventHandler=mock(EventHandler.class);
    Clock clock=SystemClock.getInstance();
    JobConf jobConf=new JobConf();
    jobConf.set(MRJobConfig.REDUCE_RESOURCE_TYPE_PREFIX + MRJobConfig.RESOURCE_TYPE_NAME_MEMORY,"2 Gi");
    TaskAttemptImpl taImpl=createReduceTaskAttemptImplForTest(eventHandler,clock,jobConf);
    long memorySize=getResourceInfoFromContainerRequest(taImpl,eventHandler).getMemorySize();
    assertEquals(2048,memorySize);
  }
  @Test public void testReducerMemoryRequestDefaultMemory(){
    EventHandler eventHandler=mock(EventHandler.class);
    Clock clock=SystemClock.getInstance();
    TaskAttemptImpl taImpl=createReduceTaskAttemptImplForTest(eventHandler,clock,new JobConf());
    long memorySize=getResourceInfoFromContainerRequest(taImpl,eventHandler).getMemorySize();
    assertEquals(MRJobConfig.DEFAULT_REDUCE_MEMORY_MB,memorySize);
  }
  @Test public void testReducerMemoryRequestWithoutUnits(){
    Clock clock=SystemClock.getInstance();
    for (    String memoryResourceName : ImmutableList.of(MRJobConfig.RESOURCE_TYPE_NAME_MEMORY,MRJobConfig.RESOURCE_TYPE_ALTERNATIVE_NAME_MEMORY)) {
      EventHandler eventHandler=mock(EventHandler.class);
      JobConf jobConf=new JobConf();
      jobConf.setInt(MRJobConfig.REDUCE_RESOURCE_TYPE_PREFIX + memoryResourceName,2048);
      TaskAttemptImpl taImpl=createReduceTaskAttemptImplForTest(eventHandler,clock,jobConf);
      long memorySize=getResourceInfoFromContainerRequest(taImpl,eventHandler).getMemorySize();
      assertEquals(2048,memorySize);
    }
  }
  @Test public void testReducerMemoryRequestOverriding(){
    for (    String memoryName : ImmutableList.of(MRJobConfig.RESOURCE_TYPE_NAME_MEMORY,MRJobConfig.RESOURCE_TYPE_ALTERNATIVE_NAME_MEMORY)) {
      TestAppender testAppender=new TestAppender();
      final Logger logger=Logger.getLogger(TaskAttemptImpl.class);
      try {
        logger.addAppender(testAppender);
        EventHandler eventHandler=mock(EventHandler.class);
        Clock clock=SystemClock.getInstance();
        JobConf jobConf=new JobConf();
        jobConf.set(MRJobConfig.REDUCE_RESOURCE_TYPE_PREFIX + memoryName,"3Gi");
        jobConf.setInt(MRJobConfig.REDUCE_MEMORY_MB,2048);
        TaskAttemptImpl taImpl=createReduceTaskAttemptImplForTest(eventHandler,clock,jobConf);
        long memorySize=getResourceInfoFromContainerRequest(taImpl,eventHandler).getMemorySize();
        assertEquals(3072,memorySize);
        assertTrue(testAppender.getLogEvents().stream().anyMatch(e -> e.getLevel() == Level.WARN && ("Configuration " + "mapreduce.reduce.resource." + memoryName + "=3Gi is "+ "overriding the mapreduce.reduce.memory.mb=2048 configuration").equals(e.getMessage())));
      }
  finally {
        logger.removeAppender(testAppender);
      }
    }
  }
  @Test(expected=IllegalArgumentException.class) public void testReducerMemoryRequestMultipleName(){
    EventHandler eventHandler=mock(EventHandler.class);
    Clock clock=SystemClock.getInstance();
    JobConf jobConf=new JobConf();
    for (    String memoryName : ImmutableList.of(MRJobConfig.RESOURCE_TYPE_NAME_MEMORY,MRJobConfig.RESOURCE_TYPE_ALTERNATIVE_NAME_MEMORY)) {
      jobConf.set(MRJobConfig.REDUCE_RESOURCE_TYPE_PREFIX + memoryName,"3Gi");
    }
    createReduceTaskAttemptImplForTest(eventHandler,clock,jobConf);
  }
  @Test public void testReducerCpuRequestViaMapreduceReduceCpuVcores(){
    EventHandler eventHandler=mock(EventHandler.class);
    Clock clock=SystemClock.getInstance();
    JobConf jobConf=new JobConf();
    jobConf.setInt(MRJobConfig.REDUCE_CPU_VCORES,3);
    TaskAttemptImpl taImpl=createReduceTaskAttemptImplForTest(eventHandler,clock,jobConf);
    int vCores=getResourceInfoFromContainerRequest(taImpl,eventHandler).getVirtualCores();
    assertEquals(3,vCores);
  }
  @Test public void testReducerCpuRequestViaMapreduceReduceResourceVcores(){
    EventHandler eventHandler=mock(EventHandler.class);
    Clock clock=SystemClock.getInstance();
    JobConf jobConf=new JobConf();
    jobConf.set(MRJobConfig.REDUCE_RESOURCE_TYPE_PREFIX + MRJobConfig.RESOURCE_TYPE_NAME_VCORE,"5");
    TaskAttemptImpl taImpl=createReduceTaskAttemptImplForTest(eventHandler,clock,jobConf);
    int vCores=getResourceInfoFromContainerRequest(taImpl,eventHandler).getVirtualCores();
    assertEquals(5,vCores);
  }
  @Test public void testReducerCpuRequestDefaultMemory(){
    EventHandler eventHandler=mock(EventHandler.class);
    Clock clock=SystemClock.getInstance();
    TaskAttemptImpl taImpl=createReduceTaskAttemptImplForTest(eventHandler,clock,new JobConf());
    int vCores=getResourceInfoFromContainerRequest(taImpl,eventHandler).getVirtualCores();
    assertEquals(MRJobConfig.DEFAULT_REDUCE_CPU_VCORES,vCores);
  }
  @Test public void testReducerCpuRequestOverriding(){
    TestAppender testAppender=new TestAppender();
    final Logger logger=Logger.getLogger(TaskAttemptImpl.class);
    try {
      logger.addAppender(testAppender);
      EventHandler eventHandler=mock(EventHandler.class);
      Clock clock=SystemClock.getInstance();
      JobConf jobConf=new JobConf();
      jobConf.set(MRJobConfig.REDUCE_RESOURCE_TYPE_PREFIX + MRJobConfig.RESOURCE_TYPE_NAME_VCORE,"7");
      jobConf.setInt(MRJobConfig.REDUCE_CPU_VCORES,9);
      TaskAttemptImpl taImpl=createReduceTaskAttemptImplForTest(eventHandler,clock,jobConf);
      long vCores=getResourceInfoFromContainerRequest(taImpl,eventHandler).getVirtualCores();
      assertEquals(7,vCores);
      assertTrue(testAppender.getLogEvents().stream().anyMatch(e -> e.getLevel() == Level.WARN && ("Configuration " + "mapreduce.reduce.resource.vcores=7 is overriding the " + "mapreduce.reduce.cpu.vcores=9 configuration").equals(e.getMessage())));
    }
  finally {
      logger.removeAppender(testAppender);
    }
  }
  private Resource getResourceInfoFromContainerRequest(  TaskAttemptImpl taImpl,  EventHandler eventHandler){
    taImpl.handle(new TaskAttemptEvent(taImpl.getID(),TaskAttemptEventType.TA_SCHEDULE));
    assertEquals("Task attempt is not in STARTING state",taImpl.getState(),TaskAttemptState.STARTING);
    ArgumentCaptor<Event> captor=ArgumentCaptor.forClass(Event.class);
    verify(eventHandler,times(2)).handle(captor.capture());
    List<ContainerRequestEvent> containerRequestEvents=new ArrayList<>();
    for (    Event e : captor.getAllValues()) {
      if (e instanceof ContainerRequestEvent) {
        containerRequestEvents.add((ContainerRequestEvent)e);
      }
    }
    assertEquals("Expected one ContainerRequestEvent after scheduling " + "task attempt",1,containerRequestEvents.size());
    return containerRequestEvents.get(0).getCapability();
  }
  @Test(expected=IllegalArgumentException.class) public void testReducerCustomResourceTypeWithInvalidUnit(){
    initResourceTypes();
    EventHandler eventHandler=mock(EventHandler.class);
    Clock clock=SystemClock.getInstance();
    JobConf jobConf=new JobConf();
    jobConf.set(MRJobConfig.REDUCE_RESOURCE_TYPE_PREFIX + CUSTOM_RESOURCE_NAME,"3z");
    createReduceTaskAttemptImplForTest(eventHandler,clock,jobConf);
  }
  private void initResourceTypes(){
    Configuration conf=new Configuration();
    conf.set(YarnConfiguration.RM_CONFIGURATION_PROVIDER_CLASS,CustomResourceTypesConfigurationProvider.class.getName());
    ResourceUtils.resetResourceTypes(conf);
  }
  private void setupTaskAttemptFinishingMonitor(  EventHandler eventHandler,  JobConf jobConf,  AppContext appCtx){
    TaskAttemptFinishingMonitor taskAttemptFinishingMonitor=new TaskAttemptFinishingMonitor(eventHandler);
    taskAttemptFinishingMonitor.init(jobConf);
    when(appCtx.getTaskAttemptFinishingMonitor()).thenReturn(taskAttemptFinishingMonitor);
  }
  private TaskAttemptImpl createTaskAttemptImpl(  MockEventHandler eventHandler){
    ApplicationId appId=ApplicationId.newInstance(1,2);
    ApplicationAttemptId appAttemptId=ApplicationAttemptId.newInstance(appId,0);
    JobId jobId=MRBuilderUtils.newJobId(appId,1);
    TaskId taskId=MRBuilderUtils.newTaskId(jobId,1,TaskType.MAP);
    TaskAttemptId attemptId=MRBuilderUtils.newTaskAttemptId(taskId,0);
    Path jobFile=mock(Path.class);
    TaskAttemptListener taListener=mock(TaskAttemptListener.class);
    when(taListener.getAddress()).thenReturn(new InetSocketAddress("localhost",0));
    JobConf jobConf=new JobConf();
    jobConf.setClass("fs.file.impl",StubbedFS.class,FileSystem.class);
    jobConf.setBoolean("fs.file.impl.disable.cache",true);
    jobConf.set(JobConf.MAPRED_MAP_TASK_ENV,"");
    jobConf.set(MRJobConfig.APPLICATION_ATTEMPT_ID,"10");
    TaskSplitMetaInfo splits=mock(TaskSplitMetaInfo.class);
    when(splits.getLocations()).thenReturn(new String[]{"127.0.0.1"});
    AppContext appCtx=mock(AppContext.class);
    ClusterInfo clusterInfo=mock(ClusterInfo.class);
    when(appCtx.getClusterInfo()).thenReturn(clusterInfo);
    setupTaskAttemptFinishingMonitor(eventHandler,jobConf,appCtx);
    TaskAttemptImpl taImpl=new MapTaskAttemptImpl(taskId,1,eventHandler,jobFile,1,splits,jobConf,taListener,mock(Token.class),new Credentials(),SystemClock.getInstance(),appCtx);
    NodeId nid=NodeId.newInstance("127.0.0.1",0);
    ContainerId contId=ContainerId.newInstance(appAttemptId,3);
    Container container=mock(Container.class);
    when(container.getId()).thenReturn(contId);
    when(container.getNodeId()).thenReturn(nid);
    when(container.getNodeHttpAddress()).thenReturn("localhost:0");
    taImpl.handle(new TaskAttemptEvent(attemptId,TaskAttemptEventType.TA_SCHEDULE));
    taImpl.handle(new TaskAttemptContainerAssignedEvent(attemptId,container,mock(Map.class)));
    taImpl.handle(new TaskAttemptContainerLaunchedEvent(attemptId,0));
    return taImpl;
  }
public static class MockEventHandler implements EventHandler {
    public boolean internalError;
    public TaskEvent lastTaskEvent;
    @Override public void handle(    Event event){
      if (event instanceof TaskEvent) {
        lastTaskEvent=(TaskEvent)event;
      }
      if (event instanceof JobEvent) {
        JobEvent je=((JobEvent)event);
        if (JobEventType.INTERNAL_ERROR == je.getType()) {
          internalError=true;
        }
      }
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapreduce.v2.app.job.impl;
import java.util.ArrayList;
import java.util.Map;
import org.apache.hadoop.mapreduce.TaskType;
import org.junit.Assert;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapreduce.MRConfig;
import org.apache.hadoop.mapreduce.MRJobConfig;
import org.apache.hadoop.mapreduce.v2.api.records.JobState;
import org.apache.hadoop.mapreduce.v2.app.AppContext;
import org.apache.hadoop.mapreduce.v2.app.MRApp;
import org.apache.hadoop.mapreduce.v2.app.job.Job;
import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncher;
import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherEvent;
import org.apache.hadoop.mapreduce.v2.app.launcher.ContainerRemoteLaunchEvent;
import org.apache.hadoop.mapreduce.v2.util.MRApps;
import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
import org.junit.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
public class TestMapReduceChildJVM {
  private static final Logger LOG=LoggerFactory.getLogger(TestMapReduceChildJVM.class);
  @Test(timeout=30000) public void testCommandLine() throws Exception {
    MyMRApp app=new MyMRApp(1,0,true,this.getClass().getName(),true);
    Configuration conf=new Configuration();
    conf.setBoolean(MRConfig.MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM,true);
    Job job=app.submit(conf);
    app.waitForState(job,JobState.SUCCEEDED);
    app.verifyCompleted();
    Assert.assertEquals("[" + MRApps.crossPlatformify("JAVA_HOME") + "/bin/java"+ " -Djava.net.preferIPv4Stack=true"+ " -Dhadoop.metrics.log.level=WARN "+ "  -Xmx820m -Djava.io.tmpdir="+ MRApps.crossPlatformify("PWD")+ "/tmp"+ " -Dlog4j.configuration=container-log4j.properties"+ " -Dyarn.app.container.log.dir=<LOG_DIR>"+ " -Dyarn.app.container.log.filesize=0"+ " -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog"+ " org.apache.hadoop.mapred.YarnChild 127.0.0.1"+ " 54321"+ " attempt_0_0000_m_000000_0"+ " 0"+ " 1><LOG_DIR>/stdout"+ " 2><LOG_DIR>/stderr ]",app.launchCmdList.get(0));
    Assert.assertTrue("HADOOP_ROOT_LOGGER not set for job",app.cmdEnvironment.containsKey("HADOOP_ROOT_LOGGER"));
    Assert.assertEquals("INFO,console",app.cmdEnvironment.get("HADOOP_ROOT_LOGGER"));
    Assert.assertTrue("HADOOP_CLIENT_OPTS not set for job",app.cmdEnvironment.containsKey("HADOOP_CLIENT_OPTS"));
    Assert.assertEquals("",app.cmdEnvironment.get("HADOOP_CLIENT_OPTS"));
  }
  @Test(timeout=30000) public void testReduceCommandLineWithSeparateShuffle() throws Exception {
    final Configuration conf=new Configuration();
    conf.setBoolean(MRJobConfig.REDUCE_SEPARATE_SHUFFLE_LOG,true);
    testReduceCommandLine(conf);
  }
  @Test(timeout=30000) public void testReduceCommandLineWithSeparateCRLAShuffle() throws Exception {
    final Configuration conf=new Configuration();
    conf.setBoolean(MRJobConfig.REDUCE_SEPARATE_SHUFFLE_LOG,true);
    conf.setLong(MRJobConfig.SHUFFLE_LOG_KB,1L);
    conf.setInt(MRJobConfig.SHUFFLE_LOG_BACKUPS,3);
    testReduceCommandLine(conf);
  }
  @Test(timeout=30000) public void testReduceCommandLine() throws Exception {
    final Configuration conf=new Configuration();
    testReduceCommandLine(conf);
  }
  private void testReduceCommandLine(  Configuration conf) throws Exception {
    MyMRApp app=new MyMRApp(0,1,true,this.getClass().getName(),true);
    conf.setBoolean(MRConfig.MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM,true);
    Job job=app.submit(conf);
    app.waitForState(job,JobState.SUCCEEDED);
    app.verifyCompleted();
    final long shuffleLogSize=conf.getLong(MRJobConfig.SHUFFLE_LOG_KB,0L) * 1024L;
    final int shuffleBackups=conf.getInt(MRJobConfig.SHUFFLE_LOG_BACKUPS,0);
    final String appenderName=shuffleLogSize > 0L && shuffleBackups > 0 ? "shuffleCRLA" : "shuffleCLA";
    Assert.assertEquals("[" + MRApps.crossPlatformify("JAVA_HOME") + "/bin/java"+ " -Djava.net.preferIPv4Stack=true"+ " -Dhadoop.metrics.log.level=WARN "+ "  -Xmx820m -Djava.io.tmpdir="+ MRApps.crossPlatformify("PWD")+ "/tmp"+ " -Dlog4j.configuration=container-log4j.properties"+ " -Dyarn.app.container.log.dir=<LOG_DIR>"+ " -Dyarn.app.container.log.filesize=0"+ " -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog"+ " -Dyarn.app.mapreduce.shuffle.logger=INFO,"+ appenderName+ " -Dyarn.app.mapreduce.shuffle.logfile=syslog.shuffle"+ " -Dyarn.app.mapreduce.shuffle.log.filesize="+ shuffleLogSize+ " -Dyarn.app.mapreduce.shuffle.log.backups="+ shuffleBackups+ " org.apache.hadoop.mapred.YarnChild 127.0.0.1"+ " 54321"+ " attempt_0_0000_r_000000_0"+ " 0"+ " 1><LOG_DIR>/stdout"+ " 2><LOG_DIR>/stderr ]",app.launchCmdList.get(0));
    Assert.assertTrue("HADOOP_ROOT_LOGGER not set for job",app.cmdEnvironment.containsKey("HADOOP_ROOT_LOGGER"));
    Assert.assertEquals("INFO,console",app.cmdEnvironment.get("HADOOP_ROOT_LOGGER"));
    Assert.assertTrue("HADOOP_CLIENT_OPTS not set for job",app.cmdEnvironment.containsKey("HADOOP_CLIENT_OPTS"));
    Assert.assertEquals("",app.cmdEnvironment.get("HADOOP_CLIENT_OPTS"));
  }
  @Test(timeout=30000) public void testCommandLineWithLog4JConifg() throws Exception {
    MyMRApp app=new MyMRApp(1,0,true,this.getClass().getName(),true);
    Configuration conf=new Configuration();
    conf.setBoolean(MRConfig.MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM,true);
    String testLogPropertieFile="test-log4j.properties";
    String testLogPropertiePath="../" + "test-log4j.properties";
    conf.set(MRJobConfig.MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE,testLogPropertiePath);
    Job job=app.submit(conf);
    app.waitForState(job,JobState.SUCCEEDED);
    app.verifyCompleted();
    Assert.assertEquals("[" + MRApps.crossPlatformify("JAVA_HOME") + "/bin/java"+ " -Djava.net.preferIPv4Stack=true"+ " -Dhadoop.metrics.log.level=WARN "+ "  -Xmx820m -Djava.io.tmpdir="+ MRApps.crossPlatformify("PWD")+ "/tmp"+ " -Dlog4j.configuration="+ testLogPropertieFile+ " -Dyarn.app.container.log.dir=<LOG_DIR>"+ " -Dyarn.app.container.log.filesize=0"+ " -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog"+ " org.apache.hadoop.mapred.YarnChild 127.0.0.1"+ " 54321"+ " attempt_0_0000_m_000000_0"+ " 0"+ " 1><LOG_DIR>/stdout"+ " 2><LOG_DIR>/stderr ]",app.launchCmdList.get(0));
  }
  @Test public void testAutoHeapSizes() throws Exception {
    testAutoHeapSize(-1,-1,null);
    testAutoHeapSize(512,768,null);
    testAutoHeapSize(100,768,null);
    testAutoHeapSize(512,100,null);
    testAutoHeapSize(512,768,"-Xmx100m");
    testAutoHeapSize(512,768,"-Xmx500m");
    testAutoHeapSize(-1,-1,"-Xmx100m");
    testAutoHeapSize(-1,-1,"-Xmx500m");
  }
  private void testAutoHeapSize(  int mapMb,  int redMb,  String xmxArg) throws Exception {
    JobConf conf=new JobConf();
    float heapRatio=conf.getFloat(MRJobConfig.HEAP_MEMORY_MB_RATIO,MRJobConfig.DEFAULT_HEAP_MEMORY_MB_RATIO);
    Assert.assertNull("Default map java opts!",conf.get(MRJobConfig.MAP_JAVA_OPTS));
    Assert.assertNull("Default reduce java opts!",conf.get(MRJobConfig.REDUCE_JAVA_OPTS));
    if (mapMb > 0) {
      conf.setInt(MRJobConfig.MAP_MEMORY_MB,mapMb);
    }
 else {
      mapMb=conf.getMemoryRequired(TaskType.MAP);
    }
    if (redMb > 0) {
      conf.setInt(MRJobConfig.REDUCE_MEMORY_MB,redMb);
    }
 else {
      redMb=conf.getMemoryRequired(TaskType.REDUCE);
    }
    if (xmxArg != null) {
      conf.set(MRJobConfig.MAP_JAVA_OPTS,xmxArg);
      conf.set(MRJobConfig.REDUCE_JAVA_OPTS,xmxArg);
    }
    MyMRApp app=new MyMRApp(1,1,true,this.getClass().getName(),true);
    Job job=app.submit(conf);
    app.waitForState(job,JobState.SUCCEEDED);
    app.verifyCompleted();
    for (    String cmd : app.launchCmdList) {
      final boolean isMap=cmd.contains("_m_");
      int heapMb;
      if (xmxArg == null) {
        heapMb=(int)(Math.ceil((isMap ? mapMb : redMb) * heapRatio));
      }
 else {
        final String javaOpts=conf.get(isMap ? MRJobConfig.MAP_JAVA_OPTS : MRJobConfig.REDUCE_JAVA_OPTS);
        heapMb=JobConf.parseMaximumHeapSizeMB(javaOpts);
      }
      Assert.assertEquals("Incorrect heapsize in the command opts",heapMb,JobConf.parseMaximumHeapSizeMB(cmd));
    }
  }
private static final class MyMRApp extends MRApp {
    private ArrayList<String> launchCmdList=new ArrayList<>();
    private Map<String,String> cmdEnvironment;
    public MyMRApp(    int maps,    int reduces,    boolean autoComplete,    String testName,    boolean cleanOnStart){
      super(maps,reduces,autoComplete,testName,cleanOnStart);
    }
    @Override protected ContainerLauncher createContainerLauncher(    AppContext context){
      return new MockContainerLauncher(){
        @Override public void handle(        ContainerLauncherEvent event){
          if (event.getType() == EventType.CONTAINER_REMOTE_LAUNCH) {
            ContainerRemoteLaunchEvent launchEvent=(ContainerRemoteLaunchEvent)event;
            ContainerLaunchContext launchContext=launchEvent.getContainerLaunchContext();
            String cmdString=launchContext.getCommands().toString();
            LOG.info("launchContext " + cmdString);
            launchCmdList.add(cmdString);
            cmdEnvironment=launchContext.getEnvironment();
          }
          super.handle(event);
        }
      }
;
    }
  }
  @Test public void testEnvironmentVariables() throws Exception {
    MyMRApp app=new MyMRApp(1,0,true,this.getClass().getName(),true);
    Configuration conf=new Configuration();
    conf.set(JobConf.MAPRED_MAP_TASK_ENV,"HADOOP_CLIENT_OPTS=test");
    conf.setStrings(MRJobConfig.MAP_LOG_LEVEL,"WARN");
    conf.setBoolean(MRConfig.MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM,false);
    Job job=app.submit(conf);
    app.waitForState(job,JobState.SUCCEEDED);
    app.verifyCompleted();
    Assert.assertTrue("HADOOP_ROOT_LOGGER not set for job",app.cmdEnvironment.containsKey("HADOOP_ROOT_LOGGER"));
    Assert.assertEquals("WARN,console",app.cmdEnvironment.get("HADOOP_ROOT_LOGGER"));
    Assert.assertTrue("HADOOP_CLIENT_OPTS not set for job",app.cmdEnvironment.containsKey("HADOOP_CLIENT_OPTS"));
    Assert.assertEquals("test",app.cmdEnvironment.get("HADOOP_CLIENT_OPTS"));
    app=new MyMRApp(1,0,true,this.getClass().getName(),true);
    conf=new Configuration();
    conf.set(JobConf.MAPRED_MAP_TASK_ENV,"HADOOP_ROOT_LOGGER=trace");
    job=app.submit(conf);
    app.waitForState(job,JobState.SUCCEEDED);
    app.verifyCompleted();
    Assert.assertTrue("HADOOP_ROOT_LOGGER not set for job",app.cmdEnvironment.containsKey("HADOOP_ROOT_LOGGER"));
    Assert.assertEquals("trace",app.cmdEnvironment.get("HADOOP_ROOT_LOGGER"));
    app=new MyMRApp(1,0,true,this.getClass().getName(),true);
    conf=new Configuration();
    conf.set(JobConf.MAPRED_MAP_TASK_ENV + ".HADOOP_ROOT_LOGGER","DEBUG,console");
    job=app.submit(conf);
    app.waitForState(job,JobState.SUCCEEDED);
    app.verifyCompleted();
    Assert.assertTrue("HADOOP_ROOT_LOGGER not set for job",app.cmdEnvironment.containsKey("HADOOP_ROOT_LOGGER"));
    Assert.assertEquals("DEBUG,console",app.cmdEnvironment.get("HADOOP_ROOT_LOGGER"));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapreduce.v2.hs;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import java.io.File;
import java.io.IOException;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileUtil;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.v2.api.MRDelegationTokenIdentifier;
import org.apache.hadoop.mapreduce.v2.hs.HistoryServerStateStoreService.HistoryServerState;
import org.apache.hadoop.mapreduce.v2.jobhistory.JHAdminConfig;
import org.apache.hadoop.security.token.delegation.DelegationKey;
import org.apache.hadoop.service.ServiceStateException;
import org.apache.hadoop.yarn.server.records.Version;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
public class TestHistoryServerLeveldbStateStoreService {
  private static final File testDir=new File(System.getProperty("test.build.data",System.getProperty("java.io.tmpdir")),"TestHistoryServerLeveldbSystemStateStoreService");
  private Configuration conf;
  @Before public void setup(){
    FileUtil.fullyDelete(testDir);
    testDir.mkdirs();
    conf=new Configuration();
    conf.setBoolean(JHAdminConfig.MR_HS_RECOVERY_ENABLE,true);
    conf.setClass(JHAdminConfig.MR_HS_STATE_STORE,HistoryServerLeveldbStateStoreService.class,HistoryServerStateStoreService.class);
    conf.set(JHAdminConfig.MR_HS_LEVELDB_STATE_STORE_PATH,testDir.getAbsoluteFile().toString());
  }
  @After public void cleanup(){
    FileUtil.fullyDelete(testDir);
  }
  private HistoryServerStateStoreService createAndStartStore() throws IOException {
    HistoryServerStateStoreService store=HistoryServerStateStoreServiceFactory.getStore(conf);
    assertTrue("Factory did not create a leveldb store",store instanceof HistoryServerLeveldbStateStoreService);
    store.init(conf);
    store.start();
    return store;
  }
  @Test public void testCheckVersion() throws IOException {
    HistoryServerLeveldbStateStoreService store=new HistoryServerLeveldbStateStoreService();
    store.init(conf);
    store.start();
    Version defaultVersion=store.getCurrentVersion();
    assertEquals(defaultVersion,store.loadVersion());
    Version compatibleVersion=Version.newInstance(defaultVersion.getMajorVersion(),defaultVersion.getMinorVersion() + 2);
    store.dbStoreVersion(compatibleVersion);
    assertEquals(compatibleVersion,store.loadVersion());
    store.close();
    store=new HistoryServerLeveldbStateStoreService();
    store.init(conf);
    store.start();
    assertEquals(defaultVersion,store.loadVersion());
    Version incompatibleVersion=Version.newInstance(defaultVersion.getMajorVersion() + 1,defaultVersion.getMinorVersion());
    store.dbStoreVersion(incompatibleVersion);
    store.close();
    store=new HistoryServerLeveldbStateStoreService();
    try {
      store.init(conf);
      store.start();
      fail("Incompatible version, should have thrown before here.");
    }
 catch (    ServiceStateException e) {
      assertTrue("Exception message mismatch",e.getMessage().contains("Incompatible version for state:"));
    }
    store.close();
  }
  @Test public void testTokenStore() throws IOException {
    HistoryServerStateStoreService store=createAndStartStore();
    HistoryServerState state=store.loadState();
    assertTrue("token state not empty",state.tokenState.isEmpty());
    assertTrue("key state not empty",state.tokenMasterKeyState.isEmpty());
    final DelegationKey key1=new DelegationKey(1,2,"keyData1".getBytes());
    final MRDelegationTokenIdentifier token1=new MRDelegationTokenIdentifier(new Text("tokenOwner1"),new Text("tokenRenewer1"),new Text("tokenUser1"));
    token1.setSequenceNumber(1);
    final Long tokenDate1=1L;
    final MRDelegationTokenIdentifier token2=new MRDelegationTokenIdentifier(new Text("tokenOwner2"),new Text("tokenRenewer2"),new Text("tokenUser2"));
    token2.setSequenceNumber(12345678);
    final Long tokenDate2=87654321L;
    store.storeTokenMasterKey(key1);
    store.storeToken(token1,tokenDate1);
    store.storeToken(token2,tokenDate2);
    store.close();
    store=createAndStartStore();
    state=store.loadState();
    assertEquals("incorrect loaded token count",2,state.tokenState.size());
    assertTrue("missing token 1",state.tokenState.containsKey(token1));
    assertEquals("incorrect token 1 date",tokenDate1,state.tokenState.get(token1));
    assertTrue("missing token 2",state.tokenState.containsKey(token2));
    assertEquals("incorrect token 2 date",tokenDate2,state.tokenState.get(token2));
    assertEquals("incorrect master key count",1,state.tokenMasterKeyState.size());
    assertTrue("missing master key 1",state.tokenMasterKeyState.contains(key1));
    final DelegationKey key2=new DelegationKey(3,4,"keyData2".getBytes());
    final DelegationKey key3=new DelegationKey(5,6,"keyData3".getBytes());
    final MRDelegationTokenIdentifier token3=new MRDelegationTokenIdentifier(new Text("tokenOwner3"),new Text("tokenRenewer3"),new Text("tokenUser3"));
    token3.setSequenceNumber(12345679);
    final Long tokenDate3=87654321L;
    store.removeToken(token1);
    store.storeTokenMasterKey(key2);
    final Long newTokenDate2=975318642L;
    store.updateToken(token2,newTokenDate2);
    store.removeTokenMasterKey(key1);
    store.storeTokenMasterKey(key3);
    store.storeToken(token3,tokenDate3);
    store.close();
    store=createAndStartStore();
    state=store.loadState();
    assertEquals("incorrect loaded token count",2,state.tokenState.size());
    assertFalse("token 1 not removed",state.tokenState.containsKey(token1));
    assertTrue("missing token 2",state.tokenState.containsKey(token2));
    assertEquals("incorrect token 2 date",newTokenDate2,state.tokenState.get(token2));
    assertTrue("missing token 3",state.tokenState.containsKey(token3));
    assertEquals("incorrect token 3 date",tokenDate3,state.tokenState.get(token3));
    assertEquals("incorrect master key count",2,state.tokenMasterKeyState.size());
    assertFalse("master key 1 not removed",state.tokenMasterKeyState.contains(key1));
    assertTrue("missing master key 2",state.tokenMasterKeyState.contains(key2));
    assertTrue("missing master key 3",state.tokenMasterKeyState.contains(key3));
    store.close();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapred;
import org.apache.hadoop.hdfs.MiniDFSCluster;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.junit.After;
import org.junit.Before;
import java.io.IOException;
import java.util.Map;
import java.util.Properties;
/** 
 * Test case to run a MapReduce job. <p/> It runs a 2 node cluster Hadoop with a 2 node DFS. <p/> The JobConf to use must be obtained via the creatJobConf() method. <p/> It creates a temporary directory -accessible via getTestRootDir()- for both input and output. <p/> The input directory is accesible via getInputDir() and the output directory via getOutputDir() <p/> The DFS filesystem is formated before the testcase starts and after it ends.
 */
public abstract class ClusterMapReduceTestCase {
  private MiniDFSCluster dfsCluster=null;
  private MiniMRCluster mrCluster=null;
  /** 
 * Creates Hadoop Cluster and DFS before a test case is run.
 * @throws Exception
 */
  @Before public void setUp() throws Exception {
    startCluster(true,null);
  }
  /** 
 * Starts the cluster within a testcase. <p/> Note that the cluster is already started when the testcase method is invoked. This method is useful if as part of the testcase the cluster has to be shutdown and restarted again. <p/> If the cluster is already running this method does nothing.
 * @param reformatDFS indicates if DFS has to be reformated
 * @param props configuration properties to inject to the mini cluster
 * @throws Exception if the cluster could not be started
 */
  protected synchronized void startCluster(  boolean reformatDFS,  Properties props) throws Exception {
    if (dfsCluster == null) {
      JobConf conf=new JobConf();
      if (props != null) {
        for (        Map.Entry entry : props.entrySet()) {
          conf.set((String)entry.getKey(),(String)entry.getValue());
        }
      }
      dfsCluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).format(reformatDFS).racks(null).build();
      ConfigurableMiniMRCluster.setConfiguration(props);
      mrCluster=new ConfigurableMiniMRCluster(2,getFileSystem().getUri().toString(),1,conf);
    }
  }
private static class ConfigurableMiniMRCluster extends MiniMRCluster {
    private static Properties config;
    public static void setConfiguration(    Properties props){
      config=props;
    }
    public ConfigurableMiniMRCluster(    int numTaskTrackers,    String namenode,    int numDir,    JobConf conf) throws Exception {
      super(0,0,numTaskTrackers,namenode,numDir,null,null,null,conf);
    }
    public JobConf createJobConf(){
      JobConf conf=super.createJobConf();
      if (config != null) {
        for (        Map.Entry entry : config.entrySet()) {
          conf.set((String)entry.getKey(),(String)entry.getValue());
        }
      }
      return conf;
    }
  }
  /** 
 * Stops the cluster within a testcase. <p/> Note that the cluster is already started when the testcase method is invoked. This method is useful if as part of the testcase the cluster has to be shutdown. <p/> If the cluster is already stopped this method does nothing.
 * @throws Exception if the cluster could not be stopped
 */
  protected void stopCluster() throws Exception {
    if (mrCluster != null) {
      mrCluster.shutdown();
      mrCluster=null;
    }
    if (dfsCluster != null) {
      dfsCluster.shutdown();
      dfsCluster=null;
    }
  }
  /** 
 * Destroys Hadoop Cluster and DFS after a test case is run.
 * @throws Exception
 */
  @After public void tearDown() throws Exception {
    stopCluster();
  }
  /** 
 * Returns a preconfigured Filesystem instance for test cases to read and write files to it. <p/> TestCases should use this Filesystem instance.
 * @return the filesystem used by Hadoop.
 * @throws IOException 
 */
  protected FileSystem getFileSystem() throws IOException {
    return dfsCluster.getFileSystem();
  }
  protected MiniMRCluster getMRCluster(){
    return mrCluster;
  }
  /** 
 * Returns the path to the root directory for the testcase.
 * @return path to the root directory for the testcase.
 */
  protected Path getTestRootDir(){
    return new Path("x").getParent();
  }
  /** 
 * Returns a path to the input directory for the testcase.
 * @return path to the input directory for the tescase.
 */
  protected Path getInputDir(){
    return new Path("target/input");
  }
  /** 
 * Returns a path to the output directory for the testcase.
 * @return path to the output directory for the tescase.
 */
  protected Path getOutputDir(){
    return new Path("target/output");
  }
  /** 
 * Returns a job configuration preconfigured to run against the Hadoop managed by the testcase.
 * @return configuration that works on the testcase Hadoop instance
 */
  protected JobConf createJobConf(){
    return mrCluster.createJobConf();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapred.join;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.DataInputStream;
import java.io.DataOutput;
import java.io.DataOutputStream;
import java.io.IOException;
import java.util.Arrays;
import java.util.Random;
import org.apache.hadoop.io.BooleanWritable;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.FloatWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.io.WritableUtils;
import org.junit.Test;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
public class TestTupleWritable {
  private TupleWritable makeTuple(  Writable[] writs){
    Writable[] sub1={writs[1],writs[2]};
    Writable[] sub3={writs[4],writs[5]};
    Writable[] sub2={writs[3],new TupleWritable(sub3),writs[6]};
    Writable[] vals={writs[0],new TupleWritable(sub1),new TupleWritable(sub2),writs[7],writs[8],writs[9]};
    TupleWritable ret=new TupleWritable(vals);
    for (int i=0; i < 6; ++i) {
      ret.setWritten(i);
    }
    ((TupleWritable)sub2[1]).setWritten(0);
    ((TupleWritable)sub2[1]).setWritten(1);
    ((TupleWritable)vals[1]).setWritten(0);
    ((TupleWritable)vals[1]).setWritten(1);
    for (int i=0; i < 3; ++i) {
      ((TupleWritable)vals[2]).setWritten(i);
    }
    return ret;
  }
  private Writable[] makeRandomWritables(){
    Random r=new Random();
    Writable[] writs={new BooleanWritable(r.nextBoolean()),new FloatWritable(r.nextFloat()),new FloatWritable(r.nextFloat()),new IntWritable(r.nextInt()),new LongWritable(r.nextLong()),new BytesWritable("dingo".getBytes()),new LongWritable(r.nextLong()),new IntWritable(r.nextInt()),new BytesWritable("yak".getBytes()),new IntWritable(r.nextInt())};
    return writs;
  }
  private Writable[] makeRandomWritables(  int numWrits){
    Writable[] writs=makeRandomWritables();
    Writable[] manyWrits=new Writable[numWrits];
    for (int i=0; i < manyWrits.length; i++) {
      manyWrits[i]=writs[i % writs.length];
    }
    return manyWrits;
  }
  private int verifIter(  Writable[] writs,  TupleWritable t,  int i){
    for (    Writable w : t) {
      if (w instanceof TupleWritable) {
        i=verifIter(writs,((TupleWritable)w),i);
        continue;
      }
      assertTrue("Bad value",w.equals(writs[i++]));
    }
    return i;
  }
  @Test public void testIterable() throws Exception {
    Random r=new Random();
    Writable[] writs={new BooleanWritable(r.nextBoolean()),new FloatWritable(r.nextFloat()),new FloatWritable(r.nextFloat()),new IntWritable(r.nextInt()),new LongWritable(r.nextLong()),new BytesWritable("dingo".getBytes()),new LongWritable(r.nextLong()),new IntWritable(r.nextInt()),new BytesWritable("yak".getBytes()),new IntWritable(r.nextInt())};
    TupleWritable t=new TupleWritable(writs);
    for (int i=0; i < 6; ++i) {
      t.setWritten(i);
    }
    verifIter(writs,t,0);
  }
  @Test public void testNestedIterable() throws Exception {
    Random r=new Random();
    Writable[] writs={new BooleanWritable(r.nextBoolean()),new FloatWritable(r.nextFloat()),new FloatWritable(r.nextFloat()),new IntWritable(r.nextInt()),new LongWritable(r.nextLong()),new BytesWritable("dingo".getBytes()),new LongWritable(r.nextLong()),new IntWritable(r.nextInt()),new BytesWritable("yak".getBytes()),new IntWritable(r.nextInt())};
    TupleWritable sTuple=makeTuple(writs);
    assertTrue("Bad count",writs.length == verifIter(writs,sTuple,0));
  }
  @Test public void testWritable() throws Exception {
    Random r=new Random();
    Writable[] writs={new BooleanWritable(r.nextBoolean()),new FloatWritable(r.nextFloat()),new FloatWritable(r.nextFloat()),new IntWritable(r.nextInt()),new LongWritable(r.nextLong()),new BytesWritable("dingo".getBytes()),new LongWritable(r.nextLong()),new IntWritable(r.nextInt()),new BytesWritable("yak".getBytes()),new IntWritable(r.nextInt())};
    TupleWritable sTuple=makeTuple(writs);
    ByteArrayOutputStream out=new ByteArrayOutputStream();
    sTuple.write(new DataOutputStream(out));
    ByteArrayInputStream in=new ByteArrayInputStream(out.toByteArray());
    TupleWritable dTuple=new TupleWritable();
    dTuple.readFields(new DataInputStream(in));
    assertTrue("Failed to write/read tuple",sTuple.equals(dTuple));
  }
  @Test public void testWideWritable() throws Exception {
    Writable[] manyWrits=makeRandomWritables(131);
    TupleWritable sTuple=new TupleWritable(manyWrits);
    for (int i=0; i < manyWrits.length; i++) {
      if (i % 3 == 0) {
        sTuple.setWritten(i);
      }
    }
    ByteArrayOutputStream out=new ByteArrayOutputStream();
    sTuple.write(new DataOutputStream(out));
    ByteArrayInputStream in=new ByteArrayInputStream(out.toByteArray());
    TupleWritable dTuple=new TupleWritable();
    dTuple.readFields(new DataInputStream(in));
    assertTrue("Failed to write/read tuple",sTuple.equals(dTuple));
    assertEquals("All tuple data has not been read from the stream",-1,in.read());
  }
  @Test public void testWideWritable2() throws Exception {
    Writable[] manyWrits=makeRandomWritables(71);
    TupleWritable sTuple=new TupleWritable(manyWrits);
    for (int i=0; i < manyWrits.length; i++) {
      sTuple.setWritten(i);
    }
    ByteArrayOutputStream out=new ByteArrayOutputStream();
    sTuple.write(new DataOutputStream(out));
    ByteArrayInputStream in=new ByteArrayInputStream(out.toByteArray());
    TupleWritable dTuple=new TupleWritable();
    dTuple.readFields(new DataInputStream(in));
    assertTrue("Failed to write/read tuple",sTuple.equals(dTuple));
    assertEquals("All tuple data has not been read from the stream",-1,in.read());
  }
  /** 
 * Tests a tuple writable with more than 64 values and the values set written spread far apart.
 */
  @Test public void testSparseWideWritable() throws Exception {
    Writable[] manyWrits=makeRandomWritables(131);
    TupleWritable sTuple=new TupleWritable(manyWrits);
    for (int i=0; i < manyWrits.length; i++) {
      if (i % 65 == 0) {
        sTuple.setWritten(i);
      }
    }
    ByteArrayOutputStream out=new ByteArrayOutputStream();
    sTuple.write(new DataOutputStream(out));
    ByteArrayInputStream in=new ByteArrayInputStream(out.toByteArray());
    TupleWritable dTuple=new TupleWritable();
    dTuple.readFields(new DataInputStream(in));
    assertTrue("Failed to write/read tuple",sTuple.equals(dTuple));
    assertEquals("All tuple data has not been read from the stream",-1,in.read());
  }
  @Test public void testWideTuple() throws Exception {
    Text emptyText=new Text("Should be empty");
    Writable[] values=new Writable[64];
    Arrays.fill(values,emptyText);
    values[42]=new Text("Number 42");
    TupleWritable tuple=new TupleWritable(values);
    tuple.setWritten(42);
    for (int pos=0; pos < tuple.size(); pos++) {
      boolean has=tuple.has(pos);
      if (pos == 42) {
        assertTrue(has);
      }
 else {
        assertFalse("Tuple position is incorrectly labelled as set: " + pos,has);
      }
    }
  }
  @Test public void testWideTuple2() throws Exception {
    Text emptyText=new Text("Should be empty");
    Writable[] values=new Writable[64];
    Arrays.fill(values,emptyText);
    values[9]=new Text("Number 9");
    TupleWritable tuple=new TupleWritable(values);
    tuple.setWritten(9);
    for (int pos=0; pos < tuple.size(); pos++) {
      boolean has=tuple.has(pos);
      if (pos == 9) {
        assertTrue(has);
      }
 else {
        assertFalse("Tuple position is incorrectly labelled as set: " + pos,has);
      }
    }
  }
  /** 
 * Tests that we can write more than 64 values.
 */
  @Test public void testWideTupleBoundary() throws Exception {
    Text emptyText=new Text("Should not be set written");
    Writable[] values=new Writable[65];
    Arrays.fill(values,emptyText);
    values[64]=new Text("Should be the only value set written");
    TupleWritable tuple=new TupleWritable(values);
    tuple.setWritten(64);
    for (int pos=0; pos < tuple.size(); pos++) {
      boolean has=tuple.has(pos);
      if (pos == 64) {
        assertTrue(has);
      }
 else {
        assertFalse("Tuple position is incorrectly labelled as set: " + pos,has);
      }
    }
  }
  /** 
 * Tests compatibility with pre-0.21 versions of TupleWritable
 */
  @Test public void testPreVersion21Compatibility() throws Exception {
    Writable[] manyWrits=makeRandomWritables(64);
    PreVersion21TupleWritable oldTuple=new PreVersion21TupleWritable(manyWrits);
    for (int i=0; i < manyWrits.length; i++) {
      if (i % 3 == 0) {
        oldTuple.setWritten(i);
      }
    }
    ByteArrayOutputStream out=new ByteArrayOutputStream();
    oldTuple.write(new DataOutputStream(out));
    ByteArrayInputStream in=new ByteArrayInputStream(out.toByteArray());
    TupleWritable dTuple=new TupleWritable();
    dTuple.readFields(new DataInputStream(in));
    assertTrue("Tuple writable is unable to read pre-0.21 versions of TupleWritable",oldTuple.isCompatible(dTuple));
    assertEquals("All tuple data has not been read from the stream",-1,in.read());
  }
  @Test public void testPreVersion21CompatibilityEmptyTuple() throws Exception {
    Writable[] manyWrits=new Writable[0];
    PreVersion21TupleWritable oldTuple=new PreVersion21TupleWritable(manyWrits);
    ByteArrayOutputStream out=new ByteArrayOutputStream();
    oldTuple.write(new DataOutputStream(out));
    ByteArrayInputStream in=new ByteArrayInputStream(out.toByteArray());
    TupleWritable dTuple=new TupleWritable();
    dTuple.readFields(new DataInputStream(in));
    assertTrue("Tuple writable is unable to read pre-0.21 versions of TupleWritable",oldTuple.isCompatible(dTuple));
    assertEquals("All tuple data has not been read from the stream",-1,in.read());
  }
  /** 
 * Writes to the DataOutput stream in the same way as pre-0.21 versions of {@link TupleWritable#write(DataOutput)}
 */
private static class PreVersion21TupleWritable {
    private Writable[] values;
    private long written=0L;
    private PreVersion21TupleWritable(    Writable[] vals){
      written=0L;
      values=vals;
    }
    private void setWritten(    int i){
      written|=1L << i;
    }
    private boolean has(    int i){
      return 0 != ((1L << i) & written);
    }
    private void write(    DataOutput out) throws IOException {
      WritableUtils.writeVInt(out,values.length);
      WritableUtils.writeVLong(out,written);
      for (int i=0; i < values.length; ++i) {
        Text.writeString(out,values[i].getClass().getName());
      }
      for (int i=0; i < values.length; ++i) {
        if (has(i)) {
          values[i].write(out);
        }
      }
    }
    public int size(){
      return values.length;
    }
    public boolean isCompatible(    TupleWritable that){
      if (this.size() != that.size()) {
        return false;
      }
      for (int i=0; i < values.length; ++i) {
        if (has(i) != that.has(i)) {
          return false;
        }
        if (has(i) && !values[i].equals(that.get(i))) {
          return false;
        }
      }
      return true;
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapred;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import java.io.IOException;
import java.util.BitSet;
import java.util.Random;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.SequenceFile;
import org.apache.hadoop.mapred.lib.CombineFileSplit;
import org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat;
import org.junit.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
public class TestCombineSequenceFileInputFormat {
  private static final Logger LOG=LoggerFactory.getLogger(TestCombineSequenceFileInputFormat.class);
  private static Configuration conf=new Configuration();
  private static FileSystem localFs=null;
static {
    try {
      conf.set("fs.defaultFS","file:///");
      localFs=FileSystem.getLocal(conf);
    }
 catch (    IOException e) {
      throw new RuntimeException("init failure",e);
    }
  }
  private static Path workDir=localFs.makeQualified(new Path(System.getProperty("test.build.data","/tmp"),"TestCombineSequenceFileInputFormat"));
  @Test(timeout=10000) public void testFormat() throws Exception {
    JobConf job=new JobConf(conf);
    Reporter reporter=Reporter.NULL;
    Random random=new Random();
    long seed=random.nextLong();
    LOG.info("seed = " + seed);
    random.setSeed(seed);
    localFs.delete(workDir,true);
    FileInputFormat.setInputPaths(job,workDir);
    final int length=10000;
    final int numFiles=10;
    createFiles(length,numFiles,random);
    InputFormat<IntWritable,BytesWritable> format=new CombineSequenceFileInputFormat<IntWritable,BytesWritable>();
    IntWritable key=new IntWritable();
    BytesWritable value=new BytesWritable();
    for (int i=0; i < 3; i++) {
      int numSplits=random.nextInt(length / (SequenceFile.SYNC_INTERVAL / 20)) + 1;
      LOG.info("splitting: requesting = " + numSplits);
      InputSplit[] splits=format.getSplits(job,numSplits);
      LOG.info("splitting: got =        " + splits.length);
      assertEquals("We got more than one splits!",1,splits.length);
      InputSplit split=splits[0];
      assertEquals("It should be CombineFileSplit",CombineFileSplit.class,split.getClass());
      BitSet bits=new BitSet(length);
      RecordReader<IntWritable,BytesWritable> reader=format.getRecordReader(split,job,reporter);
      try {
        while (reader.next(key,value)) {
          assertFalse("Key in multiple partitions.",bits.get(key.get()));
          bits.set(key.get());
        }
      }
  finally {
        reader.close();
      }
      assertEquals("Some keys in no partition.",length,bits.cardinality());
    }
  }
private static class Range {
    private final int start;
    private final int end;
    Range(    int start,    int end){
      this.start=start;
      this.end=end;
    }
    @Override public String toString(){
      return "(" + start + ", "+ end+ ")";
    }
  }
  private static Range[] createRanges(  int length,  int numFiles,  Random random){
    Range[] ranges=new Range[numFiles];
    for (int i=0; i < numFiles; i++) {
      int start=i == 0 ? 0 : ranges[i - 1].end;
      int end=i == numFiles - 1 ? length : (length / numFiles) * (2 * i + 1) / 2 + random.nextInt(length / numFiles) + 1;
      ranges[i]=new Range(start,end);
    }
    return ranges;
  }
  private static void createFiles(  int length,  int numFiles,  Random random) throws IOException {
    Range[] ranges=createRanges(length,numFiles,random);
    for (int i=0; i < numFiles; i++) {
      Path file=new Path(workDir,"test_" + i + ".seq");
      @SuppressWarnings("deprecation") SequenceFile.Writer writer=SequenceFile.createWriter(localFs,conf,file,IntWritable.class,BytesWritable.class);
      Range range=ranges[i];
      try {
        for (int j=range.start; j < range.end; j++) {
          IntWritable key=new IntWritable(j);
          byte[] data=new byte[random.nextInt(10)];
          random.nextBytes(data);
          BytesWritable value=new BytesWritable(data);
          writer.append(key,value);
        }
      }
  finally {
        writer.close();
      }
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapred;
import java.util.Map;
import org.apache.hadoop.mapred.StatisticsCollector.TimeWindow;
import org.apache.hadoop.mapred.StatisticsCollector.Stat;
import org.junit.Test;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
public class TestStatisticsCollector {
  @SuppressWarnings("rawtypes") @Test public void testMovingWindow() throws Exception {
    StatisticsCollector collector=new StatisticsCollector(1);
    TimeWindow window=new TimeWindow("test",6,2);
    TimeWindow sincStart=StatisticsCollector.SINCE_START;
    TimeWindow[] windows={sincStart,window};
    Stat stat=collector.createStat("m1",windows);
    stat.inc(3);
    collector.update();
    assertEquals(0,stat.getValues().get(window).getValue());
    assertEquals(3,stat.getValues().get(sincStart).getValue());
    stat.inc(3);
    collector.update();
    assertEquals((3 + 3),stat.getValues().get(window).getValue());
    assertEquals(6,stat.getValues().get(sincStart).getValue());
    stat.inc(10);
    collector.update();
    assertEquals((3 + 3),stat.getValues().get(window).getValue());
    assertEquals(16,stat.getValues().get(sincStart).getValue());
    stat.inc(10);
    collector.update();
    assertEquals((3 + 3 + 10+ 10),stat.getValues().get(window).getValue());
    assertEquals(26,stat.getValues().get(sincStart).getValue());
    stat.inc(10);
    collector.update();
    stat.inc(10);
    collector.update();
    assertEquals((3 + 3 + 10+ 10+ 10+ 10),stat.getValues().get(window).getValue());
    assertEquals(46,stat.getValues().get(sincStart).getValue());
    stat.inc(10);
    collector.update();
    assertEquals((3 + 3 + 10+ 10+ 10+ 10),stat.getValues().get(window).getValue());
    assertEquals(56,stat.getValues().get(sincStart).getValue());
    stat.inc(12);
    collector.update();
    assertEquals((10 + 10 + 10+ 10+ 10+ 12),stat.getValues().get(window).getValue());
    assertEquals(68,stat.getValues().get(sincStart).getValue());
    stat.inc(13);
    collector.update();
    assertEquals((10 + 10 + 10+ 10+ 10+ 12),stat.getValues().get(window).getValue());
    assertEquals(81,stat.getValues().get(sincStart).getValue());
    stat.inc(14);
    collector.update();
    assertEquals((10 + 10 + 10+ 12+ 13+ 14),stat.getValues().get(window).getValue());
    assertEquals(95,stat.getValues().get(sincStart).getValue());
    Map updaters=collector.getUpdaters();
    assertEquals(updaters.size(),2);
    Map<String,Stat> ststistics=collector.getStatistics();
    assertNotNull(ststistics.get("m1"));
    Stat newStat=collector.createStat("m2");
    assertEquals(newStat.name,"m2");
    Stat st=collector.removeStat("m1");
    assertEquals(st.name,"m1");
    assertEquals((10 + 10 + 10+ 12+ 13+ 14),stat.getValues().get(window).getValue());
    assertEquals(95,stat.getValues().get(sincStart).getValue());
    st=collector.removeStat("m1");
    assertNull(st);
    collector.start();
    Thread.sleep(2500);
    assertEquals(69,stat.getValues().get(window).getValue());
    assertEquals(95,stat.getValues().get(sincStart).getValue());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapred;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import java.io.IOException;
import java.util.StringTokenizer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Counters;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.v2.jobhistory.JHAdminConfig;
import org.apache.hadoop.yarn.conf.YarnConfiguration;
import org.junit.AfterClass;
import org.junit.BeforeClass;
import org.junit.Test;
/** 
 * Basic testing for the MiniMRClientCluster. This test shows an example class that can be used in MR1 or MR2, without any change to the test. The test will use MiniMRYarnCluster in MR2, and MiniMRCluster in MR1.
 */
public class TestMiniMRClientCluster {
  private static Path inDir=null;
  private static Path outDir=null;
  private static Path testdir=null;
  private static Path[] inFiles=new Path[5];
  private static MiniMRClientCluster mrCluster;
private class InternalClass {
  }
  @BeforeClass public static void setup() throws IOException {
    final Configuration conf=new Configuration();
    final Path TEST_ROOT_DIR=new Path(System.getProperty("test.build.data","/tmp"));
    testdir=new Path(TEST_ROOT_DIR,"TestMiniMRClientCluster");
    inDir=new Path(testdir,"in");
    outDir=new Path(testdir,"out");
    FileSystem fs=FileSystem.getLocal(conf);
    if (fs.exists(testdir) && !fs.delete(testdir,true)) {
      throw new IOException("Could not delete " + testdir);
    }
    if (!fs.mkdirs(inDir)) {
      throw new IOException("Mkdirs failed to create " + inDir);
    }
    for (int i=0; i < inFiles.length; i++) {
      inFiles[i]=new Path(inDir,"part_" + i);
      createFile(inFiles[i],conf);
    }
    mrCluster=MiniMRClientClusterFactory.create(InternalClass.class,1,new Configuration());
  }
  @AfterClass public static void cleanup() throws IOException {
    final Configuration conf=new Configuration();
    final FileSystem fs=testdir.getFileSystem(conf);
    if (fs.exists(testdir)) {
      fs.delete(testdir,true);
    }
    mrCluster.stop();
  }
  @Test public void testRestart() throws Exception {
    String rmAddress1=mrCluster.getConfig().get(YarnConfiguration.RM_ADDRESS);
    String rmAdminAddress1=mrCluster.getConfig().get(YarnConfiguration.RM_ADMIN_ADDRESS);
    String rmSchedAddress1=mrCluster.getConfig().get(YarnConfiguration.RM_SCHEDULER_ADDRESS);
    String rmRstrackerAddress1=mrCluster.getConfig().get(YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS);
    String rmWebAppAddress1=mrCluster.getConfig().get(YarnConfiguration.RM_WEBAPP_ADDRESS);
    String mrHistAddress1=mrCluster.getConfig().get(JHAdminConfig.MR_HISTORY_ADDRESS);
    String mrHistWebAppAddress1=mrCluster.getConfig().get(JHAdminConfig.MR_HISTORY_WEBAPP_ADDRESS);
    mrCluster.restart();
    String rmAddress2=mrCluster.getConfig().get(YarnConfiguration.RM_ADDRESS);
    String rmAdminAddress2=mrCluster.getConfig().get(YarnConfiguration.RM_ADMIN_ADDRESS);
    String rmSchedAddress2=mrCluster.getConfig().get(YarnConfiguration.RM_SCHEDULER_ADDRESS);
    String rmRstrackerAddress2=mrCluster.getConfig().get(YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS);
    String rmWebAppAddress2=mrCluster.getConfig().get(YarnConfiguration.RM_WEBAPP_ADDRESS);
    String mrHistAddress2=mrCluster.getConfig().get(JHAdminConfig.MR_HISTORY_ADDRESS);
    String mrHistWebAppAddress2=mrCluster.getConfig().get(JHAdminConfig.MR_HISTORY_WEBAPP_ADDRESS);
    assertEquals("Address before restart: " + rmAddress1 + " is different from new address: "+ rmAddress2,rmAddress1,rmAddress2);
    assertEquals("Address before restart: " + rmAdminAddress1 + " is different from new address: "+ rmAdminAddress2,rmAdminAddress1,rmAdminAddress2);
    assertEquals("Address before restart: " + rmSchedAddress1 + " is different from new address: "+ rmSchedAddress2,rmSchedAddress1,rmSchedAddress2);
    assertEquals("Address before restart: " + rmRstrackerAddress1 + " is different from new address: "+ rmRstrackerAddress2,rmRstrackerAddress1,rmRstrackerAddress2);
    assertEquals("Address before restart: " + rmWebAppAddress1 + " is different from new address: "+ rmWebAppAddress2,rmWebAppAddress1,rmWebAppAddress2);
    assertEquals("Address before restart: " + mrHistAddress1 + " is different from new address: "+ mrHistAddress2,mrHistAddress1,mrHistAddress2);
    assertEquals("Address before restart: " + mrHistWebAppAddress1 + " is different from new address: "+ mrHistWebAppAddress2,mrHistWebAppAddress1,mrHistWebAppAddress2);
  }
  @Test public void testJob() throws Exception {
    final Job job=createJob();
    org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job,inDir);
    org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(job,new Path(outDir,"testJob"));
    assertTrue(job.waitForCompletion(true));
    validateCounters(job.getCounters(),5,25,5,5);
  }
  private void validateCounters(  Counters counters,  long mapInputRecords,  long mapOutputRecords,  long reduceInputGroups,  long reduceOutputRecords){
    assertEquals("MapInputRecords",mapInputRecords,counters.findCounter("MyCounterGroup","MAP_INPUT_RECORDS").getValue());
    assertEquals("MapOutputRecords",mapOutputRecords,counters.findCounter("MyCounterGroup","MAP_OUTPUT_RECORDS").getValue());
    assertEquals("ReduceInputGroups",reduceInputGroups,counters.findCounter("MyCounterGroup","REDUCE_INPUT_GROUPS").getValue());
    assertEquals("ReduceOutputRecords",reduceOutputRecords,counters.findCounter("MyCounterGroup","REDUCE_OUTPUT_RECORDS").getValue());
  }
  private static void createFile(  Path inFile,  Configuration conf) throws IOException {
    final FileSystem fs=inFile.getFileSystem(conf);
    if (fs.exists(inFile)) {
      return;
    }
    FSDataOutputStream out=fs.create(inFile);
    out.writeBytes("This is a test file");
    out.close();
  }
  public static Job createJob() throws IOException {
    final Job baseJob=Job.getInstance(mrCluster.getConfig());
    baseJob.setOutputKeyClass(Text.class);
    baseJob.setOutputValueClass(IntWritable.class);
    baseJob.setMapperClass(MyMapper.class);
    baseJob.setReducerClass(MyReducer.class);
    baseJob.setNumReduceTasks(1);
    return baseJob;
  }
public static class MyMapper extends org.apache.hadoop.mapreduce.Mapper<Object,Text,Text,IntWritable> {
    private final static IntWritable one=new IntWritable(1);
    private Text word=new Text();
    public void map(    Object key,    Text value,    Context context) throws IOException, InterruptedException {
      context.getCounter("MyCounterGroup","MAP_INPUT_RECORDS").increment(1);
      StringTokenizer iter=new StringTokenizer(value.toString());
      while (iter.hasMoreTokens()) {
        word.set(iter.nextToken());
        context.write(word,one);
        context.getCounter("MyCounterGroup","MAP_OUTPUT_RECORDS").increment(1);
      }
    }
  }
public static class MyReducer extends org.apache.hadoop.mapreduce.Reducer<Text,IntWritable,Text,IntWritable> {
    private IntWritable result=new IntWritable();
    public void reduce(    Text key,    Iterable<IntWritable> values,    Context context) throws IOException, InterruptedException {
      context.getCounter("MyCounterGroup","REDUCE_INPUT_GROUPS").increment(1);
      int sum=0;
      for (      IntWritable val : values) {
        sum+=val.get();
      }
      result.set(sum);
      context.write(key,result);
      context.getCounter("MyCounterGroup","REDUCE_OUTPUT_RECORDS").increment(1);
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapred.lib;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapred.InputFormat;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.KeyValueTextInputFormat;
import org.apache.hadoop.mapred.Mapper;
import org.apache.hadoop.mapred.OutputCollector;
import org.apache.hadoop.mapred.Reporter;
import org.apache.hadoop.mapred.TextInputFormat;
import org.junit.Test;
import java.io.IOException;
import java.util.Map;
import static org.junit.Assert.assertEquals;
/** 
 * @see TestDelegatingInputFormat
 */
public class TestMultipleInputs {
  @Test public void testAddInputPathWithFormat(){
    final JobConf conf=new JobConf();
    MultipleInputs.addInputPath(conf,new Path("/foo"),TextInputFormat.class);
    MultipleInputs.addInputPath(conf,new Path("/bar"),KeyValueTextInputFormat.class);
    final Map<Path,InputFormat> inputs=MultipleInputs.getInputFormatMap(conf);
    assertEquals(TextInputFormat.class,inputs.get(new Path("/foo")).getClass());
    assertEquals(KeyValueTextInputFormat.class,inputs.get(new Path("/bar")).getClass());
  }
  @Test public void testAddInputPathWithMapper(){
    final JobConf conf=new JobConf();
    MultipleInputs.addInputPath(conf,new Path("/foo"),TextInputFormat.class,MapClass.class);
    MultipleInputs.addInputPath(conf,new Path("/bar"),KeyValueTextInputFormat.class,MapClass2.class);
    final Map<Path,InputFormat> inputs=MultipleInputs.getInputFormatMap(conf);
    final Map<Path,Class<? extends Mapper>> maps=MultipleInputs.getMapperTypeMap(conf);
    assertEquals(TextInputFormat.class,inputs.get(new Path("/foo")).getClass());
    assertEquals(KeyValueTextInputFormat.class,inputs.get(new Path("/bar")).getClass());
    assertEquals(MapClass.class,maps.get(new Path("/foo")));
    assertEquals(MapClass2.class,maps.get(new Path("/bar")));
  }
static class MapClass implements Mapper<String,String,String,String> {
    public void map(    String key,    String value,    OutputCollector<String,String> output,    Reporter reporter) throws IOException {
    }
    public void configure(    JobConf job){
    }
    public void close() throws IOException {
    }
  }
static class MapClass2 extends MapClass {
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapreduce.lib.input;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;
import org.junit.Test;
import static org.junit.Assert.*;
import static org.mockito.Mockito.*;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.BlockLocation;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.InputSplit;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.JobContext;
import org.apache.hadoop.mapreduce.RecordReader;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
public class TestMRCJCFileInputFormat {
  @Test public void testAddInputPath() throws IOException {
    final Configuration conf=new Configuration();
    conf.set("fs.defaultFS","file:///abc/");
    final Job j=Job.getInstance(conf);
    final FileSystem defaultfs=FileSystem.get(conf);
    System.out.println("defaultfs.getUri() = " + defaultfs.getUri());
{
      final Path original=new Path("file:/foo");
      System.out.println("original = " + original);
      FileInputFormat.addInputPath(j,original);
      final Path[] results=FileInputFormat.getInputPaths(j);
      System.out.println("results = " + Arrays.asList(results));
      assertEquals(1,results.length);
      assertEquals(original,results[0]);
    }
{
      final Path original=new Path("file:/bar");
      System.out.println("original = " + original);
      FileInputFormat.setInputPaths(j,original);
      final Path[] results=FileInputFormat.getInputPaths(j);
      System.out.println("results = " + Arrays.asList(results));
      assertEquals(1,results.length);
      assertEquals(original,results[0]);
    }
  }
  @Test public void testNumInputFiles() throws Exception {
    Configuration conf=spy(new Configuration());
    Job mockedJob=mock(Job.class);
    when(mockedJob.getConfiguration()).thenReturn(conf);
    FileStatus stat=mock(FileStatus.class);
    when(stat.getLen()).thenReturn(0L);
    TextInputFormat ispy=spy(new TextInputFormat());
    doReturn(Arrays.asList(stat)).when(ispy).listStatus(mockedJob);
    ispy.getSplits(mockedJob);
    verify(conf).setLong(FileInputFormat.NUM_INPUT_FILES,1);
  }
  @Test @SuppressWarnings({"rawtypes","unchecked"}) public void testLastInputSplitAtSplitBoundary() throws Exception {
    FileInputFormat fif=new FileInputFormatForTest(1024l * 1024 * 1024,128l * 1024 * 1024);
    Configuration conf=new Configuration();
    JobContext jobContext=mock(JobContext.class);
    when(jobContext.getConfiguration()).thenReturn(conf);
    List<InputSplit> splits=fif.getSplits(jobContext);
    assertEquals(8,splits.size());
    for (int i=0; i < splits.size(); i++) {
      InputSplit split=splits.get(i);
      assertEquals(("host" + i),split.getLocations()[0]);
    }
  }
  @Test @SuppressWarnings({"rawtypes","unchecked"}) public void testLastInputSplitExceedingSplitBoundary() throws Exception {
    FileInputFormat fif=new FileInputFormatForTest(1027l * 1024 * 1024,128l * 1024 * 1024);
    Configuration conf=new Configuration();
    JobContext jobContext=mock(JobContext.class);
    when(jobContext.getConfiguration()).thenReturn(conf);
    List<InputSplit> splits=fif.getSplits(jobContext);
    assertEquals(8,splits.size());
    for (int i=0; i < splits.size(); i++) {
      InputSplit split=splits.get(i);
      assertEquals(("host" + i),split.getLocations()[0]);
    }
  }
  @Test @SuppressWarnings({"rawtypes","unchecked"}) public void testLastInputSplitSingleSplit() throws Exception {
    FileInputFormat fif=new FileInputFormatForTest(100l * 1024 * 1024,128l * 1024 * 1024);
    Configuration conf=new Configuration();
    JobContext jobContext=mock(JobContext.class);
    when(jobContext.getConfiguration()).thenReturn(conf);
    List<InputSplit> splits=fif.getSplits(jobContext);
    assertEquals(1,splits.size());
    for (int i=0; i < splits.size(); i++) {
      InputSplit split=splits.get(i);
      assertEquals(("host" + i),split.getLocations()[0]);
    }
  }
  /** 
 * Test when the input file's length is 0.
 */
  @Test public void testForEmptyFile() throws Exception {
    Configuration conf=new Configuration();
    FileSystem fileSys=FileSystem.get(conf);
    Path file=new Path("test" + "/file");
    FSDataOutputStream out=fileSys.create(file,true,conf.getInt("io.file.buffer.size",4096),(short)1,(long)1024);
    out.write(new byte[0]);
    out.close();
    DummyInputFormat inFormat=new DummyInputFormat();
    Job job=Job.getInstance(conf);
    FileInputFormat.setInputPaths(job,"test");
    List<InputSplit> splits=inFormat.getSplits(job);
    assertEquals(1,splits.size());
    FileSplit fileSplit=(FileSplit)splits.get(0);
    assertEquals(0,fileSplit.getLocations().length);
    assertEquals(file.getName(),fileSplit.getPath().getName());
    assertEquals(0,fileSplit.getStart());
    assertEquals(0,fileSplit.getLength());
    fileSys.delete(file.getParent(),true);
  }
  /** 
 * Dummy class to extend FileInputFormat
 */
private class DummyInputFormat extends FileInputFormat<Text,Text> {
    @Override public RecordReader<Text,Text> createRecordReader(    InputSplit split,    TaskAttemptContext context) throws IOException {
      return null;
    }
  }
private class FileInputFormatForTest<K,V> extends FileInputFormat<K,V> {
    long splitSize;
    long length;
    FileInputFormatForTest(    long length,    long splitSize){
      this.length=length;
      this.splitSize=splitSize;
    }
    @Override public RecordReader<K,V> createRecordReader(    InputSplit split,    TaskAttemptContext context) throws IOException, InterruptedException {
      return null;
    }
    @Override protected List<FileStatus> listStatus(    JobContext job) throws IOException {
      FileStatus mockFileStatus=mock(FileStatus.class);
      when(mockFileStatus.getBlockSize()).thenReturn(splitSize);
      Path mockPath=mock(Path.class);
      FileSystem mockFs=mock(FileSystem.class);
      BlockLocation[] blockLocations=mockBlockLocations(length,splitSize);
      when(mockFs.getFileBlockLocations(mockFileStatus,0,length)).thenReturn(blockLocations);
      when(mockPath.getFileSystem(any(Configuration.class))).thenReturn(mockFs);
      when(mockFileStatus.getPath()).thenReturn(mockPath);
      when(mockFileStatus.getLen()).thenReturn(length);
      List<FileStatus> list=new ArrayList<FileStatus>();
      list.add(mockFileStatus);
      return list;
    }
    @Override protected long computeSplitSize(    long blockSize,    long minSize,    long maxSize){
      return splitSize;
    }
    private BlockLocation[] mockBlockLocations(    long size,    long splitSize){
      int numLocations=(int)(size / splitSize);
      if (size % splitSize != 0)       numLocations++;
      BlockLocation[] blockLocations=new BlockLocation[numLocations];
      for (int i=0; i < numLocations; i++) {
        String[] names=new String[]{"b" + i};
        String[] hosts=new String[]{"host" + i};
        blockLocations[i]=new BlockLocation(names,hosts,i * splitSize,Math.min(splitSize,size - (splitSize * i)));
      }
      return blockLocations;
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.streaming;
import java.io.*;
import java.util.*;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.junit.Test;
import static org.junit.Assert.*;
/** 
 * Test that streaming consumes stderr from the streaming process (before, during, and after the main processing of mapred input), and that stderr messages count as task progress.
 */
public class TestStreamingStderr {
  public TestStreamingStderr() throws IOException {
    UtilTest utilTest=new UtilTest(getClass().getName());
    utilTest.checkUserDir();
    utilTest.redirectIfAntJunit();
  }
  protected String[] genArgs(  File input,  File output,  int preLines,  int duringLines,  int postLines){
    return new String[]{"-input",input.getAbsolutePath(),"-output",output.getAbsolutePath(),"-mapper",UtilTest.makeJavaCommand(StderrApp.class,new String[]{Integer.toString(preLines),Integer.toString(duringLines),Integer.toString(postLines)}),"-reducer",StreamJob.REDUCE_NONE,"-jobconf","mapreduce.task.files.preserve.failedtasks=true","-jobconf","mapreduce.task.timeout=5000","-jobconf","stream.tmpdir=" + System.getProperty("test.build.data","/tmp")};
  }
  protected File setupInput(  String base,  boolean hasInput) throws IOException {
    File input=new File(base + "-input.txt");
    UtilTest.recursiveDelete(input);
    FileOutputStream in=new FileOutputStream(input.getAbsoluteFile());
    if (hasInput) {
      in.write("hello\n".getBytes());
    }
    in.close();
    return input;
  }
  protected File setupOutput(  String base) throws IOException {
    File output=new File(base + "-out");
    UtilTest.recursiveDelete(output);
    return output;
  }
  public void runStreamJob(  String baseName,  boolean hasInput,  int preLines,  int duringLines,  int postLines) throws Exception {
    File input=setupInput(baseName,hasInput);
    File output=setupOutput(baseName);
    boolean mayExit=false;
    int returnStatus=0;
    StreamJob job=new StreamJob(genArgs(input,output,preLines,duringLines,postLines),mayExit);
    returnStatus=job.go();
    assertEquals("StreamJob success",0,returnStatus);
  }
  @Test public void testStderrNoInput() throws Exception {
    runStreamJob("target/stderr-pre",false,10000,0,0);
  }
  @Test public void testStderrAfterOutput() throws Exception {
    runStreamJob("target/stderr-post",false,0,0,10000);
  }
  @Test public void testStderrCountsAsProgress() throws Exception {
    runStreamJob("target/stderr-progress",true,10,1000,0);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.hadoop.fs.s3a.auth;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.net.URI;
import java.nio.file.AccessDeniedException;
import java.util.ArrayList;
import java.util.List;
import java.util.stream.Collectors;
import java.util.stream.IntStream;
import com.amazonaws.auth.AWSCredentials;
import com.amazonaws.services.securitytoken.model.AWSSecurityTokenServiceException;
import org.junit.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.apache.commons.lang3.tuple.Pair;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.LocatedFileStatus;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.contract.ContractTestUtils;
import org.apache.hadoop.fs.s3a.AWSBadRequestException;
import org.apache.hadoop.fs.s3a.AbstractS3ATestBase;
import org.apache.hadoop.fs.s3a.MultipartUtils;
import org.apache.hadoop.fs.s3a.S3AFileSystem;
import org.apache.hadoop.fs.s3a.S3ATestConstants;
import org.apache.hadoop.fs.s3a.S3AUtils;
import org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider;
import org.apache.hadoop.fs.s3a.commit.CommitConstants;
import org.apache.hadoop.fs.s3a.commit.CommitOperations;
import org.apache.hadoop.fs.s3a.commit.files.PendingSet;
import org.apache.hadoop.fs.s3a.commit.files.SinglePendingCommit;
import static org.apache.hadoop.fs.contract.ContractTestUtils.assertRenameOutcome;
import static org.apache.hadoop.fs.contract.ContractTestUtils.touch;
import static org.apache.hadoop.fs.s3a.Constants.*;
import static org.apache.hadoop.fs.s3a.S3ATestUtils.*;
import static org.apache.hadoop.fs.s3a.S3AUtils.*;
import static org.apache.hadoop.fs.s3a.auth.RoleTestUtils.*;
import static org.apache.hadoop.fs.s3a.auth.RoleModel.*;
import static org.apache.hadoop.fs.s3a.auth.RolePolicies.*;
import static org.apache.hadoop.fs.s3a.auth.RoleTestUtils.forbidden;
import static org.apache.hadoop.test.GenericTestUtils.assertExceptionContains;
import static org.apache.hadoop.test.LambdaTestUtils.*;
/** 
 * Tests use of assumed roles. Only run if an assumed role is provided.
 */
@SuppressWarnings({"IOResourceOpenedButNotSafelyClosed","ThrowableNotThrown"}) public class ITestAssumeRole extends AbstractS3ATestBase {
  private static final Logger LOG=LoggerFactory.getLogger(ITestAssumeRole.class);
  private static final Path ROOT=new Path("/");
  /** 
 * test URI, built in setup.
 */
  private URI uri;
  /** 
 * A role FS; if non-null it is closed in teardown.
 */
  private S3AFileSystem roleFS;
  /** 
 * Error code from STS server.
 */
  protected static final String VALIDATION_ERROR="ValidationError";
  @Override public void setup() throws Exception {
    super.setup();
    assumeRoleTests();
    uri=new URI(S3ATestConstants.DEFAULT_CSVTEST_FILE);
  }
  @Override public void teardown() throws Exception {
    S3AUtils.closeAll(LOG,roleFS);
    super.teardown();
  }
  private void assumeRoleTests(){
    assume("No ARN for role tests",!getAssumedRoleARN().isEmpty());
  }
  private String getAssumedRoleARN(){
    return getContract().getConf().getTrimmed(ASSUMED_ROLE_ARN,"");
  }
  /** 
 * Expect a filesystem to fail to instantiate.
 * @param conf config to use
 * @param clazz class of exception to expect
 * @param text text in exception
 * @param < E > type of exception as inferred from clazz
 * @return the caught exception if it was of the expected type and contents
 * @throws Exception if the exception was the wrong class
 */
  private <E extends Throwable>E expectFileSystemCreateFailure(  Configuration conf,  Class<E> clazz,  String text) throws Exception {
    return interceptClosing(clazz,text,() -> new Path(getFileSystem().getUri()).getFileSystem(conf));
  }
  @Test public void testCreateCredentialProvider() throws IOException {
    describe("Create the credential provider");
    String roleARN=getAssumedRoleARN();
    Configuration conf=new Configuration(getContract().getConf());
    conf.set(AWS_CREDENTIALS_PROVIDER,AssumedRoleCredentialProvider.NAME);
    conf.set(ASSUMED_ROLE_ARN,roleARN);
    conf.set(ASSUMED_ROLE_SESSION_NAME,"valid");
    conf.set(ASSUMED_ROLE_SESSION_DURATION,"45m");
    bindRolePolicy(conf,RESTRICTED_POLICY);
    try (AssumedRoleCredentialProvider provider=new AssumedRoleCredentialProvider(uri,conf)){
      LOG.info("Provider is {}",provider);
      AWSCredentials credentials=provider.getCredentials();
      assertNotNull("Null credentials from " + provider,credentials);
    }
   }
  @Test public void testAssumedInvalidRole() throws Throwable {
    Configuration conf=new Configuration();
    conf.set(ASSUMED_ROLE_ARN,ROLE_ARN_EXAMPLE);
    interceptClosing(AWSSecurityTokenServiceException.class,"",() -> new AssumedRoleCredentialProvider(uri,conf));
  }
  @Test public void testAssumeRoleFSBadARN() throws Exception {
    describe("Attemnpt to create the FS with an invalid ARN");
    Configuration conf=createAssumedRoleConfig();
    conf.set(ASSUMED_ROLE_ARN,ROLE_ARN_EXAMPLE);
    expectFileSystemCreateFailure(conf,AccessDeniedException.class,"");
  }
  @Test public void testAssumeRoleNoARN() throws Exception {
    describe("Attemnpt to create the FS with no ARN");
    Configuration conf=createAssumedRoleConfig();
    conf.unset(ASSUMED_ROLE_ARN);
    expectFileSystemCreateFailure(conf,IOException.class,AssumedRoleCredentialProvider.E_NO_ROLE);
  }
  @Test public void testAssumeRoleFSBadPolicy() throws Exception {
    describe("Attemnpt to create the FS with malformed JSON");
    Configuration conf=createAssumedRoleConfig();
    conf.set(ASSUMED_ROLE_POLICY,"}");
    expectFileSystemCreateFailure(conf,AWSBadRequestException.class,"JSON");
  }
  @Test public void testAssumeRoleFSBadPolicy2() throws Exception {
    describe("Attempt to create the FS with valid but non-compliant JSON");
    Configuration conf=createAssumedRoleConfig();
    conf.set(ASSUMED_ROLE_POLICY,"{'json':'but not what AWS wants}");
    expectFileSystemCreateFailure(conf,AWSBadRequestException.class,"Syntax errors in policy");
  }
  @Test public void testAssumeRoleCannotAuthAssumedRole() throws Exception {
    describe("Assert that you can't use assumed roles to auth assumed roles");
    Configuration conf=createAssumedRoleConfig();
    conf.set(ASSUMED_ROLE_CREDENTIALS_PROVIDER,AssumedRoleCredentialProvider.NAME);
    expectFileSystemCreateFailure(conf,IOException.class,AssumedRoleCredentialProvider.E_FORBIDDEN_PROVIDER);
  }
  @Test public void testAssumeRoleBadInnerAuth() throws Exception {
    describe("Try to authenticate with a keypair with spaces");
    Configuration conf=createAssumedRoleConfig();
    conf.set(ASSUMED_ROLE_CREDENTIALS_PROVIDER,SimpleAWSCredentialsProvider.NAME);
    conf.set(ACCESS_KEY,"not valid");
    conf.set(SECRET_KEY,"not secret");
    expectFileSystemCreateFailure(conf,AWSBadRequestException.class,"not a valid " + "key=value pair (missing equal-sign) in Authorization header");
  }
  @Test public void testAssumeRoleBadInnerAuth2() throws Exception {
    describe("Try to authenticate with an invalid keypair");
    Configuration conf=createAssumedRoleConfig();
    conf.set(ASSUMED_ROLE_CREDENTIALS_PROVIDER,SimpleAWSCredentialsProvider.NAME);
    conf.set(ACCESS_KEY,"notvalid");
    conf.set(SECRET_KEY,"notsecret");
    expectFileSystemCreateFailure(conf,AccessDeniedException.class,"The security token included in the request is invalid");
  }
  @Test public void testAssumeRoleBadSession() throws Exception {
    describe("Try to authenticate with an invalid session");
    Configuration conf=createAssumedRoleConfig();
    conf.set(ASSUMED_ROLE_SESSION_NAME,"Session names cannot hava spaces!");
    expectFileSystemCreateFailure(conf,AWSBadRequestException.class,"Member must satisfy regular expression pattern");
  }
  /** 
 * A duration >1h is forbidden client-side in AWS SDK 1.11.271; with the ability to extend durations deployed in March 2018, duration checks will need to go server-side, and, presumably, later SDKs will remove the client side checks. This code exists to see when this happens.
 */
  @Test public void testAssumeRoleThreeHourSessionDuration() throws Exception {
    describe("Try to authenticate with a long session duration");
    Configuration conf=createAssumedRoleConfig();
    conf.setInt(ASSUMED_ROLE_SESSION_DURATION,3 * 60 * 60);
    try {
      new Path(getFileSystem().getUri()).getFileSystem(conf).close();
      LOG.info("Successfully created token of a duration >3h");
    }
 catch (    IOException ioe) {
      assertExceptionContains(VALIDATION_ERROR,ioe);
    }
  }
  /** 
 * A duration >1h is forbidden client-side in AWS SDK 1.11.271; with the ability to extend durations deployed in March 2018. with the later SDKs, the checks go server-side and later SDKs will remove the client side checks. This test doesn't look into the details of the exception to avoid being too brittle.
 */
  @Test public void testAssumeRoleThirtySixHourSessionDuration() throws Exception {
    describe("Try to authenticate with a long session duration");
    Configuration conf=createAssumedRoleConfig();
    conf.setInt(ASSUMED_ROLE_SESSION_DURATION,36 * 60 * 60);
    IOException ioe=expectFileSystemCreateFailure(conf,IOException.class,null);
  }
  /** 
 * Create the assumed role configuration.
 * @return a config bonded to the ARN of the assumed role
 */
  public Configuration createAssumedRoleConfig(){
    return createAssumedRoleConfig(getAssumedRoleARN());
  }
  /** 
 * Create a config for an assumed role; it also disables FS caching.
 * @param roleARN ARN of role
 * @return the new configuration
 */
  private Configuration createAssumedRoleConfig(  String roleARN){
    return newAssumedRoleConfig(getContract().getConf(),roleARN);
  }
  @Test public void testAssumeRoleUndefined() throws Throwable {
    describe("Verify that you cannot instantiate the" + " AssumedRoleCredentialProvider without a role ARN");
    Configuration conf=new Configuration();
    conf.set(ASSUMED_ROLE_ARN,"");
    interceptClosing(IOException.class,AssumedRoleCredentialProvider.E_NO_ROLE,() -> new AssumedRoleCredentialProvider(uri,conf));
  }
  @Test public void testAssumedIllegalDuration() throws Throwable {
    describe("Expect the constructor to fail if the session is to short");
    Configuration conf=new Configuration();
    conf.set(ASSUMED_ROLE_SESSION_DURATION,"30s");
    interceptClosing(AWSSecurityTokenServiceException.class,"",() -> new AssumedRoleCredentialProvider(uri,conf));
  }
  @Test public void testAssumeRoleCreateFS() throws IOException {
    describe("Create an FS client with the role and do some basic IO");
    String roleARN=getAssumedRoleARN();
    Configuration conf=createAssumedRoleConfig(roleARN);
    Path path=new Path(getFileSystem().getUri());
    LOG.info("Creating test FS and user {} with assumed role {}",conf.get(ACCESS_KEY),roleARN);
    try (FileSystem fs=path.getFileSystem(conf)){
      fs.getFileStatus(ROOT);
      fs.mkdirs(path("testAssumeRoleFS"));
    }
   }
  @Test public void testAssumeRoleRestrictedPolicyFS() throws Exception {
    describe("Restrict the policy for this session; verify that reads fail.");
    Configuration conf=createAssumedRoleConfig();
    bindRolePolicy(conf,RESTRICTED_POLICY);
    Path path=new Path(getFileSystem().getUri());
    boolean guarded=getFileSystem().hasMetadataStore();
    try (FileSystem fs=path.getFileSystem(conf)){
      if (!guarded) {
        forbidden("getFileStatus",() -> fs.getFileStatus(ROOT));
      }
      forbidden("",() -> fs.listStatus(ROOT));
      forbidden("",() -> fs.mkdirs(path("testAssumeRoleFS")));
    }
   }
  /** 
 * Tighten the extra policy on the assumed role call for torrent access, and verify that it blocks all other operations. That is: any non empty policy in the assumeRole API call overrides all of the policies attached to the role before. switches the role instance to only those policies in the
 */
  @Test public void testAssumeRolePoliciesOverrideRolePerms() throws Throwable {
    describe("extra policies in assumed roles need;" + " all required policies stated");
    Configuration conf=createAssumedRoleConfig();
    bindRolePolicy(conf,policy(statement(false,S3_ALL_BUCKETS,S3_GET_OBJECT_TORRENT),ALLOW_S3_GET_BUCKET_LOCATION,STATEMENT_S3GUARD_CLIENT,STATEMENT_ALLOW_SSE_KMS_RW));
    Path path=path("testAssumeRoleStillIncludesRolePerms");
    roleFS=(S3AFileSystem)path.getFileSystem(conf);
    assertTouchForbidden(roleFS,path);
  }
  /** 
 * After blocking all write verbs used by S3A, try to write data (fail) and read data (succeed). For S3Guard: full DDB RW access is retained. SSE-KMS key access is set to decrypt only.
 */
  @Test public void testReadOnlyOperations() throws Throwable {
    describe("Restrict role to read only");
    Configuration conf=createAssumedRoleConfig();
    bindRolePolicy(conf,policy(statement(false,S3_ALL_BUCKETS,S3_PATH_WRITE_OPERATIONS),STATEMENT_ALL_S3,STATEMENT_S3GUARD_CLIENT,STATEMENT_ALLOW_SSE_KMS_READ));
    Path path=methodPath();
    roleFS=(S3AFileSystem)path.getFileSystem(conf);
    roleFS.listStatus(ROOT);
    assertTouchForbidden(roleFS,path);
    roleFS.delete(path,true);
    getFileSystem().mkdirs(path);
    assertDeleteForbidden(this.roleFS,path);
    int counter=0;
    MultipartUtils.UploadIterator iterator=roleFS.listUploads("/");
    while (iterator.hasNext()) {
      counter++;
      iterator.next();
    }
    LOG.info("Found {} outstanding MPUs",counter);
  }
  /** 
 * Write successfully to the directory with full R/W access, fail to write or delete data elsewhere.
 */
  @SuppressWarnings("StringConcatenationMissingWhitespace") @Test public void testRestrictedWriteSubdir() throws Throwable {
    describe("Attempt writing to paths where a role only has" + " write access to a subdir of the bucket");
    Path restrictedDir=methodPath();
    Path child=new Path(restrictedDir,"child");
    S3AFileSystem fs=getFileSystem();
    fs.delete(restrictedDir,true);
    Configuration conf=createAssumedRoleConfig();
    bindRolePolicyStatements(conf,STATEMENT_S3GUARD_CLIENT,statement(true,S3_ALL_BUCKETS,S3_ROOT_READ_OPERATIONS),STATEMENT_ALLOW_SSE_KMS_RW,new Statement(Effects.Allow).addActions(S3_ALL_OPERATIONS).addResources(directory(restrictedDir)));
    roleFS=(S3AFileSystem)restrictedDir.getFileSystem(conf);
    roleFS.getFileStatus(ROOT);
    roleFS.mkdirs(restrictedDir);
    assertIsDirectory(restrictedDir);
    touch(roleFS,child);
    assertIsFile(child);
    ContractTestUtils.assertDeleted(roleFS,child,true);
    ContractTestUtils.assertDeleted(roleFS,restrictedDir,true);
    roleFS.delete(restrictedDir,false);
    Path sibling=new Path(restrictedDir.toUri() + "sibling");
    touch(fs,sibling);
    assertTouchForbidden(roleFS,sibling);
    assertDeleteForbidden(roleFS,sibling);
  }
  public Path methodPath() throws IOException {
    return path(getMethodName());
  }
  @Test public void testRestrictedRename() throws Throwable {
    describe("rename with parent paths not writeable");
    executeRestrictedRename(createAssumedRoleConfig());
  }
  @Test public void testRestrictedSingleDeleteRename() throws Throwable {
    describe("rename with parent paths not writeable" + " and multi-object delete disabled");
    Configuration conf=createAssumedRoleConfig();
    conf.setBoolean(ENABLE_MULTI_DELETE,false);
    executeRestrictedRename(conf);
  }
  /** 
 * Execute a sequence of rename operations with access locked down.
 * @param conf FS configuration
 */
  public void executeRestrictedRename(  final Configuration conf) throws IOException {
    Path basePath=methodPath();
    Path restrictedDir=new Path(basePath,"renameSrc");
    Path destPath=new Path(basePath,"renameDest");
    Path child=new Path(restrictedDir,"child");
    S3AFileSystem fs=getFileSystem();
    fs.delete(basePath,true);
    bindRolePolicyStatements(conf,STATEMENT_S3GUARD_CLIENT,STATEMENT_ALLOW_SSE_KMS_RW,statement(true,S3_ALL_BUCKETS,S3_ROOT_READ_OPERATIONS),new Statement(Effects.Allow).addActions(S3_PATH_RW_OPERATIONS).addResources(directory(restrictedDir)).addResources(directory(destPath)));
    roleFS=(S3AFileSystem)restrictedDir.getFileSystem(conf);
    roleFS.getFileStatus(ROOT);
    roleFS.mkdirs(restrictedDir);
    touch(roleFS,child);
    roleFS.delete(destPath,true);
    assertRenameOutcome(roleFS,child,destPath,true);
    assertIsFile(destPath);
    assertIsDirectory(restrictedDir);
    Path renamedDestPath=new Path(restrictedDir,destPath.getName());
    assertRenameOutcome(roleFS,destPath,restrictedDir,true);
    assertIsFile(renamedDestPath);
    roleFS.delete(restrictedDir,true);
    roleFS.delete(destPath,true);
  }
  @Test public void testRestrictedRenameReadOnlyData() throws Throwable {
    describe("rename with source read only, multidelete");
    executeRenameReadOnlyData(createAssumedRoleConfig());
  }
  @Test public void testRestrictedRenameReadOnlySingleDelete() throws Throwable {
    describe("rename with source read only single delete");
    Configuration conf=createAssumedRoleConfig();
    conf.setBoolean(ENABLE_MULTI_DELETE,false);
    executeRenameReadOnlyData(conf);
  }
  /** 
 * Without simulation of STS failures, and with STS overload likely to be very rare, there'll be no implicit test coverage of {@link AssumedRoleCredentialProvider#operationRetried(String,Exception,int,boolean)}. This test simply invokes the callback for both the first and second retry event. If the handler ever adds more than logging, this test ensures that things don't break.
 */
  @Test public void testAssumedRoleRetryHandler() throws Throwable {
    try (AssumedRoleCredentialProvider provider=new AssumedRoleCredentialProvider(getFileSystem().getUri(),createAssumedRoleConfig())){
      provider.operationRetried("retry",new IOException("failure"),0,true);
      provider.operationRetried("retry",new IOException("failure"),1,true);
    }
   }
  /** 
 * Execute a sequence of rename operations where the source data is read only to the client calling rename(). This will cause the inner delete() operations to fail, whose outcomes are explored. Multiple files are created (in parallel) for some renames, so exploring the outcome on bulk delete calls, including verifying that a MultiObjectDeleteException is translated to an AccessDeniedException. <ol> <li>The exception raised is AccessDeniedException, from single and multi DELETE calls.</li> <li>It happens after the COPY. Not ideal, but, well, we can't pretend it's a filesystem forever.</li> </ol>
 * @param conf FS configuration
 */
  public void executeRenameReadOnlyData(  final Configuration conf) throws Exception {
    assume("Does not work with S3Guard",!getFileSystem().hasMetadataStore());
    Path basePath=methodPath();
    Path destDir=new Path(basePath,"renameDest");
    Path readOnlyDir=new Path(basePath,"readonlyDir");
    Path readOnlyFile=new Path(readOnlyDir,"readonlyChild");
    S3AFileSystem fs=getFileSystem();
    fs.delete(basePath,true);
    touch(fs,readOnlyFile);
    bindRolePolicyStatements(conf,STATEMENT_S3GUARD_CLIENT,statement(true,S3_ALL_BUCKETS,S3_ROOT_READ_OPERATIONS),new Statement(Effects.Allow).addActions(S3_PATH_RW_OPERATIONS).addResources(directory(destDir)));
    roleFS=(S3AFileSystem)destDir.getFileSystem(conf);
    roleFS.delete(destDir,true);
    roleFS.mkdirs(destDir);
    forbidden(readOnlyFile.toString(),() -> roleFS.rename(readOnlyFile,destDir));
    assertIsFile(readOnlyFile);
    Path renamedFile=new Path(destDir,readOnlyFile.getName());
    assertIsFile(renamedFile);
    ContractTestUtils.assertDeleted(roleFS,renamedFile,true);
    assertFileCount("Empty Dest Dir",roleFS,destDir,0);
    int range=10;
    touchFiles(fs,readOnlyDir,range);
    final long createdFiles=range + 1;
    assertFileCount("files ready to rename",roleFS,readOnlyDir,createdFiles);
    LOG.info("Renaming readonly files {} to {}",readOnlyDir,destDir);
    AccessDeniedException ex=forbidden("",() -> roleFS.rename(readOnlyDir,destDir));
    LOG.info("Result of renaming read-only files is AccessDeniedException",ex);
    assertFileCount("files copied to the destination",roleFS,destDir,createdFiles);
    assertFileCount("files in the source directory",roleFS,readOnlyDir,createdFiles);
    forbidden("",() -> roleFS.delete(readOnlyDir,true));
  }
  /** 
 * Parallel-touch a set of files in the destination directory.
 * @param fs filesystem
 * @param destDir destination
 * @param range range 1..range inclusive of files to create.
 */
  public void touchFiles(  final S3AFileSystem fs,  final Path destDir,  final int range){
    IntStream.rangeClosed(1,range).parallel().forEach((i) -> eval(() -> touch(fs,new Path(destDir,"file-" + i))));
  }
  @Test public void testRestrictedCommitActions() throws Throwable {
    describe("Attempt commit operations against a path with restricted rights");
    Configuration conf=createAssumedRoleConfig();
    conf.setBoolean(CommitConstants.MAGIC_COMMITTER_ENABLED,true);
    final int uploadPartSize=5 * 1024 * 1024;
    Path basePath=methodPath();
    Path readOnlyDir=new Path(basePath,"readOnlyDir");
    Path writeableDir=new Path(basePath,"writeableDir");
    S3AFileSystem fs=getFileSystem();
    fs.delete(basePath,true);
    fs.mkdirs(readOnlyDir);
    bindRolePolicyStatements(conf,STATEMENT_S3GUARD_CLIENT,STATEMENT_ALLOW_SSE_KMS_RW,statement(true,S3_ALL_BUCKETS,S3_ROOT_READ_OPERATIONS),new Statement(Effects.Allow).addActions(S3_PATH_RW_OPERATIONS).addResources(directory(writeableDir)));
    roleFS=(S3AFileSystem)writeableDir.getFileSystem(conf);
    CommitOperations fullOperations=new CommitOperations(fs);
    CommitOperations operations=new CommitOperations(roleFS);
    File localSrc=File.createTempFile("source","");
    writeCSVData(localSrc);
    Path uploadDest=new Path(readOnlyDir,"restricted.csv");
    forbidden("initiate MultiPartUpload",() -> {
      return operations.uploadFileToPendingCommit(localSrc,uploadDest,"",uploadPartSize);
    }
);
    localSrc.delete();
    localSrc.mkdirs();
    int range=2;
    IntStream.rangeClosed(1,range).parallel().forEach((i) -> eval(() -> {
      String name="part-000" + i;
      File src=new File(localSrc,name);
      Path dest=new Path(readOnlyDir,name);
      writeCSVData(src);
      SinglePendingCommit pending=fullOperations.uploadFileToPendingCommit(src,dest,"",uploadPartSize);
      pending.save(fs,new Path(readOnlyDir,name + CommitConstants.PENDING_SUFFIX),true);
      assertTrue(src.delete());
    }
));
    try {
      Pair<PendingSet,List<Pair<LocatedFileStatus,IOException>>> pendingCommits=operations.loadSinglePendingCommits(readOnlyDir,true);
      List<SinglePendingCommit> commits=pendingCommits.getLeft().getCommits();
      assertEquals(range,commits.size());
      commits.parallelStream().forEach((c) -> {
        CommitOperations.MaybeIOE maybeIOE=operations.commit(c,"origin");
        Path path=c.destinationPath();
        assertCommitAccessDenied(path,maybeIOE);
      }
);
      LOG.info("abortAllSinglePendingCommits({})",readOnlyDir);
      assertCommitAccessDenied(readOnlyDir,operations.abortAllSinglePendingCommits(readOnlyDir,true));
      Path magicDestPath=new Path(readOnlyDir,CommitConstants.MAGIC + "/" + "magic.txt");
      forbidden("",() -> {
        touch(roleFS,magicDestPath);
        return fs.getFileStatus(magicDestPath);
      }
);
      forbidden("",() -> operations.abortPendingUploadsUnderPath(readOnlyDir));
    }
  finally {
      LOG.info("Cleanup");
      fullOperations.abortPendingUploadsUnderPath(readOnlyDir);
    }
  }
  /** 
 * Verifies that an operation returning a "MaybeIOE" failed with an AccessDeniedException in the maybe instance.
 * @param path path operated on
 * @param maybeIOE result to inspect
 */
  public void assertCommitAccessDenied(  final Path path,  final CommitOperations.MaybeIOE maybeIOE){
    IOException ex=maybeIOE.getException();
    assertNotNull("no IOE in " + maybeIOE + " for "+ path,ex);
    if (!(ex instanceof AccessDeniedException)) {
      ContractTestUtils.fail("Wrong exception class for commit to " + path,ex);
    }
  }
  /** 
 * Write some CSV data to a local file.
 * @param localSrc local file
 * @throws IOException failure
 */
  public void writeCSVData(  final File localSrc) throws IOException {
    try (FileOutputStream fo=new FileOutputStream(localSrc)){
      fo.write("1, true".getBytes());
    }
   }
  @Test public void testPartialDelete() throws Throwable {
    describe("delete with part of the child tree read only; multidelete");
    executePartialDelete(createAssumedRoleConfig());
  }
  @Test public void testPartialDeleteSingleDelete() throws Throwable {
    describe("delete with part of the child tree read only");
    Configuration conf=createAssumedRoleConfig();
    conf.setBoolean(ENABLE_MULTI_DELETE,false);
    executePartialDelete(conf);
  }
  /** 
 * Have a directory with full R/W permissions, but then remove write access underneath, and try to delete it.
 * @param conf FS configuration
 */
  public void executePartialDelete(  final Configuration conf) throws Exception {
    Path destDir=methodPath();
    Path readOnlyDir=new Path(destDir,"readonlyDir");
    S3AFileSystem fs=getFileSystem();
    fs.delete(destDir,true);
    bindRolePolicyStatements(conf,STATEMENT_S3GUARD_CLIENT,STATEMENT_ALLOW_SSE_KMS_RW,statement(true,S3_ALL_BUCKETS,S3_ALL_OPERATIONS),new Statement(Effects.Deny).addActions(S3_PATH_WRITE_OPERATIONS).addResources(directory(readOnlyDir)));
    roleFS=(S3AFileSystem)destDir.getFileSystem(conf);
    int range=10;
    touchFiles(fs,readOnlyDir,range);
    touchFiles(roleFS,destDir,range);
    forbidden("",() -> roleFS.delete(readOnlyDir,true));
    forbidden("",() -> roleFS.delete(destDir,true));
    Path pathWhichDoesntExist=new Path(readOnlyDir,"no-such-path");
    assertFalse("deleting " + pathWhichDoesntExist,roleFS.delete(pathWhichDoesntExist,true));
  }
  /** 
 * Assert that the number of files in a destination matches that expected.
 * @param text text to use in the message
 * @param fs filesystem
 * @param path path to list (recursively)
 * @param expected expected count
 * @throws IOException IO problem
 */
  private static void assertFileCount(  String text,  FileSystem fs,  Path path,  long expected) throws IOException {
    List<String> files=new ArrayList<>();
    applyLocatedFiles(fs.listFiles(path,true),(status) -> files.add(status.getPath().toString()));
    long actual=files.size();
    if (actual != expected) {
      String ls=files.stream().collect(Collectors.joining("\n"));
      fail(text + ": expected " + expected+ " files in "+ path+ " but got "+ actual+ "\n"+ ls);
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.hadoop.fs.s3a;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.contract.ContractTestUtils;
import org.apache.hadoop.test.LambdaTestUtils;
import org.junit.Test;
import java.io.FileNotFoundException;
import java.util.concurrent.Callable;
/** 
 * Tests behavior of a FileNotFound error that happens after open(), i.e. on the first read.
 */
public class ITestS3ADelayedFNF extends AbstractS3ATestBase {
  /** 
 * See debugging documentation <a href="https://cwiki.apache.org/confluence/display/HADOOP/S3A%3A+FileNotFound+Exception+on+Read">here</a>.
 * @throws Exception
 */
  @Test public void testNotFoundFirstRead() throws Exception {
    FileSystem fs=getFileSystem();
    Path p=path("some-file");
    ContractTestUtils.createFile(fs,p,false,new byte[]{20,21,22});
    final FSDataInputStream in=fs.open(p);
    assertDeleted(p,false);
    LambdaTestUtils.intercept(FileNotFoundException.class,new Callable<Integer>(){
      @Override public Integer call() throws Exception {
        return in.read();
      }
    }
);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.mapred.gridmix;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
import org.apache.hadoop.mapred.gridmix.RandomTextDataGenerator;
import static org.junit.Assert.*;
import org.junit.Test;
/** 
 * Test  {@link RandomTextDataGenerator}.
 */
public class TestRandomTextDataGenerator {
  /** 
 * Test if  {@link RandomTextDataGenerator} can generate random words of desired size.
 */
  @Test public void testRandomTextDataGenerator(){
    RandomTextDataGenerator rtdg=new RandomTextDataGenerator(10,0L,5);
    List<String> words=rtdg.getRandomWords();
    assertEquals("List size mismatch",10,words.size());
    Set<String> wordsSet=new HashSet<String>(words);
    assertEquals("List size mismatch due to duplicates",10,wordsSet.size());
    for (    String word : wordsSet) {
      assertEquals("Word size mismatch",5,word.length());
    }
  }
  /** 
 * Test if  {@link RandomTextDataGenerator} can generate same words given thesame list-size, word-length and seed.
 */
  @Test public void testRandomTextDataGeneratorRepeatability(){
    RandomTextDataGenerator rtdg1=new RandomTextDataGenerator(10,0L,5);
    List<String> words1=rtdg1.getRandomWords();
    RandomTextDataGenerator rtdg2=new RandomTextDataGenerator(10,0L,5);
    List<String> words2=rtdg2.getRandomWords();
    assertTrue("List mismatch",words1.equals(words2));
  }
  /** 
 * Test if  {@link RandomTextDataGenerator} can generate different words given different seeds.
 */
  @Test public void testRandomTextDataGeneratorUniqueness(){
    RandomTextDataGenerator rtdg1=new RandomTextDataGenerator(10,1L,5);
    Set<String> words1=new HashSet(rtdg1.getRandomWords());
    RandomTextDataGenerator rtdg2=new RandomTextDataGenerator(10,0L,5);
    Set<String> words2=new HashSet(rtdg2.getRandomWords());
    assertFalse("List size mismatch across lists",words1.equals(words2));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.tools.contract;
import static org.apache.hadoop.fs.contract.ContractTestUtils.*;
import java.io.IOException;
import java.util.Collections;
import java.util.HashMap;
import java.util.Map;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.LocatedFileStatus;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.RemoteIterator;
import org.apache.hadoop.fs.contract.AbstractFSContractTestBase;
import org.apache.hadoop.fs.contract.ContractTestUtils;
import org.apache.hadoop.io.SequenceFile;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Counter;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.test.GenericTestUtils;
import org.apache.hadoop.tools.CopyListingFileStatus;
import org.apache.hadoop.tools.DistCp;
import org.apache.hadoop.tools.DistCpConstants;
import org.apache.hadoop.tools.DistCpOptions;
import org.apache.hadoop.tools.mapred.CopyMapper;
import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.TestName;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
/** 
 * Contract test suite covering a file system's integration with DistCp.  The tests coordinate two file system instances: one "local", which is the local file system, and the other "remote", which is the file system implementation under test.  The tests in the suite cover both copying from local to remote (e.g. a backup use case) and copying from remote to local (e.g. a restore use case).
 */
public abstract class AbstractContractDistCpTest extends AbstractFSContractTestBase {
  private static final Logger LOG=LoggerFactory.getLogger(AbstractContractDistCpTest.class);
  public static final String SCALE_TEST_DISTCP_FILE_SIZE_KB="scale.test.distcp.file.size.kb";
  public static final int DEFAULT_DISTCP_SIZE_KB=1024;
  protected static final int MB=1024 * 1024;
  @Rule public TestName testName=new TestName();
  /** 
 * The timeout value is extended over the default so that large updates are allowed to take time, especially to remote stores.
 * @return the current test timeout
 */
  protected int getTestTimeoutMillis(){
    return 15 * 60 * 1000;
  }
  private Configuration conf;
  private FileSystem localFS, remoteFS;
  private Path localDir, remoteDir;
  private Path inputDir;
  private Path inputSubDir1;
  private Path inputSubDir2;
  private Path inputSubDir4;
  private Path inputFile1;
  private Path inputFile2;
  private Path inputFile3;
  private Path inputFile4;
  private Path inputFile5;
  private Path outputDir;
  private Path outputSubDir1;
  private Path outputSubDir2;
  private Path outputSubDir4;
  private Path outputFile1;
  private Path outputFile2;
  private Path outputFile3;
  private Path outputFile4;
  private Path outputFile5;
  private Path inputDirUnderOutputDir;
  @Override protected Configuration createConfiguration(){
    Configuration newConf=new Configuration();
    newConf.set("mapred.job.tracker","local");
    return newConf;
  }
  @Before @Override public void setup() throws Exception {
    super.setup();
    conf=getContract().getConf();
    localFS=FileSystem.getLocal(conf);
    remoteFS=getFileSystem();
    String className=getClass().getSimpleName();
    String testSubDir=className + "/" + testName.getMethodName();
    localDir=localFS.makeQualified(new Path(new Path(GenericTestUtils.getTestDir().toURI()),testSubDir + "/local"));
    mkdirs(localFS,localDir);
    remoteDir=path(testSubDir + "/remote");
    mkdirs(remoteFS,remoteDir);
    remoteFS.delete(remoteDir,true);
    localFS.delete(localDir,true);
  }
  /** 
 * Set up both input and output fields.
 * @param src source tree
 * @param dest dest tree
 */
  protected void initPathFields(  final Path src,  final Path dest){
    initInputFields(src);
    initOutputFields(dest);
  }
  /** 
 * Output field setup.
 * @param path path to set up
 */
  protected void initOutputFields(  final Path path){
    outputDir=new Path(path,"outputDir");
    inputDirUnderOutputDir=new Path(outputDir,"inputDir");
    outputFile1=new Path(inputDirUnderOutputDir,"file1");
    outputSubDir1=new Path(inputDirUnderOutputDir,"subDir1");
    outputFile2=new Path(outputSubDir1,"file2");
    outputSubDir2=new Path(inputDirUnderOutputDir,"subDir2/subDir2");
    outputFile3=new Path(outputSubDir2,"file3");
    outputSubDir4=new Path(inputDirUnderOutputDir,"subDir4/subDir4");
    outputFile4=new Path(outputSubDir4,"file4");
    outputFile5=new Path(outputSubDir4,"file5");
  }
  /** 
 * this path setup is used across different methods (copy, update, track) so they are set up as fields.
 * @param srcDir source directory for these to go under.
 */
  protected void initInputFields(  final Path srcDir){
    inputDir=new Path(srcDir,"inputDir");
    inputFile1=new Path(inputDir,"file1");
    inputSubDir1=new Path(inputDir,"subDir1");
    inputFile2=new Path(inputSubDir1,"file2");
    inputSubDir2=new Path(inputDir,"subDir2/subDir2");
    inputFile3=new Path(inputSubDir2,"file3");
    inputSubDir4=new Path(inputDir,"subDir4/subDir4");
    inputFile4=new Path(inputSubDir4,"file4");
    inputFile5=new Path(inputSubDir4,"file5");
  }
  protected FileSystem getLocalFS(){
    return localFS;
  }
  protected FileSystem getRemoteFS(){
    return remoteFS;
  }
  protected Path getLocalDir(){
    return localDir;
  }
  protected Path getRemoteDir(){
    return remoteDir;
  }
  @Test public void testUpdateDeepDirectoryStructureToRemote() throws Exception {
    describe("update a deep directory structure from local to remote");
    distCpDeepDirectoryStructure(localFS,localDir,remoteFS,remoteDir);
    distCpUpdateDeepDirectoryStructure(inputDirUnderOutputDir);
  }
  @Test public void testUpdateDeepDirectoryStructureNoChange() throws Exception {
    describe("update an unchanged directory structure" + " from local to remote; expect no copy");
    Path target=distCpDeepDirectoryStructure(localFS,localDir,remoteFS,remoteDir);
    describe("\nExecuting Update\n");
    Job job=distCpUpdate(localDir,target);
    assertCounterInRange(job,CopyMapper.Counter.SKIP,1,-1);
    assertCounterInRange(job,CopyMapper.Counter.BYTESCOPIED,0,0);
  }
  /** 
 * Assert that a counter is in a range; min and max values are inclusive.
 * @param job job to query
 * @param counter counter to examine
 * @param min min value, if negative "no minimum"
 * @param max max value, if negative "no maximum"
 * @throws IOException IO problem
 */
  void assertCounterInRange(  Job job,  Enum<?> counter,  long min,  long max) throws IOException {
    Counter c=job.getCounters().findCounter(counter);
    long value=c.getValue();
    String description=String.format("%s value %s",c.getDisplayName(),value,false);
    if (min >= 0) {
      assertTrue(description + " too below minimum " + min,value >= min);
    }
    if (max >= 0) {
      assertTrue(description + " above maximum " + max,value <= max);
    }
  }
  /** 
 * Do a distcp from the local source to the destination filesystem. This is executed as part of {@link #testUpdateDeepDirectoryStructureToRemote()}; it's designed to be overidden or wrapped by subclasses which wish to add more assertions. Life is complicated here by the way that the src/dest paths on a distcp is different with -update.
 * @param destDir output directory used by the initial distcp
 * @return the distcp job
 */
  protected Job distCpUpdateDeepDirectoryStructure(  final Path destDir) throws Exception {
    describe("Now do an incremental update with deletion of missing files");
    Path srcDir=inputDir;
    LOG.info("Source directory = {}, dest={}",srcDir,destDir);
    ContractTestUtils.assertPathsExist(localFS,"Paths for test are wrong",inputFile1,inputFile2,inputFile3,inputFile4,inputFile5);
    modifySourceDirectories();
    Job job=distCpUpdate(srcDir,destDir);
    Path outputFileNew1=new Path(outputSubDir2,"newfile1");
    lsR("Updated Remote",remoteFS,destDir);
    ContractTestUtils.assertPathDoesNotExist(remoteFS," deleted from " + inputFile1,outputFile1);
    ContractTestUtils.assertIsFile(remoteFS,outputFileNew1);
    ContractTestUtils.assertPathsDoNotExist(remoteFS,"DistCP should have deleted",outputFile3,outputFile4,outputSubDir4);
    assertCounterInRange(job,CopyMapper.Counter.COPY,1,1);
    assertCounterInRange(job,CopyMapper.Counter.SKIP,1,-1);
    return job;
  }
  /** 
 * Run distcp -update srcDir destDir.
 * @param srcDir local source directory
 * @param destDir remote destination directory.
 * @return the completed job
 * @throws Exception any failure.
 */
  private Job distCpUpdate(  final Path srcDir,  final Path destDir) throws Exception {
    describe("\nDistcp -update from " + srcDir + " to "+ destDir);
    lsR("Local to update",localFS,srcDir);
    lsR("Remote before update",remoteFS,destDir);
    return runDistCp(buildWithStandardOptions(new DistCpOptions.Builder(Collections.singletonList(srcDir),destDir).withDeleteMissing(true).withSyncFolder(true).withCRC(true).withOverwrite(false)));
  }
  /** 
 * Update the source directories as various tests expect, including adding a new file.
 * @return the path to the newly created file
 * @throws IOException IO failure
 */
  private Path modifySourceDirectories() throws IOException {
    localFS.delete(inputFile1,false);
    localFS.delete(inputFile3,false);
    localFS.delete(inputSubDir4,true);
    Path inputFileNew1=new Path(inputSubDir2,"newfile1");
    ContractTestUtils.touch(localFS,inputFileNew1);
    return inputFileNew1;
  }
  @Test public void testTrackDeepDirectoryStructureToRemote() throws Exception {
    describe("copy a deep directory structure from local to remote");
    Path destDir=distCpDeepDirectoryStructure(localFS,localDir,remoteFS,remoteDir);
    ContractTestUtils.assertIsDirectory(remoteFS,destDir);
    describe("Now do an incremental update and save of missing files");
    Path srcDir=inputDir;
    Path trackDir=new Path(localDir,"trackDir");
    describe("\nDirectories\n");
    lsR("Local to update",localFS,srcDir);
    lsR("Remote before update",remoteFS,destDir);
    ContractTestUtils.assertPathsExist(localFS,"Paths for test are wrong",inputFile2,inputFile3,inputFile4,inputFile5);
    Path inputFileNew1=modifySourceDirectories();
    runDistCp(buildWithStandardOptions(new DistCpOptions.Builder(Collections.singletonList(srcDir),inputDirUnderOutputDir).withTrackMissing(trackDir).withSyncFolder(true).withOverwrite(false)));
    lsR("tracked udpate",remoteFS,destDir);
    Path outputFileNew1=new Path(outputSubDir2,"newfile1");
    ContractTestUtils.assertIsFile(remoteFS,outputFileNew1);
    ContractTestUtils.assertPathExists(localFS,"tracking directory",trackDir);
    Path sortedSourceListing=new Path(trackDir,DistCpConstants.SOURCE_SORTED_FILE);
    ContractTestUtils.assertIsFile(localFS,sortedSourceListing);
    Path sortedTargetListing=new Path(trackDir,DistCpConstants.TARGET_SORTED_FILE);
    ContractTestUtils.assertIsFile(localFS,sortedTargetListing);
    ContractTestUtils.assertPathsExist(remoteFS,"DistCP should have retained",outputFile2,outputFile3,outputFile4,outputSubDir4);
    Map<String,Path> sourceFiles=new HashMap<>(10);
    Map<String,Path> targetFiles=new HashMap<>(10);
    try (SequenceFile.Reader sourceReader=new SequenceFile.Reader(conf,SequenceFile.Reader.file(sortedSourceListing));SequenceFile.Reader targetReader=new SequenceFile.Reader(conf,SequenceFile.Reader.file(sortedTargetListing))){
      CopyListingFileStatus copyStatus=new CopyListingFileStatus();
      Text name=new Text();
      while (sourceReader.next(name,copyStatus)) {
        String key=name.toString();
        Path path=copyStatus.getPath();
        LOG.info("{}: {}",key,path);
        sourceFiles.put(key,path);
      }
      while (targetReader.next(name,copyStatus)) {
        String key=name.toString();
        Path path=copyStatus.getPath();
        LOG.info("{}: {}",key,path);
        targetFiles.put(name.toString(),copyStatus.getPath());
      }
    }
     assertTrue("No " + outputFileNew1 + " in source listing",sourceFiles.containsValue(inputFileNew1));
    assertTrue("No " + outputFileNew1 + " in target listing",targetFiles.containsValue(outputFileNew1));
    assertTrue("No " + outputSubDir4 + " in target listing",targetFiles.containsValue(outputSubDir4));
    assertFalse("Found " + inputSubDir4 + " in source listing",sourceFiles.containsValue(inputSubDir4));
  }
  public void lsR(  final String description,  final FileSystem fs,  final Path dir) throws IOException {
    RemoteIterator<LocatedFileStatus> files=fs.listFiles(dir,true);
    LOG.info("{}: {}:",description,dir);
    StringBuilder sb=new StringBuilder();
    while (files.hasNext()) {
      LocatedFileStatus status=files.next();
      sb.append(String.format("  %s; type=%s; length=%d",status.getPath(),status.isDirectory() ? "dir" : "file",status.getLen()));
    }
    LOG.info("{}",sb);
  }
  @Test public void largeFilesToRemote() throws Exception {
    describe("copy multiple large files from local to remote");
    largeFiles(localFS,localDir,remoteFS,remoteDir);
  }
  @Test public void testDeepDirectoryStructureFromRemote() throws Exception {
    describe("copy a deep directory structure from remote to local");
    distCpDeepDirectoryStructure(remoteFS,remoteDir,localFS,localDir);
  }
  @Test public void testLargeFilesFromRemote() throws Exception {
    describe("copy multiple large files from remote to local");
    largeFiles(remoteFS,remoteDir,localFS,localDir);
  }
  /** 
 * Executes a DistCp using a file system sub-tree with multiple nesting levels. The filenames are those of the fields initialized in setup.
 * @param srcFS source FileSystem
 * @param srcDir source directory
 * @param dstFS destination FileSystem
 * @param dstDir destination directory
 * @return the target directory of the copy
 * @throws Exception if there is a failure
 */
  private Path distCpDeepDirectoryStructure(  FileSystem srcFS,  Path srcDir,  FileSystem dstFS,  Path dstDir) throws Exception {
    initPathFields(srcDir,dstDir);
    mkdirs(srcFS,inputSubDir1);
    mkdirs(srcFS,inputSubDir2);
    byte[] data1=dataset(100,33,43);
    createFile(srcFS,inputFile1,true,data1);
    byte[] data2=dataset(200,43,53);
    createFile(srcFS,inputFile2,true,data2);
    byte[] data3=dataset(300,53,63);
    createFile(srcFS,inputFile3,true,data3);
    createFile(srcFS,inputFile4,true,dataset(400,53,63));
    createFile(srcFS,inputFile5,true,dataset(500,53,63));
    Path target=new Path(dstDir,"outputDir");
    runDistCp(inputDir,target);
    ContractTestUtils.assertIsDirectory(dstFS,target);
    lsR("Destination tree after distcp",dstFS,target);
    verifyFileContents(dstFS,new Path(target,"inputDir/file1"),data1);
    verifyFileContents(dstFS,new Path(target,"inputDir/subDir1/file2"),data2);
    verifyFileContents(dstFS,new Path(target,"inputDir/subDir2/subDir2/file3"),data3);
    return target;
  }
  /** 
 * Executes a test using multiple large files.
 * @param srcFS source FileSystem
 * @param srcDir source directory
 * @param dstFS destination FileSystem
 * @param dstDir destination directory
 * @throws Exception if there is a failure
 */
  private void largeFiles(  FileSystem srcFS,  Path srcDir,  FileSystem dstFS,  Path dstDir) throws Exception {
    initPathFields(srcDir,dstDir);
    Path largeFile1=new Path(inputDir,"file1");
    Path largeFile2=new Path(inputDir,"file2");
    Path largeFile3=new Path(inputDir,"file3");
    mkdirs(srcFS,inputDir);
    int fileSizeKb=conf.getInt(SCALE_TEST_DISTCP_FILE_SIZE_KB,DEFAULT_DISTCP_SIZE_KB);
    int fileSizeMb=fileSizeKb / 1024;
    getLogger().info("{} with file size {}",testName.getMethodName(),fileSizeMb);
    byte[] data1=dataset((fileSizeMb + 1) * MB,33,43);
    createFile(srcFS,largeFile1,true,data1);
    byte[] data2=dataset((fileSizeMb + 2) * MB,43,53);
    createFile(srcFS,largeFile2,true,data2);
    byte[] data3=dataset((fileSizeMb + 3) * MB,53,63);
    createFile(srcFS,largeFile3,true,data3);
    Path target=new Path(dstDir,"outputDir");
    runDistCp(inputDir,target);
    ContractTestUtils.assertIsDirectory(dstFS,target);
    verifyFileContents(dstFS,new Path(target,"inputDir/file1"),data1);
    verifyFileContents(dstFS,new Path(target,"inputDir/file2"),data2);
    verifyFileContents(dstFS,new Path(target,"inputDir/file3"),data3);
  }
  /** 
 * Executes DistCp and asserts that the job finished successfully.
 * @param src source path
 * @param dst destination path
 * @throws Exception if there is a failure
 */
  private void runDistCp(  Path src,  Path dst) throws Exception {
    runDistCp(buildWithStandardOptions(new DistCpOptions.Builder(Collections.singletonList(src),dst)));
  }
  /** 
 * Run the distcp job.
 * @param optons distcp options
 * @return the job. It will have already completed.
 * @throws Exception failure
 */
  private Job runDistCp(  final DistCpOptions options) throws Exception {
    Job job=new DistCp(conf,options).execute();
    assertNotNull("Unexpected null job returned from DistCp execution.",job);
    assertTrue("DistCp job did not complete.",job.isComplete());
    assertTrue("DistCp job did not complete successfully.",job.isSuccessful());
    return job;
  }
  /** 
 * Add any standard options and then build.
 * @param builder DistCp option builder
 * @return the build options
 */
  private DistCpOptions buildWithStandardOptions(  DistCpOptions.Builder builder){
    return builder.withNumListstatusThreads(DistCpOptions.MAX_NUM_LISTSTATUS_THREADS).build();
  }
  /** 
 * Creates a directory and any ancestor directories required.
 * @param fs FileSystem in which to create directories
 * @param dir path of directory to create
 * @throws Exception if there is a failure
 */
  private static void mkdirs(  FileSystem fs,  Path dir) throws Exception {
    assertTrue("Failed to mkdir " + dir,fs.mkdirs(dir));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.fs.azurebfs;
import java.io.IOException;
import java.util.Arrays;
import java.util.Random;
import org.junit.Test;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotEquals;
import static org.junit.Assert.assertArrayEquals;
/** 
 * Test end to end between ABFS client and ABFS server.
 */
public class ITestAzureBlobFileSystemE2E extends AbstractAbfsIntegrationTest {
  private static final int TEST_BYTE=100;
  private static final int TEST_OFFSET=100;
  private static final int TEST_DEFAULT_BUFFER_SIZE=4 * 1024 * 1024;
  private static final int TEST_DEFAULT_READ_BUFFER_SIZE=1023900;
  public ITestAzureBlobFileSystemE2E() throws Exception {
    super();
    AbfsConfiguration configuration=this.getConfiguration();
    configuration.set(ConfigurationKeys.FS_AZURE_READ_AHEAD_QUEUE_DEPTH,"0");
  }
  @Test public void testWriteOneByteToFile() throws Exception {
    final Path testFilePath=new Path(methodName.getMethodName());
    testWriteOneByteToFile(testFilePath);
  }
  @Test public void testReadWriteBytesToFile() throws Exception {
    final AzureBlobFileSystem fs=getFileSystem();
    final Path testFilePath=new Path(methodName.getMethodName());
    testWriteOneByteToFile(testFilePath);
    try (FSDataInputStream inputStream=fs.open(testFilePath,TEST_DEFAULT_BUFFER_SIZE)){
      assertEquals(TEST_BYTE,inputStream.read());
    }
   }
  @Test(expected=IOException.class) public void testOOBWrites() throws Exception {
    final AzureBlobFileSystem fs=getFileSystem();
    int readBufferSize=fs.getAbfsStore().getAbfsConfiguration().getReadBufferSize();
    byte[] bytesToRead=new byte[readBufferSize];
    final byte[] b=new byte[2 * readBufferSize];
    new Random().nextBytes(b);
    final Path testFilePath=new Path(methodName.getMethodName());
    try (FSDataOutputStream writeStream=fs.create(testFilePath)){
      writeStream.write(b);
      writeStream.flush();
    }
     try (FSDataInputStream readStream=fs.open(testFilePath)){
      assertEquals(readBufferSize,readStream.read(bytesToRead,0,readBufferSize));
      try (FSDataOutputStream writeStream=fs.create(testFilePath)){
        writeStream.write(b);
        writeStream.flush();
      }
       assertEquals(readBufferSize,readStream.read(bytesToRead,0,readBufferSize));
    }
   }
  @Test public void testWriteWithBufferOffset() throws Exception {
    final AzureBlobFileSystem fs=getFileSystem();
    final Path testFilePath=new Path(methodName.getMethodName());
    final byte[] b=new byte[1024 * 1000];
    new Random().nextBytes(b);
    try (FSDataOutputStream stream=fs.create(testFilePath)){
      stream.write(b,TEST_OFFSET,b.length - TEST_OFFSET);
    }
     final byte[] r=new byte[TEST_DEFAULT_READ_BUFFER_SIZE];
    FSDataInputStream inputStream=fs.open(testFilePath,TEST_DEFAULT_BUFFER_SIZE);
    int result=inputStream.read(r);
    assertNotEquals(-1,result);
    assertArrayEquals(r,Arrays.copyOfRange(b,TEST_OFFSET,b.length));
    inputStream.close();
  }
  @Test public void testReadWriteHeavyBytesToFileWithSmallerChunks() throws Exception {
    final AzureBlobFileSystem fs=getFileSystem();
    final Path testFilePath=new Path(methodName.getMethodName());
    final byte[] writeBuffer=new byte[5 * 1000 * 1024];
    new Random().nextBytes(writeBuffer);
    write(testFilePath,writeBuffer);
    final byte[] readBuffer=new byte[5 * 1000 * 1024];
    FSDataInputStream inputStream=fs.open(testFilePath,TEST_DEFAULT_BUFFER_SIZE);
    int offset=0;
    while (inputStream.read(readBuffer,offset,TEST_OFFSET) > 0) {
      offset+=TEST_OFFSET;
    }
    assertArrayEquals(readBuffer,writeBuffer);
    inputStream.close();
  }
  private void testWriteOneByteToFile(  Path testFilePath) throws Exception {
    final AzureBlobFileSystem fs=getFileSystem();
    try (FSDataOutputStream stream=fs.create(testFilePath)){
      stream.write(TEST_BYTE);
    }
     FileStatus fileStatus=fs.getFileStatus(testFilePath);
    assertEquals(1,fileStatus.getLen());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.test;
import java.io.File;
import java.util.concurrent.atomic.AtomicInteger;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.crypto.key.JavaKeyStoreProvider;
import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.FileSystemTestHelper;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.permission.FsPermission;
import org.apache.hadoop.hdfs.DFSConfigKeys;
import org.apache.hadoop.hdfs.DFSTestUtil;
import org.apache.hadoop.hdfs.DistributedFileSystem;
import org.apache.hadoop.hdfs.MiniDFSCluster;
import org.apache.hadoop.hdfs.StripedFileTestUtil;
import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;
import org.junit.Test;
import org.junit.runners.model.FrameworkMethod;
import org.junit.runners.model.Statement;
public class TestHdfsHelper extends TestDirHelper {
  @Override @Test public void dummy(){
  }
  public static final String HADOOP_MINI_HDFS="test.hadoop.hdfs";
  private static final ThreadLocal<Configuration> HDFS_CONF_TL=new InheritableThreadLocal<Configuration>();
  private static final ThreadLocal<Path> HDFS_TEST_DIR_TL=new InheritableThreadLocal<Path>();
  @Override public Statement apply(  Statement statement,  FrameworkMethod frameworkMethod,  Object o){
    TestHdfs testHdfsAnnotation=frameworkMethod.getAnnotation(TestHdfs.class);
    if (testHdfsAnnotation != null) {
      statement=new HdfsStatement(statement,frameworkMethod.getName());
    }
    return super.apply(statement,frameworkMethod,o);
  }
private static class HdfsStatement extends Statement {
    private Statement statement;
    private String testName;
    public HdfsStatement(    Statement statement,    String testName){
      this.statement=statement;
      this.testName=testName;
    }
    @Override public void evaluate() throws Throwable {
      MiniDFSCluster miniHdfs=null;
      Configuration conf=HadoopUsersConfTestHelper.getBaseConf();
      if (Boolean.parseBoolean(System.getProperty(HADOOP_MINI_HDFS,"true"))) {
        miniHdfs=startMiniHdfs(conf);
        conf=miniHdfs.getConfiguration(0);
      }
      try {
        HDFS_CONF_TL.set(conf);
        HDFS_TEST_DIR_TL.set(resetHdfsTestDir(conf));
        statement.evaluate();
      }
  finally {
        HDFS_CONF_TL.remove();
        HDFS_TEST_DIR_TL.remove();
      }
    }
    private static AtomicInteger counter=new AtomicInteger();
    private Path resetHdfsTestDir(    Configuration conf){
      Path testDir=new Path("/tmp/" + testName + "-"+ counter.getAndIncrement());
      try {
        FileSystem fs=FileSystem.get(conf);
        fs.delete(testDir,true);
        fs.mkdirs(testDir);
      }
 catch (      Exception ex) {
        throw new RuntimeException(ex);
      }
      return testDir;
    }
  }
  /** 
 * Returns the HDFS test directory for the current test, only available when the test method has been annotated with  {@link TestHdfs}.
 * @return the HDFS test directory for the current test. It is an full/absolute<code>Path</code>.
 */
  public static Path getHdfsTestDir(){
    Path testDir=HDFS_TEST_DIR_TL.get();
    if (testDir == null) {
      throw new IllegalStateException("This test does not use @TestHdfs");
    }
    return testDir;
  }
  /** 
 * Returns a FileSystemAccess <code>JobConf</code> preconfigured with the FileSystemAccess cluster settings for testing. This configuration is only available when the test method has been annotated with  {@link TestHdfs}. Refer to  {@link HTestCase}header for details)
 * @return the FileSystemAccess <code>JobConf</code> preconfigured with the FileSystemAccess clustersettings for testing
 */
  public static Configuration getHdfsConf(){
    Configuration conf=HDFS_CONF_TL.get();
    if (conf == null) {
      throw new IllegalStateException("This test does not use @TestHdfs");
    }
    return new Configuration(conf);
  }
  public static final Path ENCRYPTION_ZONE=new Path("/ez");
  public static final Path ENCRYPTED_FILE=new Path("/ez/encfile");
  public static final Path ERASURE_CODING_DIR=new Path("/ec");
  public static final Path ERASURE_CODING_FILE=new Path("/ec/ecfile");
  public static final ErasureCodingPolicy ERASURE_CODING_POLICY=StripedFileTestUtil.getDefaultECPolicy();
  private static MiniDFSCluster MINI_DFS=null;
  private static synchronized MiniDFSCluster startMiniHdfs(  Configuration conf) throws Exception {
    if (MINI_DFS == null) {
      if (System.getProperty("hadoop.log.dir") == null) {
        System.setProperty("hadoop.log.dir",new File(TEST_DIR_ROOT,"hadoop-log").getAbsolutePath());
      }
      if (System.getProperty("test.build.data") == null) {
        System.setProperty("test.build.data",new File(TEST_DIR_ROOT,"hadoop-data").getAbsolutePath());
      }
      conf=new Configuration(conf);
      HadoopUsersConfTestHelper.addUserConf(conf);
      conf.set("fs.hdfs.impl.disable.cache","true");
      conf.set("dfs.block.access.token.enable","false");
      conf.set("dfs.permissions","true");
      conf.set("hadoop.security.authentication","simple");
      conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY,true);
      conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_XATTRS_ENABLED_KEY,true);
      FileSystemTestHelper helper=new FileSystemTestHelper();
      Path targetFile=new Path(new File(helper.getTestRootDir()).getAbsolutePath(),"test.jks");
      final String jceksPath=JavaKeyStoreProvider.SCHEME_NAME + "://file" + targetFile.toUri();
      conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_KEY_PROVIDER_PATH,jceksPath);
      MiniDFSCluster.Builder builder=new MiniDFSCluster.Builder(conf);
      int totalDataNodes=ERASURE_CODING_POLICY.getNumDataUnits() + ERASURE_CODING_POLICY.getNumParityUnits();
      builder.numDataNodes(totalDataNodes);
      MiniDFSCluster miniHdfs=builder.build();
      final String testkey="testkey";
      DFSTestUtil.createKey(testkey,miniHdfs,conf);
      DistributedFileSystem fileSystem=miniHdfs.getFileSystem();
      fileSystem.enableErasureCodingPolicy(ERASURE_CODING_POLICY.getName());
      fileSystem.getClient().setKeyProvider(miniHdfs.getNameNode().getNamesystem().getProvider());
      fileSystem.mkdirs(new Path("/tmp"));
      fileSystem.mkdirs(new Path("/user"));
      fileSystem.setPermission(new Path("/tmp"),FsPermission.valueOf("-rwxrwxrwx"));
      fileSystem.setPermission(new Path("/user"),FsPermission.valueOf("-rwxrwxrwx"));
      fileSystem.mkdirs(ENCRYPTION_ZONE);
      fileSystem.createEncryptionZone(ENCRYPTION_ZONE,testkey);
      fileSystem.create(ENCRYPTED_FILE).close();
      fileSystem.mkdirs(ERASURE_CODING_DIR);
      fileSystem.setErasureCodingPolicy(ERASURE_CODING_DIR,ERASURE_CODING_POLICY.getName());
      fileSystem.create(ERASURE_CODING_FILE).close();
      MINI_DFS=miniHdfs;
    }
    return MINI_DFS;
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.hdfs.protocol;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import org.junit.Test;
public class TestExtendedBlock {
  static final String POOL_A="blockpool-a";
  static final String POOL_B="blockpool-b";
  static final Block BLOCK_1_GS1=new Block(1L,100L,1L);
  static final Block BLOCK_1_GS2=new Block(1L,100L,2L);
  static final Block BLOCK_2_GS1=new Block(2L,100L,1L);
  @Test public void testEquals(){
    assertEquals(new ExtendedBlock(POOL_A,BLOCK_1_GS1),new ExtendedBlock(POOL_A,BLOCK_1_GS1));
    assertNotEquals(new ExtendedBlock(POOL_A,BLOCK_1_GS1),new ExtendedBlock(POOL_B,BLOCK_1_GS1));
    assertNotEquals(new ExtendedBlock(POOL_A,BLOCK_1_GS1),new ExtendedBlock(POOL_A,BLOCK_2_GS1));
    assertEquals(new ExtendedBlock(POOL_A,BLOCK_1_GS1),new ExtendedBlock(POOL_A,BLOCK_1_GS2));
  }
  @Test public void testHashcode(){
    assertNotEquals(new ExtendedBlock(POOL_A,BLOCK_1_GS1).hashCode(),new ExtendedBlock(POOL_B,BLOCK_1_GS1).hashCode());
    assertNotEquals(new ExtendedBlock(POOL_A,BLOCK_1_GS1).hashCode(),new ExtendedBlock(POOL_A,BLOCK_2_GS1).hashCode());
    assertEquals(new ExtendedBlock(POOL_A,BLOCK_1_GS1).hashCode(),new ExtendedBlock(POOL_A,BLOCK_1_GS1).hashCode());
  }
  private static void assertNotEquals(  Object a,  Object b){
    assertFalse("expected not equal: '" + a + "' and '"+ b+ "'",a.equals(b));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.hdfs;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
import java.io.IOException;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.contract.ContractTestUtils;
import org.apache.hadoop.fs.permission.FsPermission;
import org.apache.hadoop.hdfs.protocol.ErasureCodingPolicy;
import org.junit.After;
import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.Timeout;
/** 
 * This test ensures the statuses of EC files with the default policy.
 */
public class TestFileStatusWithDefaultECPolicy {
  private MiniDFSCluster cluster;
  private DistributedFileSystem fs;
  private DFSClient client;
  @Rule public Timeout globalTimeout=new Timeout(300000);
  @Before public void before() throws IOException {
    HdfsConfiguration conf=new HdfsConfiguration();
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
    cluster.waitActive();
    fs=cluster.getFileSystem();
    client=fs.getClient();
    fs.enableErasureCodingPolicy(getEcPolicy().getName());
  }
  @After public void after(){
    if (cluster != null) {
      cluster.shutdown();
      cluster=null;
    }
  }
  public ErasureCodingPolicy getEcPolicy(){
    return StripedFileTestUtil.getDefaultECPolicy();
  }
  @Test public void testFileStatusWithECPolicy() throws Exception {
    final Path dir=new Path("/foo");
    assertTrue(fs.mkdir(dir,FsPermission.getDirDefault()));
    ContractTestUtils.assertNotErasureCoded(fs,dir);
    assertNull(client.getFileInfo(dir.toString()).getErasureCodingPolicy());
    final Path file=new Path(dir,"foo");
    fs.create(file).close();
    assertNull(client.getFileInfo(file.toString()).getErasureCodingPolicy());
    ContractTestUtils.assertNotErasureCoded(fs,file);
    fs.delete(file,true);
    final ErasureCodingPolicy ecPolicy1=getEcPolicy();
    fs.setErasureCodingPolicy(dir,ecPolicy1.getName());
    ContractTestUtils.assertErasureCoded(fs,dir);
    final ErasureCodingPolicy ecPolicy2=client.getFileInfo(dir.toUri().getPath()).getErasureCodingPolicy();
    assertNotNull(ecPolicy2);
    assertTrue(ecPolicy1.equals(ecPolicy2));
    fs.create(file).close();
    final ErasureCodingPolicy ecPolicy3=fs.getClient().getFileInfo(file.toUri().getPath()).getErasureCodingPolicy();
    assertNotNull(ecPolicy3);
    assertTrue(ecPolicy1.equals(ecPolicy3));
    ContractTestUtils.assertErasureCoded(fs,file);
    FileStatus status=fs.getFileStatus(file);
    assertTrue(file + " should have erasure coding set in " + "FileStatus#toString(): "+ status,status.toString().contains("isErasureCoded=true"));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.hdfs.server.namenode;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
import java.io.FileNotFoundException;
import java.util.ArrayList;
import java.util.List;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.hdfs.DFSTestUtil;
import org.apache.hadoop.hdfs.DFSUtil;
import org.apache.hadoop.hdfs.DistributedFileSystem;
import org.apache.hadoop.hdfs.MiniDFSCluster;
import org.apache.hadoop.hdfs.protocol.SnapshotException;
import org.apache.hadoop.hdfs.server.namenode.snapshot.Snapshot;
import org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager;
import org.junit.AfterClass;
import org.junit.Assert;
import org.junit.Before;
import org.junit.BeforeClass;
import org.junit.Test;
import org.mockito.Mockito;
/** 
 * Test snapshot related operations. 
 */
public class TestSnapshotPathINodes {
  private static final long seed=0;
  private static final short REPLICATION=3;
  static private final Path dir=new Path("/TestSnapshot");
  static private final Path sub1=new Path(dir,"sub1");
  static private final Path file1=new Path(sub1,"file1");
  static private final Path file2=new Path(sub1,"file2");
  static private MiniDFSCluster cluster;
  static private FSDirectory fsdir;
  static private DistributedFileSystem hdfs;
  @BeforeClass public static void setUp() throws Exception {
    Configuration conf=new Configuration();
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(REPLICATION).build();
    cluster.waitActive();
    FSNamesystem fsn=cluster.getNamesystem();
    fsdir=fsn.getFSDirectory();
    hdfs=cluster.getFileSystem();
  }
  @Before public void reset() throws Exception {
    DFSTestUtil.createFile(hdfs,file1,1024,REPLICATION,seed);
    DFSTestUtil.createFile(hdfs,file2,1024,REPLICATION,seed);
  }
  @AfterClass public static void tearDown() throws Exception {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
  /** 
 * Test allow-snapshot operation. 
 */
  @Test(timeout=15000) public void testAllowSnapshot() throws Exception {
    final String pathStr=sub1.toString();
    final INode before=fsdir.getINode(pathStr);
    Assert.assertFalse(before.asDirectory().isSnapshottable());
    final Path path=new Path(pathStr);
    hdfs.allowSnapshot(path);
{
      final INode after=fsdir.getINode(pathStr);
      Assert.assertTrue(after.asDirectory().isSnapshottable());
    }
    hdfs.disallowSnapshot(path);
{
      final INode after=fsdir.getINode(pathStr);
      Assert.assertFalse(after.asDirectory().isSnapshottable());
    }
  }
  static Snapshot getSnapshot(  INodesInPath inodesInPath,  String name,  int index){
    if (name == null) {
      return null;
    }
    final INode inode=inodesInPath.getINode(index - 1);
    return inode.asDirectory().getSnapshot(DFSUtil.string2Bytes(name));
  }
  static void assertSnapshot(  INodesInPath inodesInPath,  boolean isSnapshot,  final Snapshot snapshot,  int index){
    assertEquals(isSnapshot,inodesInPath.isSnapshot());
    assertEquals(Snapshot.getSnapshotId(isSnapshot ? snapshot : null),inodesInPath.getPathSnapshotId());
    if (!isSnapshot) {
      assertEquals(Snapshot.getSnapshotId(snapshot),inodesInPath.getLatestSnapshotId());
    }
    if (isSnapshot && index >= 0) {
      assertEquals(Snapshot.Root.class,inodesInPath.getINode(index).getClass());
    }
  }
  static void assertINodeFile(  INode inode,  Path path){
    assertEquals(path.getName(),inode.getLocalName());
    assertEquals(INodeFile.class,inode.getClass());
  }
  /** 
 * for normal (non-snapshot) file.
 */
  @Test(timeout=15000) public void testNonSnapshotPathINodes() throws Exception {
    byte[][] components=INode.getPathComponents(file1.toString());
    INodesInPath nodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
    assertEquals(nodesInPath.length(),components.length);
    assertSnapshot(nodesInPath,false,null,-1);
    for (int i=0; i < components.length; i++) {
      assertEquals(components[i],nodesInPath.getPathComponent(i));
    }
    assertTrue("file1=" + file1 + ", nodesInPath="+ nodesInPath,nodesInPath.getINode(components.length - 1) != null);
    assertEquals(nodesInPath.getINode(components.length - 1).getFullPathName(),file1.toString());
    assertEquals(nodesInPath.getINode(components.length - 2).getFullPathName(),sub1.toString());
    assertEquals(nodesInPath.getINode(components.length - 3).getFullPathName(),dir.toString());
    assertEquals(Path.SEPARATOR,nodesInPath.getPath(0));
    assertEquals(dir.toString(),nodesInPath.getPath(1));
    assertEquals(sub1.toString(),nodesInPath.getPath(2));
    assertEquals(file1.toString(),nodesInPath.getPath(3));
    assertEquals(file1.getParent().toString(),nodesInPath.getParentINodesInPath().getPath());
    nodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
    assertEquals(nodesInPath.length(),components.length);
    assertSnapshot(nodesInPath,false,null,-1);
    assertEquals(nodesInPath.getLastINode().getFullPathName(),file1.toString());
  }
  /** 
 * for snapshot file.
 */
  @Test(timeout=15000) public void testSnapshotPathINodes() throws Exception {
    hdfs.allowSnapshot(sub1);
    hdfs.createSnapshot(sub1,"s1");
    String snapshotPath=sub1.toString() + "/.snapshot/s1/file1";
    byte[][] components=INode.getPathComponents(snapshotPath);
    INodesInPath nodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
    assertEquals(nodesInPath.length(),components.length - 1);
    final Snapshot snapshot=getSnapshot(nodesInPath,"s1",3);
    assertSnapshot(nodesInPath,true,snapshot,3);
    assertEquals(".snapshot/s1",DFSUtil.bytes2String(nodesInPath.getPathComponent(3)));
    assertTrue(nodesInPath.getINode(3) instanceof Snapshot.Root);
    assertEquals("s1",nodesInPath.getINode(3).getLocalName());
    INode snapshotFileNode=nodesInPath.getLastINode();
    assertINodeFile(snapshotFileNode,file1);
    assertTrue(snapshotFileNode.getParent().isWithSnapshot());
    nodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
    assertEquals(nodesInPath.length(),components.length - 1);
    assertSnapshot(nodesInPath,true,snapshot,3);
    assertINodeFile(nodesInPath.getLastINode(),file1);
    String dotSnapshotPath=sub1.toString() + "/.snapshot";
    components=INode.getPathComponents(dotSnapshotPath);
    nodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
    assertEquals(nodesInPath.length(),components.length);
    assertEquals(".snapshot",DFSUtil.bytes2String(nodesInPath.getLastLocalName()));
    assertNull(nodesInPath.getLastINode());
    assertEquals(sub1.toString(),nodesInPath.getParentINodesInPath().getPath());
    assertSnapshot(nodesInPath,true,snapshot,-1);
    assertNull(nodesInPath.getLastINode());
    assertEquals(nodesInPath.getINode(-2).getFullPathName(),sub1.toString());
    assertTrue(nodesInPath.getINode(-2).isDirectory());
    String[] invalidPathComponent={"invalidDir","foo",".snapshot","bar"};
    Path invalidPath=new Path(invalidPathComponent[0]);
    for (int i=1; i < invalidPathComponent.length; i++) {
      invalidPath=new Path(invalidPath,invalidPathComponent[i]);
      try {
        hdfs.getFileStatus(invalidPath);
        Assert.fail();
      }
 catch (      FileNotFoundException fnfe) {
        System.out.println("The exception is expected: " + fnfe);
      }
    }
    hdfs.deleteSnapshot(sub1,"s1");
    hdfs.disallowSnapshot(sub1);
  }
  /** 
 * for snapshot file after deleting the original file.
 */
  @Test(timeout=15000) public void testSnapshotPathINodesAfterDeletion() throws Exception {
    hdfs.allowSnapshot(sub1);
    hdfs.createSnapshot(sub1,"s2");
    hdfs.delete(file1,false);
    final Snapshot snapshot;
{
      String snapshotPath=sub1.toString() + "/.snapshot/s2/file1";
      byte[][] components=INode.getPathComponents(snapshotPath);
      INodesInPath nodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
      assertEquals(nodesInPath.length(),components.length - 1);
      snapshot=getSnapshot(nodesInPath,"s2",3);
      assertSnapshot(nodesInPath,true,snapshot,3);
      final INode inode=nodesInPath.getLastINode();
      assertEquals(file1.getName(),inode.getLocalName());
      assertTrue(inode.asFile().isWithSnapshot());
    }
    byte[][] components=INode.getPathComponents(file1.toString());
    INodesInPath nodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
    assertEquals(nodesInPath.length(),components.length);
    assertEquals(getNumNonNull(nodesInPath),components.length - 1);
    assertSnapshot(nodesInPath,false,snapshot,-1);
    assertNull(nodesInPath.getINode(components.length - 1));
    assertEquals(nodesInPath.getINode(components.length - 2).getFullPathName(),sub1.toString());
    assertEquals(nodesInPath.getINode(components.length - 3).getFullPathName(),dir.toString());
    hdfs.deleteSnapshot(sub1,"s2");
    hdfs.disallowSnapshot(sub1);
  }
  private int getNumNonNull(  INodesInPath iip){
    for (int i=iip.length() - 1; i >= 0; i--) {
      if (iip.getINode(i) != null) {
        return i + 1;
      }
    }
    return 0;
  }
  /** 
 * for snapshot file while adding a new file after snapshot.
 */
  @Test(timeout=15000) public void testSnapshotPathINodesWithAddedFile() throws Exception {
    hdfs.allowSnapshot(sub1);
    hdfs.createSnapshot(sub1,"s4");
    final Path file3=new Path(sub1,"file3");
    DFSTestUtil.createFile(hdfs,file3,1024,REPLICATION,seed);
    Snapshot s4;
{
      String snapshotPath=sub1.toString() + "/.snapshot/s4/file3";
      byte[][] components=INode.getPathComponents(snapshotPath);
      INodesInPath nodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
      assertEquals(nodesInPath.length(),components.length - 1);
      assertEquals(getNumNonNull(nodesInPath),components.length - 2);
      s4=getSnapshot(nodesInPath,"s4",3);
      assertSnapshot(nodesInPath,true,s4,3);
      assertNull(nodesInPath.getINode(nodesInPath.length() - 1));
    }
    byte[][] components=INode.getPathComponents(file3.toString());
    INodesInPath nodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
    assertEquals(nodesInPath.length(),components.length);
    assertSnapshot(nodesInPath,false,s4,-1);
    assertEquals(nodesInPath.getINode(components.length - 1).getFullPathName(),file3.toString());
    assertEquals(nodesInPath.getINode(components.length - 2).getFullPathName(),sub1.toString());
    assertEquals(nodesInPath.getINode(components.length - 3).getFullPathName(),dir.toString());
    hdfs.deleteSnapshot(sub1,"s4");
    hdfs.disallowSnapshot(sub1);
  }
  /** 
 * for snapshot file while modifying file after snapshot.
 */
  @Test(timeout=15000) public void testSnapshotPathINodesAfterModification() throws Exception {
    byte[][] components=INode.getPathComponents(file1.toString());
    INodesInPath nodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
    assertEquals(nodesInPath.length(),components.length);
    assertEquals(nodesInPath.getINode(components.length - 1).getFullPathName(),file1.toString());
    final long modTime=nodesInPath.getINode(nodesInPath.length() - 1).getModificationTime();
    hdfs.allowSnapshot(sub1);
    hdfs.createSnapshot(sub1,"s3");
    DFSTestUtil.appendFile(hdfs,file1,"the content for appending");
    String snapshotPath=sub1.toString() + "/.snapshot/s3/file1";
    components=INode.getPathComponents(snapshotPath);
    INodesInPath ssNodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
    assertEquals(ssNodesInPath.length(),components.length - 1);
    final Snapshot s3=getSnapshot(ssNodesInPath,"s3",3);
    assertSnapshot(ssNodesInPath,true,s3,3);
    INode snapshotFileNode=ssNodesInPath.getLastINode();
    assertEquals(snapshotFileNode.getLocalName(),file1.getName());
    assertTrue(snapshotFileNode.asFile().isWithSnapshot());
    assertEquals(modTime,snapshotFileNode.getModificationTime(ssNodesInPath.getPathSnapshotId()));
    components=INode.getPathComponents(file1.toString());
    INodesInPath newNodesInPath=INodesInPath.resolve(fsdir.rootDir,components,false);
    assertSnapshot(newNodesInPath,false,s3,-1);
    assertEquals(newNodesInPath.length(),components.length);
    final int last=components.length - 1;
    assertEquals(newNodesInPath.getINode(last).getFullPathName(),file1.toString());
    Assert.assertFalse(modTime == newNodesInPath.getINode(last).getModificationTime());
    hdfs.deleteSnapshot(sub1,"s3");
    hdfs.disallowSnapshot(sub1);
  }
  @Test public void testShortCircuitSnapshotSearch() throws SnapshotException {
    FSNamesystem fsn=cluster.getNamesystem();
    SnapshotManager sm=fsn.getSnapshotManager();
    assertEquals(0,sm.getNumSnapshottableDirs());
    INodesInPath iip=Mockito.mock(INodesInPath.class);
    List<INodeDirectory> snapDirs=new ArrayList<>();
    FSDirSnapshotOp.checkSnapshot(fsn.getFSDirectory(),iip,snapDirs);
    Mockito.verifyZeroInteractions(iip);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.hdfs.server.namenode;
import java.util.HashMap;
import java.util.LinkedHashMap;
import java.util.Map;
import org.apache.hadoop.fs.StorageType;
import org.apache.hadoop.hdfs.protocol.BlockStoragePolicy;
import org.apache.hadoop.hdfs.server.blockmanagement.BlockStoragePolicySuite;
import org.apache.hadoop.hdfs.server.namenode.StoragePolicySummary.StorageTypeAllocation;
import org.junit.Assert;
import org.junit.Test;
public class TestStoragePolicySummary {
  private Map<String,Long> convertToStringMap(  StoragePolicySummary sts){
    LinkedHashMap<String,Long> actualOutput=new LinkedHashMap<>();
    for (    Map.Entry<StorageTypeAllocation,Long> entry : StoragePolicySummary.sortByComparator(sts.storageComboCounts)) {
      actualOutput.put(entry.getKey().toString(),entry.getValue());
    }
    return actualOutput;
  }
  @Test public void testMultipleHots(){
    BlockStoragePolicySuite bsps=BlockStoragePolicySuite.createDefaultSuite();
    StoragePolicySummary sts=new StoragePolicySummary(bsps.getAllPolicies());
    BlockStoragePolicy hot=bsps.getPolicy("HOT");
    sts.add(new StorageType[]{StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK,StorageType.DISK},hot);
    Map<String,Long> actualOutput=convertToStringMap(sts);
    Assert.assertEquals(4,actualOutput.size());
    Map<String,Long> expectedOutput=new HashMap<>();
    expectedOutput.put("HOT|DISK:1(HOT)",1l);
    expectedOutput.put("HOT|DISK:2(HOT)",1l);
    expectedOutput.put("HOT|DISK:3(HOT)",1l);
    expectedOutput.put("HOT|DISK:4(HOT)",1l);
    Assert.assertEquals(expectedOutput,actualOutput);
  }
  @Test public void testMultipleHotsWithDifferentCounts(){
    BlockStoragePolicySuite bsps=BlockStoragePolicySuite.createDefaultSuite();
    StoragePolicySummary sts=new StoragePolicySummary(bsps.getAllPolicies());
    BlockStoragePolicy hot=bsps.getPolicy("HOT");
    sts.add(new StorageType[]{StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK,StorageType.DISK},hot);
    Map<String,Long> actualOutput=convertToStringMap(sts);
    Assert.assertEquals(4,actualOutput.size());
    Map<String,Long> expectedOutput=new HashMap<>();
    expectedOutput.put("HOT|DISK:1(HOT)",1l);
    expectedOutput.put("HOT|DISK:2(HOT)",2l);
    expectedOutput.put("HOT|DISK:3(HOT)",2l);
    expectedOutput.put("HOT|DISK:4(HOT)",1l);
    Assert.assertEquals(expectedOutput,actualOutput);
  }
  @Test public void testMultipleWarmsInDifferentOrder(){
    BlockStoragePolicySuite bsps=BlockStoragePolicySuite.createDefaultSuite();
    StoragePolicySummary sts=new StoragePolicySummary(bsps.getAllPolicies());
    BlockStoragePolicy warm=bsps.getPolicy("WARM");
    sts.add(new StorageType[]{StorageType.DISK,StorageType.ARCHIVE},warm);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.DISK},warm);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.DISK,StorageType.DISK},warm);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.ARCHIVE,StorageType.DISK},warm);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.ARCHIVE},warm);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.ARCHIVE,StorageType.ARCHIVE},warm);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.DISK,StorageType.ARCHIVE},warm);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.DISK},warm);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.DISK,StorageType.DISK},warm);
    Map<String,Long> actualOutput=convertToStringMap(sts);
    Assert.assertEquals(4,actualOutput.size());
    Map<String,Long> expectedOutput=new HashMap<>();
    expectedOutput.put("WARM|DISK:1,ARCHIVE:1(WARM)",2l);
    expectedOutput.put("WARM|DISK:2,ARCHIVE:1",3l);
    expectedOutput.put("WARM|DISK:1,ARCHIVE:2(WARM)",3l);
    expectedOutput.put("WARM|DISK:2,ARCHIVE:2",1l);
    Assert.assertEquals(expectedOutput,actualOutput);
  }
  @Test public void testDifferentSpecifiedPolicies(){
    BlockStoragePolicySuite bsps=BlockStoragePolicySuite.createDefaultSuite();
    StoragePolicySummary sts=new StoragePolicySummary(bsps.getAllPolicies());
    BlockStoragePolicy hot=bsps.getPolicy("HOT");
    BlockStoragePolicy warm=bsps.getPolicy("WARM");
    BlockStoragePolicy cold=bsps.getPolicy("COLD");
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK},warm);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK},cold);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.ARCHIVE,StorageType.ARCHIVE},hot);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.DISK,StorageType.ARCHIVE},warm);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.DISK},cold);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.DISK},cold);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.ARCHIVE},hot);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.ARCHIVE},hot);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.ARCHIVE},warm);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.ARCHIVE},cold);
    Map<String,Long> actualOutput=convertToStringMap(sts);
    Assert.assertEquals(9,actualOutput.size());
    Map<String,Long> expectedOutput=new HashMap<>();
    expectedOutput.put("HOT|DISK:3(HOT)",2l);
    expectedOutput.put("COLD|DISK:1,ARCHIVE:2(WARM)",2l);
    expectedOutput.put("HOT|ARCHIVE:3(COLD)",2l);
    expectedOutput.put("WARM|DISK:3(HOT)",1l);
    expectedOutput.put("COLD|DISK:3(HOT)",1l);
    expectedOutput.put("WARM|ARCHIVE:3(COLD)",1l);
    expectedOutput.put("WARM|DISK:1,ARCHIVE:2(WARM)",1l);
    expectedOutput.put("COLD|ARCHIVE:3(COLD)",1l);
    expectedOutput.put("HOT|DISK:1,ARCHIVE:2(WARM)",1l);
    Assert.assertEquals(expectedOutput,actualOutput);
  }
  @Test public void testSortInDescendingOrder(){
    BlockStoragePolicySuite bsps=BlockStoragePolicySuite.createDefaultSuite();
    StoragePolicySummary sts=new StoragePolicySummary(bsps.getAllPolicies());
    BlockStoragePolicy hot=bsps.getPolicy("HOT");
    BlockStoragePolicy warm=bsps.getPolicy("WARM");
    BlockStoragePolicy cold=bsps.getPolicy("COLD");
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.DISK,StorageType.DISK},hot);
    sts.add(new StorageType[]{StorageType.DISK,StorageType.ARCHIVE,StorageType.ARCHIVE},warm);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.DISK,StorageType.ARCHIVE},warm);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.DISK},warm);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.ARCHIVE},cold);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.ARCHIVE},cold);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.ARCHIVE},cold);
    sts.add(new StorageType[]{StorageType.ARCHIVE,StorageType.ARCHIVE,StorageType.ARCHIVE},cold);
    Map<String,Long> actualOutput=convertToStringMap(sts);
    Assert.assertEquals(3,actualOutput.size());
    Map<String,Long> expectedOutput=new LinkedHashMap<>();
    expectedOutput.put("COLD|ARCHIVE:3(COLD)",4l);
    expectedOutput.put("WARM|DISK:1,ARCHIVE:2(WARM)",3l);
    expectedOutput.put("HOT|DISK:3(HOT)",2l);
    Assert.assertEquals(expectedOutput.toString(),actualOutput.toString());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at <p/> http://www.apache.org/licenses/LICENSE-2.0 <p/> Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.hdfs.server.diskbalancer;
import org.apache.hadoop.fs.StorageType;
import org.apache.hadoop.hdfs.server.diskbalancer.connectors.ClusterConnector;
import org.apache.hadoop.hdfs.server.diskbalancer.connectors.ConnectorFactory;
import org.apache.hadoop.hdfs.server.diskbalancer.connectors.NullConnector;
import org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerCluster;
import org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerDataNode;
import org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolume;
import org.apache.hadoop.hdfs.server.diskbalancer.datamodel.DiskBalancerVolumeSet;
import org.apache.hadoop.hdfs.server.diskbalancer.planner.GreedyPlanner;
import org.apache.hadoop.hdfs.server.diskbalancer.planner.NodePlan;
import org.apache.hadoop.hdfs.server.diskbalancer.planner.Step;
import org.junit.Assert;
import org.junit.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.net.URI;
import java.util.List;
import java.util.UUID;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertTrue;
/** 
 * Test Planner.
 */
public class TestPlanner {
  static final Logger LOG=LoggerFactory.getLogger(TestPlanner.class);
  @Test public void testGreedyPlannerBalanceVolumeSet() throws Exception {
    URI clusterJson=getClass().getResource("/diskBalancer/data-cluster-3node-3disk.json").toURI();
    ClusterConnector jsonConnector=ConnectorFactory.getCluster(clusterJson,null);
    DiskBalancerCluster cluster=new DiskBalancerCluster(jsonConnector);
    cluster.readClusterInfo();
    Assert.assertEquals(3,cluster.getNodes().size());
    cluster.setNodesToProcess(cluster.getNodes());
    DiskBalancerDataNode node=cluster.getNodes().get(0);
    GreedyPlanner planner=new GreedyPlanner(10.0f,node);
    NodePlan plan=new NodePlan(node.getDataNodeName(),node.getDataNodePort());
    planner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),plan);
  }
  @Test public void testGreedyPlannerComputePlan() throws Exception {
    URI clusterJson=getClass().getResource("/diskBalancer/data-cluster-3node-3disk.json").toURI();
    ClusterConnector jsonConnector=ConnectorFactory.getCluster(clusterJson,null);
    DiskBalancerCluster cluster=new DiskBalancerCluster(jsonConnector);
    cluster.readClusterInfo();
    Assert.assertEquals(3,cluster.getNodes().size());
    cluster.setNodesToProcess(cluster.getNodes());
    List<NodePlan> plan=cluster.computePlan(10.0f);
    Assert.assertNotNull(plan);
  }
  private DiskBalancerVolume createVolume(  String path,  int capacityInGB,  int usedInGB){
    DiskBalancerTestUtil util=new DiskBalancerTestUtil();
    DiskBalancerVolume volume=util.createRandomVolume(StorageType.SSD);
    volume.setPath(path);
    volume.setCapacity(capacityInGB * DiskBalancerTestUtil.GB);
    volume.setReserved(0);
    volume.setUsed(usedInGB * DiskBalancerTestUtil.GB);
    return volume;
  }
  @Test public void testGreedyPlannerNoNodeCluster() throws Exception {
    GreedyPlanner planner=new GreedyPlanner(10.0f,null);
    assertNotNull(planner);
  }
  @Test public void testGreedyPlannerNoVolumeTest() throws Exception {
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    List<NodePlan> planList=cluster.computePlan(10.0f);
    assertNotNull(planList);
  }
  @Test public void testGreedyPlannerOneVolumeNoPlanTest() throws Exception {
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    DiskBalancerDataNode node=new DiskBalancerDataNode(UUID.randomUUID().toString());
    DiskBalancerVolume volume30=createVolume("volume30",100,30);
    node.addVolume(volume30);
    nullConnector.addNode(node);
    cluster.readClusterInfo();
    Assert.assertEquals(1,cluster.getNodes().size());
    GreedyPlanner planner=new GreedyPlanner(10.0f,node);
    NodePlan plan=new NodePlan(node.getDataNodeName(),node.getDataNodePort());
    planner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),plan);
    assertEquals(0,plan.getVolumeSetPlans().size());
  }
  @Test public void testGreedyPlannerTwoVolume() throws Exception {
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    DiskBalancerDataNode node=new DiskBalancerDataNode(UUID.randomUUID().toString());
    DiskBalancerVolume volume30=createVolume("volume30",100,30);
    DiskBalancerVolume volume10=createVolume("volume10",100,10);
    node.addVolume(volume10);
    node.addVolume(volume30);
    nullConnector.addNode(node);
    cluster.readClusterInfo();
    Assert.assertEquals(1,cluster.getNodes().size());
    GreedyPlanner planner=new GreedyPlanner(5.0f,node);
    NodePlan plan=new NodePlan(node.getDataNodeUUID(),node.getDataNodePort());
    planner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),plan);
    assertEquals(1,plan.getVolumeSetPlans().size());
    Step step=plan.getVolumeSetPlans().get(0);
    assertEquals("volume30",step.getSourceVolume().getPath());
    assertEquals("volume10",step.getDestinationVolume().getPath());
    assertEquals("10 G",step.getSizeString(step.getBytesToMove()));
  }
  /** 
 * In this test we pass 3 volumes with 30, 20 and 10 GB of data used. We expect the planner to print out 20 GB on each volume. <p/> That is the plan should say move 10 GB from volume30 to volume10.
 */
  @Test public void testGreedyPlannerEqualizeData() throws Exception {
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    DiskBalancerDataNode node=new DiskBalancerDataNode(UUID.randomUUID().toString());
    DiskBalancerVolume volume30=createVolume("volume30",100,30);
    DiskBalancerVolume volume20=createVolume("volume20",100,20);
    DiskBalancerVolume volume10=createVolume("volume10",100,10);
    node.addVolume(volume10);
    node.addVolume(volume20);
    node.addVolume(volume30);
    nullConnector.addNode(node);
    cluster.readClusterInfo();
    Assert.assertEquals(1,cluster.getNodes().size());
    GreedyPlanner planner=new GreedyPlanner(5.0f,node);
    NodePlan plan=new NodePlan(node.getDataNodeUUID(),node.getDataNodePort());
    planner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),plan);
    assertEquals(1,plan.getVolumeSetPlans().size());
    Step step=plan.getVolumeSetPlans().get(0);
    assertEquals("volume30",step.getSourceVolume().getPath());
    assertEquals("volume10",step.getDestinationVolume().getPath());
    assertEquals("10 G",step.getSizeString(step.getBytesToMove()));
  }
  @Test public void testGreedyPlannerEqualDisksNoMoves() throws Exception {
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    DiskBalancerDataNode node=new DiskBalancerDataNode(UUID.randomUUID().toString());
    DiskBalancerVolume volume1=createVolume("volume1",100,30);
    DiskBalancerVolume volume2=createVolume("volume2",100,30);
    DiskBalancerVolume volume3=createVolume("volume3",100,30);
    node.addVolume(volume1);
    node.addVolume(volume2);
    node.addVolume(volume3);
    nullConnector.addNode(node);
    cluster.readClusterInfo();
    Assert.assertEquals(1,cluster.getNodes().size());
    GreedyPlanner planner=new GreedyPlanner(10.0f,node);
    NodePlan plan=new NodePlan(node.getDataNodeName(),node.getDataNodePort());
    planner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),plan);
    assertEquals(0,plan.getVolumeSetPlans().size());
  }
  @Test public void testGreedyPlannerMoveFromSingleDisk() throws Exception {
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    DiskBalancerDataNode node=new DiskBalancerDataNode(UUID.randomUUID().toString());
    DiskBalancerVolume volume1=createVolume("volume100",200,100);
    DiskBalancerVolume volume2=createVolume("volume0-1",200,0);
    DiskBalancerVolume volume3=createVolume("volume0-2",200,0);
    node.addVolume(volume1);
    node.addVolume(volume2);
    node.addVolume(volume3);
    nullConnector.addNode(node);
    cluster.readClusterInfo();
    Assert.assertEquals(1,cluster.getNodes().size());
    GreedyPlanner planner=new GreedyPlanner(10.0f,node);
    NodePlan plan=new NodePlan(node.getDataNodeName(),node.getDataNodePort());
    planner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),plan);
    assertEquals(2,plan.getVolumeSetPlans().size());
    Step step=plan.getVolumeSetPlans().get(0);
    assertEquals("volume100",step.getSourceVolume().getPath());
    assertTrue(step.getSizeString(step.getBytesToMove()).matches("33.[2|3|4] G"));
    step=plan.getVolumeSetPlans().get(1);
    assertEquals("volume100",step.getSourceVolume().getPath());
    assertTrue(step.getSizeString(step.getBytesToMove()).matches("33.[2|3|4] G"));
  }
  @Test public void testGreedyPlannerThresholdTest() throws Exception {
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    DiskBalancerDataNode node=new DiskBalancerDataNode(UUID.randomUUID().toString());
    DiskBalancerVolume volume1=createVolume("volume100",1000,100);
    DiskBalancerVolume volume2=createVolume("volume0-1",300,0);
    DiskBalancerVolume volume3=createVolume("volume0-2",300,0);
    node.addVolume(volume1);
    node.addVolume(volume2);
    node.addVolume(volume3);
    nullConnector.addNode(node);
    cluster.readClusterInfo();
    Assert.assertEquals(1,cluster.getNodes().size());
    GreedyPlanner planner=new GreedyPlanner(10.0f,node);
    NodePlan plan=new NodePlan(node.getDataNodeName(),node.getDataNodePort());
    planner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),plan);
    assertEquals(0,plan.getVolumeSetPlans().size());
    GreedyPlanner newPlanner=new GreedyPlanner(01.0f,node);
    NodePlan newPlan=new NodePlan(node.getDataNodeName(),node.getDataNodePort());
    newPlanner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),newPlan);
    assertEquals(2,newPlan.getVolumeSetPlans().size());
    Step step=newPlan.getVolumeSetPlans().get(0);
    assertEquals("volume100",step.getSourceVolume().getPath());
    assertTrue(step.getSizeString(step.getBytesToMove()).matches("18.[6|7|8] G"));
    step=newPlan.getVolumeSetPlans().get(1);
    assertEquals("volume100",step.getSourceVolume().getPath());
    assertTrue(step.getSizeString(step.getBytesToMove()).matches("18.[6|7|8] G"));
  }
  @Test public void testGreedyPlannerPlanWithDifferentDiskSizes() throws Exception {
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    DiskBalancerDataNode node=new DiskBalancerDataNode(UUID.randomUUID().toString());
    DiskBalancerVolume volume1=createVolume("volume100",1000,100);
    DiskBalancerVolume volume2=createVolume("volume0-1",500,0);
    DiskBalancerVolume volume3=createVolume("volume0-2",250,0);
    node.addVolume(volume1);
    node.addVolume(volume2);
    node.addVolume(volume3);
    nullConnector.addNode(node);
    cluster.readClusterInfo();
    Assert.assertEquals(1,cluster.getNodes().size());
    GreedyPlanner newPlanner=new GreedyPlanner(01.0f,node);
    NodePlan newPlan=new NodePlan(node.getDataNodeName(),node.getDataNodePort());
    newPlanner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),newPlan);
    assertEquals(2,newPlan.getVolumeSetPlans().size());
    for (    Step step : newPlan.getVolumeSetPlans()) {
      if (step.getDestinationVolume().getPath().equals("volume0-1")) {
        assertEquals("volume100",step.getSourceVolume().getPath());
        assertEquals("28.5 G",step.getSizeString(step.getBytesToMove()));
      }
      if (step.getDestinationVolume().getPath().equals("volume0-2")) {
        assertEquals("volume100",step.getSourceVolume().getPath());
        assertEquals("14.3 G",step.getSizeString(step.getBytesToMove()));
      }
    }
    Step step=newPlan.getVolumeSetPlans().get(0);
    assertEquals(0.05714f,step.getIdealStorage(),0.001f);
  }
  @Test public void testLoadsCorrectClusterConnector() throws Exception {
    ClusterConnector connector=ConnectorFactory.getCluster(getClass().getResource("/diskBalancer/data-cluster-3node-3disk.json").toURI(),null);
    assertEquals(connector.getClass().toString(),"class org.apache.hadoop.hdfs.server.diskbalancer.connectors." + "JsonNodeConnector");
  }
  @Test public void testPlannerScale() throws Exception {
    final int diskCount=256;
    DiskBalancerTestUtil util=new DiskBalancerTestUtil();
    DiskBalancerVolumeSet vSet=util.createRandomVolumeSet(StorageType.SSD,diskCount);
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    DiskBalancerDataNode node=new DiskBalancerDataNode(UUID.randomUUID().toString());
    int diskNum=0;
    for (    DiskBalancerVolume vol : vSet.getVolumes()) {
      vol.setPath("volume" + diskNum++);
      node.addVolume(vol);
    }
    nullConnector.addNode(node);
    cluster.readClusterInfo();
    GreedyPlanner newPlanner=new GreedyPlanner(01.0f,node);
    NodePlan newPlan=new NodePlan(node.getDataNodeName(),node.getDataNodePort());
    newPlanner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),newPlan);
    assertTrue("No Steps Generated from random disks, very unlikely",newPlan.getVolumeSetPlans().size() > 0);
    assertTrue("Steps Generated less than disk count - false",newPlan.getVolumeSetPlans().size() < diskCount);
    LOG.info("Number of steps are : %d%n",newPlan.getVolumeSetPlans().size());
  }
  @Test public void testNodePlanSerialize() throws Exception {
    final int diskCount=12;
    DiskBalancerTestUtil util=new DiskBalancerTestUtil();
    DiskBalancerVolumeSet vSet=util.createRandomVolumeSet(StorageType.SSD,diskCount);
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    DiskBalancerDataNode node=new DiskBalancerDataNode(UUID.randomUUID().toString());
    int diskNum=0;
    for (    DiskBalancerVolume vol : vSet.getVolumes()) {
      vol.setPath("volume" + diskNum++);
      node.addVolume(vol);
    }
    nullConnector.addNode(node);
    cluster.readClusterInfo();
    GreedyPlanner newPlanner=new GreedyPlanner(01.0f,node);
    NodePlan newPlan=new NodePlan(node.getDataNodeName(),node.getDataNodePort());
    newPlanner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),newPlan);
    String planString=newPlan.toJson();
    assertNotNull(planString);
    NodePlan copy=NodePlan.parseJson(planString);
    assertNotNull(copy);
    assertEquals(newPlan.getVolumeSetPlans().size(),copy.getVolumeSetPlans().size());
  }
  @Test public void testGreedyPlannerLargeDisksWithData() throws Exception {
    NullConnector nullConnector=new NullConnector();
    DiskBalancerCluster cluster=new DiskBalancerCluster(nullConnector);
    DiskBalancerDataNode node=new DiskBalancerDataNode(UUID.randomUUID().toString());
    DiskBalancerVolume volume1=createVolume("volume1",1968,88);
    DiskBalancerVolume volume2=createVolume("volume2",1968,88);
    DiskBalancerVolume volume3=createVolume("volume3",1968,111);
    DiskBalancerVolume volume4=createVolume("volume4",1968,111);
    DiskBalancerVolume volume5=createVolume("volume5",1968,30);
    DiskBalancerVolume volume6=createVolume("volume6",1563,30);
    DiskBalancerVolume volume7=createVolume("volume7",1563,30);
    DiskBalancerVolume volume8=createVolume("volume8",1563,30);
    DiskBalancerVolume volume9=createVolume("volume9",1563,210);
    node.addVolume(volume1);
    node.addVolume(volume2);
    node.addVolume(volume3);
    node.addVolume(volume4);
    node.addVolume(volume5);
    node.addVolume(volume6);
    node.addVolume(volume7);
    node.addVolume(volume8);
    node.addVolume(volume9);
    nullConnector.addNode(node);
    cluster.readClusterInfo();
    Assert.assertEquals(1,cluster.getNodes().size());
    GreedyPlanner planner=new GreedyPlanner(1.0f,node);
    NodePlan plan=new NodePlan(node.getDataNodeName(),node.getDataNodePort());
    planner.balanceVolumeSet(node,node.getVolumeSets().get("SSD"),plan);
    assertTrue(plan.getVolumeSetPlans().size() > 2);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.hdfs;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.InetSocketAddress;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.Random;
import java.util.concurrent.locks.ReentrantReadWriteLock;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.CommonConfigurationKeys;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.hdfs.protocol.DatanodeInfo;
import org.apache.hadoop.hdfs.protocol.HdfsConstants.DatanodeReportType;
import org.apache.hadoop.hdfs.server.namenode.NameNodeAdapter;
import org.apache.hadoop.test.MockitoUtil;
import org.apache.hadoop.util.Time;
import org.junit.Assert;
import org.junit.Test;
import org.mockito.Mockito;
/** 
 * This class tests the access time on files.
 */
public class TestSetTimes {
  static final long seed=0xDEADBEEFL;
  static final int blockSize=8192;
  static final int fileSize=16384;
  static final int numDatanodes=1;
  static final SimpleDateFormat dateForm=new SimpleDateFormat("yyyy-MM-dd HH:mm");
  Random myrand=new Random();
  Path hostsFile;
  Path excludeFile;
  private FSDataOutputStream writeFile(  FileSystem fileSys,  Path name,  int repl) throws IOException {
    FSDataOutputStream stm=fileSys.create(name,true,fileSys.getConf().getInt(CommonConfigurationKeys.IO_FILE_BUFFER_SIZE_KEY,4096),(short)repl,blockSize);
    byte[] buffer=new byte[fileSize];
    Random rand=new Random(seed);
    rand.nextBytes(buffer);
    stm.write(buffer);
    return stm;
  }
  private void cleanupFile(  FileSystem fileSys,  Path name) throws IOException {
    assertTrue(fileSys.exists(name));
    fileSys.delete(name,true);
    assertTrue(!fileSys.exists(name));
  }
  private void printDatanodeReport(  DatanodeInfo[] info){
    System.out.println("-------------------------------------------------");
    for (int i=0; i < info.length; i++) {
      System.out.println(info[i].getDatanodeReport());
      System.out.println();
    }
  }
  /** 
 * Tests mod & access time in DFS.
 */
  @Test public void testTimes() throws IOException {
    Configuration conf=new HdfsConfiguration();
    final int MAX_IDLE_TIME=2000;
    conf.setInt("ipc.client.connection.maxidletime",MAX_IDLE_TIME);
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,1000);
    conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).build();
    cluster.waitActive();
    final int nnport=cluster.getNameNodePort();
    InetSocketAddress addr=new InetSocketAddress("localhost",cluster.getNameNodePort());
    DFSClient client=new DFSClient(addr,conf);
    DatanodeInfo[] info=client.datanodeReport(DatanodeReportType.LIVE);
    assertEquals("Number of Datanodes ",numDatanodes,info.length);
    FileSystem fileSys=cluster.getFileSystem();
    int replicas=1;
    assertTrue(fileSys instanceof DistributedFileSystem);
    try {
      System.out.println("Creating testdir1 and testdir1/test1.dat.");
      Path dir1=new Path("testdir1");
      Path file1=new Path(dir1,"test1.dat");
      FSDataOutputStream stm=writeFile(fileSys,file1,replicas);
      FileStatus stat=fileSys.getFileStatus(file1);
      long atimeBeforeClose=stat.getAccessTime();
      String adate=dateForm.format(new Date(atimeBeforeClose));
      System.out.println("atime on " + file1 + " before close is "+ adate+ " ("+ atimeBeforeClose+ ")");
      assertTrue(atimeBeforeClose != 0);
      stm.close();
      stat=fileSys.getFileStatus(file1);
      long atime1=stat.getAccessTime();
      long mtime1=stat.getModificationTime();
      adate=dateForm.format(new Date(atime1));
      String mdate=dateForm.format(new Date(mtime1));
      System.out.println("atime on " + file1 + " is "+ adate+ " ("+ atime1+ ")");
      System.out.println("mtime on " + file1 + " is "+ mdate+ " ("+ mtime1+ ")");
      assertTrue(atime1 != 0);
      stat=fileSys.getFileStatus(dir1);
      long mdir1=stat.getAccessTime();
      assertTrue(mdir1 == 0);
      long atime2=atime1 - (24L * 3600L * 1000L);
      fileSys.setTimes(file1,-1,atime2);
      stat=fileSys.getFileStatus(file1);
      long atime3=stat.getAccessTime();
      String adate3=dateForm.format(new Date(atime3));
      System.out.println("new atime on " + file1 + " is "+ adate3+ " ("+ atime3+ ")");
      assertTrue(atime2 == atime3);
      assertTrue(mtime1 == stat.getModificationTime());
      long mtime2=mtime1 - (3600L * 1000L);
      fileSys.setTimes(file1,mtime2,-1);
      stat=fileSys.getFileStatus(file1);
      long mtime3=stat.getModificationTime();
      String mdate3=dateForm.format(new Date(mtime3));
      System.out.println("new mtime on " + file1 + " is "+ mdate3+ " ("+ mtime3+ ")");
      assertTrue(atime2 == stat.getAccessTime());
      assertTrue(mtime2 == mtime3);
      long mtime4=Time.now() - (3600L * 1000L);
      long atime4=Time.now();
      fileSys.setTimes(dir1,mtime4,atime4);
      stat=fileSys.getFileStatus(dir1);
      assertTrue("Not matching the modification times",mtime4 == stat.getModificationTime());
      assertTrue("Not matching the access times",atime4 == stat.getAccessTime());
      Path nonExistingDir=new Path(dir1,"/nonExistingDir/");
      try {
        fileSys.setTimes(nonExistingDir,mtime4,atime4);
        fail("Expecting FileNotFoundException");
      }
 catch (      FileNotFoundException e) {
        assertTrue(e.getMessage().contains("File/Directory " + nonExistingDir.toString() + " does not exist."));
      }
      cluster.shutdown();
      try {
        Thread.sleep(2 * MAX_IDLE_TIME);
      }
 catch (      InterruptedException e) {
      }
      cluster=new MiniDFSCluster.Builder(conf).nameNodePort(nnport).format(false).build();
      cluster.waitActive();
      fileSys=cluster.getFileSystem();
      System.out.println("Verifying times after cluster restart");
      stat=fileSys.getFileStatus(file1);
      assertTrue(atime2 == stat.getAccessTime());
      assertTrue(mtime3 == stat.getModificationTime());
      cleanupFile(fileSys,file1);
      cleanupFile(fileSys,dir1);
    }
 catch (    IOException e) {
      info=client.datanodeReport(DatanodeReportType.ALL);
      printDatanodeReport(info);
      throw e;
    }
 finally {
      fileSys.close();
      cluster.shutdown();
    }
  }
  /** 
 * Tests mod time change at close in DFS.
 */
  @Test public void testTimesAtClose() throws IOException {
    Configuration conf=new HdfsConfiguration();
    final int MAX_IDLE_TIME=2000;
    int replicas=1;
    conf.setInt("ipc.client.connection.maxidletime",MAX_IDLE_TIME);
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,1000);
    conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_DATANODE_HANDLER_COUNT_KEY,50);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDatanodes).build();
    cluster.waitActive();
    InetSocketAddress addr=new InetSocketAddress("localhost",cluster.getNameNodePort());
    DFSClient client=new DFSClient(addr,conf);
    DatanodeInfo[] info=client.datanodeReport(DatanodeReportType.LIVE);
    assertEquals("Number of Datanodes ",numDatanodes,info.length);
    FileSystem fileSys=cluster.getFileSystem();
    assertTrue(fileSys instanceof DistributedFileSystem);
    try {
      Path file1=new Path("/simple.dat");
      FSDataOutputStream stm=writeFile(fileSys,file1,replicas);
      System.out.println("Created and wrote file simple.dat");
      FileStatus statBeforeClose=fileSys.getFileStatus(file1);
      long mtimeBeforeClose=statBeforeClose.getModificationTime();
      String mdateBeforeClose=dateForm.format(new Date(mtimeBeforeClose));
      System.out.println("mtime on " + file1 + " before close is "+ mdateBeforeClose+ " ("+ mtimeBeforeClose+ ")");
      assertTrue(mtimeBeforeClose != 0);
      stm.close();
      System.out.println("Closed file.");
      FileStatus statAfterClose=fileSys.getFileStatus(file1);
      long mtimeAfterClose=statAfterClose.getModificationTime();
      String mdateAfterClose=dateForm.format(new Date(mtimeAfterClose));
      System.out.println("mtime on " + file1 + " after close is "+ mdateAfterClose+ " ("+ mtimeAfterClose+ ")");
      assertTrue(mtimeAfterClose != 0);
      assertTrue(mtimeBeforeClose != mtimeAfterClose);
      cleanupFile(fileSys,file1);
    }
 catch (    IOException e) {
      info=client.datanodeReport(DatanodeReportType.ALL);
      printDatanodeReport(info);
      throw e;
    }
 finally {
      fileSys.close();
      cluster.shutdown();
    }
  }
  /** 
 * Test that when access time updates are not needed, the FSNamesystem write lock is not taken by getBlockLocations. Regression test for HDFS-3981.
 */
  @Test(timeout=60000) public void testGetBlockLocationsOnlyUsesReadLock() throws IOException {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_ACCESSTIME_PRECISION_KEY,100 * 1000);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
    ReentrantReadWriteLock spyLock=NameNodeAdapter.spyOnFsLock(cluster.getNamesystem());
    try {
      Path p=new Path("/empty-file");
      DFSTestUtil.createFile(cluster.getFileSystem(),p,0,(short)1,0L);
      MockitoUtil.doThrowWhenCallStackMatches(new AssertionError("Should not need write lock"),".*getBlockLocations.*").when(spyLock).writeLock();
      cluster.getFileSystem().getFileBlockLocations(p,0,100);
    }
  finally {
      cluster.shutdown();
    }
  }
  /** 
 * Test whether atime can be set explicitly even when the atime support is disabled.
 */
  @Test public void testAtimeUpdate() throws Exception {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_ACCESSTIME_PRECISION_KEY,0);
    MiniDFSCluster cluster=null;
    FileSystem fs=null;
    try {
      cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
      fs=cluster.getFileSystem();
      Path p=new Path("/testAtimeUpdate");
      DFSTestUtil.createFile(cluster.getFileSystem(),p,0,(short)1,0L);
      fs.setTimes(p,-1L,123456L);
      Assert.assertEquals(123456L,fs.getFileStatus(p).getAccessTime());
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  public static void main(  String[] args) throws Exception {
    new TestSetTimes().testTimes();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.hadoop.hdfs;
import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT;
import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY;
import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_BLOCK_SIZE_DEFAULT;
import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_BLOCK_SIZE_KEY;
import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_BYTES_PER_CHECKSUM_DEFAULT;
import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY;
import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_SERVER_DEFAULTS_VALIDITY_PERIOD_MS_KEY;
import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_WRITE_PACKET_SIZE_DEFAULT;
import static org.apache.hadoop.hdfs.client.HdfsClientConfigKeys.DFS_CLIENT_WRITE_PACKET_SIZE_KEY;
import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_DATANODE_SYNCONCLOSE_KEY;
import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY;
import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY;
import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_NAMENODE_REPLICATION_MIN_KEY;
import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_REPLICATION_DEFAULT;
import static org.apache.hadoop.hdfs.DFSConfigKeys.DFS_REPLICATION_KEY;
import static org.apache.hadoop.test.MetricsAsserts.assertCounter;
import static org.apache.hadoop.test.MetricsAsserts.getMetrics;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import static org.junit.Assume.assumeTrue;
import static org.mockito.Mockito.doReturn;
import java.io.BufferedReader;
import java.io.ByteArrayOutputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStreamReader;
import java.lang.reflect.Field;
import java.lang.reflect.Modifier;
import java.net.InetSocketAddress;
import java.net.URI;
import java.net.UnknownHostException;
import java.security.PrivilegedExceptionAction;
import java.util.EnumSet;
import java.util.concurrent.TimeUnit;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.CommonConfigurationKeys;
import org.apache.hadoop.fs.CreateFlag;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileAlreadyExistsException;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.FsServerDefaults;
import org.apache.hadoop.fs.InvalidPathException;
import org.apache.hadoop.fs.ParentNotDirectoryException;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.permission.FsPermission;
import org.apache.hadoop.hdfs.client.HdfsClientConfigKeys;
import org.apache.hadoop.hdfs.client.HdfsDataOutputStream;
import org.apache.hadoop.hdfs.protocol.DatanodeInfo;
import org.apache.hadoop.hdfs.protocol.ExtendedBlock;
import org.apache.hadoop.hdfs.protocol.HdfsConstants;
import org.apache.hadoop.hdfs.protocol.LocatedBlock;
import org.apache.hadoop.hdfs.protocol.LocatedBlocks;
import org.apache.hadoop.hdfs.server.blockmanagement.BlockManager;
import org.apache.hadoop.hdfs.server.datanode.DataNode;
import org.apache.hadoop.hdfs.server.datanode.DataNodeTestUtils;
import org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset;
import org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi;
import org.apache.hadoop.hdfs.server.namenode.FSNamesystem;
import org.apache.hadoop.hdfs.server.namenode.LeaseManager;
import org.apache.hadoop.hdfs.server.namenode.NameNode;
import org.apache.hadoop.hdfs.server.namenode.NameNodeAdapter;
import org.apache.hadoop.hdfs.server.protocol.NamenodeProtocols;
import org.apache.hadoop.io.EnumSetWritable;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.security.UserGroupInformation;
import org.apache.hadoop.test.GenericTestUtils;
import org.apache.hadoop.util.Time;
import org.junit.Assert;
import org.junit.Test;
import org.slf4j.event.Level;
/** 
 * This class tests various cases during file creation.
 */
public class TestFileCreation {
  static final String DIR="/" + TestFileCreation.class.getSimpleName() + "/";
{
    GenericTestUtils.setLogLevel(LeaseManager.LOG,Level.TRACE);
    GenericTestUtils.setLogLevel(FSNamesystem.LOG,Level.TRACE);
    GenericTestUtils.setLogLevel(DFSClient.LOG,Level.TRACE);
  }
  private static final String RPC_DETAILED_METRICS="RpcDetailedActivityForPort";
  static final long seed=0xDEADBEEFL;
  static final int blockSize=8192;
  static final int numBlocks=2;
  static final int fileSize=numBlocks * blockSize + 1;
  boolean simulatedStorage=false;
  private static final String[] NON_CANONICAL_PATHS=new String[]{"//foo","///foo2","//dir//file","////test2/file","/dir/./file2","/dir/../file3"};
  public static FSDataOutputStream createFile(  FileSystem fileSys,  Path name,  int repl) throws IOException {
    System.out.println("createFile: Created " + name + " with "+ repl+ " replica.");
    FSDataOutputStream stm=fileSys.create(name,true,fileSys.getConf().getInt(CommonConfigurationKeys.IO_FILE_BUFFER_SIZE_KEY,4096),(short)repl,blockSize);
    return stm;
  }
  public static HdfsDataOutputStream create(  DistributedFileSystem dfs,  Path name,  int repl) throws IOException {
    return (HdfsDataOutputStream)createFile(dfs,name,repl);
  }
  static void writeFile(  FSDataOutputStream stm) throws IOException {
    writeFile(stm,fileSize);
  }
  public static void writeFile(  FSDataOutputStream stm,  int size) throws IOException {
    byte[] buffer=AppendTestUtil.randomBytes(seed,size);
    stm.write(buffer,0,size);
  }
  /** 
 * Test that server default values can be retrieved on the client side
 */
  @Test public void testServerDefaults() throws IOException {
    Configuration conf=new HdfsConfiguration();
    conf.setLong(DFS_BLOCK_SIZE_KEY,DFS_BLOCK_SIZE_DEFAULT);
    conf.setInt(DFS_BYTES_PER_CHECKSUM_KEY,DFS_BYTES_PER_CHECKSUM_DEFAULT);
    conf.setInt(DFS_CLIENT_WRITE_PACKET_SIZE_KEY,DFS_CLIENT_WRITE_PACKET_SIZE_DEFAULT);
    conf.setInt(DFS_REPLICATION_KEY,DFS_REPLICATION_DEFAULT + 1);
    conf.setInt(IO_FILE_BUFFER_SIZE_KEY,IO_FILE_BUFFER_SIZE_DEFAULT);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DFSConfigKeys.DFS_REPLICATION_DEFAULT + 1).build();
    cluster.waitActive();
    FileSystem fs=cluster.getFileSystem();
    try {
      FsServerDefaults serverDefaults=fs.getServerDefaults(new Path("/"));
      assertEquals(DFS_BLOCK_SIZE_DEFAULT,serverDefaults.getBlockSize());
      assertEquals(DFS_BYTES_PER_CHECKSUM_DEFAULT,serverDefaults.getBytesPerChecksum());
      assertEquals(DFS_CLIENT_WRITE_PACKET_SIZE_DEFAULT,serverDefaults.getWritePacketSize());
      assertEquals(DFS_REPLICATION_DEFAULT + 1,serverDefaults.getReplication());
      assertEquals(IO_FILE_BUFFER_SIZE_DEFAULT,serverDefaults.getFileBufferSize());
      assertEquals(7,serverDefaults.getDefaultStoragePolicyId());
    }
  finally {
      fs.close();
      cluster.shutdown();
    }
  }
  /** 
 * Test that server default values are cached on the client size and are stale after namenode update.
 */
  @Test public void testServerDefaultsWithCaching() throws IOException, InterruptedException {
    Configuration clusterConf=new HdfsConfiguration();
    long originalBlockSize=DFS_BLOCK_SIZE_DEFAULT * 2;
    clusterConf.setLong(DFS_BLOCK_SIZE_KEY,originalBlockSize);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(clusterConf).numDataNodes(0).build();
    cluster.waitActive();
    FSNamesystem spyNamesystem=NameNodeAdapter.spyOnNamesystem(cluster.getNameNode());
    InetSocketAddress nameNodeAddr=cluster.getNameNode().getNameNodeAddress();
    try {
      Configuration clientConf=new HdfsConfiguration();
      clientConf.setLong(DFS_CLIENT_SERVER_DEFAULTS_VALIDITY_PERIOD_MS_KEY,TimeUnit.MINUTES.toMillis(1));
      DFSClient dfsClient=new DFSClient(nameNodeAddr,clientConf);
      FsServerDefaults defaults=dfsClient.getServerDefaults();
      assertEquals(originalBlockSize,defaults.getBlockSize());
      long updatedDefaultBlockSize=DFS_BLOCK_SIZE_DEFAULT * 3;
      FsServerDefaults newDefaults=new FsServerDefaults(updatedDefaultBlockSize,defaults.getBytesPerChecksum(),defaults.getWritePacketSize(),defaults.getReplication(),defaults.getFileBufferSize(),defaults.getEncryptDataTransfer(),defaults.getTrashInterval(),defaults.getChecksumType(),defaults.getKeyProviderUri(),defaults.getDefaultStoragePolicyId());
      doReturn(newDefaults).when(spyNamesystem).getServerDefaults();
      Thread.sleep(1);
      defaults=dfsClient.getServerDefaults();
      assertEquals(originalBlockSize,defaults.getBlockSize());
      DFSClient newDfsClient=new DFSClient(nameNodeAddr,clientConf);
      defaults=newDfsClient.getServerDefaults();
      assertEquals(updatedDefaultBlockSize,defaults.getBlockSize());
    }
  finally {
      cluster.shutdown();
    }
  }
  /** 
 * Test that server defaults are updated on the client after cache expiration.
 */
  @Test public void testServerDefaultsWithMinimalCaching() throws IOException, InterruptedException {
    Configuration clusterConf=new HdfsConfiguration();
    long originalBlockSize=DFS_BLOCK_SIZE_DEFAULT * 2;
    clusterConf.setLong(DFS_BLOCK_SIZE_KEY,originalBlockSize);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(clusterConf).numDataNodes(0).build();
    cluster.waitActive();
    FSNamesystem spyNamesystem=NameNodeAdapter.spyOnNamesystem(cluster.getNameNode());
    InetSocketAddress nameNodeAddr=cluster.getNameNode().getNameNodeAddress();
    try {
      Configuration clientConf=new HdfsConfiguration();
      clientConf.setLong(DFS_CLIENT_SERVER_DEFAULTS_VALIDITY_PERIOD_MS_KEY,0L);
      DFSClient dfsClient=new DFSClient(nameNodeAddr,clientConf);
      FsServerDefaults defaults=dfsClient.getServerDefaults();
      assertEquals(originalBlockSize,defaults.getBlockSize());
      long updatedDefaultBlockSize=DFS_BLOCK_SIZE_DEFAULT * 3;
      FsServerDefaults newDefaults=new FsServerDefaults(updatedDefaultBlockSize,defaults.getBytesPerChecksum(),defaults.getWritePacketSize(),defaults.getReplication(),defaults.getFileBufferSize(),defaults.getEncryptDataTransfer(),defaults.getTrashInterval(),defaults.getChecksumType(),defaults.getKeyProviderUri(),defaults.getDefaultStoragePolicyId());
      doReturn(newDefaults).when(spyNamesystem).getServerDefaults();
      Thread.sleep(1);
      defaults=dfsClient.getServerDefaults();
      assertEquals(updatedDefaultBlockSize,defaults.getBlockSize());
    }
  finally {
      cluster.shutdown();
    }
  }
  @Test public void testFileCreation() throws IOException {
    checkFileCreation(null,false);
  }
  /** 
 * Same test but the client should use DN hostnames 
 */
  @Test public void testFileCreationUsingHostname() throws IOException {
    assumeTrue(System.getProperty("os.name").startsWith("Linux"));
    checkFileCreation(null,true);
  }
  /** 
 * Same test but the client should bind to a local interface 
 */
  @Test public void testFileCreationSetLocalInterface() throws IOException {
    assumeTrue(System.getProperty("os.name").startsWith("Linux"));
    checkFileCreation("lo",false);
    try {
      checkFileCreation("bogus-interface",false);
      fail("Able to specify a bogus interface");
    }
 catch (    UnknownHostException e) {
      assertEquals("No such interface bogus-interface",e.getMessage());
    }
  }
  /** 
 * Test if file creation and disk space consumption works right
 * @param netIf the local interface, if any, clients should use to access DNs
 * @param useDnHostname whether the client should contact DNs by hostname
 */
  public void checkFileCreation(  String netIf,  boolean useDnHostname) throws IOException {
    Configuration conf=new HdfsConfiguration();
    if (netIf != null) {
      conf.set(HdfsClientConfigKeys.DFS_CLIENT_LOCAL_INTERFACES,netIf);
    }
    conf.setBoolean(HdfsClientConfigKeys.DFS_CLIENT_USE_DN_HOSTNAME,useDnHostname);
    if (useDnHostname) {
      conf.set(DFSConfigKeys.DFS_DATANODE_HOST_NAME_KEY,"localhost");
    }
    if (simulatedStorage) {
      SimulatedFSDataset.setFactory(conf);
    }
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).checkDataNodeHostConfig(true).build();
    FileSystem fs=cluster.getFileSystem();
    try {
      Path path=new Path("/");
      System.out.println("Path : \"" + path.toString() + "\"");
      System.out.println(fs.getFileStatus(path).isDirectory());
      assertTrue("/ should be a directory",fs.getFileStatus(path).isDirectory());
      Path dir1=new Path("/test_dir");
      fs.mkdirs(dir1);
      System.out.println("createFile: Creating " + dir1.getName() + " for overwrite of existing directory.");
      try {
        fs.create(dir1,true);
        fs.close();
        assertTrue("Did not prevent directory from being overwritten.",false);
      }
 catch (      FileAlreadyExistsException e) {
      }
      Path file1=new Path("filestatus.dat");
      Path parent=file1.getParent();
      fs.mkdirs(parent);
      DistributedFileSystem dfs=(DistributedFileSystem)fs;
      dfs.setQuota(file1.getParent(),100L,blockSize * 5);
      FSDataOutputStream stm=createFile(fs,file1,1);
      assertTrue(file1 + " should be a file",fs.getFileStatus(file1).isFile());
      System.out.println("Path : \"" + file1 + "\"");
      writeFile(stm);
      stm.close();
      long len=fs.getFileStatus(file1).getLen();
      assertTrue(file1 + " should be of size " + fileSize+ " but found to be of size "+ len,len == fileSize);
      long diskSpace=dfs.getContentSummary(file1.getParent()).getLength();
      assertEquals(file1 + " should take " + fileSize+ " bytes disk space "+ "but found to take "+ diskSpace+ " bytes",fileSize,diskSpace);
      if (simulatedStorage) {
        DataNode dn=cluster.getDataNodes().get(0);
        FsDatasetSpi<?> dataset=DataNodeTestUtils.getFSDataset(dn);
        assertEquals(fileSize,dataset.getDfsUsed());
        assertEquals(SimulatedFSDataset.DEFAULT_CAPACITY - fileSize,dataset.getRemaining());
      }
    }
  finally {
      cluster.shutdown();
    }
  }
  /** 
 * Test deleteOnExit
 */
  @Test public void testDeleteOnExit() throws IOException {
    Configuration conf=new HdfsConfiguration();
    if (simulatedStorage) {
      SimulatedFSDataset.setFactory(conf);
    }
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
    FileSystem fs=cluster.getFileSystem();
    FileSystem localfs=FileSystem.getLocal(conf);
    try {
      Path file1=new Path("filestatus.dat");
      Path file2=new Path("filestatus2.dat");
      Path file3=new Path("filestatus3.dat");
      FSDataOutputStream stm1=createFile(fs,file1,1);
      FSDataOutputStream stm2=createFile(fs,file2,1);
      FSDataOutputStream stm3=createFile(localfs,file3,1);
      System.out.println("DeleteOnExit: Created files.");
      writeFile(stm1);
      writeFile(stm3);
      stm1.close();
      stm2.close();
      stm3.close();
      fs.deleteOnExit(file1);
      fs.deleteOnExit(file2);
      localfs.deleteOnExit(file3);
      fs.close();
      localfs.close();
      fs=null;
      localfs=null;
      fs=cluster.getFileSystem();
      localfs=FileSystem.getLocal(conf);
      assertTrue(file1 + " still exists inspite of deletOnExit set.",!fs.exists(file1));
      assertTrue(file2 + " still exists inspite of deletOnExit set.",!fs.exists(file2));
      assertTrue(file3 + " still exists inspite of deletOnExit set.",!localfs.exists(file3));
      System.out.println("DeleteOnExit successful.");
    }
  finally {
      IOUtils.closeStream(fs);
      IOUtils.closeStream(localfs);
      cluster.shutdown();
    }
  }
  /** 
 * Test that a file which is open for write is overwritten by another client. Regression test for HDFS-3755.
 */
  @Test public void testOverwriteOpenForWrite() throws Exception {
    Configuration conf=new HdfsConfiguration();
    SimulatedFSDataset.setFactory(conf);
    conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY,false);
    final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
    FileSystem fs=cluster.getFileSystem();
    UserGroupInformation otherUgi=UserGroupInformation.createUserForTesting("testuser",new String[]{"testgroup"});
    FileSystem fs2=otherUgi.doAs(new PrivilegedExceptionAction<FileSystem>(){
      @Override public FileSystem run() throws Exception {
        return FileSystem.get(cluster.getConfiguration(0));
      }
    }
);
    String metricsName=RPC_DETAILED_METRICS + cluster.getNameNodePort();
    try {
      Path p=new Path("/testfile");
      FSDataOutputStream stm1=fs.create(p);
      stm1.write(1);
      assertCounter("CreateNumOps",1L,getMetrics(metricsName));
      try {
        fs2.create(p,false);
        fail("Did not throw!");
      }
 catch (      IOException abce) {
        GenericTestUtils.assertExceptionContains("Failed to CREATE_FILE",abce);
      }
      assertCounter("AlreadyBeingCreatedExceptionNumOps",1L,getMetrics(metricsName));
      FSDataOutputStream stm2=fs2.create(p,true);
      stm2.write(2);
      stm2.close();
      try {
        stm1.close();
        fail("Should have exception closing stm1 since it was deleted");
      }
 catch (      IOException ioe) {
        GenericTestUtils.assertExceptionContains("File does not exist",ioe);
      }
    }
  finally {
      IOUtils.closeStream(fs);
      IOUtils.closeStream(fs2);
      cluster.shutdown();
    }
  }
  /** 
 * Test that file data does not become corrupted even in the face of errors.
 */
  @Test public void testFileCreationError1() throws IOException {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,1000);
    conf.setInt(DFS_HEARTBEAT_INTERVAL_KEY,1);
    if (simulatedStorage) {
      SimulatedFSDataset.setFactory(conf);
    }
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
    FileSystem fs=cluster.getFileSystem();
    cluster.waitActive();
    InetSocketAddress addr=new InetSocketAddress("localhost",cluster.getNameNodePort());
    DFSClient client=new DFSClient(addr,conf);
    try {
      Path file1=new Path("/filestatus.dat");
      FSDataOutputStream stm=createFile(fs,file1,1);
      assertTrue(file1 + " should be a file",fs.getFileStatus(file1).isFile());
      System.out.println("Path : \"" + file1 + "\"");
      cluster.shutdownDataNodes();
      while (true) {
        DatanodeInfo[] info=client.datanodeReport(HdfsConstants.DatanodeReportType.LIVE);
        if (info.length == 0) {
          break;
        }
        System.out.println("testFileCreationError1: waiting for datanode " + " to die.");
        try {
          Thread.sleep(1000);
        }
 catch (        InterruptedException e) {
        }
      }
      byte[] buffer=AppendTestUtil.randomBytes(seed,1);
      try {
        stm.write(buffer);
        stm.close();
      }
 catch (      Exception e) {
        System.out.println("Encountered expected exception");
      }
      LocatedBlocks locations=client.getNamenode().getBlockLocations(file1.toString(),0,Long.MAX_VALUE);
      System.out.println("locations = " + locations.locatedBlockCount());
      assertTrue("Error blocks were not cleaned up",locations.locatedBlockCount() == 0);
    }
  finally {
      cluster.shutdown();
      client.close();
    }
  }
  /** 
 * Test that the filesystem removes the last block from a file if its lease expires.
 */
  @Test public void testFileCreationError2() throws IOException {
    long leasePeriod=1000;
    System.out.println("testFileCreationError2 start");
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,1000);
    conf.setInt(DFS_HEARTBEAT_INTERVAL_KEY,1);
    if (simulatedStorage) {
      SimulatedFSDataset.setFactory(conf);
    }
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
    DistributedFileSystem dfs=null;
    try {
      cluster.waitActive();
      dfs=cluster.getFileSystem();
      DFSClient client=dfs.dfs;
      Path file1=new Path("/filestatus.dat");
      createFile(dfs,file1,1);
      System.out.println("testFileCreationError2: " + "Created file filestatus.dat with one replicas.");
      LocatedBlocks locations=client.getNamenode().getBlockLocations(file1.toString(),0,Long.MAX_VALUE);
      System.out.println("testFileCreationError2: " + "The file has " + locations.locatedBlockCount() + " blocks.");
      LocatedBlock location=client.getNamenode().addBlock(file1.toString(),client.clientName,null,null,HdfsConstants.GRANDFATHER_INODE_ID,null,null);
      System.out.println("testFileCreationError2: " + "Added block " + location.getBlock());
      locations=client.getNamenode().getBlockLocations(file1.toString(),0,Long.MAX_VALUE);
      int count=locations.locatedBlockCount();
      System.out.println("testFileCreationError2: " + "The file now has " + count + " blocks.");
      cluster.setLeasePeriod(leasePeriod,leasePeriod);
      try {
        Thread.sleep(5 * leasePeriod);
      }
 catch (      InterruptedException e) {
      }
      locations=client.getNamenode().getBlockLocations(file1.toString(),0,Long.MAX_VALUE);
      System.out.println("testFileCreationError2: " + "locations = " + locations.locatedBlockCount());
      assertEquals(0,locations.locatedBlockCount());
      System.out.println("testFileCreationError2 successful");
    }
  finally {
      IOUtils.closeStream(dfs);
      cluster.shutdown();
    }
  }
  /** 
 * test addBlock(..) when replication<min and excludeNodes==null. 
 */
  @Test public void testFileCreationError3() throws IOException {
    System.out.println("testFileCreationError3 start");
    Configuration conf=new HdfsConfiguration();
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
    DistributedFileSystem dfs=null;
    try {
      cluster.waitActive();
      dfs=cluster.getFileSystem();
      DFSClient client=dfs.dfs;
      final Path f=new Path("/foo.txt");
      createFile(dfs,f,3);
      try {
        cluster.getNameNodeRpc().addBlock(f.toString(),client.clientName,null,null,HdfsConstants.GRANDFATHER_INODE_ID,null,null);
        fail();
      }
 catch (      IOException ioe) {
        FileSystem.LOG.info("GOOD!",ioe);
      }
      System.out.println("testFileCreationError3 successful");
    }
  finally {
      IOUtils.closeStream(dfs);
      cluster.shutdown();
    }
  }
  /** 
 * Test that file leases are persisted across namenode restarts.
 */
  @Test public void testFileCreationNamenodeRestart() throws IOException, NoSuchFieldException, IllegalAccessException {
    Configuration conf=new HdfsConfiguration();
    final int MAX_IDLE_TIME=2000;
    conf.setInt("ipc.client.connection.maxidletime",MAX_IDLE_TIME);
    conf.setInt(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,1000);
    conf.setInt(DFS_HEARTBEAT_INTERVAL_KEY,1);
    if (simulatedStorage) {
      SimulatedFSDataset.setFactory(conf);
    }
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
    DistributedFileSystem fs=null;
    try {
      cluster.waitActive();
      fs=cluster.getFileSystem();
      final int nnport=cluster.getNameNodePort();
      Path file1=new Path("/filestatus.dat");
      HdfsDataOutputStream stm=create(fs,file1,1);
      System.out.println("testFileCreationNamenodeRestart: " + "Created file " + file1);
      assertEquals(file1 + " should be replicated to 1 datanode.",1,stm.getCurrentBlockReplication());
      writeFile(stm,numBlocks * blockSize);
      stm.hflush();
      assertEquals(file1 + " should still be replicated to 1 datanode.",1,stm.getCurrentBlockReplication());
      Path fileRenamed=new Path("/filestatusRenamed.dat");
      fs.rename(file1,fileRenamed);
      System.out.println("testFileCreationNamenodeRestart: " + "Renamed file " + file1 + " to "+ fileRenamed);
      file1=fileRenamed;
      Path file2=new Path("/filestatus2.dat");
      FSDataOutputStream stm2=createFile(fs,file2,1);
      System.out.println("testFileCreationNamenodeRestart: " + "Created file " + file2);
      Path file3=new Path("/user/home/fullpath.dat");
      FSDataOutputStream stm3=createFile(fs,file3,1);
      System.out.println("testFileCreationNamenodeRestart: " + "Created file " + file3);
      Path file4=new Path("/user/home/fullpath4.dat");
      FSDataOutputStream stm4=createFile(fs,file4,1);
      System.out.println("testFileCreationNamenodeRestart: " + "Created file " + file4);
      fs.mkdirs(new Path("/bin"));
      fs.rename(new Path("/user/home"),new Path("/bin"));
      Path file3new=new Path("/bin/home/fullpath.dat");
      System.out.println("testFileCreationNamenodeRestart: " + "Renamed file " + file3 + " to "+ file3new);
      Path file4new=new Path("/bin/home/fullpath4.dat");
      System.out.println("testFileCreationNamenodeRestart: " + "Renamed file " + file4 + " to "+ file4new);
      cluster.shutdown(false,false);
      try {
        Thread.sleep(2 * MAX_IDLE_TIME);
      }
 catch (      InterruptedException e) {
      }
      cluster=new MiniDFSCluster.Builder(conf).nameNodePort(nnport).format(false).build();
      cluster.waitActive();
      cluster.shutdown(false,false);
      try {
        Thread.sleep(5000);
      }
 catch (      InterruptedException e) {
      }
      cluster=new MiniDFSCluster.Builder(conf).nameNodePort(nnport).format(false).build();
      cluster.waitActive();
      fs=cluster.getFileSystem();
      DFSOutputStream dfstream=(DFSOutputStream)(stm.getWrappedStream());
      Field f=DFSOutputStream.class.getDeclaredField("src");
      Field modifiersField=Field.class.getDeclaredField("modifiers");
      modifiersField.setAccessible(true);
      modifiersField.setInt(f,f.getModifiers() & ~Modifier.FINAL);
      f.setAccessible(true);
      f.set(dfstream,file1.toString());
      dfstream=(DFSOutputStream)(stm3.getWrappedStream());
      f.set(dfstream,file3new.toString());
      dfstream=(DFSOutputStream)(stm4.getWrappedStream());
      f.set(dfstream,file4new.toString());
      byte[] buffer=AppendTestUtil.randomBytes(seed,1);
      stm.write(buffer);
      stm.close();
      stm2.write(buffer);
      stm2.close();
      stm3.close();
      stm4.close();
      DFSClient client=fs.dfs;
      LocatedBlocks locations=client.getNamenode().getBlockLocations(file1.toString(),0,Long.MAX_VALUE);
      System.out.println("locations = " + locations.locatedBlockCount());
      assertTrue("Error blocks were not cleaned up for file " + file1,locations.locatedBlockCount() == 3);
      locations=client.getNamenode().getBlockLocations(file2.toString(),0,Long.MAX_VALUE);
      System.out.println("locations = " + locations.locatedBlockCount());
      assertTrue("Error blocks were not cleaned up for file " + file2,locations.locatedBlockCount() == 1);
    }
  finally {
      IOUtils.closeStream(fs);
      cluster.shutdown();
    }
  }
  /** 
 * Test that all open files are closed when client dies abnormally.
 */
  @Test public void testDFSClientDeath() throws IOException, InterruptedException {
    Configuration conf=new HdfsConfiguration();
    System.out.println("Testing adbornal client death.");
    if (simulatedStorage) {
      SimulatedFSDataset.setFactory(conf);
    }
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
    FileSystem fs=cluster.getFileSystem();
    DistributedFileSystem dfs=(DistributedFileSystem)fs;
    DFSClient dfsclient=dfs.dfs;
    try {
      Path file1=new Path("/clienttest.dat");
      FSDataOutputStream stm=createFile(fs,file1,1);
      System.out.println("Created file clienttest.dat");
      writeFile(stm);
      dfsclient.close();
      assertTrue(file1 + " does not exist.",AppendTestUtil.createHdfsWithDifferentUsername(conf).exists(file1));
    }
  finally {
      cluster.shutdown();
    }
  }
  /** 
 * Test file creation using createNonRecursive().
 */
  @Test public void testFileCreationNonRecursive() throws IOException {
    Configuration conf=new HdfsConfiguration();
    if (simulatedStorage) {
      SimulatedFSDataset.setFactory(conf);
    }
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
    FileSystem fs=cluster.getFileSystem();
    try {
      testFileCreationNonRecursive(fs);
    }
  finally {
      fs.close();
      cluster.shutdown();
    }
  }
  public static void testFileCreationNonRecursive(  FileSystem fs) throws IOException {
    final Path path=new Path("/" + Time.now() + "-testFileCreationNonRecursive");
    IOException expectedException=null;
    final String nonExistDir="/non-exist-" + Time.now();
    fs.delete(new Path(nonExistDir),true);
    EnumSet<CreateFlag> createFlag=EnumSet.of(CreateFlag.CREATE);
    assertNull(createNonRecursive(fs,path,1,createFlag));
    expectedException=createNonRecursive(fs,new Path(path,"Create"),1,createFlag);
    assertTrue("Create a file when parent directory exists as a file" + " should throw ParentNotDirectoryException ",expectedException != null && expectedException instanceof ParentNotDirectoryException);
    fs.delete(path,true);
    final Path path2=new Path(nonExistDir + "/testCreateNonRecursive");
    expectedException=createNonRecursive(fs,path2,1,createFlag);
    assertTrue("Create a file in a non-exist dir using" + " createNonRecursive() should throw FileNotFoundException ",expectedException != null && expectedException instanceof FileNotFoundException);
    EnumSet<CreateFlag> overwriteFlag=EnumSet.of(CreateFlag.CREATE,CreateFlag.OVERWRITE);
    assertNull(createNonRecursive(fs,path,1,overwriteFlag));
    expectedException=createNonRecursive(fs,new Path(path,"Overwrite"),1,overwriteFlag);
    assertTrue("Overwrite a file when parent directory exists as a file" + " should throw ParentNotDirectoryException ",expectedException != null && expectedException instanceof ParentNotDirectoryException);
    fs.delete(path,true);
    final Path path3=new Path(nonExistDir + "/testOverwriteNonRecursive");
    expectedException=createNonRecursive(fs,path3,1,overwriteFlag);
    assertTrue("Overwrite a file in a non-exist dir using" + " createNonRecursive() should throw FileNotFoundException ",expectedException != null && expectedException instanceof FileNotFoundException);
  }
  static IOException createNonRecursive(  FileSystem fs,  Path name,  int repl,  EnumSet<CreateFlag> flag) throws IOException {
    try {
      System.out.println("createNonRecursive: Attempting to create " + name + " with "+ repl+ " replica.");
      int bufferSize=fs.getConf().getInt(CommonConfigurationKeys.IO_FILE_BUFFER_SIZE_KEY,4096);
      FSDataOutputStream stm=fs.createNonRecursive(name,FsPermission.getDefault(),flag,bufferSize,(short)repl,blockSize,null);
      stm.close();
    }
 catch (    IOException e) {
      return e;
    }
    return null;
  }
  /** 
 * Test that file data becomes available before file is closed.
 */
  @Test public void testFileCreationSimulated() throws IOException {
    simulatedStorage=true;
    testFileCreation();
    simulatedStorage=false;
  }
  /** 
 * Test creating two files at the same time. 
 */
  @Test public void testConcurrentFileCreation() throws IOException {
    Configuration conf=new HdfsConfiguration();
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
    try {
      FileSystem fs=cluster.getFileSystem();
      Path[] p={new Path("/foo"),new Path("/bar")};
      FSDataOutputStream[] out={fs.create(p[0]),fs.create(p[1])};
      int i=0;
      for (; i < 100; i++) {
        out[0].write(i);
        out[1].write(i);
      }
      out[0].close();
      for (; i < 200; i++) {
        out[1].write(i);
      }
      out[1].close();
      FSDataInputStream[] in={fs.open(p[0]),fs.open(p[1])};
      for (i=0; i < 100; i++) {
        assertEquals(i,in[0].read());
      }
      for (i=0; i < 200; i++) {
        assertEquals(i,in[1].read());
      }
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  /** 
 * Test creating a file whose data gets sync when closed
 */
  @Test public void testFileCreationSyncOnClose() throws IOException {
    Configuration conf=new HdfsConfiguration();
    conf.setBoolean(DFS_DATANODE_SYNCONCLOSE_KEY,true);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
    try {
      FileSystem fs=cluster.getFileSystem();
      Path[] p={new Path("/foo"),new Path("/bar")};
      FSDataOutputStream[] out={fs.create(p[0]),fs.create(p[1])};
      int i=0;
      for (; i < 100; i++) {
        out[0].write(i);
        out[1].write(i);
      }
      out[0].close();
      for (; i < 200; i++) {
        out[1].write(i);
      }
      out[1].close();
      FSDataInputStream[] in={fs.open(p[0]),fs.open(p[1])};
      for (i=0; i < 100; i++) {
        assertEquals(i,in[0].read());
      }
      for (i=0; i < 200; i++) {
        assertEquals(i,in[1].read());
      }
    }
  finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  /** 
 * Create a file, write something, hflush but not close. Then change lease period and wait for lease recovery. Finally, read the block directly from each Datanode and verify the content.
 */
  @Test public void testLeaseExpireHardLimit() throws Exception {
    System.out.println("testLeaseExpireHardLimit start");
    final long leasePeriod=1000;
    final int DATANODE_NUM=3;
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,1000);
    conf.setInt(DFS_HEARTBEAT_INTERVAL_KEY,1);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_NUM).build();
    DistributedFileSystem dfs=null;
    try {
      cluster.waitActive();
      dfs=cluster.getFileSystem();
      final String f=DIR + "foo";
      final Path fpath=new Path(f);
      HdfsDataOutputStream out=create(dfs,fpath,DATANODE_NUM);
      out.write("something".getBytes());
      out.hflush();
      int actualRepl=out.getCurrentBlockReplication();
      assertTrue(f + " should be replicated to " + DATANODE_NUM+ " datanodes.",actualRepl == DATANODE_NUM);
      cluster.setLeasePeriod(leasePeriod,leasePeriod);
      try {
        Thread.sleep(5 * leasePeriod);
      }
 catch (      InterruptedException e) {
      }
      LocatedBlocks locations=dfs.dfs.getNamenode().getBlockLocations(f,0,Long.MAX_VALUE);
      assertEquals(1,locations.locatedBlockCount());
      LocatedBlock locatedblock=locations.getLocatedBlocks().get(0);
      int successcount=0;
      for (      DatanodeInfo datanodeinfo : locatedblock.getLocations()) {
        DataNode datanode=cluster.getDataNode(datanodeinfo.getIpcPort());
        ExtendedBlock blk=locatedblock.getBlock();
        try (BufferedReader in=new BufferedReader(new InputStreamReader(datanode.getFSDataset().getBlockInputStream(blk,0)))){
          assertEquals("something",in.readLine());
          successcount++;
        }
       }
      System.out.println("successcount=" + successcount);
      assertTrue(successcount > 0);
    }
  finally {
      IOUtils.closeStream(dfs);
      cluster.shutdown();
    }
    System.out.println("testLeaseExpireHardLimit successful");
  }
  @Test public void testFsClose() throws Exception {
    System.out.println("test file system close start");
    final int DATANODE_NUM=3;
    Configuration conf=new HdfsConfiguration();
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_NUM).build();
    DistributedFileSystem dfs=null;
    try {
      cluster.waitActive();
      dfs=cluster.getFileSystem();
      final String f=DIR + "foofs";
      final Path fpath=new Path(f);
      FSDataOutputStream out=TestFileCreation.createFile(dfs,fpath,DATANODE_NUM);
      out.write("something".getBytes());
      dfs.close();
    }
  finally {
      System.out.println("testFsClose successful");
      cluster.shutdown();
    }
  }
  @Test public void testFsCloseAfterClusterShutdown() throws IOException {
    System.out.println("test testFsCloseAfterClusterShutdown start");
    final int DATANODE_NUM=3;
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFS_NAMENODE_REPLICATION_MIN_KEY,3);
    conf.setBoolean("ipc.client.ping",false);
    conf.setInt("ipc.ping.interval",10000);
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_NUM).build();
    DistributedFileSystem dfs=null;
    try {
      cluster.waitActive();
      dfs=cluster.getFileSystem();
      final String f=DIR + "testFsCloseAfterClusterShutdown";
      final Path fpath=new Path(f);
      FSDataOutputStream out=TestFileCreation.createFile(dfs,fpath,DATANODE_NUM);
      out.write("something_test".getBytes());
      out.hflush();
      cluster.stopDataNode(2);
      boolean hasException=false;
      try {
        out.close();
        System.out.println("testFsCloseAfterClusterShutdown: Error here");
      }
 catch (      IOException e) {
        hasException=true;
      }
      assertTrue("Failed to close file after cluster shutdown",hasException);
    }
  finally {
      System.out.println("testFsCloseAfterClusterShutdown successful");
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
  /** 
 * Regression test for HDFS-3626. Creates a file using a non-canonical path (i.e. with extra slashes between components) and makes sure that the NN can properly restart. This test RPCs directly to the NN, to ensure that even an old client which passes an invalid path won't cause corrupt edits.
 */
  @Test public void testCreateNonCanonicalPathAndRestartRpc() throws Exception {
    doCreateTest(CreationMethod.DIRECT_NN_RPC);
  }
  /** 
 * Another regression test for HDFS-3626. This one creates files using a Path instantiated from a string object.
 */
  @Test public void testCreateNonCanonicalPathAndRestartFromString() throws Exception {
    doCreateTest(CreationMethod.PATH_FROM_STRING);
  }
  /** 
 * Another regression test for HDFS-3626. This one creates files using a Path instantiated from a URI object.
 */
  @Test public void testCreateNonCanonicalPathAndRestartFromUri() throws Exception {
    doCreateTest(CreationMethod.PATH_FROM_URI);
  }
  private enum CreationMethod {  DIRECT_NN_RPC,   PATH_FROM_URI,   PATH_FROM_STRING}
  private void doCreateTest(  CreationMethod method) throws Exception {
    Configuration conf=new HdfsConfiguration();
    MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
    try {
      FileSystem fs=cluster.getFileSystem();
      NamenodeProtocols nnrpc=cluster.getNameNodeRpc();
      for (      String pathStr : NON_CANONICAL_PATHS) {
        System.out.println("Creating " + pathStr + " by "+ method);
switch (method) {
case DIRECT_NN_RPC:
          try {
            nnrpc.create(pathStr,new FsPermission((short)0755),"client",new EnumSetWritable<CreateFlag>(EnumSet.of(CreateFlag.CREATE)),true,(short)1,128 * 1024 * 1024L,null,null);
            fail("Should have thrown exception when creating '" + pathStr + "'"+ " by "+ method);
          }
 catch (          InvalidPathException ipe) {
          }
        break;
case PATH_FROM_URI:
case PATH_FROM_STRING:
      Path p;
    if (method == CreationMethod.PATH_FROM_URI) {
      p=new Path(new URI(fs.getUri() + pathStr));
    }
 else {
      p=new Path(fs.getUri() + pathStr);
    }
  FSDataOutputStream stm=fs.create(p);
IOUtils.closeStream(stm);
break;
default :
throw new AssertionError("bad method: " + method);
}
}
cluster.restartNameNode();
}
  finally {
cluster.shutdown();
}
}
/** 
 * Test complete(..) - verifies that the fileId in the request matches that of the Inode. This test checks that FileNotFoundException exception is thrown in case the fileId does not match.
 */
@Test public void testFileIdMismatch() throws IOException {
Configuration conf=new HdfsConfiguration();
MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
DistributedFileSystem dfs=null;
try {
cluster.waitActive();
dfs=cluster.getFileSystem();
DFSClient client=dfs.dfs;
final Path f=new Path("/testFileIdMismatch.txt");
createFile(dfs,f,3);
long someOtherFileId=-1;
try {
cluster.getNameNodeRpc().complete(f.toString(),client.clientName,null,someOtherFileId);
fail();
}
 catch (FileNotFoundException e) {
FileSystem.LOG.info("Caught Expected FileNotFoundException: ",e);
}
}
  finally {
IOUtils.closeStream(dfs);
cluster.shutdown();
}
}
/** 
 * 1. Check the blocks of old file are cleaned after creating with overwrite 2. Restart NN, check the file 3. Save new checkpoint and restart NN, check the file
 */
@Test(timeout=120000) public void testFileCreationWithOverwrite() throws Exception {
Configuration conf=new Configuration();
conf.setInt("dfs.blocksize",blockSize);
MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
DistributedFileSystem dfs=cluster.getFileSystem();
try {
dfs.mkdirs(new Path("/foo/dir"));
String file="/foo/dir/file";
Path filePath=new Path(file);
NameNode nn=cluster.getNameNode();
FSNamesystem fsn=NameNodeAdapter.getNamesystem(nn);
BlockManager bm=fsn.getBlockManager();
FSDataOutputStream out=dfs.create(filePath);
byte[] oldData=AppendTestUtil.randomBytes(seed,fileSize);
try {
out.write(oldData);
}
  finally {
out.close();
}
LocatedBlocks oldBlocks=NameNodeAdapter.getBlockLocations(nn,file,0,fileSize);
assertBlocks(bm,oldBlocks,true);
out=dfs.create(filePath,true);
byte[] newData=AppendTestUtil.randomBytes(seed,fileSize);
try {
out.write(newData);
}
  finally {
out.close();
}
dfs.deleteOnExit(filePath);
LocatedBlocks newBlocks=NameNodeAdapter.getBlockLocations(nn,file,0,fileSize);
assertBlocks(bm,newBlocks,true);
assertBlocks(bm,oldBlocks,false);
FSDataInputStream in=dfs.open(filePath);
byte[] result=null;
try {
result=readAll(in);
}
  finally {
in.close();
}
Assert.assertArrayEquals(newData,result);
cluster.restartNameNode();
nn=cluster.getNameNode();
in=dfs.open(filePath);
try {
result=readAll(in);
}
  finally {
in.close();
}
Assert.assertArrayEquals(newData,result);
NameNodeAdapter.enterSafeMode(nn,false);
NameNodeAdapter.saveNamespace(nn);
cluster.restartNameNode();
nn=cluster.getNameNode();
in=dfs.open(filePath);
try {
result=readAll(in);
}
  finally {
in.close();
}
Assert.assertArrayEquals(newData,result);
}
  finally {
if (dfs != null) {
dfs.close();
}
if (cluster != null) {
cluster.shutdown();
}
}
}
private void assertBlocks(BlockManager bm,LocatedBlocks lbs,boolean exist){
for (LocatedBlock locatedBlock : lbs.getLocatedBlocks()) {
if (exist) {
assertTrue(bm.getStoredBlock(locatedBlock.getBlock().getLocalBlock()) != null);
}
 else {
assertTrue(bm.getStoredBlock(locatedBlock.getBlock().getLocalBlock()) == null);
}
}
}
private byte[] readAll(FSDataInputStream in) throws IOException {
ByteArrayOutputStream out=new ByteArrayOutputStream();
byte[] buffer=new byte[1024];
int n=0;
while ((n=in.read(buffer)) > -1) {
out.write(buffer,0,n);
}
return out.toByteArray();
}
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.hadoop.fs.contract.hdfs;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest;
import org.apache.hadoop.fs.contract.AbstractFSContract;
import org.junit.AfterClass;
import org.junit.BeforeClass;
import java.io.IOException;
public class TestHDFSContractGetFileStatus extends AbstractContractGetFileStatusTest {
  @BeforeClass public static void createCluster() throws IOException {
    HDFSContract.createCluster();
  }
  @AfterClass public static void teardownCluster() throws IOException {
    HDFSContract.destroyCluster();
  }
  @Override protected AbstractFSContract createContract(  Configuration conf){
    return new HDFSContract(conf);
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from hadoop-release-3.2.0-RC0~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.alibaba.dubbo.common.extensionloader;
import com.alibaba.dubbo.common.compiler.support.AdaptiveCompiler;
import org.junit.AfterClass;
import org.junit.BeforeClass;
public class ExtensionLoader_Adaptive_UseJdkCompiler_Test extends ExtensionLoader_Adaptive_Test {
  @BeforeClass public static void setUp() throws Exception {
    AdaptiveCompiler.setDefaultCompiler("jdk");
  }
  @AfterClass public static void tearDown() throws Exception {
    AdaptiveCompiler.setDefaultCompiler("javassist");
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.alibaba.dubbo.remoting.transport.netty4;
import com.alibaba.dubbo.common.extension.ExtensionLoader;
import com.alibaba.dubbo.remoting.Transporter;
import org.junit.Test;
import static org.junit.Assert.*;
import static org.junit.matchers.JUnitMatchers.containsString;
public class ClientsTest {
  @Test public void testGetTransportEmpty(){
    try {
      ExtensionLoader.getExtensionLoader(Transporter.class).getExtension("");
      fail();
    }
 catch (    IllegalArgumentException expected) {
      assertThat(expected.getMessage(),containsString("Extension name == null"));
    }
  }
  @Test(expected=IllegalArgumentException.class) public void testGetTransportNull(){
    String name=null;
    ExtensionLoader.getExtensionLoader(Transporter.class).getExtension(name);
  }
  @Test public void testGetTransport3(){
    String name="netty4";
    assertEquals(NettyTransporter.class,ExtensionLoader.getExtensionLoader(Transporter.class).getExtension(name).getClass());
  }
  @Test(expected=IllegalStateException.class) public void testGetTransportWrong(){
    String name="nety";
    assertNull(ExtensionLoader.getExtensionLoader(Transporter.class).getExtension(name).getClass());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.alibaba.dubbo.config;
import org.junit.Test;
import java.util.HashMap;
import java.util.Map;
import static org.hamcrest.Matchers.equalTo;
import static org.hamcrest.Matchers.is;
import static org.hamcrest.Matchers.isEmptyOrNullString;
import static org.hamcrest.Matchers.sameInstance;
import static org.junit.Assert.assertThat;
public class AbstractMethodConfigTest {
  @Test public void testTimeout() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    methodConfig.setTimeout(10);
    assertThat(methodConfig.getTimeout(),equalTo(10));
  }
  @Test public void testRetries() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    methodConfig.setRetries(3);
    assertThat(methodConfig.getRetries(),equalTo(3));
  }
  @Test public void testLoadbalance() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    methodConfig.setLoadbalance("mockloadbalance");
    assertThat(methodConfig.getLoadbalance(),equalTo("mockloadbalance"));
  }
  @Test public void testAsync() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    methodConfig.setAsync(true);
    assertThat(methodConfig.isAsync(),is(true));
  }
  @Test public void testActives() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    methodConfig.setActives(10);
    assertThat(methodConfig.getActives(),equalTo(10));
  }
  @Test public void testSent() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    methodConfig.setSent(true);
    assertThat(methodConfig.getSent(),is(true));
  }
  @Test public void testMock() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    methodConfig.setMock((Boolean)null);
    assertThat(methodConfig.getMock(),isEmptyOrNullString());
    methodConfig.setMock(true);
    assertThat(methodConfig.getMock(),equalTo("true"));
    methodConfig.setMock("return null");
    assertThat(methodConfig.getMock(),equalTo("return null"));
    methodConfig.setMock("mock");
    assertThat(methodConfig.getMock(),equalTo("mock"));
  }
  @Test public void testMerger() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    methodConfig.setMerger("merger");
    assertThat(methodConfig.getMerger(),equalTo("merger"));
  }
  @Test public void testCache() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    methodConfig.setCache("cache");
    assertThat(methodConfig.getCache(),equalTo("cache"));
  }
  @Test public void testValidation() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    methodConfig.setValidation("validation");
    assertThat(methodConfig.getValidation(),equalTo("validation"));
  }
  @Test public void testParameters() throws Exception {
    MethodConfig methodConfig=new MethodConfig();
    Map<String,String> parameters=new HashMap<String,String>();
    parameters.put("key","value");
    methodConfig.setParameters(parameters);
    assertThat(methodConfig.getParameters(),sameInstance(parameters));
  }
private static class MethodConfig extends AbstractMethodConfig {
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.alibaba.dubbo.config.spring.extension;
import com.alibaba.dubbo.config.spring.api.DemoService;
import com.alibaba.dubbo.config.spring.api.HelloService;
import com.alibaba.dubbo.config.spring.impl.DemoServiceImpl;
import com.alibaba.dubbo.config.spring.impl.HelloServiceImpl;
import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;
import org.springframework.beans.factory.NoUniqueBeanDefinitionException;
import org.springframework.context.annotation.AnnotationConfigApplicationContext;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
@Configuration public class SpringExtensionFactoryTest {
  private SpringExtensionFactory springExtensionFactory=new SpringExtensionFactory();
  private AnnotationConfigApplicationContext context1;
  private AnnotationConfigApplicationContext context2;
  @Before public void init(){
    context1=new AnnotationConfigApplicationContext();
    context1.register(getClass());
    context1.refresh();
    context2=new AnnotationConfigApplicationContext();
    context2.register(BeanForContext2.class);
    context2.refresh();
    SpringExtensionFactory.addApplicationContext(context1);
    SpringExtensionFactory.addApplicationContext(context2);
  }
  @Test public void testGetExtensionByName(){
    DemoService bean=springExtensionFactory.getExtension(DemoService.class,"bean1");
    Assert.assertNotNull(bean);
  }
  @Test public void testGetExtensionByTypeMultiple(){
    try {
      springExtensionFactory.getExtension(DemoService.class,"beanname-not-exist");
    }
 catch (    Exception e) {
      e.printStackTrace();
      Assert.assertTrue(e instanceof NoUniqueBeanDefinitionException);
    }
  }
  @Test public void testGetExtensionByType(){
    HelloService bean=springExtensionFactory.getExtension(HelloService.class,"beanname-not-exist");
    Assert.assertNotNull(bean);
  }
  @After public void destroy(){
    SpringExtensionFactory.clearContexts();
    context1.close();
    context2.close();
  }
  @Bean("bean1") public DemoService bean1(){
    return new DemoServiceImpl();
  }
  @Bean("bean2") public DemoService bean2(){
    return new DemoServiceImpl();
  }
  @Bean("hello") public HelloService helloService(){
    return new HelloServiceImpl();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.alibaba.dubbo.config.spring.status;
import com.alibaba.dubbo.common.status.Status;
import com.alibaba.dubbo.config.spring.ServiceBean;
import org.junit.Before;
import org.junit.Test;
import org.mockito.Mock;
import org.springframework.context.ApplicationContext;
import org.springframework.context.Lifecycle;
import static org.hamcrest.CoreMatchers.is;
import static org.junit.Assert.assertThat;
import static org.mockito.BDDMockito.given;
import static org.mockito.Mockito.mock;
import static org.mockito.MockitoAnnotations.initMocks;
public class SpringStatusCheckerTest {
  private SpringStatusChecker springStatusChecker;
  @Mock private ApplicationContext applicationContext;
  @Before public void setUp() throws Exception {
    initMocks(this);
    this.springStatusChecker=new SpringStatusChecker();
    new ServiceBean<Object>().setApplicationContext(applicationContext);
  }
  @Test public void testWithoutApplicationContext(){
    Status status=springStatusChecker.check();
    assertThat(status.getLevel(),is(Status.Level.UNKNOWN));
  }
  @Test public void testWithLifeCycleRunning(){
    ApplicationLifeCycle applicationLifeCycle=mock(ApplicationLifeCycle.class);
    new ServiceBean<Object>().setApplicationContext(applicationLifeCycle);
    given(applicationLifeCycle.getConfigLocations()).willReturn(new String[]{"test1","test2"});
    given(applicationLifeCycle.isRunning()).willReturn(true);
    Status status=springStatusChecker.check();
    assertThat(status.getLevel(),is(Status.Level.OK));
    assertThat(status.getMessage(),is("test1,test2"));
  }
  @Test public void testWithoutLifeCycleRunning(){
    ApplicationLifeCycle applicationLifeCycle=mock(ApplicationLifeCycle.class);
    new ServiceBean<Object>().setApplicationContext(applicationLifeCycle);
    given(applicationLifeCycle.isRunning()).willReturn(false);
    Status status=springStatusChecker.check();
    assertThat(status.getLevel(),is(Status.Level.ERROR));
  }
interface ApplicationLifeCycle extends Lifecycle, ApplicationContext {
    String[] getConfigLocations();
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from incubator-dubbo-dubbo-2.6.5~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * The MIT License Copyright (c) 2014-2016 Ilkka Seppl Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
package com.iluwatar.async.method.invocation;
import org.junit.jupiter.api.Test;
/** 
 * Application test
 */
public class AppTest {
  @Test public void test() throws Exception {
    String[] args={};
    App.main(args);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * The MIT License Copyright (c) 2014-2016 Ilkka Seppl Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
package com.iluwatar.flux.action;
import org.junit.jupiter.api.Test;
import static org.junit.jupiter.api.Assertions.assertFalse;
import static org.junit.jupiter.api.Assertions.assertNotNull;
/** 
 * Date: 12/12/15 - 10:15 PM
 * @author Jeroen Meulemeester
 */
public class MenuItemTest {
  @Test public void testToString() throws Exception {
    for (    final MenuItem menuItem : MenuItem.values()) {
      final String toString=menuItem.toString();
      assertNotNull(toString);
      assertFalse(toString.trim().isEmpty());
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * The MIT License Copyright (c) 2014-2016 Ilkka Seppl Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
package com.iluwatar.dao;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Nested;
import org.junit.jupiter.api.Test;
import java.util.Optional;
import java.util.stream.Stream;
import static org.junit.jupiter.api.Assertions.assertEquals;
import static org.junit.jupiter.api.Assertions.assertFalse;
import static org.junit.jupiter.api.Assertions.assertTrue;
import static org.junit.jupiter.api.Assumptions.assumeTrue;
/** 
 * Tests  {@link InMemoryCustomerDao}.
 */
public class InMemoryCustomerDaoTest {
  private InMemoryCustomerDao dao;
  private static final Customer CUSTOMER=new Customer(1,"Freddy","Krueger");
  @BeforeEach public void setUp(){
    dao=new InMemoryCustomerDao();
    assertTrue(dao.add(CUSTOMER));
  }
  /** 
 * Represents the scenario when the DAO operations are being performed on a non existent  customer.  
 */
@Nested public class NonExistingCustomer {
    @Test public void addingShouldResultInSuccess() throws Exception {
      try (Stream<Customer> allCustomers=dao.getAll()){
        assumeTrue(allCustomers.count() == 1);
      }
       final Customer nonExistingCustomer=new Customer(2,"Robert","Englund");
      boolean result=dao.add(nonExistingCustomer);
      assertTrue(result);
      assertCustomerCountIs(2);
      assertEquals(nonExistingCustomer,dao.getById(nonExistingCustomer.getId()).get());
    }
    @Test public void deletionShouldBeFailureAndNotAffectExistingCustomers() throws Exception {
      final Customer nonExistingCustomer=new Customer(2,"Robert","Englund");
      boolean result=dao.delete(nonExistingCustomer);
      assertFalse(result);
      assertCustomerCountIs(1);
    }
    @Test public void updationShouldBeFailureAndNotAffectExistingCustomers() throws Exception {
      final int nonExistingId=getNonExistingCustomerId();
      final String newFirstname="Douglas";
      final String newLastname="MacArthur";
      final Customer customer=new Customer(nonExistingId,newFirstname,newLastname);
      boolean result=dao.update(customer);
      assertFalse(result);
      assertFalse(dao.getById(nonExistingId).isPresent());
    }
    @Test public void retrieveShouldReturnNoCustomer() throws Exception {
      assertFalse(dao.getById(getNonExistingCustomerId()).isPresent());
    }
  }
  /** 
 * Represents the scenario when the DAO operations are being performed on an already existing customer.
 */
@Nested public class ExistingCustomer {
    @Test public void addingShouldResultInFailureAndNotAffectExistingCustomers() throws Exception {
      boolean result=dao.add(CUSTOMER);
      assertFalse(result);
      assertCustomerCountIs(1);
      assertEquals(CUSTOMER,dao.getById(CUSTOMER.getId()).get());
    }
    @Test public void deletionShouldBeSuccessAndCustomerShouldBeNonAccessible() throws Exception {
      boolean result=dao.delete(CUSTOMER);
      assertTrue(result);
      assertCustomerCountIs(0);
      assertFalse(dao.getById(CUSTOMER.getId()).isPresent());
    }
    @Test public void updationShouldBeSuccessAndAccessingTheSameCustomerShouldReturnUpdatedInformation() throws Exception {
      final String newFirstname="Bernard";
      final String newLastname="Montgomery";
      final Customer customer=new Customer(CUSTOMER.getId(),newFirstname,newLastname);
      boolean result=dao.update(customer);
      assertTrue(result);
      final Customer cust=dao.getById(CUSTOMER.getId()).get();
      assertEquals(newFirstname,cust.getFirstName());
      assertEquals(newLastname,cust.getLastName());
    }
    @Test public void retriveShouldReturnTheCustomer(){
      Optional<Customer> optionalCustomer=dao.getById(CUSTOMER.getId());
      assertTrue(optionalCustomer.isPresent());
      assertEquals(CUSTOMER,optionalCustomer.get());
    }
  }
  /** 
 * An arbitrary number which does not correspond to an active Customer id.
 * @return an int of a customer id which doesn't exist
 */
  private int getNonExistingCustomerId(){
    return 999;
  }
  private void assertCustomerCountIs(  int count) throws Exception {
    try (Stream<Customer> allCustomers=dao.getAll()){
      assertTrue(allCustomers.count() == count);
    }
   }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * The MIT License Copyright (c) 2014-2016 Ilkka Seppl Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 */
package com.iluwatar.monad;
import org.junit.jupiter.api.Test;
import java.util.Objects;
import static org.junit.jupiter.api.Assertions.assertSame;
import static org.junit.jupiter.api.Assertions.assertThrows;
/** 
 * Test for Monad Pattern
 */
public class MonadTest {
  @Test public void testForInvalidName(){
    User tom=new User(null,21,Sex.MALE,"tom@foo.bar");
    assertThrows(IllegalStateException.class,() -> {
      Validator.of(tom).validate(User::getName,Objects::nonNull,"name cannot be null").get();
    }
);
  }
  @Test public void testForInvalidAge(){
    User john=new User("John",17,Sex.MALE,"john@qwe.bar");
    assertThrows(IllegalStateException.class,() -> {
      Validator.of(john).validate(User::getName,Objects::nonNull,"name cannot be null").validate(User::getAge,age -> age > 21,"user is underaged").get();
    }
);
  }
  @Test public void testForValid(){
    User sarah=new User("Sarah",42,Sex.FEMALE,"sarah@det.org");
    User validated=Validator.of(sarah).validate(User::getName,Objects::nonNull,"name cannot be null").validate(User::getAge,age -> age > 21,"user is underaged").validate(User::getSex,sex -> sex == Sex.FEMALE,"user is not female").validate(User::getEmail,email -> email.contains("@"),"email does not contain @ sign").get();
    assertSame(validated,sarah);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
import org.junit.jupiter.api.Test;
/** 
 * Application test
 */
public class AppTest {
  @Test public void test(){
    String[] args={};
    App.main(args);
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from java-design-patterns-1.20.0~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.kafka.common.network;
import org.apache.kafka.common.KafkaException;
import org.apache.kafka.common.MetricName;
import org.apache.kafka.common.memory.MemoryPool;
import org.apache.kafka.common.memory.SimpleMemoryPool;
import org.apache.kafka.common.metrics.KafkaMetric;
import org.apache.kafka.common.metrics.Metrics;
import org.apache.kafka.common.security.auth.SecurityProtocol;
import org.apache.kafka.common.utils.LogContext;
import org.apache.kafka.common.utils.MockTime;
import org.apache.kafka.common.utils.Time;
import org.apache.kafka.common.utils.Utils;
import org.apache.kafka.test.TestCondition;
import org.apache.kafka.test.TestUtils;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import java.io.ByteArrayOutputStream;
import java.io.DataOutputStream;
import java.io.IOException;
import java.lang.reflect.Field;
import java.net.InetSocketAddress;
import java.net.ServerSocket;
import java.nio.ByteBuffer;
import java.nio.channels.SelectionKey;
import java.nio.channels.ServerSocketChannel;
import java.nio.channels.SocketChannel;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Random;
import java.util.Set;
import java.util.Optional;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertNull;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.fail;
import static org.mockito.Mockito.atLeastOnce;
import static org.mockito.Mockito.doThrow;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.when;
/** 
 * A set of tests for the selector. These use a test harness that runs a simple socket server that echos back responses.
 */
public class SelectorTest {
  protected static final int BUFFER_SIZE=4 * 1024;
  protected EchoServer server;
  protected Time time;
  protected Selector selector;
  protected ChannelBuilder channelBuilder;
  protected Metrics metrics;
  @Before public void setUp() throws Exception {
    Map<String,Object> configs=new HashMap<>();
    this.server=new EchoServer(SecurityProtocol.PLAINTEXT,configs);
    this.server.start();
    this.time=new MockTime();
    this.channelBuilder=new PlaintextChannelBuilder(ListenerName.forSecurityProtocol(SecurityProtocol.PLAINTEXT));
    this.channelBuilder.configure(configs);
    this.metrics=new Metrics();
    this.selector=new Selector(5000,this.metrics,time,"MetricGroup",channelBuilder,new LogContext());
  }
  @After public void tearDown() throws Exception {
    try {
      verifySelectorEmpty();
    }
  finally {
      this.selector.close();
      this.server.close();
      this.metrics.close();
    }
  }
  public SecurityProtocol securityProtocol(){
    return SecurityProtocol.PLAINTEXT;
  }
  /** 
 * Validate that when the server disconnects, a client send ends up with that node in the disconnected list.
 */
  @Test public void testServerDisconnect() throws Exception {
    final String node="0";
    blockingConnect(node);
    assertEquals("hello",blockingRequest(node,"hello"));
    KafkaChannel channel=selector.channel(node);
    this.server.closeConnections();
    TestUtils.waitForCondition(new TestCondition(){
      @Override public boolean conditionMet(){
        try {
          selector.poll(1000L);
          return selector.disconnected().containsKey(node);
        }
 catch (        IOException e) {
          throw new RuntimeException(e);
        }
      }
    }
,5000,"Failed to observe disconnected node in disconnected set");
    assertNull(channel.selectionKey().attachment());
    blockingConnect(node);
    assertEquals("hello",blockingRequest(node,"hello"));
  }
  /** 
 * Sending a request with one already in flight should result in an exception
 */
  @Test public void testCantSendWithInProgress() throws Exception {
    String node="0";
    blockingConnect(node);
    selector.send(createSend(node,"test1"));
    try {
      selector.send(createSend(node,"test2"));
      fail("IllegalStateException not thrown when sending a request with one in flight");
    }
 catch (    IllegalStateException e) {
    }
    selector.poll(0);
    assertTrue("Channel not closed",selector.disconnected().containsKey(node));
    assertEquals(ChannelState.FAILED_SEND,selector.disconnected().get(node));
  }
  /** 
 * Sending a request to a node without an existing connection should result in an exception
 */
  @Test(expected=IllegalStateException.class) public void testCantSendWithoutConnecting() throws Exception {
    selector.send(createSend("0","test"));
    selector.poll(1000L);
  }
  /** 
 * Sending a request to a node with a bad hostname should result in an exception during connect
 */
  @Test(expected=IOException.class) public void testNoRouteToHost() throws Exception {
    selector.connect("0",new InetSocketAddress("some.invalid.hostname.foo.bar.local",server.port),BUFFER_SIZE,BUFFER_SIZE);
  }
  /** 
 * Sending a request to a node not listening on that port should result in disconnection
 */
  @Test public void testConnectionRefused() throws Exception {
    String node="0";
    ServerSocket nonListeningSocket=new ServerSocket(0);
    int nonListeningPort=nonListeningSocket.getLocalPort();
    selector.connect(node,new InetSocketAddress("localhost",nonListeningPort),BUFFER_SIZE,BUFFER_SIZE);
    while (selector.disconnected().containsKey(node)) {
      assertEquals(ChannelState.NOT_CONNECTED,selector.disconnected().get(node));
      selector.poll(1000L);
    }
    nonListeningSocket.close();
  }
  /** 
 * Send multiple requests to several connections in parallel. Validate that responses are received in the order that requests were sent.
 */
  @Test public void testNormalOperation() throws Exception {
    int conns=5;
    int reqs=500;
    InetSocketAddress addr=new InetSocketAddress("localhost",server.port);
    for (int i=0; i < conns; i++)     connect(Integer.toString(i),addr);
    Map<String,Integer> requests=new HashMap<>();
    Map<String,Integer> responses=new HashMap<>();
    int responseCount=0;
    for (int i=0; i < conns; i++) {
      String node=Integer.toString(i);
      selector.send(createSend(node,node + "-0"));
    }
    while (responseCount < conns * reqs) {
      selector.poll(0L);
      assertEquals("No disconnects should have occurred.",0,selector.disconnected().size());
      for (      NetworkReceive receive : selector.completedReceives()) {
        String[] pieces=asString(receive).split("-");
        assertEquals("Should be in the form 'conn-counter'",2,pieces.length);
        assertEquals("Check the source",receive.source(),pieces[0]);
        assertEquals("Check that the receive has kindly been rewound",0,receive.payload().position());
        if (responses.containsKey(receive.source())) {
          assertEquals("Check the request counter",(int)responses.get(receive.source()),Integer.parseInt(pieces[1]));
          responses.put(receive.source(),responses.get(receive.source()) + 1);
        }
 else {
          assertEquals("Check the request counter",0,Integer.parseInt(pieces[1]));
          responses.put(receive.source(),1);
        }
        responseCount++;
      }
      for (      Send send : selector.completedSends()) {
        String dest=send.destination();
        if (requests.containsKey(dest))         requests.put(dest,requests.get(dest) + 1);
 else         requests.put(dest,1);
        if (requests.get(dest) < reqs)         selector.send(createSend(dest,dest + "-" + requests.get(dest)));
      }
    }
  }
  /** 
 * Validate that we can send and receive a message larger than the receive and send buffer size
 */
  @Test public void testSendLargeRequest() throws Exception {
    String node="0";
    blockingConnect(node);
    String big=TestUtils.randomString(10 * BUFFER_SIZE);
    assertEquals(big,blockingRequest(node,big));
  }
  @Test public void testLargeMessageSequence() throws Exception {
    int bufferSize=512 * 1024;
    String node="0";
    int reqs=50;
    InetSocketAddress addr=new InetSocketAddress("localhost",server.port);
    connect(node,addr);
    String requestPrefix=TestUtils.randomString(bufferSize);
    sendAndReceive(node,requestPrefix,0,reqs);
  }
  @Test public void testEmptyRequest() throws Exception {
    String node="0";
    blockingConnect(node);
    assertEquals("",blockingRequest(node,""));
  }
  @Test(expected=IllegalStateException.class) public void testExistingConnectionId() throws IOException {
    blockingConnect("0");
    blockingConnect("0");
  }
  @Test public void testMute() throws Exception {
    blockingConnect("0");
    blockingConnect("1");
    selector.send(createSend("0","hello"));
    selector.send(createSend("1","hi"));
    selector.mute("1");
    while (selector.completedReceives().isEmpty())     selector.poll(5);
    assertEquals("We should have only one response",1,selector.completedReceives().size());
    assertEquals("The response should not be from the muted node","0",selector.completedReceives().get(0).source());
    selector.unmute("1");
    do {
      selector.poll(5);
    }
 while (selector.completedReceives().isEmpty());
    assertEquals("We should have only one response",1,selector.completedReceives().size());
    assertEquals("The response should be from the previously muted node","1",selector.completedReceives().get(0).source());
  }
  @Test public void registerFailure() throws Exception {
    ChannelBuilder channelBuilder=new PlaintextChannelBuilder(null){
      @Override public KafkaChannel buildChannel(      String id,      SelectionKey key,      int maxReceiveSize,      MemoryPool memoryPool) throws KafkaException {
        throw new RuntimeException("Test exception");
      }
      @Override public void close(){
      }
    }
;
    Selector selector=new Selector(5000,new Metrics(),new MockTime(),"MetricGroup",channelBuilder,new LogContext());
    SocketChannel socketChannel=SocketChannel.open();
    socketChannel.configureBlocking(false);
    try {
      selector.register("1",socketChannel);
      fail("Register did not fail");
    }
 catch (    IOException e) {
      assertTrue("Unexpected exception: " + e,e.getCause().getMessage().contains("Test exception"));
      assertFalse("Socket not closed",socketChannel.isOpen());
    }
    selector.close();
  }
  @Test public void testCloseConnectionInClosingState() throws Exception {
    KafkaChannel channel=createConnectionWithStagedReceives(5);
    String id=channel.id();
    selector.mute(id);
    time.sleep(6000);
    selector.poll(0);
    assertNull("Channel not expired",selector.channel(id));
    assertEquals(channel,selector.closingChannel(id));
    assertEquals(ChannelState.EXPIRED,channel.state());
    selector.close(id);
    assertNull("Channel not removed from channels",selector.channel(id));
    assertNull("Channel not removed from closingChannels",selector.closingChannel(id));
    assertTrue("Unexpected disconnect notification",selector.disconnected().isEmpty());
    assertEquals(ChannelState.EXPIRED,channel.state());
    assertNull(channel.selectionKey().attachment());
    selector.poll(0);
    assertTrue("Unexpected disconnect notification",selector.disconnected().isEmpty());
  }
  @Test public void testCloseOldestConnection() throws Exception {
    String id="0";
    blockingConnect(id);
    time.sleep(6000);
    selector.poll(0);
    assertTrue("The idle connection should have been closed",selector.disconnected().containsKey(id));
    assertEquals(ChannelState.EXPIRED,selector.disconnected().get(id));
  }
  @Test public void testIdleExpiryWithoutReadyKeys() throws IOException {
    String id="0";
    selector.connect(id,new InetSocketAddress("localhost",server.port),BUFFER_SIZE,BUFFER_SIZE);
    KafkaChannel channel=selector.channel(id);
    channel.selectionKey().interestOps(0);
    time.sleep(6000);
    selector.poll(0);
    assertTrue("The idle connection should have been closed",selector.disconnected().containsKey(id));
    assertEquals(ChannelState.EXPIRED,selector.disconnected().get(id));
  }
  @Test public void testImmediatelyConnectedCleaned() throws Exception {
    Metrics metrics=new Metrics();
    Selector selector=new Selector(5000,metrics,time,"MetricGroup",channelBuilder,new LogContext()){
      @Override protected boolean doConnect(      SocketChannel channel,      InetSocketAddress address) throws IOException {
        channel.configureBlocking(true);
        boolean connected=super.doConnect(channel,address);
        channel.configureBlocking(false);
        return connected;
      }
    }
;
    try {
      testImmediatelyConnectedCleaned(selector,true);
      testImmediatelyConnectedCleaned(selector,false);
    }
  finally {
      selector.close();
      metrics.close();
    }
  }
  private void testImmediatelyConnectedCleaned(  Selector selector,  boolean closeAfterFirstPoll) throws Exception {
    String id="0";
    selector.connect(id,new InetSocketAddress("localhost",server.port),BUFFER_SIZE,BUFFER_SIZE);
    verifyNonEmptyImmediatelyConnectedKeys(selector);
    if (closeAfterFirstPoll) {
      selector.poll(0);
      verifyEmptyImmediatelyConnectedKeys(selector);
    }
    selector.close(id);
    verifySelectorEmpty(selector);
  }
  @Test public void testCloseOldestConnectionWithOneStagedReceive() throws Exception {
    verifyCloseOldestConnectionWithStagedReceives(1);
  }
  @Test public void testCloseOldestConnectionWithMultipleStagedReceives() throws Exception {
    verifyCloseOldestConnectionWithStagedReceives(5);
  }
  private KafkaChannel createConnectionWithStagedReceives(  int maxStagedReceives) throws Exception {
    String id="0";
    blockingConnect(id);
    KafkaChannel channel=selector.channel(id);
    int retries=100;
    do {
      selector.mute(id);
      for (int i=0; i <= maxStagedReceives; i++) {
        selector.send(createSend(id,String.valueOf(i)));
        do {
          selector.poll(1000);
        }
 while (selector.completedSends().isEmpty());
      }
      selector.unmute(id);
      do {
        selector.poll(1000);
      }
 while (selector.completedReceives().isEmpty());
    }
 while (selector.numStagedReceives(channel) == 0 && --retries > 0);
    assertTrue("No staged receives after 100 attempts",selector.numStagedReceives(channel) > 0);
    return channel;
  }
  private void verifyCloseOldestConnectionWithStagedReceives(  int maxStagedReceives) throws Exception {
    KafkaChannel channel=createConnectionWithStagedReceives(maxStagedReceives);
    String id=channel.id();
    int stagedReceives=selector.numStagedReceives(channel);
    int completedReceives=0;
    while (selector.disconnected().isEmpty()) {
      time.sleep(6000);
      selector.poll(0);
      completedReceives+=selector.completedReceives().size();
      int newStaged=selector.numStagedReceives(channel) - (stagedReceives - completedReceives);
      if (newStaged > 0) {
        stagedReceives+=newStaged;
        assertNotNull("Channel should not have been expired",selector.channel(id));
        assertFalse("Channel should not have been disconnected",selector.disconnected().containsKey(id));
      }
 else       if (!selector.completedReceives().isEmpty()) {
        assertEquals(1,selector.completedReceives().size());
        assertTrue("Channel not found",selector.closingChannel(id) != null || selector.channel(id) != null);
        assertFalse("Disconnect notified too early",selector.disconnected().containsKey(id));
      }
    }
    assertEquals(stagedReceives,completedReceives);
    assertNull("Channel not removed",selector.channel(id));
    assertNull("Channel not removed",selector.closingChannel(id));
    assertTrue("Disconnect not notified",selector.disconnected().containsKey(id));
    assertTrue("Unexpected receive",selector.completedReceives().isEmpty());
  }
  @Test public void testMuteOnOOM() throws Exception {
    selector.close();
    MemoryPool pool=new SimpleMemoryPool(900,900,false,null);
    selector=new Selector(NetworkReceive.UNLIMITED,5000,metrics,time,"MetricGroup",new HashMap<String,String>(),true,false,channelBuilder,pool,new LogContext());
    try (ServerSocketChannel ss=ServerSocketChannel.open()){
      ss.bind(new InetSocketAddress(0));
      InetSocketAddress serverAddress=(InetSocketAddress)ss.getLocalAddress();
      Thread sender1=createSender(serverAddress,randomPayload(900));
      Thread sender2=createSender(serverAddress,randomPayload(900));
      sender1.start();
      sender2.start();
      sender1.join(5000);
      sender2.join(5000);
      SocketChannel channelX=ss.accept();
      channelX.configureBlocking(false);
      SocketChannel channelY=ss.accept();
      channelY.configureBlocking(false);
      selector.register("clientX",channelX);
      selector.register("clientY",channelY);
      List<NetworkReceive> completed=Collections.emptyList();
      long deadline=System.currentTimeMillis() + 5000;
      while (System.currentTimeMillis() < deadline && completed.isEmpty()) {
        selector.poll(1000);
        completed=selector.completedReceives();
      }
      assertEquals("could not read a single request within timeout",1,completed.size());
      NetworkReceive firstReceive=completed.get(0);
      assertEquals(0,pool.availableMemory());
      assertTrue(selector.isOutOfMemory());
      selector.poll(10);
      assertTrue(selector.completedReceives().isEmpty());
      assertEquals(0,pool.availableMemory());
      assertTrue(selector.isOutOfMemory());
      firstReceive.close();
      assertEquals(900,pool.availableMemory());
      completed=Collections.emptyList();
      deadline=System.currentTimeMillis() + 5000;
      while (System.currentTimeMillis() < deadline && completed.isEmpty()) {
        selector.poll(1000);
        completed=selector.completedReceives();
      }
      assertEquals("could not read a single request within timeout",1,selector.completedReceives().size());
      assertEquals(0,pool.availableMemory());
      assertFalse(selector.isOutOfMemory());
    }
   }
  private Thread createSender(  InetSocketAddress serverAddress,  byte[] payload){
    return new PlaintextSender(serverAddress,payload);
  }
  protected byte[] randomPayload(  int sizeBytes) throws Exception {
    Random random=new Random();
    byte[] payload=new byte[sizeBytes + 4];
    random.nextBytes(payload);
    ByteArrayOutputStream prefixOs=new ByteArrayOutputStream();
    DataOutputStream prefixDos=new DataOutputStream(prefixOs);
    prefixDos.writeInt(sizeBytes);
    prefixDos.flush();
    prefixDos.close();
    prefixOs.flush();
    prefixOs.close();
    byte[] prefix=prefixOs.toByteArray();
    System.arraycopy(prefix,0,payload,0,prefix.length);
    return payload;
  }
  /** 
 * Tests that a connect and disconnect in a single poll invocation results in the channel id being in `disconnected`, but not `connected`.
 */
  @Test public void testConnectDisconnectDuringInSinglePoll() throws Exception {
    KafkaChannel kafkaChannel=mock(KafkaChannel.class);
    when(kafkaChannel.id()).thenReturn("1");
    when(kafkaChannel.socketDescription()).thenReturn("");
    when(kafkaChannel.state()).thenReturn(ChannelState.NOT_CONNECTED);
    when(kafkaChannel.finishConnect()).thenReturn(true);
    when(kafkaChannel.isConnected()).thenReturn(true);
    when(kafkaChannel.ready()).thenReturn(false);
    doThrow(new IOException()).when(kafkaChannel).prepare();
    SelectionKey selectionKey=mock(SelectionKey.class);
    when(kafkaChannel.selectionKey()).thenReturn(selectionKey);
    when(selectionKey.channel()).thenReturn(SocketChannel.open());
    when(selectionKey.readyOps()).thenReturn(SelectionKey.OP_CONNECT);
    selectionKey.attach(kafkaChannel);
    Set<SelectionKey> selectionKeys=Utils.mkSet(selectionKey);
    selector.pollSelectionKeys(selectionKeys,false,System.nanoTime());
    assertFalse(selector.connected().contains(kafkaChannel.id()));
    assertTrue(selector.disconnected().containsKey(kafkaChannel.id()));
    assertNull(selectionKey.attachment());
    verify(kafkaChannel,atLeastOnce()).ready();
    verify(kafkaChannel).disconnect();
    verify(kafkaChannel).close();
    verify(selectionKey).cancel();
  }
  @Test public void testOutboundConnectionsCountInConnectionCreationMetric() throws Exception {
    int expectedConnections=5;
    InetSocketAddress addr=new InetSocketAddress("localhost",server.port);
    for (int i=0; i < expectedConnections; i++)     connect(Integer.toString(i),addr);
    int seenConnections=0;
    for (int i=0; i < 10; i++) {
      selector.poll(100L);
      seenConnections+=selector.connected().size();
      if (seenConnections == expectedConnections)       break;
    }
    assertEquals((double)expectedConnections,getMetric("connection-creation-total").metricValue());
    assertEquals((double)expectedConnections,getMetric("connection-count").metricValue());
  }
  @Test public void testInboundConnectionsCountInConnectionCreationMetric() throws Exception {
    int conns=5;
    try (ServerSocketChannel ss=ServerSocketChannel.open()){
      ss.bind(new InetSocketAddress(0));
      InetSocketAddress serverAddress=(InetSocketAddress)ss.getLocalAddress();
      for (int i=0; i < conns; i++) {
        Thread sender=createSender(serverAddress,randomPayload(1));
        sender.start();
        SocketChannel channel=ss.accept();
        channel.configureBlocking(false);
        selector.register(Integer.toString(i),channel);
      }
    }
     assertEquals((double)conns,getMetric("connection-creation-total").metricValue());
    assertEquals((double)conns,getMetric("connection-count").metricValue());
  }
  private String blockingRequest(  String node,  String s) throws IOException {
    selector.send(createSend(node,s));
    selector.poll(1000L);
    while (true) {
      selector.poll(1000L);
      for (      NetworkReceive receive : selector.completedReceives())       if (receive.source().equals(node))       return asString(receive);
    }
  }
  protected void connect(  String node,  InetSocketAddress serverAddr) throws IOException {
    selector.connect(node,serverAddr,BUFFER_SIZE,BUFFER_SIZE);
  }
  private void blockingConnect(  String node) throws IOException {
    blockingConnect(node,new InetSocketAddress("localhost",server.port));
  }
  protected void blockingConnect(  String node,  InetSocketAddress serverAddr) throws IOException {
    selector.connect(node,serverAddr,BUFFER_SIZE,BUFFER_SIZE);
    while (!selector.connected().contains(node))     selector.poll(10000L);
    while (!selector.isChannelReady(node))     selector.poll(10000L);
  }
  protected NetworkSend createSend(  String node,  String s){
    return new NetworkSend(node,ByteBuffer.wrap(s.getBytes()));
  }
  protected String asString(  NetworkReceive receive){
    return new String(Utils.toArray(receive.payload()));
  }
  private void sendAndReceive(  String node,  String requestPrefix,  int startIndex,  int endIndex) throws Exception {
    int requests=startIndex;
    int responses=startIndex;
    selector.send(createSend(node,requestPrefix + "-" + startIndex));
    requests++;
    while (responses < endIndex) {
      selector.poll(0L);
      assertEquals("No disconnects should have occurred.",0,selector.disconnected().size());
      for (      NetworkReceive receive : selector.completedReceives()) {
        assertEquals(requestPrefix + "-" + responses,asString(receive));
        responses++;
      }
      for (int i=0; i < selector.completedSends().size() && requests < endIndex; i++, requests++) {
        selector.send(createSend(node,requestPrefix + "-" + requests));
      }
    }
  }
  private void verifyNonEmptyImmediatelyConnectedKeys(  Selector selector) throws Exception {
    Field field=Selector.class.getDeclaredField("immediatelyConnectedKeys");
    field.setAccessible(true);
    Collection<?> immediatelyConnectedKeys=(Collection<?>)field.get(selector);
    assertFalse(immediatelyConnectedKeys.isEmpty());
  }
  private void verifyEmptyImmediatelyConnectedKeys(  Selector selector) throws Exception {
    Field field=Selector.class.getDeclaredField("immediatelyConnectedKeys");
    ensureEmptySelectorField(selector,field);
  }
  protected void verifySelectorEmpty() throws Exception {
    verifySelectorEmpty(this.selector);
  }
  private void verifySelectorEmpty(  Selector selector) throws Exception {
    for (    KafkaChannel channel : selector.channels()) {
      selector.close(channel.id());
      assertNull(channel.selectionKey().attachment());
    }
    selector.poll(0);
    selector.poll(0);
    for (    Field field : Selector.class.getDeclaredFields()) {
      ensureEmptySelectorField(selector,field);
    }
  }
  private void ensureEmptySelectorField(  Selector selector,  Field field) throws Exception {
    field.setAccessible(true);
    Object obj=field.get(selector);
    if (obj instanceof Collection)     assertTrue("Field not empty: " + field + " "+ obj,((Collection<?>)obj).isEmpty());
 else     if (obj instanceof Map)     assertTrue("Field not empty: " + field + " "+ obj,((Map<?,?>)obj).isEmpty());
  }
  private KafkaMetric getMetric(  String name) throws Exception {
    Optional<Map.Entry<MetricName,KafkaMetric>> metric=metrics.metrics().entrySet().stream().filter(entry -> entry.getKey().name().equals(name)).findFirst();
    if (!metric.isPresent())     throw new Exception(String.format("Could not find metric called %s",name));
    return metric.get().getValue();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.kafka.common.network;
import static org.junit.Assert.assertEquals;
import org.apache.kafka.common.MetricName;
import org.apache.kafka.common.config.AbstractConfig;
import org.apache.kafka.common.metrics.KafkaMetric;
import org.apache.kafka.common.metrics.Metrics;
import org.apache.kafka.common.security.auth.SecurityProtocol;
import org.apache.kafka.common.security.authenticator.CredentialCache;
import org.apache.kafka.common.security.scram.ScramCredential;
import org.apache.kafka.common.security.scram.internals.ScramMechanism;
import org.apache.kafka.common.utils.LogContext;
import org.apache.kafka.common.utils.Time;
import org.apache.kafka.test.TestCondition;
import org.apache.kafka.test.TestUtils;
import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.nio.channels.SelectionKey;
import java.nio.channels.ServerSocketChannel;
import java.nio.channels.SocketChannel;
import java.nio.channels.WritableByteChannel;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import org.apache.kafka.common.security.token.delegation.internals.DelegationTokenCache;
/** 
 * Non-blocking EchoServer implementation that uses ChannelBuilder to create channels with the configured security protocol.
 */
public class NioEchoServer extends Thread {
  private static final double EPS=0.0001;
  private final int port;
  private final ServerSocketChannel serverSocketChannel;
  private final List<SocketChannel> newChannels;
  private final List<SocketChannel> socketChannels;
  private final AcceptorThread acceptorThread;
  private final Selector selector;
  private volatile WritableByteChannel outputChannel;
  private final CredentialCache credentialCache;
  private final Metrics metrics;
  private volatile int numSent=0;
  private volatile boolean closeKafkaChannels;
  private final DelegationTokenCache tokenCache;
  public NioEchoServer(  ListenerName listenerName,  SecurityProtocol securityProtocol,  AbstractConfig config,  String serverHost,  ChannelBuilder channelBuilder,  CredentialCache credentialCache,  Time time) throws Exception {
    this(listenerName,securityProtocol,config,serverHost,channelBuilder,credentialCache,100,time);
  }
  public NioEchoServer(  ListenerName listenerName,  SecurityProtocol securityProtocol,  AbstractConfig config,  String serverHost,  ChannelBuilder channelBuilder,  CredentialCache credentialCache,  int failedAuthenticationDelayMs,  Time time) throws Exception {
    super("echoserver");
    setDaemon(true);
    serverSocketChannel=ServerSocketChannel.open();
    serverSocketChannel.configureBlocking(false);
    serverSocketChannel.socket().bind(new InetSocketAddress(serverHost,0));
    this.port=serverSocketChannel.socket().getLocalPort();
    this.socketChannels=Collections.synchronizedList(new ArrayList<SocketChannel>());
    this.newChannels=Collections.synchronizedList(new ArrayList<SocketChannel>());
    this.credentialCache=credentialCache;
    this.tokenCache=new DelegationTokenCache(ScramMechanism.mechanismNames());
    if (securityProtocol == SecurityProtocol.SASL_PLAINTEXT || securityProtocol == SecurityProtocol.SASL_SSL) {
      for (      String mechanism : ScramMechanism.mechanismNames()) {
        if (credentialCache.cache(mechanism,ScramCredential.class) == null)         credentialCache.createCache(mechanism,ScramCredential.class);
      }
    }
    if (channelBuilder == null)     channelBuilder=ChannelBuilders.serverChannelBuilder(listenerName,false,securityProtocol,config,credentialCache,tokenCache);
    this.metrics=new Metrics();
    this.selector=new Selector(10000,failedAuthenticationDelayMs,metrics,time,"MetricGroup",channelBuilder,new LogContext());
    acceptorThread=new AcceptorThread();
  }
  public int port(){
    return port;
  }
  public CredentialCache credentialCache(){
    return credentialCache;
  }
  public DelegationTokenCache tokenCache(){
    return tokenCache;
  }
  @SuppressWarnings("deprecation") public double metricValue(  String name){
    for (    Map.Entry<MetricName,KafkaMetric> entry : metrics.metrics().entrySet()) {
      if (entry.getKey().name().equals(name))       return (double)entry.getValue().metricValue();
    }
    throw new IllegalStateException("Metric not found, " + name + ", found="+ metrics.metrics().keySet());
  }
  public void verifyAuthenticationMetrics(  int successfulAuthentications,  final int failedAuthentications) throws InterruptedException {
    waitForMetric("successful-authentication",successfulAuthentications);
    waitForMetric("failed-authentication",failedAuthentications);
  }
  public void waitForMetric(  String name,  final double expectedValue) throws InterruptedException {
    final String totalName=name + "-total";
    final String rateName=name + "-rate";
    if (expectedValue == 0.0) {
      assertEquals(expectedValue,metricValue(totalName),EPS);
      assertEquals(expectedValue,metricValue(rateName),EPS);
    }
 else {
      TestUtils.waitForCondition(new TestCondition(){
        @Override public boolean conditionMet(){
          return Math.abs(metricValue(totalName) - expectedValue) <= EPS;
        }
      }
,"Metric not updated " + totalName);
      TestUtils.waitForCondition(new TestCondition(){
        @Override public boolean conditionMet(){
          return metricValue(rateName) > 0.0;
        }
      }
,"Metric not updated " + rateName);
    }
  }
  @Override public void run(){
    try {
      acceptorThread.start();
      while (serverSocketChannel.isOpen()) {
        selector.poll(100);
synchronized (newChannels) {
          for (          SocketChannel socketChannel : newChannels) {
            String id=id(socketChannel);
            selector.register(id,socketChannel);
            socketChannels.add(socketChannel);
          }
          newChannels.clear();
        }
        if (closeKafkaChannels) {
          for (          KafkaChannel channel : selector.channels())           selector.close(channel.id());
        }
        List<NetworkReceive> completedReceives=selector.completedReceives();
        for (        NetworkReceive rcv : completedReceives) {
          KafkaChannel channel=channel(rcv.source());
          String channelId=channel.id();
          selector.mute(channelId);
          NetworkSend send=new NetworkSend(rcv.source(),rcv.payload());
          if (outputChannel == null)           selector.send(send);
 else {
            for (            ByteBuffer buffer : send.buffers)             outputChannel.write(buffer);
            selector.unmute(channelId);
          }
        }
        for (        Send send : selector.completedSends()) {
          selector.unmute(send.destination());
          numSent+=1;
        }
      }
    }
 catch (    IOException e) {
    }
  }
  public int numSent(){
    return numSent;
  }
  private String id(  SocketChannel channel){
    return channel.socket().getLocalAddress().getHostAddress() + ":" + channel.socket().getLocalPort()+ "-"+ channel.socket().getInetAddress().getHostAddress()+ ":"+ channel.socket().getPort();
  }
  private KafkaChannel channel(  String id){
    KafkaChannel channel=selector.channel(id);
    return channel == null ? selector.closingChannel(id) : channel;
  }
  /** 
 * Sets the output channel to which messages received on this server are echoed. This is useful in tests where the clients sending the messages don't receive the responses (eg. testing graceful close).
 */
  public void outputChannel(  WritableByteChannel channel){
    this.outputChannel=channel;
  }
  public Selector selector(){
    return selector;
  }
  public void closeKafkaChannels() throws IOException {
    closeKafkaChannels=true;
    selector.wakeup();
    try {
      TestUtils.waitForCondition(() -> selector.channels().isEmpty(),"Channels not closed");
    }
 catch (    InterruptedException e) {
      throw new RuntimeException(e);
    }
 finally {
      closeKafkaChannels=false;
    }
  }
  public void closeSocketChannels() throws IOException {
    for (    SocketChannel channel : socketChannels) {
      channel.close();
    }
    socketChannels.clear();
  }
  public void close() throws IOException, InterruptedException {
    this.serverSocketChannel.close();
    closeSocketChannels();
    acceptorThread.interrupt();
    acceptorThread.join();
    interrupt();
    join();
  }
private class AcceptorThread extends Thread {
    public AcceptorThread() throws IOException {
      setName("acceptor");
    }
    public void run(){
      try {
        java.nio.channels.Selector acceptSelector=java.nio.channels.Selector.open();
        serverSocketChannel.register(acceptSelector,SelectionKey.OP_ACCEPT);
        while (serverSocketChannel.isOpen()) {
          if (acceptSelector.select(1000) > 0) {
            Iterator<SelectionKey> it=acceptSelector.selectedKeys().iterator();
            while (it.hasNext()) {
              SelectionKey key=it.next();
              if (key.isAcceptable()) {
                SocketChannel socketChannel=((ServerSocketChannel)key.channel()).accept();
                socketChannel.configureBlocking(false);
                newChannels.add(socketChannel);
                selector.wakeup();
              }
              it.remove();
            }
          }
        }
      }
 catch (      IOException e) {
      }
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.kafka.streams.tools;
import kafka.tools.StreamsResetter;
import org.apache.kafka.clients.admin.MockAdminClient;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.MockConsumer;
import org.apache.kafka.clients.consumer.OffsetResetStrategy;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.Node;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.TopicPartitionInfo;
import org.junit.Before;
import org.junit.Test;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.time.Duration;
import java.util.Collections;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ExecutionException;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.fail;
public class StreamsResetterTest {
  private static final String TOPIC="topic1";
  private final StreamsResetter streamsResetter=new StreamsResetter();
  private final MockConsumer<byte[],byte[]> consumer=new MockConsumer<>(OffsetResetStrategy.EARLIEST);
  private final TopicPartition topicPartition=new TopicPartition(TOPIC,0);
  private final Set<TopicPartition> inputTopicPartitions=new HashSet<>(Collections.singletonList(topicPartition));
  @Before public void setUp(){
    consumer.assign(Collections.singletonList(topicPartition));
    consumer.addRecord(new ConsumerRecord<>(TOPIC,0,0L,new byte[]{},new byte[]{}));
    consumer.addRecord(new ConsumerRecord<>(TOPIC,0,1L,new byte[]{},new byte[]{}));
    consumer.addRecord(new ConsumerRecord<>(TOPIC,0,2L,new byte[]{},new byte[]{}));
    consumer.addRecord(new ConsumerRecord<>(TOPIC,0,3L,new byte[]{},new byte[]{}));
    consumer.addRecord(new ConsumerRecord<>(TOPIC,0,4L,new byte[]{},new byte[]{}));
  }
  @Test public void testResetToSpecificOffsetWhenBetweenBeginningAndEndOffset(){
    final Map<TopicPartition,Long> endOffsets=new HashMap<>();
    endOffsets.put(topicPartition,4L);
    consumer.updateEndOffsets(endOffsets);
    final Map<TopicPartition,Long> beginningOffsets=new HashMap<>();
    beginningOffsets.put(topicPartition,0L);
    consumer.updateBeginningOffsets(beginningOffsets);
    streamsResetter.resetOffsetsTo(consumer,inputTopicPartitions,2L);
    final ConsumerRecords<byte[],byte[]> records=consumer.poll(Duration.ofMillis(500));
    assertEquals(3,records.count());
  }
  @Test public void testResetToSpecificOffsetWhenBeforeBeginningOffset(){
    final Map<TopicPartition,Long> endOffsets=new HashMap<>();
    endOffsets.put(topicPartition,4L);
    consumer.updateEndOffsets(endOffsets);
    final Map<TopicPartition,Long> beginningOffsets=new HashMap<>();
    beginningOffsets.put(topicPartition,3L);
    consumer.updateBeginningOffsets(beginningOffsets);
    streamsResetter.resetOffsetsTo(consumer,inputTopicPartitions,2L);
    final ConsumerRecords<byte[],byte[]> records=consumer.poll(Duration.ofMillis(500));
    assertEquals(2,records.count());
  }
  @Test public void testResetToSpecificOffsetWhenAfterEndOffset(){
    final Map<TopicPartition,Long> endOffsets=new HashMap<>();
    endOffsets.put(topicPartition,3L);
    consumer.updateEndOffsets(endOffsets);
    final Map<TopicPartition,Long> beginningOffsets=new HashMap<>();
    beginningOffsets.put(topicPartition,0L);
    consumer.updateBeginningOffsets(beginningOffsets);
    streamsResetter.resetOffsetsTo(consumer,inputTopicPartitions,4L);
    final ConsumerRecords<byte[],byte[]> records=consumer.poll(Duration.ofMillis(500));
    assertEquals(2,records.count());
  }
  @Test public void testShiftOffsetByWhenBetweenBeginningAndEndOffset(){
    final Map<TopicPartition,Long> endOffsets=new HashMap<>();
    endOffsets.put(topicPartition,4L);
    consumer.updateEndOffsets(endOffsets);
    final Map<TopicPartition,Long> beginningOffsets=new HashMap<>();
    beginningOffsets.put(topicPartition,0L);
    consumer.updateBeginningOffsets(beginningOffsets);
    streamsResetter.shiftOffsetsBy(consumer,inputTopicPartitions,3L);
    final ConsumerRecords<byte[],byte[]> records=consumer.poll(Duration.ofMillis(500));
    assertEquals(2,records.count());
  }
  @Test public void testShiftOffsetByWhenBeforeBeginningOffset(){
    final Map<TopicPartition,Long> endOffsets=new HashMap<>();
    endOffsets.put(topicPartition,4L);
    consumer.updateEndOffsets(endOffsets);
    final Map<TopicPartition,Long> beginningOffsets=new HashMap<>();
    beginningOffsets.put(topicPartition,0L);
    consumer.updateBeginningOffsets(beginningOffsets);
    streamsResetter.shiftOffsetsBy(consumer,inputTopicPartitions,-3L);
    final ConsumerRecords<byte[],byte[]> records=consumer.poll(Duration.ofMillis(500));
    assertEquals(5,records.count());
  }
  @Test public void testShiftOffsetByWhenAfterEndOffset(){
    final Map<TopicPartition,Long> endOffsets=new HashMap<>();
    endOffsets.put(topicPartition,3L);
    consumer.updateEndOffsets(endOffsets);
    final Map<TopicPartition,Long> beginningOffsets=new HashMap<>();
    beginningOffsets.put(topicPartition,0L);
    consumer.updateBeginningOffsets(beginningOffsets);
    streamsResetter.shiftOffsetsBy(consumer,inputTopicPartitions,5L);
    final ConsumerRecords<byte[],byte[]> records=consumer.poll(Duration.ofMillis(500));
    assertEquals(2,records.count());
  }
  @Test public void testResetUsingPlanWhenBetweenBeginningAndEndOffset(){
    final Map<TopicPartition,Long> endOffsets=new HashMap<>();
    endOffsets.put(topicPartition,4L);
    consumer.updateEndOffsets(endOffsets);
    final Map<TopicPartition,Long> beginningOffsets=new HashMap<>();
    beginningOffsets.put(topicPartition,0L);
    consumer.updateBeginningOffsets(beginningOffsets);
    final Map<TopicPartition,Long> topicPartitionsAndOffset=new HashMap<>();
    topicPartitionsAndOffset.put(topicPartition,3L);
    streamsResetter.resetOffsetsFromResetPlan(consumer,inputTopicPartitions,topicPartitionsAndOffset);
    final ConsumerRecords<byte[],byte[]> records=consumer.poll(Duration.ofMillis(500));
    assertEquals(2,records.count());
  }
  @Test public void testResetUsingPlanWhenBeforeBeginningOffset(){
    final Map<TopicPartition,Long> endOffsets=new HashMap<>();
    endOffsets.put(topicPartition,4L);
    consumer.updateEndOffsets(endOffsets);
    final Map<TopicPartition,Long> beginningOffsets=new HashMap<>();
    beginningOffsets.put(topicPartition,3L);
    consumer.updateBeginningOffsets(beginningOffsets);
    final Map<TopicPartition,Long> topicPartitionsAndOffset=new HashMap<>();
    topicPartitionsAndOffset.put(topicPartition,1L);
    streamsResetter.resetOffsetsFromResetPlan(consumer,inputTopicPartitions,topicPartitionsAndOffset);
    final ConsumerRecords<byte[],byte[]> records=consumer.poll(Duration.ofMillis(500));
    assertEquals(2,records.count());
  }
  @Test public void testResetUsingPlanWhenAfterEndOffset(){
    final Map<TopicPartition,Long> endOffsets=new HashMap<>();
    endOffsets.put(topicPartition,3L);
    consumer.updateEndOffsets(endOffsets);
    final Map<TopicPartition,Long> beginningOffsets=new HashMap<>();
    beginningOffsets.put(topicPartition,0L);
    consumer.updateBeginningOffsets(beginningOffsets);
    final Map<TopicPartition,Long> topicPartitionsAndOffset=new HashMap<>();
    topicPartitionsAndOffset.put(topicPartition,5L);
    streamsResetter.resetOffsetsFromResetPlan(consumer,inputTopicPartitions,topicPartitionsAndOffset);
    final ConsumerRecords<byte[],byte[]> records=consumer.poll(Duration.ofMillis(500));
    assertEquals(2,records.count());
  }
  @Test public void shouldSeekToEndOffset(){
    final Map<TopicPartition,Long> endOffsets=new HashMap<>();
    endOffsets.put(topicPartition,3L);
    consumer.updateEndOffsets(endOffsets);
    final Map<TopicPartition,Long> beginningOffsets=new HashMap<>();
    beginningOffsets.put(topicPartition,0L);
    consumer.updateBeginningOffsets(beginningOffsets);
    final Set<TopicPartition> intermediateTopicPartitions=new HashSet<>();
    intermediateTopicPartitions.add(topicPartition);
    streamsResetter.maybeSeekToEnd("g1",consumer,intermediateTopicPartitions);
    final ConsumerRecords<byte[],byte[]> records=consumer.poll(Duration.ofMillis(500));
    assertEquals(2,records.count());
  }
  @Test public void shouldDeleteTopic() throws InterruptedException, ExecutionException {
    final Cluster cluster=createCluster(1);
    try (final MockAdminClient adminClient=new MockAdminClient(cluster.nodes(),cluster.nodeById(0))){
      final TopicPartitionInfo topicPartitionInfo=new TopicPartitionInfo(0,cluster.nodeById(0),cluster.nodes(),Collections.<Node>emptyList());
      adminClient.addTopic(false,TOPIC,Collections.singletonList(topicPartitionInfo),null);
      streamsResetter.doDelete(Collections.singletonList(TOPIC),adminClient);
      assertEquals(Collections.emptySet(),adminClient.listTopics().names().get());
    }
   }
  private Cluster createCluster(  final int numNodes){
    final HashMap<Integer,Node> nodes=new HashMap<>();
    for (int i=0; i < numNodes; ++i) {
      nodes.put(i,new Node(i,"localhost",8121 + i));
    }
    return new Cluster("mockClusterId",nodes.values(),Collections.<PartitionInfo>emptySet(),Collections.<String>emptySet(),Collections.<String>emptySet(),nodes.get(0));
  }
  @Test public void shouldAcceptValidDateFormats() throws ParseException {
    invokeGetDateTimeMethod(new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSS"));
    invokeGetDateTimeMethod(new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSZ"));
    invokeGetDateTimeMethod(new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSX"));
    invokeGetDateTimeMethod(new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSXX"));
    invokeGetDateTimeMethod(new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSXXX"));
  }
  @Test public void shouldThrowOnInvalidDateFormat() throws ParseException {
    try {
      invokeGetDateTimeMethod(new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss"));
      fail("Call to getDateTime should fail");
    }
 catch (    final Exception e) {
      e.printStackTrace();
    }
    try {
      invokeGetDateTimeMethod(new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.X"));
      fail("Call to getDateTime should fail");
    }
 catch (    final Exception e) {
      e.printStackTrace();
    }
  }
  private void invokeGetDateTimeMethod(  final SimpleDateFormat format) throws ParseException {
    final Date checkpoint=new Date();
    final StreamsResetter streamsResetter=new StreamsResetter();
    final String formattedCheckpoint=format.format(checkpoint);
    streamsResetter.getDateTime(formattedCheckpoint);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.kafka.streams.kstream.internals;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.common.serialization.StringSerializer;
import org.apache.kafka.common.utils.Bytes;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.TopologyTestDriver;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.ForeachAction;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Merger;
import org.apache.kafka.streams.kstream.Serialized;
import org.apache.kafka.streams.kstream.SessionWindowedKStream;
import org.apache.kafka.streams.kstream.SessionWindows;
import org.apache.kafka.streams.kstream.Windowed;
import org.apache.kafka.streams.state.SessionStore;
import org.apache.kafka.streams.test.ConsumerRecordFactory;
import org.apache.kafka.test.MockAggregator;
import org.apache.kafka.test.MockInitializer;
import org.apache.kafka.test.MockReducer;
import org.apache.kafka.test.StreamsTestUtils;
import org.junit.Before;
import org.junit.Test;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import static java.time.Duration.ofMillis;
import static org.hamcrest.CoreMatchers.equalTo;
import static org.hamcrest.MatcherAssert.assertThat;
public class SessionWindowedKStreamImplTest {
  private static final String TOPIC="input";
  private final StreamsBuilder builder=new StreamsBuilder();
  private final ConsumerRecordFactory<String,String> recordFactory=new ConsumerRecordFactory<>(new StringSerializer(),new StringSerializer());
  private final Properties props=StreamsTestUtils.getStreamsConfig(Serdes.String(),Serdes.String());
  private final Merger<String,String> sessionMerger=new Merger<String,String>(){
    @Override public String apply(    final String aggKey,    final String aggOne,    final String aggTwo){
      return aggOne + "+" + aggTwo;
    }
  }
;
  private SessionWindowedKStream<String,String> stream;
  @Before public void before(){
    final KStream<String,String> stream=builder.stream(TOPIC,Consumed.with(Serdes.String(),Serdes.String()));
    this.stream=stream.groupByKey(Serialized.with(Serdes.String(),Serdes.String())).windowedBy(SessionWindows.with(ofMillis(500)));
  }
  @Test public void shouldCountSessionWindowed(){
    final Map<Windowed<String>,Long> results=new HashMap<>();
    stream.count().toStream().foreach(new ForeachAction<Windowed<String>,Long>(){
      @Override public void apply(      final Windowed<String> key,      final Long value){
        results.put(key,value);
      }
    }
);
    try (final TopologyTestDriver driver=new TopologyTestDriver(builder.build(),props,0L)){
      processData(driver);
    }
     assertThat(results.get(new Windowed<>("1",new SessionWindow(10,15))),equalTo(2L));
    assertThat(results.get(new Windowed<>("2",new SessionWindow(600,600))),equalTo(1L));
    assertThat(results.get(new Windowed<>("1",new SessionWindow(600,600))),equalTo(1L));
  }
  @Test public void shouldReduceWindowed(){
    final Map<Windowed<String>,String> results=new HashMap<>();
    stream.reduce(MockReducer.STRING_ADDER).toStream().foreach(new ForeachAction<Windowed<String>,String>(){
      @Override public void apply(      final Windowed<String> key,      final String value){
        results.put(key,value);
      }
    }
);
    try (final TopologyTestDriver driver=new TopologyTestDriver(builder.build(),props,0L)){
      processData(driver);
    }
     assertThat(results.get(new Windowed<>("1",new SessionWindow(10,15))),equalTo("1+2"));
    assertThat(results.get(new Windowed<>("2",new SessionWindow(600,600))),equalTo("1"));
    assertThat(results.get(new Windowed<>("1",new SessionWindow(600,600))),equalTo("3"));
  }
  @Test public void shouldAggregateSessionWindowed(){
    final Map<Windowed<String>,String> results=new HashMap<>();
    stream.aggregate(MockInitializer.STRING_INIT,MockAggregator.TOSTRING_ADDER,sessionMerger,Materialized.<String,String,SessionStore<Bytes,byte[]>>with(Serdes.String(),Serdes.String())).toStream().foreach(new ForeachAction<Windowed<String>,String>(){
      @Override public void apply(      final Windowed<String> key,      final String value){
        results.put(key,value);
      }
    }
);
    try (final TopologyTestDriver driver=new TopologyTestDriver(builder.build(),props,0L)){
      processData(driver);
    }
     assertThat(results.get(new Windowed<>("1",new SessionWindow(10,15))),equalTo("0+0+1+2"));
    assertThat(results.get(new Windowed<>("2",new SessionWindow(600,600))),equalTo("0+1"));
    assertThat(results.get(new Windowed<>("1",new SessionWindow(600,600))),equalTo("0+3"));
  }
  @Test public void shouldMaterializeCount(){
    stream.count(Materialized.<String,Long,SessionStore<Bytes,byte[]>>as("count-store"));
    try (final TopologyTestDriver driver=new TopologyTestDriver(builder.build(),props,0L)){
      processData(driver);
      final SessionStore<String,Long> store=driver.getSessionStore("count-store");
      final List<KeyValue<Windowed<String>,Long>> data=StreamsTestUtils.toList(store.fetch("1","2"));
      assertThat(data,equalTo(Arrays.asList(KeyValue.pair(new Windowed<>("1",new SessionWindow(10,15)),2L),KeyValue.pair(new Windowed<>("1",new SessionWindow(600,600)),1L),KeyValue.pair(new Windowed<>("2",new SessionWindow(600,600)),1L))));
    }
   }
  @Test public void shouldMaterializeReduced(){
    stream.reduce(MockReducer.STRING_ADDER,Materialized.<String,String,SessionStore<Bytes,byte[]>>as("reduced"));
    try (final TopologyTestDriver driver=new TopologyTestDriver(builder.build(),props,0L)){
      processData(driver);
      final SessionStore<String,String> sessionStore=driver.getSessionStore("reduced");
      final List<KeyValue<Windowed<String>,String>> data=StreamsTestUtils.toList(sessionStore.fetch("1","2"));
      assertThat(data,equalTo(Arrays.asList(KeyValue.pair(new Windowed<>("1",new SessionWindow(10,15)),"1+2"),KeyValue.pair(new Windowed<>("1",new SessionWindow(600,600)),"3"),KeyValue.pair(new Windowed<>("2",new SessionWindow(600,600)),"1"))));
    }
   }
  @Test public void shouldMaterializeAggregated(){
    stream.aggregate(MockInitializer.STRING_INIT,MockAggregator.TOSTRING_ADDER,sessionMerger,Materialized.<String,String,SessionStore<Bytes,byte[]>>as("aggregated").withValueSerde(Serdes.String()));
    try (final TopologyTestDriver driver=new TopologyTestDriver(builder.build(),props,0L)){
      processData(driver);
      final SessionStore<String,String> sessionStore=driver.getSessionStore("aggregated");
      final List<KeyValue<Windowed<String>,String>> data=StreamsTestUtils.toList(sessionStore.fetch("1","2"));
      assertThat(data,equalTo(Arrays.asList(KeyValue.pair(new Windowed<>("1",new SessionWindow(10,15)),"0+0+1+2"),KeyValue.pair(new Windowed<>("1",new SessionWindow(600,600)),"0+3"),KeyValue.pair(new Windowed<>("2",new SessionWindow(600,600)),"0+1"))));
    }
   }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnAggregateIfInitializerIsNull(){
    stream.aggregate(null,MockAggregator.TOSTRING_ADDER,sessionMerger);
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnAggregateIfAggregatorIsNull(){
    stream.aggregate(MockInitializer.STRING_INIT,null,sessionMerger);
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnAggregateIfMergerIsNull(){
    stream.aggregate(MockInitializer.STRING_INIT,MockAggregator.TOSTRING_ADDER,null);
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnReduceIfReducerIsNull(){
    stream.reduce(null);
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnMaterializedAggregateIfInitializerIsNull(){
    stream.aggregate(null,MockAggregator.TOSTRING_ADDER,sessionMerger,Materialized.<String,String,SessionStore<Bytes,byte[]>>as("store"));
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnMaterializedAggregateIfAggregatorIsNull(){
    stream.aggregate(MockInitializer.STRING_INIT,null,sessionMerger,Materialized.<String,String,SessionStore<Bytes,byte[]>>as("store"));
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnMaterializedAggregateIfMergerIsNull(){
    stream.aggregate(MockInitializer.STRING_INIT,MockAggregator.TOSTRING_ADDER,null,Materialized.<String,String,SessionStore<Bytes,byte[]>>as("store"));
  }
  @SuppressWarnings("unchecked") @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnMaterializedAggregateIfMaterializedIsNull(){
    stream.aggregate(MockInitializer.STRING_INIT,MockAggregator.TOSTRING_ADDER,sessionMerger,(Materialized)null);
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnMaterializedReduceIfReducerIsNull(){
    stream.reduce(null,Materialized.<String,String,SessionStore<Bytes,byte[]>>as("store"));
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnMaterializedReduceIfMaterializedIsNull(){
    stream.reduce(MockReducer.STRING_ADDER,null);
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerOnCountIfMaterializedIsNull(){
    stream.count(null);
  }
  private void processData(  final TopologyTestDriver driver){
    driver.pipeInput(recordFactory.create(TOPIC,"1","1",10));
    driver.pipeInput(recordFactory.create(TOPIC,"1","2",15));
    driver.pipeInput(recordFactory.create(TOPIC,"1","3",600));
    driver.pipeInput(recordFactory.create(TOPIC,"2","1",600));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.kafka.streams.integration;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.common.utils.Bytes;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.ForeachAction;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.state.KeyValueStore;
import org.apache.kafka.test.IntegrationTest;
import org.junit.Before;
import org.junit.Test;
import org.junit.experimental.categories.Category;
import org.junit.runner.RunWith;
import org.junit.runners.Parameterized;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
/** 
 * Tests all available joins of Kafka Streams DSL.
 */
@Category({IntegrationTest.class}) @RunWith(value=Parameterized.class) public class TableTableJoinIntegrationTest extends AbstractJoinIntegrationTest {
  private KTable<Long,String> leftTable;
  private KTable<Long,String> rightTable;
  public TableTableJoinIntegrationTest(  final boolean cacheEnabled){
    super(cacheEnabled);
  }
  @Before public void prepareTopology() throws InterruptedException {
    super.prepareEnvironment();
    appID="table-table-join-integration-test";
    builder=new StreamsBuilder();
    leftTable=builder.table(INPUT_TOPIC_LEFT,Materialized.<Long,String,KeyValueStore<Bytes,byte[]>>as("left").withLoggingDisabled());
    rightTable=builder.table(INPUT_TOPIC_RIGHT,Materialized.<Long,String,KeyValueStore<Bytes,byte[]>>as("right").withLoggingDisabled());
  }
  final private String expectedFinalJoinResult="D-d";
  final private String expectedFinalMultiJoinResult="D-d-d";
  final private String storeName=appID + "-store";
  private Materialized<Long,String,KeyValueStore<Bytes,byte[]>> materialized=Materialized.<Long,String,KeyValueStore<Bytes,byte[]>>as(storeName).withKeySerde(Serdes.Long()).withValueSerde(Serdes.String()).withCachingDisabled().withLoggingDisabled();
final private class CountingPeek implements ForeachAction<Long,String> {
    final private String expected;
    CountingPeek(    final boolean multiJoin){
      this.expected=multiJoin ? expectedFinalMultiJoinResult : expectedFinalJoinResult;
    }
    @Override public void apply(    final Long key,    final String value){
      numRecordsExpected++;
      if (expected.equals(value)) {
        final boolean ret=finalResultReached.compareAndSet(false,true);
        if (!ret) {
        }
      }
    }
  }
  @Test public void testInner() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-inner");
    if (cacheEnabled) {
      leftTable.join(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(false)).to(OUTPUT_TOPIC);
      runTest(expectedFinalJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,null,Collections.singletonList("A-a"),Collections.singletonList("B-a"),Collections.singletonList("B-b"),Collections.singletonList((String)null),null,null,Collections.singletonList("C-c"),Collections.singletonList((String)null),null,null,null,Collections.singletonList("D-d"));
      leftTable.join(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testLeft() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-left");
    if (cacheEnabled) {
      leftTable.leftJoin(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(false)).to(OUTPUT_TOPIC);
      runTest(expectedFinalJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,Collections.singletonList("A-null"),Collections.singletonList("A-a"),Collections.singletonList("B-a"),Collections.singletonList("B-b"),Collections.singletonList((String)null),null,Collections.singletonList("C-null"),Collections.singletonList("C-c"),Collections.singletonList("C-null"),Collections.singletonList((String)null),null,null,Collections.singletonList("D-d"));
      leftTable.leftJoin(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testOuter() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-outer");
    if (cacheEnabled) {
      leftTable.outerJoin(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(false)).to(OUTPUT_TOPIC);
      runTest(expectedFinalJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,Collections.singletonList("A-null"),Collections.singletonList("A-a"),Collections.singletonList("B-a"),Collections.singletonList("B-b"),Collections.singletonList("null-b"),Collections.singletonList((String)null),Collections.singletonList("C-null"),Collections.singletonList("C-c"),Collections.singletonList("C-null"),Collections.singletonList((String)null),null,Collections.singletonList("null-d"),Collections.singletonList("D-d"));
      leftTable.outerJoin(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testInnerInner() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-inner-inner");
    if (cacheEnabled) {
      leftTable.join(rightTable,valueJoiner).join(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(true)).to(OUTPUT_TOPIC);
      runTest(expectedFinalMultiJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,null,Arrays.asList("A-a-a","A-a-a"),Collections.singletonList("B-a-a"),Arrays.asList("B-b-b","B-b-b"),Collections.singletonList((String)null),null,null,Arrays.asList("C-c-c","C-c-c"),null,null,null,null,Collections.singletonList("D-d-d"));
      leftTable.join(rightTable,valueJoiner).join(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testInnerLeft() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-inner-left");
    if (cacheEnabled) {
      leftTable.join(rightTable,valueJoiner).leftJoin(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(true)).to(OUTPUT_TOPIC);
      runTest(expectedFinalMultiJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,null,Arrays.asList("A-a-a","A-a-a"),Collections.singletonList("B-a-a"),Arrays.asList("B-b-b","B-b-b"),Collections.singletonList((String)null),null,null,Arrays.asList("C-c-c","C-c-c"),Collections.singletonList((String)null),null,null,null,Collections.singletonList("D-d-d"));
      leftTable.join(rightTable,valueJoiner).leftJoin(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testInnerOuter() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-inner-outer");
    if (cacheEnabled) {
      leftTable.join(rightTable,valueJoiner).outerJoin(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(true)).to(OUTPUT_TOPIC);
      runTest(expectedFinalMultiJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,null,Arrays.asList("A-a-a","A-a-a"),Collections.singletonList("B-a-a"),Arrays.asList("B-b-b","B-b-b"),Collections.singletonList("null-b"),Collections.singletonList((String)null),null,Arrays.asList("C-c-c","C-c-c"),Arrays.asList((String)null,null),null,null,null,Arrays.asList("null-d","D-d-d"));
      leftTable.join(rightTable,valueJoiner).outerJoin(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testLeftInner() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-inner-inner");
    if (cacheEnabled) {
      leftTable.leftJoin(rightTable,valueJoiner).join(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(true)).to(OUTPUT_TOPIC);
      runTest(expectedFinalMultiJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,null,Arrays.asList("A-a-a","A-a-a"),Collections.singletonList("B-a-a"),Arrays.asList("B-b-b","B-b-b"),Collections.singletonList((String)null),null,null,Arrays.asList("C-c-c","C-c-c"),Collections.singletonList((String)null),null,null,null,Collections.singletonList("D-d-d"));
      leftTable.leftJoin(rightTable,valueJoiner).join(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testLeftLeft() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-inner-left");
    if (cacheEnabled) {
      leftTable.leftJoin(rightTable,valueJoiner).leftJoin(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(true)).to(OUTPUT_TOPIC);
      runTest(expectedFinalMultiJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,null,Arrays.asList("A-null-null","A-a-a","A-a-a"),Collections.singletonList("B-a-a"),Arrays.asList("B-b-b","B-b-b"),Collections.singletonList((String)null),null,null,Arrays.asList("C-null-null","C-c-c","C-c-c"),Arrays.asList("C-null-null","C-null-null"),Collections.singletonList((String)null),null,null,Collections.singletonList("D-d-d"));
      leftTable.leftJoin(rightTable,valueJoiner).leftJoin(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testLeftOuter() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-inner-outer");
    if (cacheEnabled) {
      leftTable.leftJoin(rightTable,valueJoiner).outerJoin(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(true)).to(OUTPUT_TOPIC);
      runTest(expectedFinalMultiJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,null,Arrays.asList("A-null-null","A-a-a","A-a-a"),Collections.singletonList("B-a-a"),Arrays.asList("B-b-b","B-b-b"),Collections.singletonList("null-b"),Collections.singletonList((String)null),null,Arrays.asList("C-null-null","C-c-c","C-c-c"),Arrays.asList("C-null-null","C-null-null"),Collections.singletonList((String)null),null,null,Arrays.asList("null-d","D-d-d"));
      leftTable.leftJoin(rightTable,valueJoiner).outerJoin(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testOuterInner() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-inner-inner");
    if (cacheEnabled) {
      leftTable.outerJoin(rightTable,valueJoiner).join(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(true)).to(OUTPUT_TOPIC);
      runTest(expectedFinalMultiJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,null,Arrays.asList("A-a-a","A-a-a"),Collections.singletonList("B-a-a"),Arrays.asList("B-b-b","B-b-b"),Collections.singletonList("null-b-b"),null,null,Arrays.asList("C-c-c","C-c-c"),Collections.singletonList((String)null),null,null,Arrays.asList("null-d-d","null-d-d"),Collections.singletonList("D-d-d"));
      leftTable.outerJoin(rightTable,valueJoiner).join(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testOuterLeft() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-inner-left");
    if (cacheEnabled) {
      leftTable.outerJoin(rightTable,valueJoiner).leftJoin(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(true)).to(OUTPUT_TOPIC);
      runTest(expectedFinalMultiJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,null,Arrays.asList("A-null-null","A-a-a","A-a-a"),Collections.singletonList("B-a-a"),Arrays.asList("B-b-b","B-b-b"),Collections.singletonList("null-b-b"),Collections.singletonList((String)null),null,Arrays.asList("C-null-null","C-c-c","C-c-c"),Arrays.asList("C-null-null","C-null-null"),Collections.singletonList((String)null),null,Arrays.asList("null-d-d","null-d-d"),Collections.singletonList("D-d-d"));
      leftTable.outerJoin(rightTable,valueJoiner).leftJoin(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
  @Test public void testOuterOuter() throws Exception {
    STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG,appID + "-inner-outer");
    if (cacheEnabled) {
      leftTable.outerJoin(rightTable,valueJoiner).outerJoin(rightTable,valueJoiner,materialized).toStream().peek(new CountingPeek(true)).to(OUTPUT_TOPIC);
      runTest(expectedFinalMultiJoinResult,storeName);
    }
 else {
      final List<List<String>> expectedResult=Arrays.asList(null,null,null,Arrays.asList("A-null-null","A-a-a","A-a-a"),Collections.singletonList("B-a-a"),Arrays.asList("B-b-b","B-b-b"),Collections.singletonList("null-b-b"),Arrays.asList((String)null,null),null,Arrays.asList("C-null-null","C-c-c","C-c-c"),Arrays.asList("C-null-null","C-null-null"),Collections.singletonList((String)null),null,null,Arrays.asList("null-d-d","null-d-d","D-d-d"));
      leftTable.outerJoin(rightTable,valueJoiner).outerJoin(rightTable,valueJoiner,materialized).toStream().to(OUTPUT_TOPIC);
      runTest(expectedResult,storeName);
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.kafka.streams.state.internals;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.common.utils.Bytes;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.kstream.Windowed;
import org.apache.kafka.streams.kstream.internals.TimeWindow;
import org.apache.kafka.streams.state.StateSerdes;
import org.apache.kafka.test.KeyValueIteratorStub;
import org.junit.Test;
import java.util.Collections;
import java.util.Iterator;
import static org.hamcrest.CoreMatchers.equalTo;
import static org.hamcrest.MatcherAssert.assertThat;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
public class MergedSortedCacheWrappedWindowStoreKeyValueIteratorTest {
  private static final SegmentedCacheFunction SINGLE_SEGMENT_CACHE_FUNCTION=new SegmentedCacheFunction(null,-1){
    @Override public long segmentId(    final Bytes key){
      return 0;
    }
  }
;
  private static final int WINDOW_SIZE=10;
  private final String storeKey="a";
  private final String cacheKey="b";
  private final TimeWindow storeWindow=new TimeWindow(0,1);
  private final Iterator<KeyValue<Windowed<Bytes>,byte[]>> storeKvs=Collections.singleton(KeyValue.pair(new Windowed<>(Bytes.wrap(storeKey.getBytes()),storeWindow),storeKey.getBytes())).iterator();
  private final TimeWindow cacheWindow=new TimeWindow(10,20);
  private final Iterator<KeyValue<Bytes,LRUCacheEntry>> cacheKvs=Collections.singleton(KeyValue.pair(SINGLE_SEGMENT_CACHE_FUNCTION.cacheKey(WindowKeySchema.toStoreKeyBinary(new Windowed<>(cacheKey,cacheWindow),0,new StateSerdes<>("dummy",Serdes.String(),Serdes.ByteArray()))),new LRUCacheEntry(cacheKey.getBytes()))).iterator();
  private Deserializer<String> deserializer=Serdes.String().deserializer();
  @Test public void shouldHaveNextFromStore(){
    final MergedSortedCacheWindowStoreKeyValueIterator mergeIterator=createIterator(storeKvs,Collections.<KeyValue<Bytes,LRUCacheEntry>>emptyIterator());
    assertTrue(mergeIterator.hasNext());
  }
  @Test public void shouldGetNextFromStore(){
    final MergedSortedCacheWindowStoreKeyValueIterator mergeIterator=createIterator(storeKvs,Collections.<KeyValue<Bytes,LRUCacheEntry>>emptyIterator());
    assertThat(convertKeyValuePair(mergeIterator.next()),equalTo(KeyValue.pair(new Windowed<>(storeKey,storeWindow),storeKey)));
  }
  @Test public void shouldPeekNextKeyFromStore(){
    final MergedSortedCacheWindowStoreKeyValueIterator mergeIterator=createIterator(storeKvs,Collections.<KeyValue<Bytes,LRUCacheEntry>>emptyIterator());
    assertThat(convertWindowedKey(mergeIterator.peekNextKey()),equalTo(new Windowed<>(storeKey,storeWindow)));
  }
  @Test public void shouldHaveNextFromCache(){
    final MergedSortedCacheWindowStoreKeyValueIterator mergeIterator=createIterator(Collections.<KeyValue<Windowed<Bytes>,byte[]>>emptyIterator(),cacheKvs);
    assertTrue(mergeIterator.hasNext());
  }
  @Test public void shouldGetNextFromCache(){
    final MergedSortedCacheWindowStoreKeyValueIterator mergeIterator=createIterator(Collections.<KeyValue<Windowed<Bytes>,byte[]>>emptyIterator(),cacheKvs);
    assertThat(convertKeyValuePair(mergeIterator.next()),equalTo(KeyValue.pair(new Windowed<>(cacheKey,cacheWindow),cacheKey)));
  }
  @Test public void shouldPeekNextKeyFromCache(){
    final MergedSortedCacheWindowStoreKeyValueIterator mergeIterator=createIterator(Collections.<KeyValue<Windowed<Bytes>,byte[]>>emptyIterator(),cacheKvs);
    assertThat(convertWindowedKey(mergeIterator.peekNextKey()),equalTo(new Windowed<>(cacheKey,cacheWindow)));
  }
  @Test public void shouldIterateBothStoreAndCache(){
    final MergedSortedCacheWindowStoreKeyValueIterator iterator=createIterator(storeKvs,cacheKvs);
    assertThat(convertKeyValuePair(iterator.next()),equalTo(KeyValue.pair(new Windowed<>(storeKey,storeWindow),storeKey)));
    assertThat(convertKeyValuePair(iterator.next()),equalTo(KeyValue.pair(new Windowed<>(cacheKey,cacheWindow),cacheKey)));
    assertFalse(iterator.hasNext());
  }
  private KeyValue<Windowed<String>,String> convertKeyValuePair(  final KeyValue<Windowed<Bytes>,byte[]> next){
    final String value=deserializer.deserialize("",next.value);
    return KeyValue.pair(convertWindowedKey(next.key),value);
  }
  private Windowed<String> convertWindowedKey(  final Windowed<Bytes> bytesWindowed){
    final String key=deserializer.deserialize("",bytesWindowed.key().get());
    return new Windowed<>(key,bytesWindowed.window());
  }
  private MergedSortedCacheWindowStoreKeyValueIterator createIterator(  final Iterator<KeyValue<Windowed<Bytes>,byte[]>> storeKvs,  final Iterator<KeyValue<Bytes,LRUCacheEntry>> cacheKvs){
    final DelegatingPeekingKeyValueIterator<Windowed<Bytes>,byte[]> storeIterator=new DelegatingPeekingKeyValueIterator<>("store",new KeyValueIteratorStub<>(storeKvs));
    final PeekingKeyValueIterator<Bytes,LRUCacheEntry> cacheIterator=new DelegatingPeekingKeyValueIterator<>("cache",new KeyValueIteratorStub<>(cacheKvs));
    return new MergedSortedCacheWindowStoreKeyValueIterator(cacheIterator,storeIterator,new StateSerdes<>("name",Serdes.Bytes(),Serdes.ByteArray()),WINDOW_SIZE,SINGLE_SEGMENT_CACHE_FUNCTION);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.kafka.streams.state.internals;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.errors.InvalidStateStoreException;
import org.apache.kafka.streams.kstream.Windowed;
import org.apache.kafka.streams.kstream.internals.SessionWindow;
import org.apache.kafka.streams.state.KeyValueIterator;
import org.apache.kafka.streams.state.QueryableStoreTypes;
import org.apache.kafka.test.ReadOnlySessionStoreStub;
import org.apache.kafka.test.StateStoreProviderStub;
import org.apache.kafka.test.StreamsTestUtils;
import org.junit.Before;
import org.junit.Test;
import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import static org.apache.kafka.test.StreamsTestUtils.toList;
import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.core.IsEqual.equalTo;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.fail;
public class CompositeReadOnlySessionStoreTest {
  private final String storeName="session-store";
  private final StateStoreProviderStub stubProviderOne=new StateStoreProviderStub(false);
  private final StateStoreProviderStub stubProviderTwo=new StateStoreProviderStub(false);
  private final ReadOnlySessionStoreStub<String,Long> underlyingSessionStore=new ReadOnlySessionStoreStub<>();
  private final ReadOnlySessionStoreStub<String,Long> otherUnderlyingStore=new ReadOnlySessionStoreStub<>();
  private CompositeReadOnlySessionStore<String,Long> sessionStore;
  @Before public void before(){
    stubProviderOne.addStore(storeName,underlyingSessionStore);
    stubProviderOne.addStore("other-session-store",otherUnderlyingStore);
    sessionStore=new CompositeReadOnlySessionStore<>(new WrappingStoreProvider(Arrays.<StateStoreProvider>asList(stubProviderOne,stubProviderTwo)),QueryableStoreTypes.<String,Long>sessionStore(),storeName);
  }
  @Test public void shouldFetchResulstFromUnderlyingSessionStore(){
    underlyingSessionStore.put(new Windowed<>("a",new SessionWindow(0,0)),1L);
    underlyingSessionStore.put(new Windowed<>("a",new SessionWindow(10,10)),2L);
    final List<KeyValue<Windowed<String>,Long>> results=toList(sessionStore.fetch("a"));
    assertEquals(Arrays.asList(KeyValue.pair(new Windowed<>("a",new SessionWindow(0,0)),1L),KeyValue.pair(new Windowed<>("a",new SessionWindow(10,10)),2L)),results);
  }
  @Test public void shouldReturnEmptyIteratorIfNoData(){
    final KeyValueIterator<Windowed<String>,Long> result=sessionStore.fetch("b");
    assertFalse(result.hasNext());
  }
  @Test public void shouldFindValueForKeyWhenMultiStores(){
    final ReadOnlySessionStoreStub<String,Long> secondUnderlying=new ReadOnlySessionStoreStub<>();
    stubProviderTwo.addStore(storeName,secondUnderlying);
    final Windowed<String> keyOne=new Windowed<>("key-one",new SessionWindow(0,0));
    final Windowed<String> keyTwo=new Windowed<>("key-two",new SessionWindow(0,0));
    underlyingSessionStore.put(keyOne,0L);
    secondUnderlying.put(keyTwo,10L);
    final List<KeyValue<Windowed<String>,Long>> keyOneResults=toList(sessionStore.fetch("key-one"));
    final List<KeyValue<Windowed<String>,Long>> keyTwoResults=toList(sessionStore.fetch("key-two"));
    assertEquals(Collections.singletonList(KeyValue.pair(keyOne,0L)),keyOneResults);
    assertEquals(Collections.singletonList(KeyValue.pair(keyTwo,10L)),keyTwoResults);
  }
  @Test public void shouldNotGetValueFromOtherStores(){
    final Windowed<String> expectedKey=new Windowed<>("foo",new SessionWindow(0,0));
    otherUnderlyingStore.put(new Windowed<>("foo",new SessionWindow(10,10)),10L);
    underlyingSessionStore.put(expectedKey,1L);
    final KeyValueIterator<Windowed<String>,Long> result=sessionStore.fetch("foo");
    assertEquals(KeyValue.pair(expectedKey,1L),result.next());
    assertFalse(result.hasNext());
  }
  @Test(expected=InvalidStateStoreException.class) public void shouldThrowInvalidStateStoreExceptionOnRebalance(){
    final CompositeReadOnlySessionStore<String,String> store=new CompositeReadOnlySessionStore<>(new StateStoreProviderStub(true),QueryableStoreTypes.<String,String>sessionStore(),"whateva");
    store.fetch("a");
  }
  @Test public void shouldThrowInvalidStateStoreExceptionIfSessionFetchThrows(){
    underlyingSessionStore.setOpen(false);
    try {
      sessionStore.fetch("key");
      fail("Should have thrown InvalidStateStoreException with session store");
    }
 catch (    final InvalidStateStoreException e) {
    }
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNullPointerExceptionIfFetchingNullKey(){
    sessionStore.fetch(null);
  }
  @Test public void shouldFetchKeyRangeAcrossStores(){
    final ReadOnlySessionStoreStub<String,Long> secondUnderlying=new ReadOnlySessionStoreStub<>();
    stubProviderTwo.addStore(storeName,secondUnderlying);
    underlyingSessionStore.put(new Windowed<>("a",new SessionWindow(0,0)),0L);
    secondUnderlying.put(new Windowed<>("b",new SessionWindow(0,0)),10L);
    final List<KeyValue<Windowed<String>,Long>> results=StreamsTestUtils.toList(sessionStore.fetch("a","b"));
    assertThat(results.size(),equalTo(2));
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNPEIfKeyIsNull(){
    underlyingSessionStore.fetch(null);
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNPEIfFromKeyIsNull(){
    underlyingSessionStore.fetch(null,"a");
  }
  @Test(expected=NullPointerException.class) public void shouldThrowNPEIfToKeyIsNull(){
    underlyingSessionStore.fetch("a",null);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.kafka.connect.runtime;
import org.apache.kafka.connect.runtime.isolation.Plugins;
import org.apache.kafka.connect.tools.MockConnector;
import org.apache.kafka.connect.transforms.Cast;
import org.apache.kafka.connect.transforms.ExtractField;
import org.apache.kafka.connect.transforms.Flatten;
import org.apache.kafka.connect.transforms.HoistField;
import org.apache.kafka.connect.transforms.InsertField;
import org.apache.kafka.connect.transforms.MaskField;
import org.apache.kafka.connect.transforms.RegexRouter;
import org.apache.kafka.connect.transforms.ReplaceField;
import org.apache.kafka.connect.transforms.SetSchemaMetadata;
import org.apache.kafka.connect.transforms.TimestampConverter;
import org.apache.kafka.connect.transforms.TimestampRouter;
import org.apache.kafka.connect.transforms.ValueToKey;
import org.junit.Test;
import java.util.HashMap;
/** 
 * Tests that transformations' configs can be composed with ConnectorConfig during its construction, ensuring no conflicting fields or other issues. This test appears here simply because it requires both connect-runtime and connect-transforms and connect-runtime already depends on connect-transforms.
 */
public class TransformationConfigTest {
  @Test public void testEmbeddedConfigCast(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",Cast.Value.class.getName());
    connProps.put("transforms.example.spec","int8");
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigExtractField(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",ExtractField.Value.class.getName());
    connProps.put("transforms.example.field","field");
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigFlatten(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",Flatten.Value.class.getName());
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigHoistField(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",HoistField.Value.class.getName());
    connProps.put("transforms.example.field","field");
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigInsertField(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",InsertField.Value.class.getName());
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigMaskField(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",MaskField.Value.class.getName());
    connProps.put("transforms.example.fields","field");
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigRegexRouter(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",RegexRouter.class.getName());
    connProps.put("transforms.example.regex","(.*)");
    connProps.put("transforms.example.replacement","prefix-$1");
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigReplaceField(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",ReplaceField.Value.class.getName());
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigSetSchemaMetadata(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",SetSchemaMetadata.Value.class.getName());
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigTimestampConverter(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",TimestampConverter.Value.class.getName());
    connProps.put("transforms.example.target.type","unix");
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigTimestampRouter(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",TimestampRouter.class.getName());
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
  @Test public void testEmbeddedConfigValueToKey(){
    HashMap<String,String> connProps=new HashMap<>();
    connProps.put("name","foo");
    connProps.put("connector.class",MockConnector.class.getName());
    connProps.put("transforms","example");
    connProps.put("transforms.example.type",ValueToKey.class.getName());
    connProps.put("transforms.example.fields","field");
    Plugins plugins=null;
    new ConnectorConfig(plugins,connProps);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.kafka.connect.storage;
import org.apache.kafka.connect.data.Schema;
import org.apache.kafka.connect.data.SchemaAndValue;
import org.junit.Test;
import java.io.UnsupportedEncodingException;
import java.util.Collections;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertArrayEquals;
public class StringConverterTest {
  private static final String TOPIC="topic";
  private static final String SAMPLE_STRING="a string";
  private StringConverter converter=new StringConverter();
  @Test public void testStringToBytes() throws UnsupportedEncodingException {
    assertArrayEquals(SAMPLE_STRING.getBytes("UTF8"),converter.fromConnectData(TOPIC,Schema.STRING_SCHEMA,SAMPLE_STRING));
  }
  @Test public void testNonStringToBytes() throws UnsupportedEncodingException {
    assertArrayEquals("true".getBytes("UTF8"),converter.fromConnectData(TOPIC,Schema.BOOLEAN_SCHEMA,true));
  }
  @Test public void testNullToBytes(){
    assertEquals(null,converter.fromConnectData(TOPIC,Schema.OPTIONAL_STRING_SCHEMA,null));
  }
  @Test public void testToBytesIgnoresSchema() throws UnsupportedEncodingException {
    assertArrayEquals("true".getBytes("UTF8"),converter.fromConnectData(TOPIC,null,true));
  }
  @Test public void testToBytesNonUtf8Encoding() throws UnsupportedEncodingException {
    converter.configure(Collections.singletonMap("converter.encoding","UTF-16"),true);
    assertArrayEquals(SAMPLE_STRING.getBytes("UTF-16"),converter.fromConnectData(TOPIC,Schema.STRING_SCHEMA,SAMPLE_STRING));
  }
  @Test public void testBytesToString(){
    SchemaAndValue data=converter.toConnectData(TOPIC,SAMPLE_STRING.getBytes());
    assertEquals(Schema.OPTIONAL_STRING_SCHEMA,data.schema());
    assertEquals(SAMPLE_STRING,data.value());
  }
  @Test public void testBytesNullToString(){
    SchemaAndValue data=converter.toConnectData(TOPIC,null);
    assertEquals(Schema.OPTIONAL_STRING_SCHEMA,data.schema());
    assertEquals(null,data.value());
  }
  @Test public void testBytesToStringNonUtf8Encoding() throws UnsupportedEncodingException {
    converter.configure(Collections.singletonMap("converter.encoding","UTF-16"),true);
    SchemaAndValue data=converter.toConnectData(TOPIC,SAMPLE_STRING.getBytes("UTF-16"));
    assertEquals(Schema.OPTIONAL_STRING_SCHEMA,data.schema());
    assertEquals(SAMPLE_STRING,data.value());
  }
  @Test public void testStringHeaderValueToBytes() throws UnsupportedEncodingException {
    assertArrayEquals(SAMPLE_STRING.getBytes("UTF8"),converter.fromConnectHeader(TOPIC,"hdr",Schema.STRING_SCHEMA,SAMPLE_STRING));
  }
  @Test public void testNonStringHeaderValueToBytes() throws UnsupportedEncodingException {
    assertArrayEquals("true".getBytes("UTF8"),converter.fromConnectHeader(TOPIC,"hdr",Schema.BOOLEAN_SCHEMA,true));
  }
  @Test public void testNullHeaderValueToBytes(){
    assertEquals(null,converter.fromConnectHeader(TOPIC,"hdr",Schema.OPTIONAL_STRING_SCHEMA,null));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.apache.kafka.connect.data;
import org.apache.kafka.connect.data.Schema.Type;
import org.apache.kafka.connect.errors.DataException;
import org.apache.kafka.connect.errors.SchemaProjectorException;
import org.junit.Test;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.fail;
public class SchemaProjectorTest {
  @Test public void testPrimitiveTypeProjection() throws Exception {
    Object projected;
    projected=SchemaProjector.project(Schema.BOOLEAN_SCHEMA,false,Schema.BOOLEAN_SCHEMA);
    assertEquals(false,projected);
    byte[] bytes={(byte)1,(byte)2};
    projected=SchemaProjector.project(Schema.BYTES_SCHEMA,bytes,Schema.BYTES_SCHEMA);
    assertEquals(bytes,projected);
    projected=SchemaProjector.project(Schema.STRING_SCHEMA,"abc",Schema.STRING_SCHEMA);
    assertEquals("abc",projected);
    projected=SchemaProjector.project(Schema.BOOLEAN_SCHEMA,false,Schema.OPTIONAL_BOOLEAN_SCHEMA);
    assertEquals(false,projected);
    projected=SchemaProjector.project(Schema.BYTES_SCHEMA,bytes,Schema.OPTIONAL_BYTES_SCHEMA);
    assertEquals(bytes,projected);
    projected=SchemaProjector.project(Schema.STRING_SCHEMA,"abc",Schema.OPTIONAL_STRING_SCHEMA);
    assertEquals("abc",projected);
    try {
      SchemaProjector.project(Schema.OPTIONAL_BOOLEAN_SCHEMA,false,Schema.BOOLEAN_SCHEMA);
      fail("Cannot project optional schema to schema with no default value.");
    }
 catch (    DataException e) {
    }
    try {
      SchemaProjector.project(Schema.OPTIONAL_BYTES_SCHEMA,bytes,Schema.BYTES_SCHEMA);
      fail("Cannot project optional schema to schema with no default value.");
    }
 catch (    DataException e) {
    }
    try {
      SchemaProjector.project(Schema.OPTIONAL_STRING_SCHEMA,"abc",Schema.STRING_SCHEMA);
      fail("Cannot project optional schema to schema with no default value.");
    }
 catch (    DataException e) {
    }
  }
  @Test public void testNumericTypeProjection() throws Exception {
    Schema[] promotableSchemas={Schema.INT8_SCHEMA,Schema.INT16_SCHEMA,Schema.INT32_SCHEMA,Schema.INT64_SCHEMA,Schema.FLOAT32_SCHEMA,Schema.FLOAT64_SCHEMA};
    Schema[] promotableOptionalSchemas={Schema.OPTIONAL_INT8_SCHEMA,Schema.OPTIONAL_INT16_SCHEMA,Schema.OPTIONAL_INT32_SCHEMA,Schema.OPTIONAL_INT64_SCHEMA,Schema.OPTIONAL_FLOAT32_SCHEMA,Schema.OPTIONAL_FLOAT64_SCHEMA};
    Object[] values={(byte)127,(short)255,32767,327890L,1.2F,1.2345};
    Map<Object,List<?>> expectedProjected=new HashMap<>();
    expectedProjected.put(values[0],Arrays.asList((byte)127,(short)127,127,127L,127.F,127.));
    expectedProjected.put(values[1],Arrays.asList((short)255,255,255L,255.F,255.));
    expectedProjected.put(values[2],Arrays.asList(32767,32767L,32767.F,32767.));
    expectedProjected.put(values[3],Arrays.asList(327890L,327890.F,327890.));
    expectedProjected.put(values[4],Arrays.asList(1.2F,1.2));
    expectedProjected.put(values[5],Arrays.asList(1.2345));
    Object promoted;
    for (int i=0; i < promotableSchemas.length; ++i) {
      Schema source=promotableSchemas[i];
      List<?> expected=expectedProjected.get(values[i]);
      for (int j=i; j < promotableSchemas.length; ++j) {
        Schema target=promotableSchemas[j];
        promoted=SchemaProjector.project(source,values[i],target);
        if (target.type() == Type.FLOAT64) {
          assertEquals((Double)(expected.get(j - i)),(double)promoted,1e-6);
        }
 else {
          assertEquals(expected.get(j - i),promoted);
        }
      }
      for (int j=i; j < promotableOptionalSchemas.length; ++j) {
        Schema target=promotableOptionalSchemas[j];
        promoted=SchemaProjector.project(source,values[i],target);
        if (target.type() == Type.FLOAT64) {
          assertEquals((Double)(expected.get(j - i)),(double)promoted,1e-6);
        }
 else {
          assertEquals(expected.get(j - i),promoted);
        }
      }
    }
    for (int i=0; i < promotableOptionalSchemas.length; ++i) {
      Schema source=promotableSchemas[i];
      List<?> expected=expectedProjected.get(values[i]);
      for (int j=i; j < promotableOptionalSchemas.length; ++j) {
        Schema target=promotableOptionalSchemas[j];
        promoted=SchemaProjector.project(source,values[i],target);
        if (target.type() == Type.FLOAT64) {
          assertEquals((Double)(expected.get(j - i)),(double)promoted,1e-6);
        }
 else {
          assertEquals(expected.get(j - i),promoted);
        }
      }
    }
    Schema[] nonPromotableSchemas={Schema.BOOLEAN_SCHEMA,Schema.BYTES_SCHEMA,Schema.STRING_SCHEMA};
    for (    Schema promotableSchema : promotableSchemas) {
      for (      Schema nonPromotableSchema : nonPromotableSchemas) {
        Object dummy=new Object();
        try {
          SchemaProjector.project(promotableSchema,dummy,nonPromotableSchema);
          fail("Cannot promote " + promotableSchema.type() + " to "+ nonPromotableSchema.type());
        }
 catch (        DataException e) {
        }
      }
    }
  }
  @Test public void testPrimitiveOptionalProjection() throws Exception {
    verifyOptionalProjection(Schema.OPTIONAL_BOOLEAN_SCHEMA,Type.BOOLEAN,false,true,false,true);
    verifyOptionalProjection(Schema.OPTIONAL_BOOLEAN_SCHEMA,Type.BOOLEAN,false,true,false,false);
    byte[] bytes={(byte)1,(byte)2};
    byte[] defaultBytes={(byte)3,(byte)4};
    verifyOptionalProjection(Schema.OPTIONAL_BYTES_SCHEMA,Type.BYTES,bytes,defaultBytes,bytes,true);
    verifyOptionalProjection(Schema.OPTIONAL_BYTES_SCHEMA,Type.BYTES,bytes,defaultBytes,bytes,false);
    verifyOptionalProjection(Schema.OPTIONAL_STRING_SCHEMA,Type.STRING,"abc","def","abc",true);
    verifyOptionalProjection(Schema.OPTIONAL_STRING_SCHEMA,Type.STRING,"abc","def","abc",false);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.INT8,(byte)12,(byte)127,(byte)12,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.INT8,(byte)12,(byte)127,(byte)12,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.INT16,(byte)12,(short)127,(short)12,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.INT16,(byte)12,(short)127,(short)12,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.INT32,(byte)12,12789,12,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.INT32,(byte)12,12789,12,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.INT64,(byte)12,127890L,12L,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.INT64,(byte)12,127890L,12L,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.FLOAT32,(byte)12,3.45F,12.F,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.FLOAT32,(byte)12,3.45F,12.F,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.FLOAT64,(byte)12,3.4567,12.,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT8_SCHEMA,Type.FLOAT64,(byte)12,3.4567,12.,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT16_SCHEMA,Type.INT16,(short)12,(short)127,(short)12,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT16_SCHEMA,Type.INT16,(short)12,(short)127,(short)12,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT16_SCHEMA,Type.INT32,(short)12,12789,12,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT16_SCHEMA,Type.INT32,(short)12,12789,12,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT16_SCHEMA,Type.INT64,(short)12,127890L,12L,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT16_SCHEMA,Type.INT64,(short)12,127890L,12L,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT16_SCHEMA,Type.FLOAT32,(short)12,3.45F,12.F,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT16_SCHEMA,Type.FLOAT32,(short)12,3.45F,12.F,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT16_SCHEMA,Type.FLOAT64,(short)12,3.4567,12.,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT16_SCHEMA,Type.FLOAT64,(short)12,3.4567,12.,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT32_SCHEMA,Type.INT32,12,12789,12,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT32_SCHEMA,Type.INT32,12,12789,12,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT32_SCHEMA,Type.INT64,12,127890L,12L,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT32_SCHEMA,Type.INT64,12,127890L,12L,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT32_SCHEMA,Type.FLOAT32,12,3.45F,12.F,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT32_SCHEMA,Type.FLOAT32,12,3.45F,12.F,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT32_SCHEMA,Type.FLOAT64,12,3.4567,12.,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT32_SCHEMA,Type.FLOAT64,12,3.4567,12.,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT64_SCHEMA,Type.INT64,12L,127890L,12L,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT64_SCHEMA,Type.INT64,12L,127890L,12L,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT64_SCHEMA,Type.FLOAT32,12L,3.45F,12.F,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT64_SCHEMA,Type.FLOAT32,12L,3.45F,12.F,false);
    verifyOptionalProjection(Schema.OPTIONAL_INT64_SCHEMA,Type.FLOAT64,12L,3.4567,12.,true);
    verifyOptionalProjection(Schema.OPTIONAL_INT64_SCHEMA,Type.FLOAT64,12L,3.4567,12.,false);
    verifyOptionalProjection(Schema.OPTIONAL_FLOAT32_SCHEMA,Type.FLOAT32,12.345F,3.45F,12.345F,true);
    verifyOptionalProjection(Schema.OPTIONAL_FLOAT32_SCHEMA,Type.FLOAT32,12.345F,3.45F,12.345F,false);
    verifyOptionalProjection(Schema.OPTIONAL_FLOAT32_SCHEMA,Type.FLOAT64,12.345F,3.4567,12.345,true);
    verifyOptionalProjection(Schema.OPTIONAL_FLOAT32_SCHEMA,Type.FLOAT64,12.345F,3.4567,12.345,false);
    verifyOptionalProjection(Schema.OPTIONAL_FLOAT32_SCHEMA,Type.FLOAT64,12.345,3.4567,12.345,true);
    verifyOptionalProjection(Schema.OPTIONAL_FLOAT32_SCHEMA,Type.FLOAT64,12.345,3.4567,12.345,false);
  }
  @Test public void testStructAddField() throws Exception {
    Schema source=SchemaBuilder.struct().field("field",Schema.INT32_SCHEMA).build();
    Struct sourceStruct=new Struct(source);
    sourceStruct.put("field",1);
    Schema target=SchemaBuilder.struct().field("field",Schema.INT32_SCHEMA).field("field2",SchemaBuilder.int32().defaultValue(123).build()).build();
    Struct targetStruct=(Struct)SchemaProjector.project(source,sourceStruct,target);
    assertEquals(1,(int)targetStruct.getInt32("field"));
    assertEquals(123,(int)targetStruct.getInt32("field2"));
    Schema incompatibleTargetSchema=SchemaBuilder.struct().field("field",Schema.INT32_SCHEMA).field("field2",Schema.INT32_SCHEMA).build();
    try {
      SchemaProjector.project(source,sourceStruct,incompatibleTargetSchema);
      fail("Incompatible schema.");
    }
 catch (    DataException e) {
    }
  }
  @Test public void testStructRemoveField() throws Exception {
    Schema source=SchemaBuilder.struct().field("field",Schema.INT32_SCHEMA).field("field2",Schema.INT32_SCHEMA).build();
    Struct sourceStruct=new Struct(source);
    sourceStruct.put("field",1);
    sourceStruct.put("field2",234);
    Schema target=SchemaBuilder.struct().field("field",Schema.INT32_SCHEMA).build();
    Struct targetStruct=(Struct)SchemaProjector.project(source,sourceStruct,target);
    assertEquals(1,targetStruct.get("field"));
    try {
      targetStruct.get("field2");
      fail("field2 is not part of the projected struct");
    }
 catch (    DataException e) {
    }
  }
  @Test public void testStructDefaultValue() throws Exception {
    Schema source=SchemaBuilder.struct().optional().field("field",Schema.INT32_SCHEMA).field("field2",Schema.INT32_SCHEMA).build();
    SchemaBuilder builder=SchemaBuilder.struct().field("field",Schema.INT32_SCHEMA).field("field2",Schema.INT32_SCHEMA);
    Struct defaultStruct=new Struct(builder).put("field",12).put("field2",345);
    builder.defaultValue(defaultStruct);
    Schema target=builder.build();
    Object projected=SchemaProjector.project(source,null,target);
    assertEquals(defaultStruct,projected);
    Struct sourceStruct=new Struct(source).put("field",45).put("field2",678);
    Struct targetStruct=(Struct)SchemaProjector.project(source,sourceStruct,target);
    assertEquals(sourceStruct.get("field"),targetStruct.get("field"));
    assertEquals(sourceStruct.get("field2"),targetStruct.get("field2"));
  }
  @Test public void testNestedSchemaProjection() throws Exception {
    Schema sourceFlatSchema=SchemaBuilder.struct().field("field",Schema.INT32_SCHEMA).build();
    Schema targetFlatSchema=SchemaBuilder.struct().field("field",Schema.INT32_SCHEMA).field("field2",SchemaBuilder.int32().defaultValue(123).build()).build();
    Schema sourceNestedSchema=SchemaBuilder.struct().field("first",Schema.INT32_SCHEMA).field("second",Schema.STRING_SCHEMA).field("array",SchemaBuilder.array(Schema.INT32_SCHEMA).build()).field("map",SchemaBuilder.map(Schema.INT32_SCHEMA,Schema.STRING_SCHEMA).build()).field("nested",sourceFlatSchema).build();
    Schema targetNestedSchema=SchemaBuilder.struct().field("first",Schema.INT32_SCHEMA).field("second",Schema.STRING_SCHEMA).field("array",SchemaBuilder.array(Schema.INT32_SCHEMA).build()).field("map",SchemaBuilder.map(Schema.INT32_SCHEMA,Schema.STRING_SCHEMA).build()).field("nested",targetFlatSchema).build();
    Struct sourceFlatStruct=new Struct(sourceFlatSchema);
    sourceFlatStruct.put("field",113);
    Struct sourceNestedStruct=new Struct(sourceNestedSchema);
    sourceNestedStruct.put("first",1);
    sourceNestedStruct.put("second","abc");
    sourceNestedStruct.put("array",Arrays.asList(1,2));
    sourceNestedStruct.put("map",Collections.singletonMap(5,"def"));
    sourceNestedStruct.put("nested",sourceFlatStruct);
    Struct targetNestedStruct=(Struct)SchemaProjector.project(sourceNestedSchema,sourceNestedStruct,targetNestedSchema);
    assertEquals(1,targetNestedStruct.get("first"));
    assertEquals("abc",targetNestedStruct.get("second"));
    assertEquals(Arrays.asList(1,2),(List<Integer>)targetNestedStruct.get("array"));
    assertEquals(Collections.singletonMap(5,"def"),(Map<Integer,String>)targetNestedStruct.get("map"));
    Struct projectedStruct=(Struct)targetNestedStruct.get("nested");
    assertEquals(113,projectedStruct.get("field"));
    assertEquals(123,projectedStruct.get("field2"));
  }
  @Test public void testLogicalTypeProjection() throws Exception {
    Schema[] logicalTypeSchemas={Decimal.schema(2),Date.SCHEMA,Time.SCHEMA,Timestamp.SCHEMA};
    Object projected;
    BigDecimal testDecimal=new BigDecimal(new BigInteger("156"),2);
    projected=SchemaProjector.project(Decimal.schema(2),testDecimal,Decimal.schema(2));
    assertEquals(testDecimal,projected);
    projected=SchemaProjector.project(Date.SCHEMA,1000,Date.SCHEMA);
    assertEquals(1000,projected);
    projected=SchemaProjector.project(Time.SCHEMA,231,Time.SCHEMA);
    assertEquals(231,projected);
    projected=SchemaProjector.project(Timestamp.SCHEMA,34567L,Timestamp.SCHEMA);
    assertEquals(34567L,projected);
    java.util.Date date=new java.util.Date();
    projected=SchemaProjector.project(Date.SCHEMA,date,Date.SCHEMA);
    assertEquals(date,projected);
    projected=SchemaProjector.project(Time.SCHEMA,date,Time.SCHEMA);
    assertEquals(date,projected);
    projected=SchemaProjector.project(Timestamp.SCHEMA,date,Timestamp.SCHEMA);
    assertEquals(date,projected);
    Schema namedSchema=SchemaBuilder.int32().name("invalidLogicalTypeName").build();
    for (    Schema logicalTypeSchema : logicalTypeSchemas) {
      try {
        SchemaProjector.project(logicalTypeSchema,null,Schema.BOOLEAN_SCHEMA);
        fail("Cannot project logical types to non-logical types.");
      }
 catch (      SchemaProjectorException e) {
      }
      try {
        SchemaProjector.project(logicalTypeSchema,null,namedSchema);
        fail("Reader name is not a valid logical type name.");
      }
 catch (      SchemaProjectorException e) {
      }
      try {
        SchemaProjector.project(Schema.BOOLEAN_SCHEMA,null,logicalTypeSchema);
        fail("Cannot project non-logical types to logical types.");
      }
 catch (      SchemaProjectorException e) {
      }
    }
  }
  @Test public void testArrayProjection() throws Exception {
    Schema source=SchemaBuilder.array(Schema.INT32_SCHEMA).build();
    Object projected=SchemaProjector.project(source,Arrays.asList(1,2,3),source);
    assertEquals(Arrays.asList(1,2,3),(List<Integer>)projected);
    Schema optionalSource=SchemaBuilder.array(Schema.INT32_SCHEMA).optional().build();
    Schema target=SchemaBuilder.array(Schema.INT32_SCHEMA).defaultValue(Arrays.asList(1,2,3)).build();
    projected=SchemaProjector.project(optionalSource,Arrays.asList(4,5),target);
    assertEquals(Arrays.asList(4,5),(List<Integer>)projected);
    projected=SchemaProjector.project(optionalSource,null,target);
    assertEquals(Arrays.asList(1,2,3),(List<Integer>)projected);
    Schema promotedTarget=SchemaBuilder.array(Schema.INT64_SCHEMA).defaultValue(Arrays.asList(1L,2L,3L)).build();
    projected=SchemaProjector.project(optionalSource,Arrays.asList(4,5),promotedTarget);
    List<Long> expectedProjected=Arrays.asList(4L,5L);
    assertEquals(expectedProjected,(List<Long>)projected);
    projected=SchemaProjector.project(optionalSource,null,promotedTarget);
    assertEquals(Arrays.asList(1L,2L,3L),(List<Long>)projected);
    Schema noDefaultValueTarget=SchemaBuilder.array(Schema.INT32_SCHEMA).build();
    try {
      SchemaProjector.project(optionalSource,null,noDefaultValueTarget);
      fail("Target schema does not provide a default value.");
    }
 catch (    SchemaProjectorException e) {
    }
    Schema nonPromotableTarget=SchemaBuilder.array(Schema.BOOLEAN_SCHEMA).build();
    try {
      SchemaProjector.project(optionalSource,null,nonPromotableTarget);
      fail("Neither source type matches target type nor source type can be promoted to target type");
    }
 catch (    SchemaProjectorException e) {
    }
  }
  @Test public void testMapProjection() throws Exception {
    Schema source=SchemaBuilder.map(Schema.INT32_SCHEMA,Schema.INT32_SCHEMA).optional().build();
    Schema target=SchemaBuilder.map(Schema.INT32_SCHEMA,Schema.INT32_SCHEMA).defaultValue(Collections.singletonMap(1,2)).build();
    Object projected=SchemaProjector.project(source,Collections.singletonMap(3,4),target);
    assertEquals(Collections.singletonMap(3,4),(Map<Integer,Integer>)projected);
    projected=SchemaProjector.project(source,null,target);
    assertEquals(Collections.singletonMap(1,2),(Map<Integer,Integer>)projected);
    Schema promotedTarget=SchemaBuilder.map(Schema.INT64_SCHEMA,Schema.FLOAT32_SCHEMA).defaultValue(Collections.singletonMap(3L,4.5F)).build();
    projected=SchemaProjector.project(source,Collections.singletonMap(3,4),promotedTarget);
    assertEquals(Collections.singletonMap(3L,4.F),(Map<Long,Float>)projected);
    projected=SchemaProjector.project(source,null,promotedTarget);
    assertEquals(Collections.singletonMap(3L,4.5F),(Map<Long,Float>)projected);
    Schema noDefaultValueTarget=SchemaBuilder.map(Schema.INT32_SCHEMA,Schema.INT32_SCHEMA).build();
    try {
      SchemaProjector.project(source,null,noDefaultValueTarget);
      fail("Reader does not provide a default value.");
    }
 catch (    SchemaProjectorException e) {
    }
    Schema nonPromotableTarget=SchemaBuilder.map(Schema.BOOLEAN_SCHEMA,Schema.STRING_SCHEMA).build();
    try {
      SchemaProjector.project(source,null,nonPromotableTarget);
      fail("Neither source type matches target type nor source type can be promoted to target type");
    }
 catch (    SchemaProjectorException e) {
    }
  }
  @Test public void testMaybeCompatible() throws Exception {
    Schema source=SchemaBuilder.int32().name("source").build();
    Schema target=SchemaBuilder.int32().name("target").build();
    try {
      SchemaProjector.project(source,12,target);
      fail("Source name and target name mismatch.");
    }
 catch (    SchemaProjectorException e) {
    }
    Schema targetWithParameters=SchemaBuilder.int32().parameters(Collections.singletonMap("key","value"));
    try {
      SchemaProjector.project(source,34,targetWithParameters);
      fail("Source parameters and target parameters mismatch.");
    }
 catch (    SchemaProjectorException e) {
    }
  }
  @Test public void testProjectMissingDefaultValuedStructField(){
    final Schema source=SchemaBuilder.struct().build();
    final Schema target=SchemaBuilder.struct().field("id",SchemaBuilder.int64().defaultValue(42L).build()).build();
    assertEquals(42L,(long)((Struct)SchemaProjector.project(source,new Struct(source),target)).getInt64("id"));
  }
  @Test public void testProjectMissingOptionalStructField(){
    final Schema source=SchemaBuilder.struct().build();
    final Schema target=SchemaBuilder.struct().field("id",SchemaBuilder.OPTIONAL_INT64_SCHEMA).build();
    assertEquals(null,((Struct)SchemaProjector.project(source,new Struct(source),target)).getInt64("id"));
  }
  @Test(expected=SchemaProjectorException.class) public void testProjectMissingRequiredField(){
    final Schema source=SchemaBuilder.struct().build();
    final Schema target=SchemaBuilder.struct().field("id",SchemaBuilder.INT64_SCHEMA).build();
    SchemaProjector.project(source,new Struct(source),target);
  }
  private void verifyOptionalProjection(  Schema source,  Type targetType,  Object value,  Object defaultValue,  Object expectedProjected,  boolean optional){
    Schema target;
    assert source.isOptional();
    assert value != null;
    if (optional) {
      target=SchemaBuilder.type(targetType).optional().defaultValue(defaultValue).build();
    }
 else {
      target=SchemaBuilder.type(targetType).defaultValue(defaultValue).build();
    }
    Object projected=SchemaProjector.project(source,value,target);
    if (targetType == Type.FLOAT64) {
      assertEquals((double)expectedProjected,(double)projected,1e-6);
    }
 else {
      assertEquals(expectedProjected,projected);
    }
    projected=SchemaProjector.project(source,null,target);
    if (optional) {
      assertEquals(null,projected);
    }
 else {
      assertEquals(defaultValue,projected);
    }
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from kafka-2.1.0~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package com.badlogic.gdx.math;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import org.junit.Test;
public class Shape2DTest {
  @Test public void testCircle(){
    Circle c1=new Circle(0,0,1);
    Circle c2=new Circle(0,0,1);
    Circle c3=new Circle(2,0,1);
    Circle c4=new Circle(0,0,2);
    assertTrue(c1.overlaps(c1));
    assertTrue(c1.overlaps(c2));
    assertFalse(c1.overlaps(c3));
    assertTrue(c1.overlaps(c4));
    assertTrue(c4.overlaps(c1));
    assertTrue(c1.contains(0,1));
    assertFalse(c1.contains(0,2));
    assertTrue(c1.contains(c1));
    assertFalse(c1.contains(c4));
    assertTrue(c4.contains(c1));
  }
  @Test public void testRectangle(){
    Rectangle r1=new Rectangle(0,0,1,1);
    Rectangle r2=new Rectangle(1,0,2,1);
    assertTrue(r1.overlaps(r1));
    assertFalse(r1.overlaps(r2));
    assertTrue(r1.contains(0,0));
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from libgdx-gdx-parent-1.9.9~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from maven-project-0.4~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.mockitousage.plugins.instantiator;
import org.junit.Test;
import java.util.List;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.fail;
import static org.mockito.Mockito.mock;
public class InstantiatorProviderTest {
  @SuppressWarnings("CheckReturnValue") @Test public void uses_custom_instantiator_provider(){
    mock(List.class);
    MyInstantiatorProvider2.explosive.set(true);
    try {
      mock(List.class);
      fail();
    }
 catch (    Exception e) {
      assertEquals(MyInstantiatorProvider2.class.getName(),e.getMessage());
    }
 finally {
      MyInstantiatorProvider2.explosive.remove();
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.mockitoutil.async;
import org.junit.After;
import org.junit.Test;
import org.mockitoutil.Stopwatch;
import java.util.concurrent.atomic.AtomicInteger;
import static java.util.concurrent.TimeUnit.MILLISECONDS;
import static org.junit.Assert.assertEquals;
import static org.mockitoutil.Stopwatch.createNotStarted;
public class AsyncTestingTest {
  private AsyncTesting async=new AsyncTesting();
  private Stopwatch watch=createNotStarted();
  @After public void after(){
    async.cleanUp();
  }
  @Test public void sanity_test(){
    watch.start();
    final AtomicInteger value=new AtomicInteger(0);
    async.runAfter(200,new Runnable(){
      public void run(){
        value.incrementAndGet();
      }
    }
);
    assertEquals(0,value.get());
    watch.waitFor(300);
    watch.assertElapsedTimeIsMoreThan(200,MILLISECONDS);
    assertEquals(1,value.get());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.mockito.internal.progress;
import org.junit.After;
import org.junit.Test;
import org.mockito.internal.verification.DummyVerificationMode;
import org.mockitoutil.TestBase;
import java.util.List;
import static org.junit.Assert.assertNotNull;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.verify;
import static org.mockito.internal.progress.ThreadSafeMockingProgress.mockingProgress;
public class ThreadSafeMockingProgressTest extends TestBase {
  @After public void after(){
    this.resetState();
  }
  @Test public void shouldShareState() throws Exception {
    MockingProgress p=mockingProgress();
    p.verificationStarted(new DummyVerificationMode());
    p=mockingProgress();
    assertNotNull(p.pullVerificationMode());
  }
  @SuppressWarnings({"CheckReturnValue","MockitoUsage"}) @Test public void shouldKnowWhenVerificationHasStarted() throws Exception {
    verify(mock(List.class));
    MockingProgress p=mockingProgress();
    assertNotNull(p.pullVerificationMode());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.mockito.internal.stubbing.defaultanswers;
import static org.assertj.core.api.Assertions.assertThat;
import org.junit.Test;
import org.mockito.exceptions.verification.SmartNullPointerException;
import org.mockito.stubbing.Answer;
import org.mockitoutil.TestBase;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.fail;
public class ReturnsSmartNullsTest extends TestBase {
  @Test public void should_return_the_usual_default_values_for_primitives() throws Throwable {
    Answer<Object> answer=new ReturnsSmartNulls();
    assertEquals(false,answer.answer(invocationOf(HasPrimitiveMethods.class,"booleanMethod")));
    assertEquals((char)0,answer.answer(invocationOf(HasPrimitiveMethods.class,"charMethod")));
    assertEquals((byte)0,answer.answer(invocationOf(HasPrimitiveMethods.class,"byteMethod")));
    assertEquals((short)0,answer.answer(invocationOf(HasPrimitiveMethods.class,"shortMethod")));
    assertEquals(0,answer.answer(invocationOf(HasPrimitiveMethods.class,"intMethod")));
    assertEquals(0L,answer.answer(invocationOf(HasPrimitiveMethods.class,"longMethod")));
    assertEquals(0f,answer.answer(invocationOf(HasPrimitiveMethods.class,"floatMethod")));
    assertEquals(0d,answer.answer(invocationOf(HasPrimitiveMethods.class,"doubleMethod")));
  }
@SuppressWarnings("unused") interface Foo {
    Foo get();
    Foo withArgs(    String oneArg,    String otherArg);
  }
  @Test public void should_return_an_object_that_fails_on_any_method_invocation_for_non_primitives() throws Throwable {
    Answer<Object> answer=new ReturnsSmartNulls();
    Foo smartNull=(Foo)answer.answer(invocationOf(Foo.class,"get"));
    try {
      smartNull.get();
      fail();
    }
 catch (    SmartNullPointerException expected) {
    }
  }
  @Test public void should_return_an_object_that_allows_object_methods() throws Throwable {
    Answer<Object> answer=new ReturnsSmartNulls();
    Foo smartNull=(Foo)answer.answer(invocationOf(Foo.class,"get"));
    assertThat(smartNull.toString()).contains("SmartNull returned by").contains("foo.get()");
  }
  @Test public void should_print_the_parameters_when_calling_a_method_with_args() throws Throwable {
    Answer<Object> answer=new ReturnsSmartNulls();
    Foo smartNull=(Foo)answer.answer(invocationOf(Foo.class,"withArgs","oompa","lumpa"));
    assertThat(smartNull.toString()).contains("foo.withArgs").contains("oompa").contains("lumpa");
  }
  @Test public void should_print_the_parameters_on_SmartNullPointerException_message() throws Throwable {
    Answer<Object> answer=new ReturnsSmartNulls();
    Foo smartNull=(Foo)answer.answer(invocationOf(Foo.class,"withArgs","oompa","lumpa"));
    try {
      smartNull.get();
      fail();
    }
 catch (    SmartNullPointerException e) {
      assertThat(e).hasMessageContaining("oompa").hasMessageContaining("lumpa");
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.mockito.internal.listeners;
import org.assertj.core.util.Lists;
import org.junit.Test;
import org.mockito.ArgumentMatcher;
import org.mockito.internal.creation.settings.CreationSettings;
import org.mockito.invocation.Invocation;
import org.mockito.stubbing.Stubbing;
import org.mockitoutil.TestBase;
import java.util.Collection;
import java.util.List;
import static org.assertj.core.util.Lists.emptyList;
import static org.mockito.ArgumentMatchers.argThat;
import static org.mockito.Mockito.doReturn;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.verify;
import static org.mockito.internal.listeners.StubbingLookupNotifier.notifyStubbedAnswerLookup;
public class StubbingLookupNotifierTest extends TestBase {
  Invocation invocation=mock(Invocation.class);
  Stubbing stubbingFound=mock(Stubbing.class);
  Collection<Stubbing> allStubbings=mock(Collection.class);
  CreationSettings creationSettings=mock(CreationSettings.class);
  @Test public void does_not_do_anything_when_list_is_empty(){
    doReturn(emptyList()).when(creationSettings).getStubbingLookupListeners();
    notifyStubbedAnswerLookup(invocation,stubbingFound,allStubbings,creationSettings);
  }
  @Test public void call_on_stubbing_lookup_method_of_listeners_with_correct_event(){
    StubbingLookupListener listener1=mock(StubbingLookupListener.class);
    StubbingLookupListener listener2=mock(StubbingLookupListener.class);
    List<StubbingLookupListener> listeners=Lists.newArrayList(listener1,listener2);
    doReturn(listeners).when(creationSettings).getStubbingLookupListeners();
    notifyStubbedAnswerLookup(invocation,stubbingFound,allStubbings,creationSettings);
    verify(listener1).onStubbingLookup(argThat(new EventArgumentMatcher()));
    verify(listener2).onStubbingLookup(argThat(new EventArgumentMatcher()));
  }
class EventArgumentMatcher implements ArgumentMatcher<StubbingLookupNotifier.Event> {
    @Override public boolean matches(    StubbingLookupNotifier.Event argument){
      return invocation == argument.getInvocation() && stubbingFound == argument.getStubbingFound() && allStubbings == argument.getAllStubbings() && creationSettings == argument.getMockSettings();
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.mockito.internal.session;
import org.junit.After;
import org.junit.Test;
import org.mockito.Mock;
import org.mockito.MockitoSession;
import org.mockito.StateMaster;
import org.mockito.exceptions.misusing.UnfinishedMockingSessionException;
import org.mockito.quality.Strictness;
import org.mockito.session.MockitoSessionLogger;
import org.mockitoutil.ThrowableAssert;
import java.util.ArrayList;
import java.util.List;
import java.util.Set;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;
import static org.mockito.Mockito.when;
import static org.mockito.quality.Strictness.WARN;
public class DefaultMockitoSessionBuilderTest {
  @After public void after(){
    new StateMaster().clearMockitoListeners();
  }
  @Test public void creates_sessions(){
    new DefaultMockitoSessionBuilder().startMocking().finishMocking();
    new DefaultMockitoSessionBuilder().initMocks((Object)null).startMocking().finishMocking();
    new DefaultMockitoSessionBuilder().initMocks((Object[])null).startMocking().finishMocking();
    new DefaultMockitoSessionBuilder().initMocks(null,null).strictness(null).startMocking().finishMocking();
    new DefaultMockitoSessionBuilder().strictness(null).startMocking().finishMocking();
    new DefaultMockitoSessionBuilder().initMocks(this).startMocking().finishMocking();
    new DefaultMockitoSessionBuilder().initMocks(new Object()).startMocking().finishMocking();
    new DefaultMockitoSessionBuilder().strictness(Strictness.LENIENT).startMocking().finishMocking();
  }
  @Test public void creates_sessions_for_multiple_test_class_instances_for_repeated_calls(){
    TestClass testClass=new TestClass();
    TestClass.NestedTestClass nestedTestClass=testClass.new NestedTestClass();
    new DefaultMockitoSessionBuilder().initMocks(testClass).initMocks(nestedTestClass).startMocking().finishMocking();
    assertNotNull(testClass.set);
    assertNotNull(nestedTestClass.list);
  }
  @Test public void creates_sessions_for_multiple_test_class_instances_for_varargs_call(){
    TestClass testClass=new TestClass();
    TestClass.NestedTestClass nestedTestClass=testClass.new NestedTestClass();
    new DefaultMockitoSessionBuilder().initMocks(testClass,nestedTestClass).startMocking().finishMocking();
    assertNotNull(testClass.set);
    assertNotNull(nestedTestClass.list);
  }
  @Test public void uses_logger_and_strictness(){
    TestClass testClass=new TestClass();
    final List<String> hints=new ArrayList<String>();
    MockitoSession session=new DefaultMockitoSessionBuilder().initMocks(testClass).strictness(WARN).logger(new MockitoSessionLogger(){
      @Override public void log(      String hint){
        hints.add(hint);
      }
    }
).startMocking();
    when(testClass.set.add(1)).thenReturn(true);
    session.finishMocking();
    assertFalse(hints.isEmpty());
  }
  @Test public void requires_finish_mocking(){
    new DefaultMockitoSessionBuilder().startMocking();
    ThrowableAssert.assertThat(new Runnable(){
      public void run(){
        new DefaultMockitoSessionBuilder().startMocking();
      }
    }
).throwsException(UnfinishedMockingSessionException.class);
  }
  @Test public void auto_cleans_dirty_listeners(){
    new DefaultMockitoSessionBuilder().startMocking();
    ThrowableAssert.assertThat(new Runnable(){
      public void run(){
        new DefaultMockitoSessionBuilder().startMocking();
      }
    }
).throwsException(UnfinishedMockingSessionException.class);
  }
class TestClass {
    @Mock public Set<Object> set;
class NestedTestClass {
      @Mock public List<Object> list;
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.mockitousage.basicapi;
import org.junit.Test;
import org.mockitoutil.TestBase;
import java.io.Serializable;
import static org.junit.Assert.assertSame;
import static org.mockitoutil.SimpleSerializationUtil.serializeAndBack;
@SuppressWarnings("serial") public class ObjectsSerializationTest extends TestBase implements Serializable {
class Bar implements Serializable {
    Foo foo;
  }
class Foo implements Serializable {
    Bar bar;
    Foo(){
      bar=new Bar();
      bar.foo=this;
    }
  }
  @Test public void shouldSerializationWork() throws Exception {
    Foo foo=new Foo();
    foo=serializeAndBack(foo);
    assertSame(foo,foo.bar.foo);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.mockitousage.bugs;
import org.assertj.core.api.Assertions;
import org.junit.Test;
import org.mockito.Spy;
import org.mockitoutil.TestBase;
import java.util.LinkedList;
import java.util.List;
import static org.junit.Assert.fail;
import static org.mockito.Mockito.verify;
public class SpyShouldHaveNiceNameTest extends TestBase {
  @Spy List<Integer> veryCoolSpy=new LinkedList<Integer>();
  @Test public void shouldPrintNiceName(){
    veryCoolSpy.add(1);
    try {
      verify(veryCoolSpy).add(2);
      fail();
    }
 catch (    AssertionError e) {
      Assertions.assertThat(e.getMessage()).contains("veryCoolSpy");
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.mockitousage.bugs;
import org.junit.Test;
import org.mockito.Mock;
import org.mockito.exceptions.verification.NeverWantedButInvoked;
import org.mockitousage.IMethods;
import org.mockitoutil.TestBase;
import static org.junit.Assert.fail;
import static org.mockito.Mockito.*;
public class VerifyingWithAnExtraCallToADifferentMockTest extends TestBase {
  @Mock IMethods mock;
  @Mock IMethods mockTwo;
  @Test public void shouldAllowVerifyingWhenOtherMockCallIsInTheSameLine(){
    when(mock.otherMethod()).thenReturn("foo");
    mockTwo.simpleMethod("foo");
    verify(mockTwo).simpleMethod(mock.otherMethod());
    try {
      verify(mockTwo,never()).simpleMethod(mock.otherMethod());
      fail();
    }
 catch (    NeverWantedButInvoked e) {
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.mockitousage.matchers;
import org.junit.Ignore;
import org.junit.Test;
import org.mockito.Mock;
import org.mockitousage.IMethods;
import org.mockitoutil.TestBase;
import static org.mockito.Matchers.anyBoolean;
import static org.mockito.Matchers.anyString;
import static org.mockito.Mockito.verify;
public class MatchersMixedWithRawArgumentsTest extends TestBase {
  @Mock private IMethods mock;
  @Ignore("prototyping new feature that allows to avoid eq() matchers when raw args passed") @Test public void shouldAllowMixingRawArgumentsWithMatchers(){
    mock.varargs("1","2","3");
    verify(mock).varargs("1",anyString(),"3");
    verify(mock).varargs(anyBoolean(),false);
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from mockito-2.23.11~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright 2009-2015 the original author or authors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.ibatis.cache;
import org.apache.ibatis.cache.decorators.LoggingCache;
import org.apache.ibatis.cache.decorators.ScheduledCache;
import org.apache.ibatis.cache.decorators.SerializedCache;
import org.apache.ibatis.cache.decorators.SynchronizedCache;
import org.apache.ibatis.cache.impl.PerpetualCache;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import org.junit.Test;
import java.util.HashSet;
import java.util.Set;
public class BaseCacheTest {
  @Test public void shouldDemonstrateEqualsAndHashCodeForVariousCacheTypes(){
    PerpetualCache cache=new PerpetualCache("test_cache");
    assertTrue(cache.equals(cache));
    assertTrue(cache.equals(new SynchronizedCache(cache)));
    assertTrue(cache.equals(new SerializedCache(cache)));
    assertTrue(cache.equals(new LoggingCache(cache)));
    assertTrue(cache.equals(new ScheduledCache(cache)));
    assertEquals(cache.hashCode(),new SynchronizedCache(cache).hashCode());
    assertEquals(cache.hashCode(),new SerializedCache(cache).hashCode());
    assertEquals(cache.hashCode(),new LoggingCache(cache).hashCode());
    assertEquals(cache.hashCode(),new ScheduledCache(cache).hashCode());
    Set<Cache> caches=new HashSet<Cache>();
    caches.add(cache);
    caches.add(new SynchronizedCache(cache));
    caches.add(new SerializedCache(cache));
    caches.add(new LoggingCache(cache));
    caches.add(new ScheduledCache(cache));
    assertEquals(1,caches.size());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright 2009-2017 the original author or authors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.ibatis.submitted.named_constructor_args.usesjava8;
import static org.junit.Assert.*;
import java.io.Reader;
import java.sql.Connection;
import org.apache.ibatis.io.Resources;
import org.apache.ibatis.jdbc.ScriptRunner;
import org.apache.ibatis.session.SqlSession;
import org.apache.ibatis.session.SqlSessionFactory;
import org.apache.ibatis.session.SqlSessionFactoryBuilder;
import org.apache.ibatis.submitted.named_constructor_args.usesjava8.Mapper;
import org.apache.ibatis.submitted.named_constructor_args.User;
import org.junit.BeforeClass;
import org.junit.Test;
public class NamedConstructorArgsUseActualNameTest {
  private static SqlSessionFactory sqlSessionFactory;
  @BeforeClass public static void setUp() throws Exception {
    Reader reader=Resources.getResourceAsReader("org/apache/ibatis/submitted/named_constructor_args/mybatis-config.xml");
    sqlSessionFactory=new SqlSessionFactoryBuilder().build(reader);
    reader.close();
    sqlSessionFactory.getConfiguration().addMapper(Mapper.class);
    SqlSession session=sqlSessionFactory.openSession();
    Connection conn=session.getConnection();
    reader=Resources.getResourceAsReader("org/apache/ibatis/submitted/named_constructor_args/CreateDB.sql");
    ScriptRunner runner=new ScriptRunner(conn);
    runner.setLogWriter(null);
    runner.runScript(reader);
    conn.close();
    reader.close();
    session.close();
  }
  @Test public void argsByActualNames(){
    SqlSession sqlSession=sqlSessionFactory.openSession();
    try {
      Mapper mapper=sqlSession.getMapper(Mapper.class);
      User user=mapper.mapConstructorWithoutParamAnnos(1);
      assertEquals(Integer.valueOf(1),user.getId());
      assertEquals("User1",user.getName());
    }
  finally {
      sqlSession.close();
    }
  }
  @Test public void argsByActualNamesXml(){
    SqlSession sqlSession=sqlSessionFactory.openSession();
    try {
      Mapper mapper=sqlSession.getMapper(Mapper.class);
      User user=mapper.mapConstructorWithoutParamAnnosXml(1);
      assertEquals(Integer.valueOf(1),user.getId());
      assertEquals("User1",user.getName());
    }
  finally {
      sqlSession.close();
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright 2009-2017 the original author or authors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.ibatis.submitted.overwritingproperties;
import org.apache.ibatis.io.Resources;
import org.apache.ibatis.jdbc.ScriptRunner;
import org.apache.ibatis.session.*;
import org.junit.*;
import java.io.Reader;
import java.sql.Connection;
import java.sql.SQLException;
public class FooMapperTest {
  private final static String SQL_MAP_CONFIG="org/apache/ibatis/submitted/overwritingproperties/sqlmap.xml";
  private static SqlSession session;
  private static Connection conn;
  @BeforeClass public static void setUpBeforeClass(){
    try {
      final SqlSessionFactory factory=new SqlSessionFactoryBuilder().build(Resources.getResourceAsReader(SQL_MAP_CONFIG));
      session=factory.openSession();
      conn=session.getConnection();
      ScriptRunner runner=new ScriptRunner(conn);
      runner.setLogWriter(null);
      runner.setErrorLogWriter(null);
      Reader reader=Resources.getResourceAsReader("org/apache/ibatis/submitted/overwritingproperties/create-schema-mysql.sql");
      runner.runScript(reader);
      reader.close();
    }
 catch (    Exception ex) {
      Assert.fail(ex.getMessage());
    }
  }
  @Before public void setUp(){
    final FooMapper mapper=session.getMapper(FooMapper.class);
    mapper.deleteAllFoo();
    session.commit();
  }
  @Test public void testOverwriteWithDefault(){
    final FooMapper mapper=session.getMapper(FooMapper.class);
    final Bar bar=new Bar(2L);
    final Foo inserted=new Foo(1L,bar,3,4);
    mapper.insertFoo(inserted);
    final Foo selected=mapper.selectFoo();
    Assert.assertEquals(inserted.getField1(),selected.getField1());
    Assert.assertEquals(inserted.getField3(),selected.getField4());
    Assert.assertEquals(inserted.getField4(),selected.getField3());
    Assert.assertEquals(inserted.getField2().getField1(),selected.getField2().getField1());
  }
  @AfterClass public static void tearDownAfterClass(){
    try {
      conn.close();
    }
 catch (    SQLException e) {
      Assert.fail(e.getMessage());
    }
    session.close();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright 2009-2017 the original author or authors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.ibatis.submitted.nestedresulthandler_multiple_association;
import java.io.Reader;
import java.sql.Connection;
import java.util.List;
import org.apache.ibatis.io.Resources;
import org.apache.ibatis.jdbc.ScriptRunner;
import org.apache.ibatis.session.SqlSession;
import org.apache.ibatis.session.SqlSessionFactory;
import org.apache.ibatis.session.SqlSessionFactoryBuilder;
import org.junit.Assert;
import org.junit.BeforeClass;
import org.junit.Test;
public class NestedResultHandlerMultipleAssociationTest {
  private static SqlSessionFactory sqlSessionFactory;
  @BeforeClass public static void setUp() throws Exception {
    Reader reader=Resources.getResourceAsReader("org/apache/ibatis/submitted/nestedresulthandler_multiple_association/mybatis-config.xml");
    sqlSessionFactory=new SqlSessionFactoryBuilder().build(reader);
    reader.close();
    SqlSession session=sqlSessionFactory.openSession();
    Connection conn=session.getConnection();
    reader=Resources.getResourceAsReader("org/apache/ibatis/submitted/nestedresulthandler_multiple_association/CreateDB.sql");
    ScriptRunner runner=new ScriptRunner(conn);
    runner.setLogWriter(null);
    runner.runScript(reader);
    conn.close();
    reader.close();
    session.close();
  }
  @Test public void failure() throws Exception {
    SqlSession sqlSession=sqlSessionFactory.openSession();
    List<ParentBean> list=sqlSession.selectList("selectParentBeans");
    for (    ParentBean pb : list) {
      for (      Binome<ChildBean,ChildBean> childs : pb.getChilds()) {
        Assert.assertNotNull(childs);
        Assert.assertNotNull(childs.getOne());
        Assert.assertNotNull(childs.getTwo());
      }
    }
    sqlSession.close();
  }
  @Test public void success() throws Exception {
    SqlSession sqlSession=sqlSessionFactory.openSession();
    ParentBean parent=sqlSession.selectOne("selectParentBeanById",2);
    for (    Binome<ChildBean,ChildBean> childs : parent.getChilds()) {
      Assert.assertNotNull(childs);
      Assert.assertNotNull(childs.getOne());
      Assert.assertNotNull(childs.getTwo());
    }
    sqlSession.close();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright 2009-2015 the original author or authors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.ibatis.submitted.nonexistentvariables;
import static org.junit.Assert.fail;
import java.io.Reader;
import java.sql.Connection;
import java.sql.DriverManager;
import org.apache.ibatis.exceptions.PersistenceException;
import org.apache.ibatis.io.Resources;
import org.apache.ibatis.jdbc.ScriptRunner;
import org.apache.ibatis.session.SqlSession;
import org.apache.ibatis.session.SqlSessionFactory;
import org.apache.ibatis.session.SqlSessionFactoryBuilder;
import org.junit.BeforeClass;
import org.junit.Test;
public class NonExistentVariablesTest {
  protected static SqlSessionFactory sqlSessionFactory;
  @BeforeClass public static void setUp() throws Exception {
    Connection conn=null;
    try {
      Class.forName("org.hsqldb.jdbcDriver");
      conn=DriverManager.getConnection("jdbc:hsqldb:mem:nonexistentvariables","sa","");
      Reader reader=Resources.getResourceAsReader("org/apache/ibatis/submitted/nonexistentvariables/CreateDB.sql");
      ScriptRunner runner=new ScriptRunner(conn);
      runner.setLogWriter(null);
      runner.setErrorLogWriter(null);
      runner.runScript(reader);
      conn.commit();
      reader.close();
      reader=Resources.getResourceAsReader("org/apache/ibatis/submitted/nonexistentvariables/mybatis-config.xml");
      sqlSessionFactory=new SqlSessionFactoryBuilder().build(reader);
      reader.close();
    }
  finally {
      if (conn != null) {
        conn.close();
      }
    }
  }
  @Test(expected=PersistenceException.class) public void testWrongParameter(){
    SqlSession sqlSession=sqlSessionFactory.openSession();
    try {
      Mapper mapper=sqlSession.getMapper(Mapper.class);
      mapper.count(1,"John");
      fail("should have failed");
    }
  finally {
      sqlSession.close();
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright 2009-2015 the original author or authors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.ibatis.submitted.blobtest;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import java.io.Reader;
import java.sql.Connection;
import java.sql.DriverManager;
import java.util.List;
import org.apache.ibatis.io.Resources;
import org.apache.ibatis.jdbc.ScriptRunner;
import org.apache.ibatis.session.SqlSession;
import org.apache.ibatis.session.SqlSessionFactory;
import org.apache.ibatis.session.SqlSessionFactoryBuilder;
import org.junit.BeforeClass;
import org.junit.Test;
public class BlobTest {
  private static SqlSessionFactory sqlSessionFactory;
  @BeforeClass public static void initDatabase() throws Exception {
    Connection conn=null;
    try {
      Class.forName("org.hsqldb.jdbcDriver");
      conn=DriverManager.getConnection("jdbc:hsqldb:mem:blobtest","sa","");
      Reader reader=Resources.getResourceAsReader("org/apache/ibatis/submitted/blobtest/CreateDB.sql");
      ScriptRunner runner=new ScriptRunner(conn);
      runner.setLogWriter(null);
      runner.setErrorLogWriter(null);
      runner.runScript(reader);
      conn.commit();
      reader.close();
      reader=Resources.getResourceAsReader("org/apache/ibatis/submitted/blobtest/MapperConfig.xml");
      sqlSessionFactory=new SqlSessionFactoryBuilder().build(reader);
      reader.close();
    }
  finally {
      if (conn != null) {
        conn.close();
      }
    }
  }
  @Test public void testInsertBlobThenSelectAll(){
    SqlSession sqlSession=sqlSessionFactory.openSession();
    try {
      BlobMapper blobMapper=sqlSession.getMapper(BlobMapper.class);
      byte[] myblob=new byte[]{1,2,3,4,5};
      BlobRecord blobRecord=new BlobRecord(1,myblob);
      int rows=blobMapper.insert(blobRecord);
      assertEquals(1,rows);
      List<BlobRecord> results=blobMapper.selectAll();
      assertEquals(1,results.size());
      BlobRecord result=results.get(0);
      assertEquals(blobRecord.getId(),result.getId());
      assertTrue(blobsAreEqual(blobRecord.getBlob(),result.getBlob()));
    }
  finally {
      sqlSession.close();
    }
  }
  @Test public void testInsertBlobObjectsThenSelectAll(){
    SqlSession sqlSession=sqlSessionFactory.openSession();
    try {
      BlobMapper blobMapper=sqlSession.getMapper(BlobMapper.class);
      Byte[] myblob=new Byte[]{1,2,3,4,5};
      BlobRecord blobRecord=new BlobRecord(1,myblob);
      int rows=blobMapper.insert(blobRecord);
      assertEquals(1,rows);
      List<BlobRecord> results=blobMapper.selectAllWithBlobObjects();
      assertEquals(1,results.size());
      BlobRecord result=results.get(0);
      assertEquals(blobRecord.getId(),result.getId());
      assertTrue(blobsAreEqual(blobRecord.getBlob(),result.getBlob()));
    }
  finally {
      sqlSession.close();
    }
  }
  public static boolean blobsAreEqual(  byte[] blob1,  byte[] blob2){
    if (blob1 == null) {
      return blob2 == null;
    }
    if (blob2 == null) {
      return blob1 == null;
    }
    boolean rc=blob1.length == blob2.length;
    if (rc) {
      for (int i=0; i < blob1.length; i++) {
        if (blob1[i] != blob2[i]) {
          rc=false;
          break;
        }
      }
    }
    return rc;
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright 2009-2018 the original author or authors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.ibatis.builder;
import java.io.InputStream;
import java.util.regex.Pattern;
import org.apache.ibatis.builder.xml.XMLMapperBuilder;
import org.apache.ibatis.io.Resources;
import org.apache.ibatis.mapping.MappedStatement;
import org.apache.ibatis.mapping.ResultSetType;
import org.apache.ibatis.mapping.StatementType;
import org.apache.ibatis.session.Configuration;
import org.junit.Rule;
import org.apache.ibatis.type.TypeHandler;
import org.junit.Test;
import org.junit.rules.ExpectedException;
import static com.googlecode.catchexception.apis.BDDCatchException.*;
import static org.assertj.core.api.BDDAssertions.then;
import static org.assertj.core.api.Assertions.assertThat;
public class XmlMapperBuilderTest {
  @Rule public ExpectedException expectedEx=ExpectedException.none();
  @Test public void shouldSuccessfullyLoadXMLMapperFile() throws Exception {
    Configuration configuration=new Configuration();
    String resource="org/apache/ibatis/builder/AuthorMapper.xml";
    InputStream inputStream=Resources.getResourceAsStream(resource);
    XMLMapperBuilder builder=new XMLMapperBuilder(inputStream,configuration,resource,configuration.getSqlFragments());
    builder.parse();
    inputStream.close();
  }
  @Test public void mappedStatementWithOptions() throws Exception {
    Configuration configuration=new Configuration();
    String resource="org/apache/ibatis/builder/AuthorMapper.xml";
    InputStream inputStream=Resources.getResourceAsStream(resource);
    XMLMapperBuilder builder=new XMLMapperBuilder(inputStream,configuration,resource,configuration.getSqlFragments());
    builder.parse();
    MappedStatement mappedStatement=configuration.getMappedStatement("selectWithOptions");
    assertThat(mappedStatement.getFetchSize()).isEqualTo(200);
    assertThat(mappedStatement.getTimeout()).isEqualTo(10);
    assertThat(mappedStatement.getStatementType()).isEqualTo(StatementType.PREPARED);
    assertThat(mappedStatement.getResultSetType()).isEqualTo(ResultSetType.SCROLL_SENSITIVE);
    assertThat(mappedStatement.isFlushCacheRequired()).isFalse();
    assertThat(mappedStatement.isUseCache()).isFalse();
    inputStream.close();
  }
  @Test public void parseExpression(){
    BaseBuilder builder=new BaseBuilder(new Configuration()){
{
      }
    }
;
{
      Pattern pattern=builder.parseExpression("[0-9]","[a-z]");
      assertThat(pattern.matcher("0").find()).isTrue();
      assertThat(pattern.matcher("a").find()).isFalse();
    }
{
      Pattern pattern=builder.parseExpression(null,"[a-z]");
      assertThat(pattern.matcher("0").find()).isFalse();
      assertThat(pattern.matcher("a").find()).isTrue();
    }
  }
  @Test public void resolveJdbcTypeWithUndefinedValue(){
    BaseBuilder builder=new BaseBuilder(new Configuration()){
{
      }
    }
;
    when(builder).resolveJdbcType("aaa");
    then(caughtException()).isInstanceOf(BuilderException.class).hasMessageStartingWith("Error resolving JdbcType. Cause: java.lang.IllegalArgumentException: No enum").hasMessageEndingWith("org.apache.ibatis.type.JdbcType.aaa");
  }
  @Test public void resolveResultSetTypeWithUndefinedValue(){
    BaseBuilder builder=new BaseBuilder(new Configuration()){
{
      }
    }
;
    when(builder).resolveResultSetType("bbb");
    then(caughtException()).isInstanceOf(BuilderException.class).hasMessageStartingWith("Error resolving ResultSetType. Cause: java.lang.IllegalArgumentException: No enum").hasMessageEndingWith("org.apache.ibatis.mapping.ResultSetType.bbb");
  }
  @Test public void resolveParameterModeWithUndefinedValue(){
    BaseBuilder builder=new BaseBuilder(new Configuration()){
{
      }
    }
;
    when(builder).resolveParameterMode("ccc");
    then(caughtException()).isInstanceOf(BuilderException.class).hasMessageStartingWith("Error resolving ParameterMode. Cause: java.lang.IllegalArgumentException: No enum").hasMessageEndingWith("org.apache.ibatis.mapping.ParameterMode.ccc");
  }
  @Test public void createInstanceWithAbstractClass(){
    BaseBuilder builder=new BaseBuilder(new Configuration()){
{
      }
    }
;
    when(builder).createInstance("org.apache.ibatis.builder.BaseBuilder");
    then(caughtException()).isInstanceOf(BuilderException.class).hasMessage("Error creating instance. Cause: java.lang.InstantiationException: org.apache.ibatis.builder.BaseBuilder");
  }
  @Test public void resolveClassWithNotFound(){
    BaseBuilder builder=new BaseBuilder(new Configuration()){
{
      }
    }
;
    when(builder).resolveClass("ddd");
    then(caughtException()).isInstanceOf(BuilderException.class).hasMessage("Error resolving class. Cause: org.apache.ibatis.type.TypeException: Could not resolve type alias 'ddd'.  Cause: java.lang.ClassNotFoundException: Cannot find class: ddd");
  }
  @Test public void resolveTypeHandlerTypeHandlerAliasIsNull(){
    BaseBuilder builder=new BaseBuilder(new Configuration()){
{
      }
    }
;
    TypeHandler<?> typeHandler=builder.resolveTypeHandler(String.class,(String)null);
    assertThat(typeHandler).isNull();
  }
  @Test public void resolveTypeHandlerNoAssignable(){
    BaseBuilder builder=new BaseBuilder(new Configuration()){
{
      }
    }
;
    when(builder).resolveTypeHandler(String.class,"integer");
    then(caughtException()).isInstanceOf(BuilderException.class).hasMessage("Type java.lang.Integer is not a valid TypeHandler because it does not implement TypeHandler interface");
  }
  @Test public void setCurrentNamespaceValueIsNull(){
    MapperBuilderAssistant builder=new MapperBuilderAssistant(new Configuration(),"resource");
    when(builder).setCurrentNamespace(null);
    then(caughtException()).isInstanceOf(BuilderException.class).hasMessage("The mapper element requires a namespace attribute to be specified.");
  }
  @Test public void useCacheRefNamespaceIsNull(){
    MapperBuilderAssistant builder=new MapperBuilderAssistant(new Configuration(),"resource");
    when(builder).useCacheRef(null);
    then(caughtException()).isInstanceOf(BuilderException.class).hasMessage("cache-ref element requires a namespace attribute.");
  }
  @Test public void useCacheRefNamespaceIsUndefined(){
    MapperBuilderAssistant builder=new MapperBuilderAssistant(new Configuration(),"resource");
    when(builder).useCacheRef("eee");
    then(caughtException()).hasMessage("No cache for namespace 'eee' could be found.");
  }
  @Test public void shouldFailedLoadXMLMapperFile() throws Exception {
    expectedEx.expect(BuilderException.class);
    expectedEx.expectMessage("Error parsing Mapper XML. The XML location is 'org/apache/ibatis/builder/ProblemMapper.xml'");
    Configuration configuration=new Configuration();
    String resource="org/apache/ibatis/builder/ProblemMapper.xml";
    InputStream inputStream=Resources.getResourceAsStream(resource);
    XMLMapperBuilder builder=new XMLMapperBuilder(inputStream,configuration,resource,configuration.getSqlFragments());
    builder.parse();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
/** 
 * Copyright 2009-2015 the original author or authors. Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.
 */
package org.apache.ibatis.reflection;
import static org.junit.Assert.assertEquals;
import org.junit.Test;
import java.lang.reflect.InvocationTargetException;
import java.lang.reflect.UndeclaredThrowableException;
public class ExceptionUtilTest {
  @Test public void shouldUnwrapThrowable(){
    Exception exception=new Exception();
    assertEquals(exception,ExceptionUtil.unwrapThrowable(exception));
    assertEquals(exception,ExceptionUtil.unwrapThrowable(new InvocationTargetException(exception,"test")));
    assertEquals(exception,ExceptionUtil.unwrapThrowable(new UndeclaredThrowableException(exception,"test")));
    assertEquals(exception,ExceptionUtil.unwrapThrowable(new InvocationTargetException(new InvocationTargetException(exception,"test"),"test")));
    assertEquals(exception,ExceptionUtil.unwrapThrowable(new InvocationTargetException(new UndeclaredThrowableException(exception,"test"),"test")));
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from mybatis-3-mybatis-3.4.6~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package io.netty.handler.ssl;
import io.netty.buffer.UnpooledByteBufAllocator;
import org.junit.BeforeClass;
import org.junit.Test;
import javax.net.ssl.KeyManagerFactory;
import java.security.KeyStore;
import static org.junit.Assert.*;
import static org.junit.Assume.assumeTrue;
public class OpenSslKeyMaterialProviderTest {
  static final String PASSWORD="example";
  static final String EXISTING_ALIAS="1";
  private static final String NON_EXISTING_ALIAS="nonexisting";
  @BeforeClass public static void checkOpenSsl(){
    assumeTrue(OpenSsl.isAvailable());
  }
  protected KeyManagerFactory newKeyManagerFactory() throws Exception {
    char[] password=PASSWORD.toCharArray();
    final KeyStore keystore=KeyStore.getInstance("PKCS12");
    keystore.load(getClass().getResourceAsStream("mutual_auth_server.p12"),password);
    KeyManagerFactory kmf=KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());
    kmf.init(keystore,password);
    return kmf;
  }
  protected OpenSslKeyMaterialProvider newMaterialProvider(  KeyManagerFactory factory,  String password){
    return new OpenSslKeyMaterialProvider(ReferenceCountedOpenSslContext.chooseX509KeyManager(factory.getKeyManagers()),password);
  }
  protected void assertRelease(  OpenSslKeyMaterial material){
    assertTrue(material.release());
  }
  @Test public void testChooseKeyMaterial() throws Exception {
    OpenSslKeyMaterialProvider provider=newMaterialProvider(newKeyManagerFactory(),PASSWORD);
    OpenSslKeyMaterial nonExistingMaterial=provider.chooseKeyMaterial(UnpooledByteBufAllocator.DEFAULT,NON_EXISTING_ALIAS);
    assertNull(nonExistingMaterial);
    OpenSslKeyMaterial material=provider.chooseKeyMaterial(UnpooledByteBufAllocator.DEFAULT,EXISTING_ALIAS);
    assertNotNull(material);
    assertNotEquals(0,material.certificateChainAddress());
    assertNotEquals(0,material.privateKeyAddress());
    assertRelease(material);
    provider.destroy();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package io.netty.channel;
import io.netty.bootstrap.Bootstrap;
import io.netty.bootstrap.ServerBootstrap;
import io.netty.channel.embedded.EmbeddedChannel;
import io.netty.channel.local.LocalAddress;
import io.netty.channel.local.LocalChannel;
import io.netty.channel.local.LocalServerChannel;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import java.util.Iterator;
import java.util.Map;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertSame;
public class ChannelInitializerTest {
  private static final int TIMEOUT_MILLIS=1000;
  private static final LocalAddress SERVER_ADDRESS=new LocalAddress("addr");
  private EventLoopGroup group;
  private ServerBootstrap server;
  private Bootstrap client;
  private InspectableHandler testHandler;
  @Before public void setUp(){
    group=new DefaultEventLoopGroup(1);
    server=new ServerBootstrap().group(group).channel(LocalServerChannel.class).localAddress(SERVER_ADDRESS);
    client=new Bootstrap().group(group).channel(LocalChannel.class).handler(new ChannelInboundHandlerAdapter());
    testHandler=new InspectableHandler();
  }
  @After public void tearDown(){
    group.shutdownGracefully(0,TIMEOUT_MILLIS,TimeUnit.MILLISECONDS).syncUninterruptibly();
  }
  @Test public void testInitChannelThrowsRegisterFirst(){
    testInitChannelThrows(true);
  }
  @Test public void testInitChannelThrowsRegisterAfter(){
    testInitChannelThrows(false);
  }
  private void testInitChannelThrows(  boolean registerFirst){
    final Exception exception=new Exception();
    final AtomicReference<Throwable> causeRef=new AtomicReference<Throwable>();
    ChannelPipeline pipeline=new LocalChannel().pipeline();
    if (registerFirst) {
      group.register(pipeline.channel()).syncUninterruptibly();
    }
    pipeline.addFirst(new ChannelInitializer<Channel>(){
      @Override protected void initChannel(      Channel ch) throws Exception {
        throw exception;
      }
      @Override public void exceptionCaught(      ChannelHandlerContext ctx,      Throwable cause) throws Exception {
        causeRef.set(cause);
        super.exceptionCaught(ctx,cause);
      }
    }
);
    if (!registerFirst) {
      group.register(pipeline.channel()).syncUninterruptibly();
    }
    pipeline.channel().close().syncUninterruptibly();
    pipeline.channel().closeFuture().syncUninterruptibly();
    assertSame(exception,causeRef.get());
  }
  @Test public void testChannelInitializerInInitializerCorrectOrdering(){
    final ChannelInboundHandlerAdapter handler1=new ChannelInboundHandlerAdapter();
    final ChannelInboundHandlerAdapter handler2=new ChannelInboundHandlerAdapter();
    final ChannelInboundHandlerAdapter handler3=new ChannelInboundHandlerAdapter();
    final ChannelInboundHandlerAdapter handler4=new ChannelInboundHandlerAdapter();
    client.handler(new ChannelInitializer<Channel>(){
      @Override protected void initChannel(      Channel ch) throws Exception {
        ch.pipeline().addLast(handler1);
        ch.pipeline().addLast(new ChannelInitializer<Channel>(){
          @Override protected void initChannel(          Channel ch) throws Exception {
            ch.pipeline().addLast(handler2);
            ch.pipeline().addLast(handler3);
          }
        }
);
        ch.pipeline().addLast(handler4);
      }
    }
).localAddress(LocalAddress.ANY);
    Channel channel=client.bind().syncUninterruptibly().channel();
    try {
      channel.eventLoop().submit(new Runnable(){
        @Override public void run(){
        }
      }
).syncUninterruptibly();
      Iterator<Map.Entry<String,ChannelHandler>> handlers=channel.pipeline().iterator();
      assertSame(handler1,handlers.next().getValue());
      assertSame(handler2,handlers.next().getValue());
      assertSame(handler3,handlers.next().getValue());
      assertSame(handler4,handlers.next().getValue());
      assertFalse(handlers.hasNext());
    }
  finally {
      channel.close().syncUninterruptibly();
    }
  }
  @Test public void testChannelInitializerReentrance(){
    final AtomicInteger registeredCalled=new AtomicInteger(0);
    final ChannelInboundHandlerAdapter handler1=new ChannelInboundHandlerAdapter(){
      @Override public void channelRegistered(      ChannelHandlerContext ctx) throws Exception {
        registeredCalled.incrementAndGet();
      }
    }
;
    final AtomicInteger initChannelCalled=new AtomicInteger(0);
    client.handler(new ChannelInitializer<Channel>(){
      @Override protected void initChannel(      Channel ch) throws Exception {
        initChannelCalled.incrementAndGet();
        ch.pipeline().addLast(handler1);
        ch.pipeline().fireChannelRegistered();
      }
    }
).localAddress(LocalAddress.ANY);
    Channel channel=client.bind().syncUninterruptibly().channel();
    try {
      channel.eventLoop().submit(new Runnable(){
        @Override public void run(){
        }
      }
).syncUninterruptibly();
      assertEquals(1,initChannelCalled.get());
      assertEquals(2,registeredCalled.get());
    }
  finally {
      channel.close().syncUninterruptibly();
    }
  }
  @Test(timeout=TIMEOUT_MILLIS) public void firstHandlerInPipelineShouldReceiveChannelRegisteredEvent(){
    testChannelRegisteredEventPropagation(new ChannelInitializer<LocalChannel>(){
      @Override public void initChannel(      LocalChannel channel){
        channel.pipeline().addFirst(testHandler);
      }
    }
);
  }
  @Test(timeout=TIMEOUT_MILLIS) public void lastHandlerInPipelineShouldReceiveChannelRegisteredEvent(){
    testChannelRegisteredEventPropagation(new ChannelInitializer<LocalChannel>(){
      @Override public void initChannel(      LocalChannel channel){
        channel.pipeline().addLast(testHandler);
      }
    }
);
  }
  @Test public void testAddFirstChannelInitializer(){
    testAddChannelInitializer(true);
  }
  @Test public void testAddLastChannelInitializer(){
    testAddChannelInitializer(false);
  }
  private static void testAddChannelInitializer(  final boolean first){
    final AtomicBoolean called=new AtomicBoolean();
    EmbeddedChannel channel=new EmbeddedChannel(new ChannelInitializer<Channel>(){
      @Override protected void initChannel(      Channel ch) throws Exception {
        ChannelHandler handler=new ChannelInitializer<Channel>(){
          @Override protected void initChannel(          Channel ch) throws Exception {
            called.set(true);
          }
        }
;
        if (first) {
          ch.pipeline().addFirst(handler);
        }
 else {
          ch.pipeline().addLast(handler);
        }
      }
    }
);
    channel.finish();
    assertTrue(called.get());
  }
  private void testChannelRegisteredEventPropagation(  ChannelInitializer<LocalChannel> init){
    Channel clientChannel=null, serverChannel=null;
    try {
      server.childHandler(init);
      serverChannel=server.bind().syncUninterruptibly().channel();
      clientChannel=client.connect(SERVER_ADDRESS).syncUninterruptibly().channel();
      assertEquals(1,testHandler.channelRegisteredCount.get());
    }
  finally {
      closeChannel(clientChannel);
      closeChannel(serverChannel);
    }
  }
  private static void closeChannel(  Channel c){
    if (c != null) {
      c.close().syncUninterruptibly();
    }
  }
private static final class InspectableHandler extends ChannelDuplexHandler {
    final AtomicInteger channelRegisteredCount=new AtomicInteger(0);
    @Override public void channelRegistered(    ChannelHandlerContext ctx){
      channelRegisteredCount.incrementAndGet();
      ctx.fireChannelRegistered();
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package io.netty.handler.codec.compression;
import io.netty.buffer.ByteBuf;
import io.netty.buffer.ByteBufInputStream;
import io.netty.buffer.Unpooled;
import io.netty.channel.embedded.EmbeddedChannel;
import io.netty.util.CharsetUtil;
import io.netty.util.ReferenceCountUtil;
import io.netty.util.internal.EmptyArrays;
import io.netty.util.internal.PlatformDependent;
import org.junit.Test;
import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.io.OutputStream;
import java.util.Random;
import java.util.zip.DeflaterOutputStream;
import java.util.zip.GZIPInputStream;
import java.util.zip.GZIPOutputStream;
import static org.junit.Assert.*;
public abstract class ZlibTest {
  private static final byte[] BYTES_SMALL=new byte[128];
  private static final byte[] BYTES_LARGE=new byte[1024 * 1024];
  private static final byte[] BYTES_LARGE2=("<!--?xml version=\"1.0\" encoding=\"ISO-8859-1\"?-->\n" + "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" " + "\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n"+ "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\"><head>\n"+ "    <title>Apache Tomcat</title>\n"+ "</head>\n" + '\n' + "<body>\n"+ "<h1>It works !</h1>\n"+ '\n'+ "<p>If you're seeing this page via a web browser, it means you've setup Tomcat successfully."+ " Congratulations!</p>\n"+ " \n"+ "<p>This is the default Tomcat home page."+ " It can be found on the local filesystem at: <code>/var/lib/tomcat7/webapps/ROOT/index.html</code></p>\n"+ '\n'+ "<p>Tomcat7 veterans might be pleased to learn that this system instance of Tomcat is installed with"+ " <code>CATALINA_HOME</code> in <code>/usr/share/tomcat7</code> and <code>CATALINA_BASE</code> in"+ " <code>/var/lib/tomcat7</code>, following the rules from"+ " <code>/usr/share/doc/tomcat7-common/RUNNING.txt.gz</code>.</p>\n"+ '\n'+ "<p>You might consider installing the following packages, if you haven't already done so:</p>\n"+ '\n'+ "<p><b>tomcat7-docs</b>: This package installs a web application that allows to browse the Tomcat 7"+ " documentation locally. Once installed, you can access it by clicking <a href=\"docs/\">here</a>.</p>\n"+ '\n'+ "<p><b>tomcat7-examples</b>: This package installs a web application that allows to access the Tomcat"+ " 7 Servlet and JSP examples. Once installed, you can access it by clicking"+ " <a href=\"examples/\">here</a>.</p>\n"+ '\n'+ "<p><b>tomcat7-admin</b>: This package installs two web applications that can help managing this Tomcat"+ " instance. Once installed, you can access the <a href=\"manager/html\">manager webapp</a> and"+ " the <a href=\"host-manager/html\">host-manager webapp</a>.</p><p>\n"+ '\n'+ "</p><p>NOTE: For security reasons, using the manager webapp is restricted"+ " to users with role \"manager\"."+ " The host-manager webapp is restricted to users with role \"admin\". Users are "+ "defined in <code>/etc/tomcat7/tomcat-users.xml</code>.</p>\n"+ '\n'+ '\n'+ '\n'+ "</body></html>").getBytes(CharsetUtil.UTF_8);
static {
    Random rand=PlatformDependent.threadLocalRandom();
    rand.nextBytes(BYTES_SMALL);
    rand.nextBytes(BYTES_LARGE);
  }
  protected abstract ZlibEncoder createEncoder(  ZlibWrapper wrapper);
  protected abstract ZlibDecoder createDecoder(  ZlibWrapper wrapper);
  @Test public void testGZIP2() throws Exception {
    byte[] bytes="message".getBytes(CharsetUtil.UTF_8);
    ByteBuf data=Unpooled.wrappedBuffer(bytes);
    ByteBuf deflatedData=Unpooled.wrappedBuffer(gzip(bytes));
    EmbeddedChannel chDecoderGZip=new EmbeddedChannel(createDecoder(ZlibWrapper.GZIP));
    try {
      chDecoderGZip.writeInbound(deflatedData);
      assertTrue(chDecoderGZip.finish());
      ByteBuf buf=chDecoderGZip.readInbound();
      assertEquals(buf,data);
      assertNull(chDecoderGZip.readInbound());
      data.release();
      buf.release();
    }
  finally {
      dispose(chDecoderGZip);
    }
  }
  private void testCompress0(  ZlibWrapper encoderWrapper,  ZlibWrapper decoderWrapper,  ByteBuf data) throws Exception {
    EmbeddedChannel chEncoder=new EmbeddedChannel(createEncoder(encoderWrapper));
    EmbeddedChannel chDecoderZlib=new EmbeddedChannel(createDecoder(decoderWrapper));
    try {
      chEncoder.writeOutbound(data.retain());
      chEncoder.flush();
      data.resetReaderIndex();
      for (; ; ) {
        ByteBuf deflatedData=chEncoder.readOutbound();
        if (deflatedData == null) {
          break;
        }
        chDecoderZlib.writeInbound(deflatedData);
      }
      byte[] decompressed=new byte[data.readableBytes()];
      int offset=0;
      for (; ; ) {
        ByteBuf buf=chDecoderZlib.readInbound();
        if (buf == null) {
          break;
        }
        int length=buf.readableBytes();
        buf.readBytes(decompressed,offset,length);
        offset+=length;
        buf.release();
        if (offset == decompressed.length) {
          break;
        }
      }
      assertEquals(data,Unpooled.wrappedBuffer(decompressed));
      assertNull(chDecoderZlib.readInbound());
      assertTrue(chEncoder.finish());
      for (; ; ) {
        Object msg=chEncoder.readOutbound();
        if (msg == null) {
          break;
        }
        ReferenceCountUtil.release(msg);
      }
      assertFalse(chDecoderZlib.finish());
      data.release();
    }
  finally {
      dispose(chEncoder);
      dispose(chDecoderZlib);
    }
  }
  private void testCompressNone(  ZlibWrapper encoderWrapper,  ZlibWrapper decoderWrapper) throws Exception {
    EmbeddedChannel chEncoder=new EmbeddedChannel(createEncoder(encoderWrapper));
    EmbeddedChannel chDecoderZlib=new EmbeddedChannel(createDecoder(decoderWrapper));
    try {
      assertTrue(chEncoder.finish());
      for (; ; ) {
        ByteBuf deflatedData=chEncoder.readOutbound();
        if (deflatedData == null) {
          break;
        }
        chDecoderZlib.writeInbound(deflatedData);
      }
      boolean decoded=false;
      for (; ; ) {
        ByteBuf buf=chDecoderZlib.readInbound();
        if (buf == null) {
          break;
        }
        buf.release();
        decoded=true;
      }
      assertFalse("should decode nothing",decoded);
      assertFalse(chDecoderZlib.finish());
    }
  finally {
      dispose(chEncoder);
      dispose(chDecoderZlib);
    }
  }
  private static void dispose(  EmbeddedChannel ch){
    if (ch.finish()) {
      for (; ; ) {
        Object msg=ch.readInbound();
        if (msg == null) {
          break;
        }
        ReferenceCountUtil.release(msg);
      }
      for (; ; ) {
        Object msg=ch.readOutbound();
        if (msg == null) {
          break;
        }
        ReferenceCountUtil.release(msg);
      }
    }
  }
  private void testDecompressOnly(  ZlibWrapper decoderWrapper,  byte[] compressed,  byte[] data) throws Exception {
    EmbeddedChannel chDecoder=new EmbeddedChannel(createDecoder(decoderWrapper));
    chDecoder.writeInbound(Unpooled.wrappedBuffer(compressed));
    assertTrue(chDecoder.finish());
    ByteBuf decoded=Unpooled.buffer(data.length);
    for (; ; ) {
      ByteBuf buf=chDecoder.readInbound();
      if (buf == null) {
        break;
      }
      decoded.writeBytes(buf);
      buf.release();
    }
    assertEquals(Unpooled.wrappedBuffer(data),decoded);
    decoded.release();
  }
  private void testCompressSmall(  ZlibWrapper encoderWrapper,  ZlibWrapper decoderWrapper) throws Exception {
    testCompress0(encoderWrapper,decoderWrapper,Unpooled.wrappedBuffer(BYTES_SMALL));
    testCompress0(encoderWrapper,decoderWrapper,Unpooled.directBuffer(BYTES_SMALL.length).writeBytes(BYTES_SMALL));
  }
  private void testCompressLarge(  ZlibWrapper encoderWrapper,  ZlibWrapper decoderWrapper) throws Exception {
    testCompress0(encoderWrapper,decoderWrapper,Unpooled.wrappedBuffer(BYTES_LARGE));
    testCompress0(encoderWrapper,decoderWrapper,Unpooled.directBuffer(BYTES_LARGE.length).writeBytes(BYTES_LARGE));
  }
  @Test public void testZLIB() throws Exception {
    testCompressNone(ZlibWrapper.ZLIB,ZlibWrapper.ZLIB);
    testCompressSmall(ZlibWrapper.ZLIB,ZlibWrapper.ZLIB);
    testCompressLarge(ZlibWrapper.ZLIB,ZlibWrapper.ZLIB);
    testDecompressOnly(ZlibWrapper.ZLIB,deflate(BYTES_LARGE2),BYTES_LARGE2);
  }
  @Test public void testNONE() throws Exception {
    testCompressNone(ZlibWrapper.NONE,ZlibWrapper.NONE);
    testCompressSmall(ZlibWrapper.NONE,ZlibWrapper.NONE);
    testCompressLarge(ZlibWrapper.NONE,ZlibWrapper.NONE);
  }
  @Test public void testGZIP() throws Exception {
    testCompressNone(ZlibWrapper.GZIP,ZlibWrapper.GZIP);
    testCompressSmall(ZlibWrapper.GZIP,ZlibWrapper.GZIP);
    testCompressLarge(ZlibWrapper.GZIP,ZlibWrapper.GZIP);
    testDecompressOnly(ZlibWrapper.GZIP,gzip(BYTES_LARGE2),BYTES_LARGE2);
  }
  @Test public void testGZIPCompressOnly() throws Exception {
    testGZIPCompressOnly0(null);
    testGZIPCompressOnly0(EmptyArrays.EMPTY_BYTES);
    testGZIPCompressOnly0(BYTES_SMALL);
    testGZIPCompressOnly0(BYTES_LARGE);
  }
  private void testGZIPCompressOnly0(  byte[] data) throws IOException {
    EmbeddedChannel chEncoder=new EmbeddedChannel(createEncoder(ZlibWrapper.GZIP));
    if (data != null) {
      chEncoder.writeOutbound(Unpooled.wrappedBuffer(data));
    }
    assertTrue(chEncoder.finish());
    ByteBuf encoded=Unpooled.buffer();
    for (; ; ) {
      ByteBuf buf=chEncoder.readOutbound();
      if (buf == null) {
        break;
      }
      encoded.writeBytes(buf);
      buf.release();
    }
    ByteBuf decoded=Unpooled.buffer();
    GZIPInputStream stream=new GZIPInputStream(new ByteBufInputStream(encoded,true));
    try {
      byte[] buf=new byte[8192];
      for (; ; ) {
        int readBytes=stream.read(buf);
        if (readBytes < 0) {
          break;
        }
        decoded.writeBytes(buf,0,readBytes);
      }
    }
  finally {
      stream.close();
    }
    if (data != null) {
      assertEquals(Unpooled.wrappedBuffer(data),decoded);
    }
 else {
      assertFalse(decoded.isReadable());
    }
    decoded.release();
  }
  @Test public void testZLIB_OR_NONE() throws Exception {
    testCompressNone(ZlibWrapper.NONE,ZlibWrapper.ZLIB_OR_NONE);
    testCompressSmall(ZlibWrapper.NONE,ZlibWrapper.ZLIB_OR_NONE);
    testCompressLarge(ZlibWrapper.NONE,ZlibWrapper.ZLIB_OR_NONE);
  }
  @Test public void testZLIB_OR_NONE2() throws Exception {
    testCompressNone(ZlibWrapper.ZLIB,ZlibWrapper.ZLIB_OR_NONE);
    testCompressSmall(ZlibWrapper.ZLIB,ZlibWrapper.ZLIB_OR_NONE);
    testCompressLarge(ZlibWrapper.ZLIB,ZlibWrapper.ZLIB_OR_NONE);
  }
  @Test public void testZLIB_OR_NONE3() throws Exception {
    testCompressNone(ZlibWrapper.GZIP,ZlibWrapper.ZLIB_OR_NONE);
    testCompressSmall(ZlibWrapper.GZIP,ZlibWrapper.ZLIB_OR_NONE);
    testCompressLarge(ZlibWrapper.GZIP,ZlibWrapper.ZLIB_OR_NONE);
  }
  private static byte[] gzip(  byte[] bytes) throws IOException {
    ByteArrayOutputStream out=new ByteArrayOutputStream();
    GZIPOutputStream stream=new GZIPOutputStream(out);
    stream.write(bytes);
    stream.close();
    return out.toByteArray();
  }
  private static byte[] deflate(  byte[] bytes) throws IOException {
    ByteArrayOutputStream out=new ByteArrayOutputStream();
    OutputStream stream=new DeflaterOutputStream(out);
    stream.write(bytes);
    stream.close();
    return out.toByteArray();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package io.netty.util.internal;
import org.junit.Test;
import java.util.Arrays;
import static io.netty.util.internal.StringUtil.NEWLINE;
import static io.netty.util.internal.StringUtil.commonSuffixOfLength;
import static io.netty.util.internal.StringUtil.simpleClassName;
import static io.netty.util.internal.StringUtil.substringAfter;
import static io.netty.util.internal.StringUtil.toHexString;
import static io.netty.util.internal.StringUtil.toHexStringPadded;
import static io.netty.util.internal.StringUtil.unescapeCsv;
import static io.netty.util.internal.StringUtil.unescapeCsvFields;
import static org.hamcrest.CoreMatchers.is;
import static org.junit.Assert.assertArrayEquals;
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;
import static org.junit.Assert.assertSame;
import static org.junit.Assert.assertThat;
import static org.junit.Assert.assertTrue;
public class StringUtilTest {
  @Test public void ensureNewlineExists(){
    assertNotNull(NEWLINE);
  }
  @Test public void testToHexString(){
    assertThat(toHexString(new byte[]{0}),is("0"));
    assertThat(toHexString(new byte[]{1}),is("1"));
    assertThat(toHexString(new byte[]{0,0}),is("0"));
    assertThat(toHexString(new byte[]{1,0}),is("100"));
    assertThat(toHexString(EmptyArrays.EMPTY_BYTES),is(""));
  }
  @Test public void testToHexStringPadded(){
    assertThat(toHexStringPadded(new byte[]{0}),is("00"));
    assertThat(toHexStringPadded(new byte[]{1}),is("01"));
    assertThat(toHexStringPadded(new byte[]{0,0}),is("0000"));
    assertThat(toHexStringPadded(new byte[]{1,0}),is("0100"));
    assertThat(toHexStringPadded(EmptyArrays.EMPTY_BYTES),is(""));
  }
  @Test public void splitSimple(){
    assertArrayEquals(new String[]{"foo","bar"},"foo:bar".split(":"));
  }
  @Test public void splitWithTrailingDelimiter(){
    assertArrayEquals(new String[]{"foo","bar"},"foo,bar,".split(","));
  }
  @Test public void splitWithTrailingDelimiters(){
    assertArrayEquals(new String[]{"foo","bar"},"foo!bar!!".split("!"));
  }
  @Test public void splitWithTrailingDelimitersDot(){
    assertArrayEquals(new String[]{"foo","bar"},"foo.bar..".split("\\."));
  }
  @Test public void splitWithTrailingDelimitersEq(){
    assertArrayEquals(new String[]{"foo","bar"},"foo=bar==".split("="));
  }
  @Test public void splitWithTrailingDelimitersSpace(){
    assertArrayEquals(new String[]{"foo","bar"},"foo bar  ".split(" "));
  }
  @Test public void splitWithConsecutiveDelimiters(){
    assertArrayEquals(new String[]{"foo","","bar"},"foo$$bar".split("\\$"));
  }
  @Test public void splitWithDelimiterAtBeginning(){
    assertArrayEquals(new String[]{"","foo","bar"},"#foo#bar".split("#"));
  }
  @Test public void splitMaxPart(){
    assertArrayEquals(new String[]{"foo","bar:bar2"},"foo:bar:bar2".split(":",2));
    assertArrayEquals(new String[]{"foo","bar","bar2"},"foo:bar:bar2".split(":",3));
  }
  @Test public void substringAfterTest(){
    assertEquals("bar:bar2",substringAfter("foo:bar:bar2",':'));
  }
  @Test public void commonSuffixOfLengthTest(){
    checkNotCommonSuffix("abc","abc",-1);
    checkNotCommonSuffix("abc",null,0);
    checkNotCommonSuffix(null,null,0);
    checkCommonSuffix("abc","xx",0);
    checkCommonSuffix("abc","abc",0);
    checkCommonSuffix("abc","abc",1);
    checkCommonSuffix("abc","abc",2);
    checkCommonSuffix("abc","abc",3);
    checkNotCommonSuffix("abc","abc",4);
    checkCommonSuffix("abcd","cd",1);
    checkCommonSuffix("abcd","cd",2);
    checkNotCommonSuffix("abcd","cd",3);
    checkCommonSuffix("abcd","axcd",1);
    checkCommonSuffix("abcd","axcd",2);
    checkNotCommonSuffix("abcd","axcd",3);
    checkNotCommonSuffix("abcx","abcy",1);
  }
  private static void checkNotCommonSuffix(  String s,  String p,  int len){
    assertFalse(checkCommonSuffixSymmetric(s,p,len));
  }
  private static void checkCommonSuffix(  String s,  String p,  int len){
    assertTrue(checkCommonSuffixSymmetric(s,p,len));
  }
  private static boolean checkCommonSuffixSymmetric(  String s,  String p,  int len){
    boolean sp=commonSuffixOfLength(s,p,len);
    boolean ps=commonSuffixOfLength(p,s,len);
    assertEquals(sp,ps);
    return sp;
  }
  @Test(expected=NullPointerException.class) public void escapeCsvNull(){
    StringUtil.escapeCsv(null);
  }
  @Test public void escapeCsvEmpty(){
    CharSequence value="";
    CharSequence expected=value;
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvUnquoted(){
    CharSequence value="something";
    CharSequence expected=value;
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvAlreadyQuoted(){
    CharSequence value="\"something\"";
    CharSequence expected="\"something\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithQuote(){
    CharSequence value="s\"";
    CharSequence expected="\"s\"\"\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithQuoteInMiddle(){
    CharSequence value="some text\"and more text";
    CharSequence expected="\"some text\"\"and more text\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithQuoteInMiddleAlreadyQuoted(){
    CharSequence value="\"some text\"and more text\"";
    CharSequence expected="\"some text\"\"and more text\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithQuotedWords(){
    CharSequence value="\"foo\"\"goo\"";
    CharSequence expected="\"foo\"\"goo\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithAlreadyEscapedQuote(){
    CharSequence value="foo\"\"goo";
    CharSequence expected="foo\"\"goo";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvEndingWithQuote(){
    CharSequence value="some\"";
    CharSequence expected="\"some\"\"\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithSingleQuote(){
    CharSequence value="\"";
    CharSequence expected="\"\"\"\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithSingleQuoteAndCharacter(){
    CharSequence value="\"f";
    CharSequence expected="\"\"\"f\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvAlreadyEscapedQuote(){
    CharSequence value="\"some\"\"";
    CharSequence expected="\"some\"\"\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvQuoted(){
    CharSequence value="\"foo,goo\"";
    CharSequence expected=value;
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithLineFeed(){
    CharSequence value="some text\n more text";
    CharSequence expected="\"some text\n more text\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithSingleLineFeedCharacter(){
    CharSequence value="\n";
    CharSequence expected="\"\n\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithMultipleLineFeedCharacter(){
    CharSequence value="\n\n";
    CharSequence expected="\"\n\n\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithQuotedAndLineFeedCharacter(){
    CharSequence value=" \" \n ";
    CharSequence expected="\" \"\" \n \"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithLineFeedAtEnd(){
    CharSequence value="testing\n";
    CharSequence expected="\"testing\n\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithComma(){
    CharSequence value="test,ing";
    CharSequence expected="\"test,ing\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithSingleComma(){
    CharSequence value=",";
    CharSequence expected="\",\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithSingleCarriageReturn(){
    CharSequence value="\r";
    CharSequence expected="\"\r\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithMultipleCarriageReturn(){
    CharSequence value="\r\r";
    CharSequence expected="\"\r\r\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithCarriageReturn(){
    CharSequence value="some text\r more text";
    CharSequence expected="\"some text\r more text\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithQuotedAndCarriageReturnCharacter(){
    CharSequence value="\"\r";
    CharSequence expected="\"\"\"\r\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithCarriageReturnAtEnd(){
    CharSequence value="testing\r";
    CharSequence expected="\"testing\r\"";
    escapeCsv(value,expected);
  }
  @Test public void escapeCsvWithCRLFCharacter(){
    CharSequence value="\r\n";
    CharSequence expected="\"\r\n\"";
    escapeCsv(value,expected);
  }
  private static void escapeCsv(  CharSequence value,  CharSequence expected){
    escapeCsv(value,expected,false);
  }
  private static void escapeCsvWithTrimming(  CharSequence value,  CharSequence expected){
    escapeCsv(value,expected,true);
  }
  private static void escapeCsv(  CharSequence value,  CharSequence expected,  boolean trimOws){
    CharSequence escapedValue=value;
    for (int i=0; i < 10; ++i) {
      escapedValue=StringUtil.escapeCsv(escapedValue,trimOws);
      assertEquals(expected,escapedValue.toString());
    }
  }
  @Test public void escapeCsvWithTrimming(){
    assertSame("",StringUtil.escapeCsv("",true));
    assertSame("ab",StringUtil.escapeCsv("ab",true));
    escapeCsvWithTrimming("","");
    escapeCsvWithTrimming(" \t ","");
    escapeCsvWithTrimming("ab","ab");
    escapeCsvWithTrimming("a b","a b");
    escapeCsvWithTrimming(" \ta \tb","a \tb");
    escapeCsvWithTrimming("a \tb \t","a \tb");
    escapeCsvWithTrimming("\t a \tb \t","a \tb");
    escapeCsvWithTrimming("\"\t a b \"","\"\t a b \"");
    escapeCsvWithTrimming(" \"\t a b \"\t","\"\t a b \"");
    escapeCsvWithTrimming(" testing\t\n ","\"testing\t\n\"");
    escapeCsvWithTrimming("\ttest,ing ","\"test,ing\"");
  }
  @Test public void escapeCsvGarbageFree(){
    assertSame("1",StringUtil.escapeCsv("1",true));
    assertSame(" 123 ",StringUtil.escapeCsv(" 123 ",false));
    assertSame("\" 123 \"",StringUtil.escapeCsv("\" 123 \"",true));
    assertSame("\"\"",StringUtil.escapeCsv("\"\"",true));
    assertSame("123 \"\"",StringUtil.escapeCsv("123 \"\"",true));
    assertSame("123\"\"321",StringUtil.escapeCsv("123\"\"321",true));
    assertSame("\"123\"\"321\"",StringUtil.escapeCsv("\"123\"\"321\"",true));
  }
  @Test public void testUnescapeCsv(){
    assertEquals("",unescapeCsv(""));
    assertEquals("\"",unescapeCsv("\"\"\"\""));
    assertEquals("\"\"",unescapeCsv("\"\"\"\"\"\""));
    assertEquals("\"\"\"",unescapeCsv("\"\"\"\"\"\"\"\""));
    assertEquals("\"netty\"",unescapeCsv("\"\"\"netty\"\"\""));
    assertEquals("netty",unescapeCsv("netty"));
    assertEquals("netty",unescapeCsv("\"netty\""));
    assertEquals("\r",unescapeCsv("\"\r\""));
    assertEquals("\n",unescapeCsv("\"\n\""));
    assertEquals("hello,netty",unescapeCsv("\"hello,netty\""));
  }
  @Test(expected=IllegalArgumentException.class) public void unescapeCsvWithSingleQuote(){
    unescapeCsv("\"");
  }
  @Test(expected=IllegalArgumentException.class) public void unescapeCsvWithOddQuote(){
    unescapeCsv("\"\"\"");
  }
  @Test(expected=IllegalArgumentException.class) public void unescapeCsvWithCRAndWithoutQuote(){
    unescapeCsv("\r");
  }
  @Test(expected=IllegalArgumentException.class) public void unescapeCsvWithLFAndWithoutQuote(){
    unescapeCsv("\n");
  }
  @Test(expected=IllegalArgumentException.class) public void unescapeCsvWithCommaAndWithoutQuote(){
    unescapeCsv(",");
  }
  @Test public void escapeCsvAndUnEscapeCsv(){
    assertEscapeCsvAndUnEscapeCsv("");
    assertEscapeCsvAndUnEscapeCsv("netty");
    assertEscapeCsvAndUnEscapeCsv("hello,netty");
    assertEscapeCsvAndUnEscapeCsv("hello,\"netty\"");
    assertEscapeCsvAndUnEscapeCsv("\"");
    assertEscapeCsvAndUnEscapeCsv(",");
    assertEscapeCsvAndUnEscapeCsv("\r");
    assertEscapeCsvAndUnEscapeCsv("\n");
  }
  private static void assertEscapeCsvAndUnEscapeCsv(  String value){
    assertEquals(value,unescapeCsv(StringUtil.escapeCsv(value)));
  }
  @Test public void testUnescapeCsvFields(){
    assertEquals(Arrays.asList(""),unescapeCsvFields(""));
    assertEquals(Arrays.asList("",""),unescapeCsvFields(","));
    assertEquals(Arrays.asList("a",""),unescapeCsvFields("a,"));
    assertEquals(Arrays.asList("","a"),unescapeCsvFields(",a"));
    assertEquals(Arrays.asList("\""),unescapeCsvFields("\"\"\"\""));
    assertEquals(Arrays.asList("\"","\""),unescapeCsvFields("\"\"\"\",\"\"\"\""));
    assertEquals(Arrays.asList("netty"),unescapeCsvFields("netty"));
    assertEquals(Arrays.asList("hello","netty"),unescapeCsvFields("hello,netty"));
    assertEquals(Arrays.asList("hello,netty"),unescapeCsvFields("\"hello,netty\""));
    assertEquals(Arrays.asList("hello","netty"),unescapeCsvFields("\"hello\",\"netty\""));
    assertEquals(Arrays.asList("a\"b","c\"d"),unescapeCsvFields("\"a\"\"b\",\"c\"\"d\""));
    assertEquals(Arrays.asList("a\rb","c\nd"),unescapeCsvFields("\"a\rb\",\"c\nd\""));
  }
  @Test(expected=IllegalArgumentException.class) public void unescapeCsvFieldsWithCRWithoutQuote(){
    unescapeCsvFields("a,\r");
  }
  @Test(expected=IllegalArgumentException.class) public void unescapeCsvFieldsWithLFWithoutQuote(){
    unescapeCsvFields("a,\r");
  }
  @Test(expected=IllegalArgumentException.class) public void unescapeCsvFieldsWithQuote(){
    unescapeCsvFields("a,\"");
  }
  @Test(expected=IllegalArgumentException.class) public void unescapeCsvFieldsWithQuote2(){
    unescapeCsvFields("\",a");
  }
  @Test(expected=IllegalArgumentException.class) public void unescapeCsvFieldsWithQuote3(){
    unescapeCsvFields("a\"b,a");
  }
  @Test public void testSimpleClassName() throws Exception {
    testSimpleClassName(String.class);
  }
  @Test public void testSimpleInnerClassName() throws Exception {
    testSimpleClassName(TestClass.class);
  }
  private static void testSimpleClassName(  Class<?> clazz) throws Exception {
    Package pkg=clazz.getPackage();
    String name;
    if (pkg != null) {
      name=clazz.getName().substring(pkg.getName().length() + 1);
    }
 else {
      name=clazz.getName();
    }
    assertEquals(name,simpleClassName(clazz));
  }
private static final class TestClass {
  }
  @Test public void testEndsWith(){
    assertFalse(StringUtil.endsWith("",'u'));
    assertTrue(StringUtil.endsWith("u",'u'));
    assertTrue(StringUtil.endsWith("-u",'u'));
    assertFalse(StringUtil.endsWith("-",'u'));
    assertFalse(StringUtil.endsWith("u-",'u'));
  }
  @Test public void trimOws(){
    assertSame("",StringUtil.trimOws(""));
    assertEquals("",StringUtil.trimOws(" \t "));
    assertSame("a",StringUtil.trimOws("a"));
    assertEquals("a",StringUtil.trimOws(" a"));
    assertEquals("a",StringUtil.trimOws("a "));
    assertEquals("a",StringUtil.trimOws(" a "));
    assertSame("abc",StringUtil.trimOws("abc"));
    assertEquals("abc",StringUtil.trimOws("\tabc"));
    assertEquals("abc",StringUtil.trimOws("abc\t"));
    assertEquals("abc",StringUtil.trimOws("\tabc\t"));
    assertSame("a\t b",StringUtil.trimOws("a\t b"));
    assertEquals("",StringUtil.trimOws("\t ").toString());
    assertEquals("a b",StringUtil.trimOws("\ta b \t").toString());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package io.netty.handler.codec.http2;
import io.netty.buffer.ByteBuf;
import io.netty.buffer.Unpooled;
import io.netty.channel.Channel;
import io.netty.channel.ChannelHandlerContext;
import io.netty.channel.ChannelInboundHandlerAdapter;
import io.netty.channel.ChannelInitializer;
import io.netty.channel.embedded.EmbeddedChannel;
import io.netty.handler.codec.http.DefaultHttpHeaders;
import io.netty.handler.codec.http.HttpMethod;
import io.netty.handler.codec.http.HttpRequest;
import io.netty.handler.codec.http.HttpServerCodec;
import io.netty.handler.codec.http.HttpServerUpgradeHandler;
import io.netty.handler.codec.http.HttpServerUpgradeHandler.UpgradeCodec;
import io.netty.handler.codec.http.HttpServerUpgradeHandler.UpgradeCodecFactory;
import io.netty.handler.codec.http.HttpServerUpgradeHandler.UpgradeEvent;
import io.netty.handler.codec.http.HttpVersion;
import io.netty.handler.codec.http.LastHttpContent;
import io.netty.handler.codec.http2.CleartextHttp2ServerUpgradeHandler.PriorKnowledgeUpgradeEvent;
import io.netty.handler.codec.http2.Http2Stream.State;
import io.netty.util.CharsetUtil;
import io.netty.util.ReferenceCountUtil;
import org.junit.After;
import org.junit.Test;
import java.util.ArrayList;
import java.util.List;
import static org.junit.Assert.*;
import static org.mockito.Mockito.*;
/** 
 * Tests for  {@link CleartextHttp2ServerUpgradeHandler}
 */
public class CleartextHttp2ServerUpgradeHandlerTest {
  private EmbeddedChannel channel;
  private Http2FrameListener frameListener;
  private Http2ConnectionHandler http2ConnectionHandler;
  private List<Object> userEvents;
  private void setUpServerChannel(){
    frameListener=mock(Http2FrameListener.class);
    http2ConnectionHandler=new Http2ConnectionHandlerBuilder().frameListener(frameListener).build();
    UpgradeCodecFactory upgradeCodecFactory=new UpgradeCodecFactory(){
      @Override public UpgradeCodec newUpgradeCodec(      CharSequence protocol){
        return new Http2ServerUpgradeCodec(http2ConnectionHandler);
      }
    }
;
    userEvents=new ArrayList<Object>();
    HttpServerCodec httpServerCodec=new HttpServerCodec();
    HttpServerUpgradeHandler upgradeHandler=new HttpServerUpgradeHandler(httpServerCodec,upgradeCodecFactory);
    CleartextHttp2ServerUpgradeHandler handler=new CleartextHttp2ServerUpgradeHandler(httpServerCodec,upgradeHandler,http2ConnectionHandler);
    channel=new EmbeddedChannel(handler,new ChannelInboundHandlerAdapter(){
      @Override public void userEventTriggered(      ChannelHandlerContext ctx,      Object evt) throws Exception {
        userEvents.add(evt);
      }
    }
);
  }
  @After public void tearDown() throws Exception {
    channel.finishAndReleaseAll();
  }
  @Test public void priorKnowledge() throws Exception {
    setUpServerChannel();
    channel.writeInbound(Http2CodecUtil.connectionPrefaceBuf());
    ByteBuf settingsFrame=settingsFrameBuf();
    assertFalse(channel.writeInbound(settingsFrame));
    assertEquals(1,userEvents.size());
    assertTrue(userEvents.get(0) instanceof PriorKnowledgeUpgradeEvent);
    assertEquals(100,http2ConnectionHandler.connection().local().maxActiveStreams());
    assertEquals(65535,http2ConnectionHandler.connection().local().flowController().initialWindowSize());
    verify(frameListener).onSettingsRead(any(ChannelHandlerContext.class),eq(expectedSettings()));
  }
  @Test public void upgrade() throws Exception {
    setUpServerChannel();
    String upgradeString="GET / HTTP/1.1\r\n" + "Host: example.com\r\n" + "Connection: Upgrade, HTTP2-Settings\r\n"+ "Upgrade: h2c\r\n"+ "HTTP2-Settings: AAMAAABkAAQAAP__\r\n\r\n";
    ByteBuf upgrade=Unpooled.copiedBuffer(upgradeString,CharsetUtil.US_ASCII);
    assertFalse(channel.writeInbound(upgrade));
    assertEquals(1,userEvents.size());
    Object userEvent=userEvents.get(0);
    assertTrue(userEvent instanceof UpgradeEvent);
    assertEquals("h2c",((UpgradeEvent)userEvent).protocol());
    ReferenceCountUtil.release(userEvent);
    assertEquals(100,http2ConnectionHandler.connection().local().maxActiveStreams());
    assertEquals(65535,http2ConnectionHandler.connection().local().flowController().initialWindowSize());
    assertEquals(1,http2ConnectionHandler.connection().numActiveStreams());
    assertNotNull(http2ConnectionHandler.connection().stream(1));
    Http2Stream stream=http2ConnectionHandler.connection().stream(1);
    assertEquals(State.HALF_CLOSED_REMOTE,stream.state());
    assertFalse(stream.isHeadersSent());
    String expectedHttpResponse="HTTP/1.1 101 Switching Protocols\r\n" + "connection: upgrade\r\n" + "upgrade: h2c\r\n\r\n";
    ByteBuf responseBuffer=channel.readOutbound();
    assertEquals(expectedHttpResponse,responseBuffer.toString(CharsetUtil.UTF_8));
    responseBuffer.release();
    ByteBuf settingsBuffer=channel.readOutbound();
    assertNotNull(settingsBuffer);
    settingsBuffer.release();
    assertNull(channel.readOutbound());
  }
  @Test public void priorKnowledgeInFragments() throws Exception {
    setUpServerChannel();
    ByteBuf connectionPreface=Http2CodecUtil.connectionPrefaceBuf();
    assertFalse(channel.writeInbound(connectionPreface.readBytes(5),connectionPreface));
    ByteBuf settingsFrame=settingsFrameBuf();
    assertFalse(channel.writeInbound(settingsFrame));
    assertEquals(1,userEvents.size());
    assertTrue(userEvents.get(0) instanceof PriorKnowledgeUpgradeEvent);
    assertEquals(100,http2ConnectionHandler.connection().local().maxActiveStreams());
    assertEquals(65535,http2ConnectionHandler.connection().local().flowController().initialWindowSize());
    verify(frameListener).onSettingsRead(any(ChannelHandlerContext.class),eq(expectedSettings()));
  }
  @Test public void downgrade() throws Exception {
    setUpServerChannel();
    String requestString="GET / HTTP/1.1\r\n" + "Host: example.com\r\n\r\n";
    ByteBuf inbound=Unpooled.buffer().writeBytes(requestString.getBytes(CharsetUtil.US_ASCII));
    assertTrue(channel.writeInbound(inbound));
    Object firstInbound=channel.readInbound();
    assertTrue(firstInbound instanceof HttpRequest);
    HttpRequest request=(HttpRequest)firstInbound;
    assertEquals(HttpMethod.GET,request.method());
    assertEquals("/",request.uri());
    assertEquals(HttpVersion.HTTP_1_1,request.protocolVersion());
    assertEquals(new DefaultHttpHeaders().add("Host","example.com"),request.headers());
    ((LastHttpContent)channel.readInbound()).release();
    assertNull(channel.readInbound());
  }
  @Test public void usedHttp2MultiplexCodec() throws Exception {
    final Http2MultiplexCodec http2Codec=new Http2MultiplexCodecBuilder(true,new ChannelInitializer<Channel>(){
      @Override protected void initChannel(      Channel ch) throws Exception {
      }
    }
).build();
    UpgradeCodecFactory upgradeCodecFactory=new UpgradeCodecFactory(){
      @Override public UpgradeCodec newUpgradeCodec(      CharSequence protocol){
        return new Http2ServerUpgradeCodec(http2Codec);
      }
    }
;
    http2ConnectionHandler=http2Codec;
    userEvents=new ArrayList<Object>();
    HttpServerCodec httpServerCodec=new HttpServerCodec();
    HttpServerUpgradeHandler upgradeHandler=new HttpServerUpgradeHandler(httpServerCodec,upgradeCodecFactory);
    CleartextHttp2ServerUpgradeHandler handler=new CleartextHttp2ServerUpgradeHandler(httpServerCodec,upgradeHandler,http2Codec);
    channel=new EmbeddedChannel(handler,new ChannelInboundHandlerAdapter(){
      @Override public void userEventTriggered(      ChannelHandlerContext ctx,      Object evt) throws Exception {
        userEvents.add(evt);
      }
    }
);
    assertFalse(channel.writeInbound(Http2CodecUtil.connectionPrefaceBuf()));
    ByteBuf settingsFrame=settingsFrameBuf();
    assertTrue(channel.writeInbound(settingsFrame));
    assertEquals(1,userEvents.size());
    assertTrue(userEvents.get(0) instanceof PriorKnowledgeUpgradeEvent);
  }
  private static ByteBuf settingsFrameBuf(){
    ByteBuf settingsFrame=Unpooled.buffer();
    settingsFrame.writeMedium(12);
    settingsFrame.writeByte(0x4);
    settingsFrame.writeByte(0x0);
    settingsFrame.writeInt(0x0);
    settingsFrame.writeShort(0x3);
    settingsFrame.writeInt(100);
    settingsFrame.writeShort(0x4);
    settingsFrame.writeInt(65535);
    return settingsFrame;
  }
  private static Http2Settings expectedSettings(){
    return new Http2Settings().maxConcurrentStreams(100).initialWindowSize(65535);
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from netty-netty-4.1.32.Final~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package okhttp3.mockwebserver;
import java.io.Closeable;
import java.io.IOException;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.net.ProtocolException;
import java.net.Proxy;
import java.net.ServerSocket;
import java.net.Socket;
import java.net.SocketException;
import java.security.SecureRandom;
import java.security.cert.CertificateException;
import java.security.cert.X509Certificate;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Iterator;
import java.util.List;
import java.util.Locale;
import java.util.Set;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.LinkedBlockingQueue;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.logging.Level;
import java.util.logging.Logger;
import javax.net.ServerSocketFactory;
import javax.net.ssl.SSLContext;
import javax.net.ssl.SSLSocket;
import javax.net.ssl.SSLSocketFactory;
import javax.net.ssl.TrustManager;
import javax.net.ssl.X509TrustManager;
import okhttp3.Headers;
import okhttp3.HttpUrl;
import okhttp3.Protocol;
import okhttp3.Request;
import okhttp3.Response;
import okhttp3.internal.Internal;
import okhttp3.internal.NamedRunnable;
import okhttp3.internal.Util;
import okhttp3.internal.http.HttpMethod;
import okhttp3.internal.http2.ErrorCode;
import okhttp3.internal.http2.Header;
import okhttp3.internal.http2.Http2Connection;
import okhttp3.internal.http2.Http2Stream;
import okhttp3.internal.http2.Settings;
import okhttp3.internal.platform.Platform;
import okhttp3.internal.ws.RealWebSocket;
import okhttp3.internal.ws.WebSocketProtocol;
import okio.Buffer;
import okio.BufferedSink;
import okio.BufferedSource;
import okio.ByteString;
import okio.Okio;
import okio.Sink;
import okio.Timeout;
import org.junit.rules.ExternalResource;
import static okhttp3.internal.Util.closeQuietly;
import static okhttp3.mockwebserver.SocketPolicy.CONTINUE_ALWAYS;
import static okhttp3.mockwebserver.SocketPolicy.DISCONNECT_AFTER_REQUEST;
import static okhttp3.mockwebserver.SocketPolicy.DISCONNECT_AT_END;
import static okhttp3.mockwebserver.SocketPolicy.DISCONNECT_AT_START;
import static okhttp3.mockwebserver.SocketPolicy.DISCONNECT_DURING_REQUEST_BODY;
import static okhttp3.mockwebserver.SocketPolicy.DISCONNECT_DURING_RESPONSE_BODY;
import static okhttp3.mockwebserver.SocketPolicy.EXPECT_CONTINUE;
import static okhttp3.mockwebserver.SocketPolicy.FAIL_HANDSHAKE;
import static okhttp3.mockwebserver.SocketPolicy.NO_RESPONSE;
import static okhttp3.mockwebserver.SocketPolicy.RESET_STREAM_AT_START;
import static okhttp3.mockwebserver.SocketPolicy.SHUTDOWN_INPUT_AT_END;
import static okhttp3.mockwebserver.SocketPolicy.SHUTDOWN_OUTPUT_AT_END;
import static okhttp3.mockwebserver.SocketPolicy.SHUTDOWN_SERVER_AFTER_RESPONSE;
import static okhttp3.mockwebserver.SocketPolicy.STALL_SOCKET_AT_START;
import static okhttp3.mockwebserver.SocketPolicy.UPGRADE_TO_SSL_AT_END;
/** 
 * A scriptable web server. Callers supply canned responses and the server replays them upon request in sequence.
 */
public final class MockWebServer extends ExternalResource implements Closeable {
static {
    Internal.initializeInstanceForTests();
  }
  private static final int CLIENT_AUTH_NONE=0;
  private static final int CLIENT_AUTH_REQUESTED=1;
  private static final int CLIENT_AUTH_REQUIRED=2;
  private static final X509TrustManager UNTRUSTED_TRUST_MANAGER=new X509TrustManager(){
    @Override public void checkClientTrusted(    X509Certificate[] chain,    String authType) throws CertificateException {
      throw new CertificateException();
    }
    @Override public void checkServerTrusted(    X509Certificate[] chain,    String authType){
      throw new AssertionError();
    }
    @Override public X509Certificate[] getAcceptedIssuers(){
      throw new AssertionError();
    }
  }
;
  private static final Logger logger=Logger.getLogger(MockWebServer.class.getName());
  private final BlockingQueue<RecordedRequest> requestQueue=new LinkedBlockingQueue<>();
  private final Set<Socket> openClientSockets=Collections.newSetFromMap(new ConcurrentHashMap<Socket,Boolean>());
  private final Set<Http2Connection> openConnections=Collections.newSetFromMap(new ConcurrentHashMap<Http2Connection,Boolean>());
  private final AtomicInteger requestCount=new AtomicInteger();
  private long bodyLimit=Long.MAX_VALUE;
  private ServerSocketFactory serverSocketFactory=ServerSocketFactory.getDefault();
  private ServerSocket serverSocket;
  private SSLSocketFactory sslSocketFactory;
  private ExecutorService executor;
  private boolean tunnelProxy;
  private int clientAuth=CLIENT_AUTH_NONE;
  private Dispatcher dispatcher=new QueueDispatcher();
  private int port=-1;
  private InetSocketAddress inetSocketAddress;
  private boolean protocolNegotiationEnabled=true;
  private List<Protocol> protocols=Util.immutableList(Protocol.HTTP_2,Protocol.HTTP_1_1);
  private boolean started;
  @Override protected synchronized void before(){
    if (started)     return;
    try {
      start();
    }
 catch (    IOException e) {
      throw new RuntimeException(e);
    }
  }
  public int getPort(){
    before();
    return port;
  }
  public String getHostName(){
    before();
    return inetSocketAddress.getAddress().getCanonicalHostName();
  }
  public Proxy toProxyAddress(){
    before();
    InetSocketAddress address=new InetSocketAddress(inetSocketAddress.getAddress().getCanonicalHostName(),getPort());
    return new Proxy(Proxy.Type.HTTP,address);
  }
  public void setServerSocketFactory(  ServerSocketFactory serverSocketFactory){
    if (executor != null) {
      throw new IllegalStateException("setServerSocketFactory() must be called before start()");
    }
    this.serverSocketFactory=serverSocketFactory;
  }
  /** 
 * Returns a URL for connecting to this server.
 * @param path the request path, such as "/".
 */
  public HttpUrl url(  String path){
    return new HttpUrl.Builder().scheme(sslSocketFactory != null ? "https" : "http").host(getHostName()).port(getPort()).build().resolve(path);
  }
  /** 
 * Sets the number of bytes of the POST body to keep in memory to the given limit.
 */
  public void setBodyLimit(  long maxBodyLength){
    this.bodyLimit=maxBodyLength;
  }
  /** 
 * Sets whether ALPN is used on incoming HTTPS connections to negotiate a protocol like HTTP/1.1 or HTTP/2. Call this method to disable negotiation and restrict connections to HTTP/1.1.
 */
  public void setProtocolNegotiationEnabled(  boolean protocolNegotiationEnabled){
    this.protocolNegotiationEnabled=protocolNegotiationEnabled;
  }
  /** 
 * Indicates the protocols supported by ALPN on incoming HTTPS connections. This list is ignored when  {@link #setProtocolNegotiationEnabled negotiation is disabled}.
 * @param protocols the protocols to use, in order of preference. The list must contain{@linkplain Protocol#HTTP_1_1}. It must not contain null.
 */
  public void setProtocols(  List<Protocol> protocols){
    protocols=Util.immutableList(protocols);
    if (protocols.contains(Protocol.H2_PRIOR_KNOWLEDGE) && protocols.size() > 1) {
      throw new IllegalArgumentException("protocols containing h2_prior_knowledge cannot use other protocols: " + protocols);
    }
 else     if (!protocols.contains(Protocol.H2_PRIOR_KNOWLEDGE) && !protocols.contains(Protocol.HTTP_1_1)) {
      throw new IllegalArgumentException("protocols doesn't contain http/1.1: " + protocols);
    }
    if (protocols.contains(null)) {
      throw new IllegalArgumentException("protocols must not contain null");
    }
    this.protocols=protocols;
  }
  public List<Protocol> protocols(){
    return protocols;
  }
  /** 
 * Serve requests with HTTPS rather than otherwise.
 * @param tunnelProxy true to expect the HTTP CONNECT method before negotiating TLS.
 */
  public void useHttps(  SSLSocketFactory sslSocketFactory,  boolean tunnelProxy){
    this.sslSocketFactory=sslSocketFactory;
    this.tunnelProxy=tunnelProxy;
  }
  /** 
 * Configure the server to not perform SSL authentication of the client. This leaves authentication to another layer such as in an HTTP cookie or header. This is the default and most common configuration.
 */
  public void noClientAuth(){
    this.clientAuth=CLIENT_AUTH_NONE;
  }
  /** 
 * Configure the server to  {@linkplain SSLSocket#setWantClientAuth want client auth}. If the client presents a certificate that is  {@linkplain TrustManager trusted} the handshake willproceed normally. The connection will also proceed normally if the client presents no certificate at all! But if the client presents an untrusted certificate the handshake will fail and no connection will be established.
 */
  public void requestClientAuth(){
    this.clientAuth=CLIENT_AUTH_REQUESTED;
  }
  /** 
 * Configure the server to  {@linkplain SSLSocket#setNeedClientAuth need client auth}. If the client presents a certificate that is  {@linkplain TrustManager trusted} the handshake willproceed normally. If the client presents an untrusted certificate or no certificate at all the handshake will fail and no connection will be established.
 */
  public void requireClientAuth(){
    this.clientAuth=CLIENT_AUTH_REQUIRED;
  }
  /** 
 * Awaits the next HTTP request, removes it, and returns it. Callers should use this to verify the request was sent as intended. This method will block until the request is available, possibly forever.
 * @return the head of the request queue
 */
  public RecordedRequest takeRequest() throws InterruptedException {
    return requestQueue.take();
  }
  /** 
 * Awaits the next HTTP request (waiting up to the specified wait time if necessary), removes it, and returns it. Callers should use this to verify the request was sent as intended within the given time.
 * @param timeout how long to wait before giving up, in units of {@code unit}
 * @param unit a {@code TimeUnit} determining how to interpret the {@code timeout} parameter
 * @return the head of the request queue
 */
  public RecordedRequest takeRequest(  long timeout,  TimeUnit unit) throws InterruptedException {
    return requestQueue.poll(timeout,unit);
  }
  /** 
 * Returns the number of HTTP requests received thus far by this server. This may exceed the number of HTTP connections when connection reuse is in practice.
 */
  public int getRequestCount(){
    return requestCount.get();
  }
  /** 
 * Scripts  {@code response} to be returned to a request made in sequence. The first request isserved by the first enqueued response; the second request by the second enqueued response; and so on.
 * @throws ClassCastException if the default dispatcher has been replaced with {@link #setDispatcher(Dispatcher)}.
 */
  public void enqueue(  MockResponse response){
    ((QueueDispatcher)dispatcher).enqueueResponse(response.clone());
  }
  /** 
 * Equivalent to  {@code start(0)}. 
 */
  public void start() throws IOException {
    start(0);
  }
  /** 
 * Starts the server on the loopback interface for the given port.
 * @param port the port to listen to, or 0 for any available port. Automated tests should alwaysuse port 0 to avoid flakiness when a specific port is unavailable.
 */
  public void start(  int port) throws IOException {
    start(InetAddress.getByName("localhost"),port);
  }
  /** 
 * Starts the server on the given address and port.
 * @param inetAddress the address to create the server socket on
 * @param port the port to listen to, or 0 for any available port. Automated tests should alwaysuse port 0 to avoid flakiness when a specific port is unavailable.
 */
  public void start(  InetAddress inetAddress,  int port) throws IOException {
    start(new InetSocketAddress(inetAddress,port));
  }
  /** 
 * Starts the server and binds to the given socket address.
 * @param inetSocketAddress the socket address to bind the server on
 */
  private synchronized void start(  InetSocketAddress inetSocketAddress) throws IOException {
    if (started)     throw new IllegalStateException("start() already called");
    started=true;
    executor=Executors.newCachedThreadPool(Util.threadFactory("MockWebServer",false));
    this.inetSocketAddress=inetSocketAddress;
    serverSocket=serverSocketFactory.createServerSocket();
    serverSocket.setReuseAddress(inetSocketAddress.getPort() != 0);
    serverSocket.bind(inetSocketAddress,50);
    port=serverSocket.getLocalPort();
    executor.execute(new NamedRunnable("MockWebServer %s",port){
      @Override protected void execute(){
        try {
          logger.info(MockWebServer.this + " starting to accept connections");
          acceptConnections();
        }
 catch (        Throwable e) {
          logger.log(Level.WARNING,MockWebServer.this + " failed unexpectedly",e);
        }
        closeQuietly(serverSocket);
        for (Iterator<Socket> s=openClientSockets.iterator(); s.hasNext(); ) {
          closeQuietly(s.next());
          s.remove();
        }
        for (Iterator<Http2Connection> s=openConnections.iterator(); s.hasNext(); ) {
          closeQuietly(s.next());
          s.remove();
        }
        dispatcher.shutdown();
        executor.shutdown();
      }
      private void acceptConnections() throws Exception {
        while (true) {
          Socket socket;
          try {
            socket=serverSocket.accept();
          }
 catch (          SocketException e) {
            logger.info(MockWebServer.this + " done accepting connections: " + e.getMessage());
            return;
          }
          SocketPolicy socketPolicy=dispatcher.peek().getSocketPolicy();
          if (socketPolicy == DISCONNECT_AT_START) {
            dispatchBookkeepingRequest(0,socket);
            socket.close();
          }
 else {
            openClientSockets.add(socket);
            serveConnection(socket);
          }
        }
      }
    }
);
  }
  public synchronized void shutdown() throws IOException {
    if (!started)     return;
    if (serverSocket == null)     throw new IllegalStateException("shutdown() before start()");
    serverSocket.close();
    try {
      if (!executor.awaitTermination(5,TimeUnit.SECONDS)) {
        throw new IOException("Gave up waiting for executor to shut down");
      }
    }
 catch (    InterruptedException e) {
      throw new AssertionError();
    }
  }
  @Override protected synchronized void after(){
    try {
      shutdown();
    }
 catch (    IOException e) {
      logger.log(Level.WARNING,"MockWebServer shutdown failed",e);
    }
  }
  private void serveConnection(  final Socket raw){
    executor.execute(new NamedRunnable("MockWebServer %s",raw.getRemoteSocketAddress()){
      int sequenceNumber=0;
      @Override protected void execute(){
        try {
          processConnection();
        }
 catch (        IOException e) {
          logger.info(MockWebServer.this + " connection from " + raw.getInetAddress()+ " failed: "+ e);
        }
catch (        Exception e) {
          logger.log(Level.SEVERE,MockWebServer.this + " connection from " + raw.getInetAddress()+ " crashed",e);
        }
      }
      public void processConnection() throws Exception {
        SocketPolicy socketPolicy=dispatcher.peek().getSocketPolicy();
        Protocol protocol=Protocol.HTTP_1_1;
        Socket socket;
        if (sslSocketFactory != null) {
          if (tunnelProxy) {
            createTunnel();
          }
          if (socketPolicy == FAIL_HANDSHAKE) {
            dispatchBookkeepingRequest(sequenceNumber,raw);
            processHandshakeFailure(raw);
            return;
          }
          socket=sslSocketFactory.createSocket(raw,raw.getInetAddress().getHostAddress(),raw.getPort(),true);
          SSLSocket sslSocket=(SSLSocket)socket;
          sslSocket.setUseClientMode(false);
          if (clientAuth == CLIENT_AUTH_REQUIRED) {
            sslSocket.setNeedClientAuth(true);
          }
 else           if (clientAuth == CLIENT_AUTH_REQUESTED) {
            sslSocket.setWantClientAuth(true);
          }
          openClientSockets.add(socket);
          if (protocolNegotiationEnabled) {
            Platform.get().configureTlsExtensions(sslSocket,null,protocols);
          }
          sslSocket.startHandshake();
          if (protocolNegotiationEnabled) {
            String protocolString=Platform.get().getSelectedProtocol(sslSocket);
            protocol=protocolString != null ? Protocol.get(protocolString) : Protocol.HTTP_1_1;
          }
          openClientSockets.remove(raw);
        }
 else         if (protocols.contains(Protocol.H2_PRIOR_KNOWLEDGE)) {
          socket=raw;
          protocol=Protocol.H2_PRIOR_KNOWLEDGE;
        }
 else {
          socket=raw;
        }
        if (socketPolicy == STALL_SOCKET_AT_START) {
          return;
        }
        if (protocol == Protocol.HTTP_2 || protocol == Protocol.H2_PRIOR_KNOWLEDGE) {
          Http2SocketHandler http2SocketHandler=new Http2SocketHandler(socket,protocol);
          Http2Connection connection=new Http2Connection.Builder(false).socket(socket).listener(http2SocketHandler).build();
          connection.start();
          openConnections.add(connection);
          openClientSockets.remove(socket);
          return;
        }
 else         if (protocol != Protocol.HTTP_1_1) {
          throw new AssertionError();
        }
        BufferedSource source=Okio.buffer(Okio.source(socket));
        BufferedSink sink=Okio.buffer(Okio.sink(socket));
        while (processOneRequest(socket,source,sink)) {
        }
        if (sequenceNumber == 0) {
          logger.warning(MockWebServer.this + " connection from " + raw.getInetAddress()+ " didn't make a request");
        }
        socket.close();
        openClientSockets.remove(socket);
      }
      /** 
 * Respond to CONNECT requests until a SWITCH_TO_SSL_AT_END response is dispatched.
 */
      private void createTunnel() throws IOException, InterruptedException {
        BufferedSource source=Okio.buffer(Okio.source(raw));
        BufferedSink sink=Okio.buffer(Okio.sink(raw));
        while (true) {
          SocketPolicy socketPolicy=dispatcher.peek().getSocketPolicy();
          if (!processOneRequest(raw,source,sink)) {
            throw new IllegalStateException("Tunnel without any CONNECT!");
          }
          if (socketPolicy == UPGRADE_TO_SSL_AT_END)           return;
        }
      }
      /** 
 * Reads a request and writes its response. Returns true if further calls should be attempted on the socket.
 */
      private boolean processOneRequest(      Socket socket,      BufferedSource source,      BufferedSink sink) throws IOException, InterruptedException {
        RecordedRequest request=readRequest(socket,source,sink,sequenceNumber);
        if (request == null)         return false;
        requestCount.incrementAndGet();
        requestQueue.add(request);
        MockResponse response=dispatcher.dispatch(request);
        if (response.getSocketPolicy() == DISCONNECT_AFTER_REQUEST) {
          socket.close();
          return false;
        }
        if (response.getSocketPolicy() == NO_RESPONSE) {
          if (source.exhausted())           return false;
          throw new ProtocolException("unexpected data");
        }
        boolean reuseSocket=true;
        boolean requestWantsWebSockets="Upgrade".equalsIgnoreCase(request.getHeader("Connection")) && "websocket".equalsIgnoreCase(request.getHeader("Upgrade"));
        boolean responseWantsWebSockets=response.getWebSocketListener() != null;
        if (requestWantsWebSockets && responseWantsWebSockets) {
          handleWebSocketUpgrade(socket,source,sink,request,response);
          reuseSocket=false;
        }
 else {
          writeHttpResponse(socket,sink,response);
        }
        if (logger.isLoggable(Level.INFO)) {
          logger.info(MockWebServer.this + " received request: " + request+ " and responded: "+ response);
        }
        if (response.getSocketPolicy() == DISCONNECT_AT_END) {
          socket.close();
          return false;
        }
 else         if (response.getSocketPolicy() == SHUTDOWN_INPUT_AT_END) {
          socket.shutdownInput();
        }
 else         if (response.getSocketPolicy() == SHUTDOWN_OUTPUT_AT_END) {
          socket.shutdownOutput();
        }
 else         if (response.getSocketPolicy() == SHUTDOWN_SERVER_AFTER_RESPONSE) {
          shutdown();
        }
        sequenceNumber++;
        return reuseSocket;
      }
    }
);
  }
  private void processHandshakeFailure(  Socket raw) throws Exception {
    SSLContext context=SSLContext.getInstance("TLS");
    context.init(null,new TrustManager[]{UNTRUSTED_TRUST_MANAGER},new SecureRandom());
    SSLSocketFactory sslSocketFactory=context.getSocketFactory();
    SSLSocket socket=(SSLSocket)sslSocketFactory.createSocket(raw,raw.getInetAddress().getHostAddress(),raw.getPort(),true);
    try {
      socket.startHandshake();
      throw new AssertionError();
    }
 catch (    IOException expected) {
    }
    socket.close();
  }
  private void dispatchBookkeepingRequest(  int sequenceNumber,  Socket socket) throws InterruptedException {
    RecordedRequest request=new RecordedRequest(null,null,null,-1,null,sequenceNumber,socket);
    requestCount.incrementAndGet();
    requestQueue.add(request);
    dispatcher.dispatch(request);
  }
  /** 
 * @param sequenceNumber the index of this request on this connection. 
 */
  private RecordedRequest readRequest(  Socket socket,  BufferedSource source,  BufferedSink sink,  int sequenceNumber) throws IOException {
    String request;
    try {
      request=source.readUtf8LineStrict();
    }
 catch (    IOException streamIsClosed) {
      return null;
    }
    if (request.length() == 0) {
      return null;
    }
    Headers.Builder headers=new Headers.Builder();
    long contentLength=-1;
    boolean chunked=false;
    boolean expectContinue=false;
    String header;
    while ((header=source.readUtf8LineStrict()).length() != 0) {
      Internal.instance.addLenient(headers,header);
      String lowercaseHeader=header.toLowerCase(Locale.US);
      if (contentLength == -1 && lowercaseHeader.startsWith("content-length:")) {
        contentLength=Long.parseLong(header.substring(15).trim());
      }
      if (lowercaseHeader.startsWith("transfer-encoding:") && lowercaseHeader.substring(18).trim().equals("chunked")) {
        chunked=true;
      }
      if (lowercaseHeader.startsWith("expect:") && lowercaseHeader.substring(7).trim().equalsIgnoreCase("100-continue")) {
        expectContinue=true;
      }
    }
    final SocketPolicy socketPolicy=dispatcher.peek().getSocketPolicy();
    if (expectContinue && socketPolicy == EXPECT_CONTINUE || socketPolicy == CONTINUE_ALWAYS) {
      sink.writeUtf8("HTTP/1.1 100 Continue\r\n");
      sink.writeUtf8("Content-Length: 0\r\n");
      sink.writeUtf8("\r\n");
      sink.flush();
    }
    boolean hasBody=false;
    TruncatingBuffer requestBody=new TruncatingBuffer(bodyLimit);
    List<Integer> chunkSizes=new ArrayList<>();
    MockResponse policy=dispatcher.peek();
    if (contentLength != -1) {
      hasBody=contentLength > 0;
      throttledTransfer(policy,socket,source,Okio.buffer(requestBody),contentLength,true);
    }
 else     if (chunked) {
      hasBody=true;
      while (true) {
        int chunkSize=Integer.parseInt(source.readUtf8LineStrict().trim(),16);
        if (chunkSize == 0) {
          readEmptyLine(source);
          break;
        }
        chunkSizes.add(chunkSize);
        throttledTransfer(policy,socket,source,Okio.buffer(requestBody),chunkSize,true);
        readEmptyLine(source);
      }
    }
    String method=request.substring(0,request.indexOf(' '));
    if (hasBody && !HttpMethod.permitsRequestBody(method)) {
      throw new IllegalArgumentException("Request must not have a body: " + request);
    }
    return new RecordedRequest(request,headers.build(),chunkSizes,requestBody.receivedByteCount,requestBody.buffer,sequenceNumber,socket);
  }
  private void handleWebSocketUpgrade(  Socket socket,  BufferedSource source,  BufferedSink sink,  RecordedRequest request,  MockResponse response) throws IOException {
    String key=request.getHeader("Sec-WebSocket-Key");
    response.setHeader("Sec-WebSocket-Accept",WebSocketProtocol.acceptHeader(key));
    writeHttpResponse(socket,sink,response);
    String scheme=request.getTlsVersion() != null ? "https" : "http";
    String authority=request.getHeader("Host");
    final Request fancyRequest=new Request.Builder().url(scheme + "://" + authority+ "/").headers(request.getHeaders()).build();
    final Response fancyResponse=new Response.Builder().code(Integer.parseInt(response.getStatus().split(" ")[1])).message(response.getStatus().split(" ",3)[2]).headers(response.getHeaders()).request(fancyRequest).protocol(Protocol.HTTP_1_1).build();
    final CountDownLatch connectionClose=new CountDownLatch(1);
    RealWebSocket.Streams streams=new RealWebSocket.Streams(false,source,sink){
      @Override public void close(){
        connectionClose.countDown();
      }
    }
;
    RealWebSocket webSocket=new RealWebSocket(fancyRequest,response.getWebSocketListener(),new SecureRandom(),0);
    response.getWebSocketListener().onOpen(webSocket,fancyResponse);
    String name="MockWebServer WebSocket " + request.getPath();
    webSocket.initReaderAndWriter(name,streams);
    try {
      webSocket.loopReader();
      try {
        connectionClose.await();
      }
 catch (      InterruptedException e) {
        throw new AssertionError(e);
      }
    }
 catch (    IOException e) {
      webSocket.failWebSocket(e,null);
    }
 finally {
      closeQuietly(source);
    }
  }
  private void writeHttpResponse(  Socket socket,  BufferedSink sink,  MockResponse response) throws IOException {
    sleepIfDelayed(response.getHeadersDelay(TimeUnit.MILLISECONDS));
    sink.writeUtf8(response.getStatus());
    sink.writeUtf8("\r\n");
    Headers headers=response.getHeaders();
    for (int i=0, size=headers.size(); i < size; i++) {
      sink.writeUtf8(headers.name(i));
      sink.writeUtf8(": ");
      sink.writeUtf8(headers.value(i));
      sink.writeUtf8("\r\n");
    }
    sink.writeUtf8("\r\n");
    sink.flush();
    Buffer body=response.getBody();
    if (body == null)     return;
    sleepIfDelayed(response.getBodyDelay(TimeUnit.MILLISECONDS));
    throttledTransfer(response,socket,body,sink,body.size(),false);
  }
  private void sleepIfDelayed(  long delayMs){
    if (delayMs != 0) {
      try {
        Thread.sleep(delayMs);
      }
 catch (      InterruptedException e) {
        throw new AssertionError(e);
      }
    }
  }
  /** 
 * Transfer bytes from  {@code source} to {@code sink} until either {@code byteCount} bytes havebeen transferred or  {@code source} is exhausted. The transfer is throttled according to {@code policy}.
 */
  private void throttledTransfer(  MockResponse policy,  Socket socket,  BufferedSource source,  BufferedSink sink,  long byteCount,  boolean isRequest) throws IOException {
    if (byteCount == 0)     return;
    Buffer buffer=new Buffer();
    long bytesPerPeriod=policy.getThrottleBytesPerPeriod();
    long periodDelayMs=policy.getThrottlePeriod(TimeUnit.MILLISECONDS);
    long halfByteCount=byteCount / 2;
    boolean disconnectHalfway=isRequest ? policy.getSocketPolicy() == DISCONNECT_DURING_REQUEST_BODY : policy.getSocketPolicy() == DISCONNECT_DURING_RESPONSE_BODY;
    while (!socket.isClosed()) {
      for (int b=0; b < bytesPerPeriod; ) {
        long toRead=Math.min(byteCount,bytesPerPeriod - b);
        if (disconnectHalfway) {
          toRead=Math.min(toRead,byteCount - halfByteCount);
        }
        long read=source.read(buffer,toRead);
        if (read == -1)         return;
        sink.write(buffer,read);
        sink.flush();
        b+=read;
        byteCount-=read;
        if (disconnectHalfway && byteCount == halfByteCount) {
          socket.close();
          return;
        }
        if (byteCount == 0)         return;
      }
      if (periodDelayMs != 0) {
        try {
          Thread.sleep(periodDelayMs);
        }
 catch (        InterruptedException e) {
          throw new AssertionError(e);
        }
      }
    }
  }
  private void readEmptyLine(  BufferedSource source) throws IOException {
    String line=source.readUtf8LineStrict();
    if (line.length() != 0)     throw new IllegalStateException("Expected empty but was: " + line);
  }
  /** 
 * Sets the dispatcher used to match incoming requests to mock responses. The default dispatcher simply serves a fixed sequence of responses from a  {@link #enqueue(MockResponse) queue}; custom dispatchers can vary the response based on timing or the content of the request.
 */
  public void setDispatcher(  Dispatcher dispatcher){
    if (dispatcher == null)     throw new NullPointerException();
    this.dispatcher=dispatcher;
  }
  @Override public String toString(){
    return "MockWebServer[" + port + "]";
  }
  @Override public void close() throws IOException {
    shutdown();
  }
  /** 
 * A buffer wrapper that drops data after  {@code bodyLimit} bytes. 
 */
private static class TruncatingBuffer implements Sink {
    private final Buffer buffer=new Buffer();
    private long remainingByteCount;
    private long receivedByteCount;
    TruncatingBuffer(    long bodyLimit){
      remainingByteCount=bodyLimit;
    }
    @Override public void write(    Buffer source,    long byteCount) throws IOException {
      long toRead=Math.min(remainingByteCount,byteCount);
      if (toRead > 0) {
        source.read(buffer,toRead);
      }
      long toSkip=byteCount - toRead;
      if (toSkip > 0) {
        source.skip(toSkip);
      }
      remainingByteCount-=toRead;
      receivedByteCount+=byteCount;
    }
    @Override public void flush() throws IOException {
    }
    @Override public Timeout timeout(){
      return Timeout.NONE;
    }
    @Override public void close() throws IOException {
    }
  }
  /** 
 * Processes HTTP requests layered over HTTP/2. 
 */
private class Http2SocketHandler extends Http2Connection.Listener {
    private final Socket socket;
    private final Protocol protocol;
    private final AtomicInteger sequenceNumber=new AtomicInteger();
    private Http2SocketHandler(    Socket socket,    Protocol protocol){
      this.socket=socket;
      this.protocol=protocol;
    }
    @Override public void onStream(    Http2Stream stream) throws IOException {
      MockResponse peekedResponse=dispatcher.peek();
      if (peekedResponse.getSocketPolicy() == RESET_STREAM_AT_START) {
        try {
          dispatchBookkeepingRequest(sequenceNumber.getAndIncrement(),socket);
          stream.close(ErrorCode.fromHttp2(peekedResponse.getHttp2ErrorCode()));
          return;
        }
 catch (        InterruptedException e) {
          throw new AssertionError(e);
        }
      }
      RecordedRequest request=readRequest(stream);
      requestCount.incrementAndGet();
      requestQueue.add(request);
      MockResponse response;
      try {
        response=dispatcher.dispatch(request);
      }
 catch (      InterruptedException e) {
        throw new AssertionError(e);
      }
      if (response.getSocketPolicy() == DISCONNECT_AFTER_REQUEST) {
        socket.close();
        return;
      }
      writeResponse(stream,response);
      if (logger.isLoggable(Level.INFO)) {
        logger.info(MockWebServer.this + " received request: " + request+ " and responded: "+ response+ " protocol is "+ protocol.toString());
      }
      if (response.getSocketPolicy() == DISCONNECT_AT_END) {
        Http2Connection connection=stream.getConnection();
        connection.shutdown(ErrorCode.NO_ERROR);
      }
    }
    private RecordedRequest readRequest(    Http2Stream stream) throws IOException {
      Headers streamHeaders=stream.takeHeaders();
      Headers.Builder httpHeaders=new Headers.Builder();
      String method="<:method omitted>";
      String path="<:path omitted>";
      boolean readBody=true;
      for (int i=0, size=streamHeaders.size(); i < size; i++) {
        String name=streamHeaders.name(i);
        String value=streamHeaders.value(i);
        if (name.equals(Header.TARGET_METHOD_UTF8)) {
          method=value;
        }
 else         if (name.equals(Header.TARGET_PATH_UTF8)) {
          path=value;
        }
 else         if (protocol == Protocol.HTTP_2 || protocol == Protocol.H2_PRIOR_KNOWLEDGE) {
          httpHeaders.add(name,value);
        }
 else {
          throw new IllegalStateException();
        }
        if (name.equals("expect") && value.equalsIgnoreCase("100-continue")) {
          readBody=false;
        }
      }
      Headers headers=httpHeaders.build();
      MockResponse peek=dispatcher.peek();
      if (!readBody && peek.getSocketPolicy() == EXPECT_CONTINUE) {
        stream.writeHeaders(Collections.singletonList(new Header(Header.RESPONSE_STATUS,ByteString.encodeUtf8("100 Continue"))),true);
        stream.getConnection().flush();
        readBody=true;
      }
      Buffer body=new Buffer();
      if (readBody) {
        String contentLengthString=headers.get("content-length");
        long byteCount=contentLengthString != null ? Long.parseLong(contentLengthString) : Long.MAX_VALUE;
        throttledTransfer(peek,socket,Okio.buffer(stream.getSource()),body,byteCount,true);
      }
      String requestLine=method + ' ' + path+ " HTTP/1.1";
      List<Integer> chunkSizes=Collections.emptyList();
      return new RecordedRequest(requestLine,headers,chunkSizes,body.size(),body,sequenceNumber.getAndIncrement(),socket);
    }
    private void writeResponse(    Http2Stream stream,    MockResponse response) throws IOException {
      Settings settings=response.getSettings();
      if (settings != null) {
        stream.getConnection().setSettings(settings);
      }
      if (response.getSocketPolicy() == NO_RESPONSE) {
        return;
      }
      List<Header> http2Headers=new ArrayList<>();
      String[] statusParts=response.getStatus().split(" ",3);
      if (statusParts.length < 2) {
        throw new AssertionError("Unexpected status: " + response.getStatus());
      }
      http2Headers.add(new Header(Header.RESPONSE_STATUS,statusParts[1]));
      Headers headers=response.getHeaders();
      for (int i=0, size=headers.size(); i < size; i++) {
        http2Headers.add(new Header(headers.name(i),headers.value(i)));
      }
      sleepIfDelayed(response.getHeadersDelay(TimeUnit.MILLISECONDS));
      Buffer body=response.getBody();
      boolean closeStreamAfterHeaders=body != null || !response.getPushPromises().isEmpty();
      stream.writeHeaders(http2Headers,closeStreamAfterHeaders);
      pushPromises(stream,response.getPushPromises());
      if (body != null) {
        BufferedSink sink=Okio.buffer(stream.getSink());
        sleepIfDelayed(response.getBodyDelay(TimeUnit.MILLISECONDS));
        throttledTransfer(response,socket,body,sink,body.size(),false);
        sink.close();
      }
 else       if (closeStreamAfterHeaders) {
        stream.close(ErrorCode.NO_ERROR);
      }
    }
    private void pushPromises(    Http2Stream stream,    List<PushPromise> promises) throws IOException {
      for (      PushPromise pushPromise : promises) {
        List<Header> pushedHeaders=new ArrayList<>();
        pushedHeaders.add(new Header(Header.TARGET_AUTHORITY,url(pushPromise.path()).host()));
        pushedHeaders.add(new Header(Header.TARGET_METHOD,pushPromise.method()));
        pushedHeaders.add(new Header(Header.TARGET_PATH,pushPromise.path()));
        Headers pushPromiseHeaders=pushPromise.headers();
        for (int i=0, size=pushPromiseHeaders.size(); i < size; i++) {
          pushedHeaders.add(new Header(pushPromiseHeaders.name(i),pushPromiseHeaders.value(i)));
        }
        String requestLine=pushPromise.method() + ' ' + pushPromise.path()+ " HTTP/1.1";
        List<Integer> chunkSizes=Collections.emptyList();
        requestQueue.add(new RecordedRequest(requestLine,pushPromise.headers(),chunkSizes,0,new Buffer(),sequenceNumber.getAndIncrement(),socket));
        boolean hasBody=pushPromise.response().getBody() != null;
        Http2Stream pushedStream=stream.getConnection().pushStream(stream.getId(),pushedHeaders,hasBody);
        writeResponse(pushedStream,pushPromise.response());
      }
    }
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from okhttp-parent-3.12.1~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package retrofit2;
import java.util.Set;
import org.junit.Test;
import static org.assertj.core.api.Assertions.assertThat;
public final class RequestFactoryParserTest {
  @Test public void pathParameterParsing() throws Exception {
    expectParams("/");
    expectParams("/foo");
    expectParams("/foo/bar");
    expectParams("/foo/bar/{}");
    expectParams("/foo/bar/{taco}","taco");
    expectParams("/foo/bar/{t}","t");
    expectParams("/foo/bar/{!!!}/");
    expectParams("/foo/bar/{}/{taco}","taco");
    expectParams("/foo/bar/{taco}/or/{burrito}","taco","burrito");
    expectParams("/foo/bar/{taco}/or/{taco}","taco");
    expectParams("/foo/bar/{taco-shell}","taco-shell");
    expectParams("/foo/bar/{taco_shell}","taco_shell");
    expectParams("/foo/bar/{sha256}","sha256");
    expectParams("/foo/bar/{TACO}","TACO");
    expectParams("/foo/bar/{taco}/{tAco}/{taCo}","taco","tAco","taCo");
    expectParams("/foo/bar/{1}");
  }
  private static void expectParams(  String path,  String... expected){
    Set<String> calculated=RequestFactoryParser.parsePathParameters(path);
    assertThat(calculated).containsExactly(expected);
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from retrofit-parent-2.0.0-beta3~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package sample;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.boot.test.context.SpringBootTest.WebEnvironment;
import org.springframework.boot.test.web.client.TestRestTemplate;
import static org.assertj.core.api.Assertions.assertThat;
@SpringBootTest(webEnvironment=WebEnvironment.RANDOM_PORT) class SampleJunitJupiterApplicationTests {
  @Autowired private TestRestTemplate restTemplate;
  @Test void testMessage(){
    String message=this.restTemplate.getForObject("/hi",String.class);
    assertThat(message).isEqualTo("Hello World");
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.test.json;
import org.junit.Test;
import org.springframework.core.ResolvableType;
import static org.assertj.core.api.Assertions.assertThat;
import static org.assertj.core.api.Assertions.assertThatIllegalArgumentException;
/** 
 * Tests for  {@link ObjectContent}.
 * @author Phillip Webb
 */
public class ObjectContentTests {
  private static final ExampleObject OBJECT=new ExampleObject();
  private static final ResolvableType TYPE=ResolvableType.forClass(ExampleObject.class);
  @Test public void createWhenObjectIsNullShouldThrowException(){
    assertThatIllegalArgumentException().isThrownBy(() -> new ObjectContent<ExampleObject>(TYPE,null)).withMessageContaining("Object must not be null");
  }
  @Test public void createWhenTypeIsNullShouldCreateContent(){
    ObjectContent<ExampleObject> content=new ObjectContent<>(null,OBJECT);
    assertThat(content).isNotNull();
  }
  @Test public void assertThatShouldReturnObjectContentAssert(){
    ObjectContent<ExampleObject> content=new ObjectContent<>(TYPE,OBJECT);
    assertThat(content.assertThat()).isInstanceOf(ObjectContentAssert.class);
  }
  @Test public void getObjectShouldReturnObject(){
    ObjectContent<ExampleObject> content=new ObjectContent<>(TYPE,OBJECT);
    assertThat(content.getObject()).isEqualTo(OBJECT);
  }
  @Test public void toStringWhenHasTypeShouldReturnString(){
    ObjectContent<ExampleObject> content=new ObjectContent<>(TYPE,OBJECT);
    assertThat(content.toString()).isEqualTo("ObjectContent " + OBJECT + " created from "+ TYPE);
  }
  @Test public void toStringWhenHasNoTypeShouldReturnString(){
    ObjectContent<ExampleObject> content=new ObjectContent<>(null,OBJECT);
    assertThat(content.toString()).isEqualTo("ObjectContent " + OBJECT);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.autoconfigure.web.reactive;
import org.junit.Test;
import org.springframework.boot.autoconfigure.AutoConfigurations;
import org.springframework.boot.test.context.runner.ReactiveWebApplicationContextRunner;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.http.server.reactive.HttpHandler;
import org.springframework.web.reactive.function.server.RouterFunction;
import org.springframework.web.reactive.function.server.ServerResponse;
import static org.assertj.core.api.Assertions.assertThat;
import static org.springframework.web.reactive.function.server.RequestPredicates.GET;
import static org.springframework.web.reactive.function.server.RouterFunctions.route;
/** 
 * Tests for  {@link HttpHandlerAutoConfiguration}.
 * @author Brian Clozel
 * @author Stephane Nicoll
 * @author Andy Wilkinson
 */
public class HttpHandlerAutoConfigurationTests {
  private final ReactiveWebApplicationContextRunner contextRunner=new ReactiveWebApplicationContextRunner().withConfiguration(AutoConfigurations.of(HttpHandlerAutoConfiguration.class));
  @Test public void shouldNotProcessIfExistingHttpHandler(){
    this.contextRunner.withUserConfiguration(CustomHttpHandler.class).run((context) -> {
      assertThat(context).hasSingleBean(HttpHandler.class);
      assertThat(context).getBean(HttpHandler.class).isSameAs(context.getBean("customHttpHandler"));
    }
);
  }
  @Test public void shouldConfigureHttpHandlerAnnotation(){
    this.contextRunner.withConfiguration(AutoConfigurations.of(WebFluxAutoConfiguration.class)).run((context) -> assertThat(context).hasSingleBean(HttpHandler.class));
  }
@Configuration protected static class CustomHttpHandler {
    @Bean public HttpHandler customHttpHandler(){
      return (serverHttpRequest,serverHttpResponse) -> null;
    }
    @Bean public RouterFunction<ServerResponse> routerFunction(){
      return route(GET("/test"),(serverRequest) -> null);
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.autoconfigure.template;
import java.nio.charset.StandardCharsets;
import org.junit.Test;
import org.springframework.util.MimeTypeUtils;
import static org.assertj.core.api.Assertions.assertThat;
/** 
 * Tests for  {@link AbstractViewResolverProperties}.
 * @author Stephane Nicoll
 */
public class ViewResolverPropertiesTests {
  @Test public void defaultContentType(){
    assertThat(new ViewResolverProperties().getContentType()).hasToString("text/html;charset=UTF-8");
  }
  @Test public void customContentTypeDefaultCharset(){
    ViewResolverProperties properties=new ViewResolverProperties();
    properties.setContentType(MimeTypeUtils.parseMimeType("text/plain"));
    assertThat(properties.getContentType()).hasToString("text/plain;charset=UTF-8");
  }
  @Test public void defaultContentTypeCustomCharset(){
    ViewResolverProperties properties=new ViewResolverProperties();
    properties.setCharset(StandardCharsets.UTF_16);
    assertThat(properties.getContentType()).hasToString("text/html;charset=UTF-16");
  }
  @Test public void customContentTypeCustomCharset(){
    ViewResolverProperties properties=new ViewResolverProperties();
    properties.setContentType(MimeTypeUtils.parseMimeType("text/plain"));
    properties.setCharset(StandardCharsets.UTF_16);
    assertThat(properties.getContentType()).hasToString("text/plain;charset=UTF-16");
  }
  @Test public void customContentTypeWithPropertyAndCustomCharset(){
    ViewResolverProperties properties=new ViewResolverProperties();
    properties.setContentType(MimeTypeUtils.parseMimeType("text/plain;foo=bar"));
    properties.setCharset(StandardCharsets.UTF_16);
    assertThat(properties.getContentType()).hasToString("text/plain;charset=UTF-16;foo=bar");
  }
private static class ViewResolverProperties extends AbstractViewResolverProperties {
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.autoconfigure.jdbc;
import java.sql.Connection;
import java.sql.DatabaseMetaData;
import java.sql.SQLException;
import java.util.UUID;
import javax.sql.DataSource;
import com.zaxxer.hikari.HikariDataSource;
import org.junit.Test;
import org.springframework.boot.jdbc.DataSourceBuilder;
import org.springframework.boot.jdbc.DataSourceInitializationMode;
import org.springframework.jdbc.core.JdbcTemplate;
import static org.assertj.core.api.Assertions.assertThat;
import static org.mockito.BDDMockito.given;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.verify;
/** 
 * Tests for  {@link DataSourceInitializer}.
 * @author Stephane Nicoll
 */
public class DataSourceInitializerTests {
  @Test public void initializeEmbeddedByDefault(){
    try (HikariDataSource dataSource=createDataSource()){
      DataSourceInitializer initializer=new DataSourceInitializer(dataSource,new DataSourceProperties());
      JdbcTemplate jdbcTemplate=new JdbcTemplate(dataSource);
      assertThat(initializer.createSchema()).isTrue();
      assertNumberOfRows(jdbcTemplate,0);
      initializer.initSchema();
      assertNumberOfRows(jdbcTemplate,1);
    }
   }
  @Test public void initializeWithModeAlways(){
    try (HikariDataSource dataSource=createDataSource()){
      DataSourceProperties properties=new DataSourceProperties();
      properties.setInitializationMode(DataSourceInitializationMode.ALWAYS);
      DataSourceInitializer initializer=new DataSourceInitializer(dataSource,properties);
      JdbcTemplate jdbcTemplate=new JdbcTemplate(dataSource);
      assertThat(initializer.createSchema()).isTrue();
      assertNumberOfRows(jdbcTemplate,0);
      initializer.initSchema();
      assertNumberOfRows(jdbcTemplate,1);
    }
   }
  private void assertNumberOfRows(  JdbcTemplate jdbcTemplate,  int count){
    assertThat(jdbcTemplate.queryForObject("SELECT COUNT(*) from BAR",Integer.class)).isEqualTo(count);
  }
  @Test public void initializeWithModeNever(){
    try (HikariDataSource dataSource=createDataSource()){
      DataSourceProperties properties=new DataSourceProperties();
      properties.setInitializationMode(DataSourceInitializationMode.NEVER);
      DataSourceInitializer initializer=new DataSourceInitializer(dataSource,properties);
      assertThat(initializer.createSchema()).isFalse();
    }
   }
  @Test public void initializeOnlyEmbeddedByDefault() throws SQLException {
    DatabaseMetaData metadata=mock(DatabaseMetaData.class);
    given(metadata.getDatabaseProductName()).willReturn("MySQL");
    Connection connection=mock(Connection.class);
    given(connection.getMetaData()).willReturn(metadata);
    DataSource dataSource=mock(DataSource.class);
    given(dataSource.getConnection()).willReturn(connection);
    DataSourceInitializer initializer=new DataSourceInitializer(dataSource,new DataSourceProperties());
    assertThat(initializer.createSchema()).isFalse();
    verify(dataSource).getConnection();
  }
  private HikariDataSource createDataSource(){
    return DataSourceBuilder.create().type(HikariDataSource.class).url("jdbc:h2:mem:" + UUID.randomUUID()).build();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.autoconfigure.condition;
import org.junit.Test;
import reactor.core.publisher.Mono;
import org.springframework.boot.autoconfigure.web.reactive.MockReactiveWebServerFactory;
import org.springframework.boot.test.context.runner.ApplicationContextRunner;
import org.springframework.boot.test.context.runner.ReactiveWebApplicationContextRunner;
import org.springframework.boot.test.context.runner.WebApplicationContextRunner;
import org.springframework.boot.web.reactive.server.ReactiveWebServerFactory;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.http.server.reactive.HttpHandler;
import static org.assertj.core.api.Assertions.assertThat;
import static org.assertj.core.api.Assertions.entry;
/** 
 * Tests for  {@link ConditionalOnNotWebApplication}.
 * @author Dave Syer
 * @author Stephane Nicoll
 */
public class ConditionalOnNotWebApplicationTests {
  @Test public void testNotWebApplicationWithServletContext(){
    new WebApplicationContextRunner().withUserConfiguration(NotWebApplicationConfiguration.class).run((context) -> assertThat(context).doesNotHaveBean(String.class));
  }
  @Test public void testNotWebApplicationWithReactiveContext(){
    new ReactiveWebApplicationContextRunner().withUserConfiguration(ReactiveApplicationConfig.class,NotWebApplicationConfiguration.class).run((context) -> assertThat(context).doesNotHaveBean(String.class));
  }
  @Test public void testNotWebApplication(){
    new ApplicationContextRunner().withUserConfiguration(NotWebApplicationConfiguration.class).run((context) -> assertThat(context).getBeans(String.class).containsExactly(entry("none","none")));
  }
@Configuration protected static class ReactiveApplicationConfig {
    @Bean public ReactiveWebServerFactory reactiveWebServerFactory(){
      return new MockReactiveWebServerFactory();
    }
    @Bean public HttpHandler httpHandler(){
      return (request,response) -> Mono.empty();
    }
  }
@Configuration @ConditionalOnNotWebApplication protected static class NotWebApplicationConfiguration {
    @Bean public String none(){
      return "none";
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.testsupport;
import org.junit.AssumptionViolatedException;
import org.springframework.util.ClassUtils;
/** 
 * Provides utility methods that allow JUnit tests to  {@link org.junit.Assume} certainconditions hold  {@code true}. If the assumption fails, it means the test should be skipped.
 * @author Stephane Nicoll
 */
public abstract class Assume {
  public static void javaEight(){
    if (ClassUtils.isPresent("java.security.cert.URICertStoreParameters",null)) {
      throw new AssumptionViolatedException("Assumed Java 8 but got Java 9");
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.gradle.tasks.bundling;
import java.io.File;
import java.io.IOException;
import java.util.jar.JarFile;
import org.gradle.testkit.runner.InvalidRunnerConfigurationException;
import org.gradle.testkit.runner.TaskOutcome;
import org.gradle.testkit.runner.UnexpectedBuildFailure;
import org.junit.Rule;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.boot.gradle.junit.GradleCompatibilitySuite;
import org.springframework.boot.gradle.testkit.GradleBuild;
import org.springframework.boot.loader.tools.FileUtils;
import static org.assertj.core.api.Assertions.assertThat;
/** 
 * Integration tests for  {@link BootJar}.
 * @author Andy Wilkinson
 */
@RunWith(GradleCompatibilitySuite.class) public abstract class AbstractBootArchiveIntegrationTests {
  @Rule public GradleBuild gradleBuild;
  private final String taskName;
  protected AbstractBootArchiveIntegrationTests(  String taskName){
    this.taskName=taskName;
  }
  @Test public void basicBuild() throws InvalidRunnerConfigurationException, UnexpectedBuildFailure, IOException {
    assertThat(this.gradleBuild.build(this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
  }
  @Test public void reproducibleArchive() throws InvalidRunnerConfigurationException, UnexpectedBuildFailure, IOException, InterruptedException {
    assertThat(this.gradleBuild.build(this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
    File jar=new File(this.gradleBuild.getProjectDir(),"build/libs").listFiles()[0];
    String firstHash=FileUtils.sha1Hash(jar);
    Thread.sleep(1500);
    assertThat(this.gradleBuild.build("clean",this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
    String secondHash=FileUtils.sha1Hash(jar);
    assertThat(firstHash).isEqualTo(secondHash);
  }
  @Test public void upToDateWhenBuiltTwice() throws InvalidRunnerConfigurationException, UnexpectedBuildFailure, IOException {
    assertThat(this.gradleBuild.build(this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
    assertThat(this.gradleBuild.build(this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.UP_TO_DATE);
  }
  @Test public void upToDateWhenBuiltTwiceWithLaunchScriptIncluded() throws InvalidRunnerConfigurationException, UnexpectedBuildFailure, IOException {
    assertThat(this.gradleBuild.build("-PincludeLaunchScript=true",this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
    assertThat(this.gradleBuild.build("-PincludeLaunchScript=true",this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.UP_TO_DATE);
  }
  @Test public void notUpToDateWhenLaunchScriptWasNotIncludedAndThenIsIncluded(){
    assertThat(this.gradleBuild.build(this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
    assertThat(this.gradleBuild.build("-PincludeLaunchScript=true",this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
  }
  @Test public void notUpToDateWhenLaunchScriptWasIncludedAndThenIsNotIncluded(){
    assertThat(this.gradleBuild.build(this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
    assertThat(this.gradleBuild.build("-PincludeLaunchScript=true",this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
  }
  @Test public void notUpToDateWhenLaunchScriptPropertyChanges(){
    assertThat(this.gradleBuild.build("-PincludeLaunchScript=true","-PlaunchScriptProperty=foo",this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
    assertThat(this.gradleBuild.build("-PincludeLaunchScript=true","-PlaunchScriptProperty=bar",this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
  }
  @Test public void applicationPluginMainClassNameIsUsed() throws IOException {
    assertThat(this.gradleBuild.build(this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
    try (JarFile jarFile=new JarFile(new File(this.gradleBuild.getProjectDir(),"build/libs").listFiles()[0])){
      assertThat(jarFile.getManifest().getMainAttributes().getValue("Start-Class")).isEqualTo("com.example.CustomMain");
    }
   }
  @Test public void springBootExtensionMainClassNameIsUsed() throws IOException {
    assertThat(this.gradleBuild.build(this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
    try (JarFile jarFile=new JarFile(new File(this.gradleBuild.getProjectDir(),"build/libs").listFiles()[0])){
      assertThat(jarFile.getManifest().getMainAttributes().getValue("Start-Class")).isEqualTo("com.example.CustomMain");
    }
   }
  @Test public void duplicatesAreHandledGracefully() throws IOException {
    assertThat(this.gradleBuild.build(this.taskName).task(":" + this.taskName).getOutcome()).isEqualTo(TaskOutcome.SUCCESS);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.cli;
import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.lang.reflect.Field;
import java.net.URI;
import java.net.URL;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;
import org.junit.Assume;
import org.junit.rules.TestRule;
import org.junit.runner.Description;
import org.junit.runners.model.Statement;
import org.springframework.boot.cli.command.AbstractCommand;
import org.springframework.boot.cli.command.OptionParsingCommand;
import org.springframework.boot.cli.command.archive.JarCommand;
import org.springframework.boot.cli.command.grab.GrabCommand;
import org.springframework.boot.cli.command.run.RunCommand;
import org.springframework.boot.test.rule.OutputCapture;
import org.springframework.util.FileCopyUtils;
import org.springframework.util.StringUtils;
/** 
 * {@link TestRule} that can be used to invoke CLI commands.
 * @author Phillip Webb
 * @author Dave Syer
 * @author Andy Wilkinson
 */
public class CliTester implements TestRule {
  private final OutputCapture outputCapture=new OutputCapture();
  private long timeout=TimeUnit.MINUTES.toMillis(6);
  private final List<AbstractCommand> commands=new ArrayList<>();
  private final String prefix;
  public CliTester(  String prefix){
    this.prefix=prefix;
  }
  public void setTimeout(  long timeout){
    this.timeout=timeout;
  }
  public String run(  String... args) throws Exception {
    List<String> updatedArgs=new ArrayList<>();
    boolean classpathUpdated=false;
    for (    String arg : args) {
      if (arg.startsWith("--classpath=")) {
        arg=arg + ":" + new File("target/test-classes").getAbsolutePath();
        classpathUpdated=true;
      }
      updatedArgs.add(arg);
    }
    if (!classpathUpdated) {
      updatedArgs.add("--classpath=.:" + new File("target/test-classes").getAbsolutePath());
    }
    Future<RunCommand> future=submitCommand(new RunCommand(),StringUtils.toStringArray(updatedArgs));
    this.commands.add(future.get(this.timeout,TimeUnit.MILLISECONDS));
    return getOutput();
  }
  public String grab(  String... args) throws Exception {
    Future<GrabCommand> future=submitCommand(new GrabCommand(),args);
    this.commands.add(future.get(this.timeout,TimeUnit.MILLISECONDS));
    return getOutput();
  }
  public String jar(  String... args) throws Exception {
    Future<JarCommand> future=submitCommand(new JarCommand(),args);
    this.commands.add(future.get(this.timeout,TimeUnit.MILLISECONDS));
    return getOutput();
  }
  private <T extends OptionParsingCommand>Future<T> submitCommand(  T command,  String... args){
    clearUrlHandler();
    final String[] sources=getSources(args);
    return Executors.newSingleThreadExecutor().submit(() -> {
      ClassLoader loader=Thread.currentThread().getContextClassLoader();
      System.setProperty("server.port","0");
      System.setProperty("spring.application.class.name","org.springframework.boot.cli.CliTesterSpringApplication");
      System.setProperty("portfile",new File("target/server.port").getAbsolutePath());
      try {
        command.run(sources);
        return command;
      }
  finally {
        System.clearProperty("server.port");
        System.clearProperty("spring.application.class.name");
        System.clearProperty("portfile");
        Thread.currentThread().setContextClassLoader(loader);
      }
    }
);
  }
  /** 
 * The TomcatURLStreamHandlerFactory fails if the factory is already set, use reflection to reset it.
 */
  private void clearUrlHandler(){
    try {
      Field field=URL.class.getDeclaredField("factory");
      field.setAccessible(true);
      field.set(null,null);
    }
 catch (    Exception ex) {
      throw new IllegalStateException(ex);
    }
  }
  protected String[] getSources(  String... args){
    final String[] sources=new String[args.length];
    for (int i=0; i < args.length; i++) {
      String arg=args[i];
      if (!arg.endsWith(".groovy") && !arg.endsWith(".xml")) {
        if (new File(this.prefix + arg).isDirectory()) {
          sources[i]=this.prefix + arg;
        }
 else {
          sources[i]=arg;
        }
      }
 else {
        sources[i]=new File(arg).isAbsolute() ? arg : this.prefix + arg;
      }
    }
    return sources;
  }
  private String getOutput(){
    String output=this.outputCapture.toString();
    this.outputCapture.reset();
    return output;
  }
  @Override public Statement apply(  Statement base,  Description description){
    final Statement statement=CliTester.this.outputCapture.apply(new RunLauncherStatement(base),description);
    return new Statement(){
      @Override public void evaluate() throws Throwable {
        Assume.assumeTrue("Not running sample integration tests because integration profile not active",System.getProperty("spring.profiles.active","integration").contains("integration"));
        statement.evaluate();
      }
    }
;
  }
  public String getHttpOutput(){
    return getHttpOutput("/");
  }
  public String getHttpOutput(  String uri){
    try {
      int port=Integer.parseInt(FileCopyUtils.copyToString(new FileReader("target/server.port")));
      InputStream stream=URI.create("http://localhost:" + port + uri).toURL().openStream();
      BufferedReader reader=new BufferedReader(new InputStreamReader(stream));
      return reader.lines().collect(Collectors.joining());
    }
 catch (    Exception ex) {
      throw new IllegalStateException(ex);
    }
  }
private final class RunLauncherStatement extends Statement {
    private final Statement base;
    private RunLauncherStatement(    Statement base){
      this.base=base;
    }
    @Override public void evaluate() throws Throwable {
      System.setProperty("disableSpringSnapshotRepos","false");
      try {
        try {
          this.base.evaluate();
        }
  finally {
          for (          AbstractCommand command : CliTester.this.commands) {
            if (command != null && command instanceof RunCommand) {
              ((RunCommand)command).stop();
            }
          }
          System.clearProperty("disableSpringSnapshotRepos");
        }
      }
 catch (      Exception ex) {
        throw new IllegalStateException(ex);
      }
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.cli.command;
import org.junit.Rule;
import org.junit.Test;
import org.springframework.boot.cli.command.run.RunCommand;
import org.springframework.boot.test.rule.OutputCapture;
import static org.assertj.core.api.Assertions.assertThat;
/** 
 * @author Dave Syer
 */
public class CommandRunnerIntegrationTests {
  @Rule public OutputCapture output=new OutputCapture();
  @Test public void debugAddsAutoconfigReport(){
    CommandRunner runner=new CommandRunner("spring");
    runner.addCommand(new RunCommand());
    runner.runAndHandleErrors("run","samples/app.groovy","-d");
    assertThat(this.output.toString()).contains("Negative matches:");
  }
  @Test public void debugSwitchedOffForAppArgs(){
    CommandRunner runner=new CommandRunner("spring");
    runner.addCommand(new RunCommand());
    runner.runAndHandleErrors("run","samples/app.groovy","--","-d");
    assertThat(this.output.toString()).doesNotContain("Negative matches:");
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.cli.command;
import org.junit.Test;
import org.springframework.boot.cli.command.options.OptionHandler;
import static org.assertj.core.api.Assertions.assertThat;
/** 
 * Tests for  {@link OptionParsingCommand}.
 * @author Dave Syer
 */
public class OptionParsingCommandTests {
  @Test public void optionHelp(){
    OptionHandler handler=new OptionHandler();
    handler.option("bar","Bar");
    OptionParsingCommand command=new TestOptionParsingCommand("foo","Foo",handler);
    assertThat(command.getHelp()).contains("--bar");
  }
private static class TestOptionParsingCommand extends OptionParsingCommand {
    TestOptionParsingCommand(    String name,    String description,    OptionHandler handler){
      super(name,description,handler);
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.cli.compiler.dependencies;
import org.junit.Test;
import static org.assertj.core.api.Assertions.assertThat;
import static org.hamcrest.Matchers.empty;
/** 
 * Tests for  {@link SpringBootDependenciesDependencyManagement}
 * @author Andy Wilkinson
 */
public class SpringBootDependenciesDependencyManagementTests {
  private final DependencyManagement dependencyManagement=new SpringBootDependenciesDependencyManagement();
  @Test public void springBootVersion(){
    assertThat(this.dependencyManagement.getSpringBootVersion()).isNotNull();
  }
  @Test public void find(){
    Dependency dependency=this.dependencyManagement.find("spring-boot");
    assertThat(dependency).isNotNull();
    assertThat(dependency.getGroupId()).isEqualTo("org.springframework.boot");
    assertThat(dependency.getArtifactId()).isEqualTo("spring-boot");
  }
  @Test public void getDependencies(){
    assertThat(this.dependencyManagement.getDependencies()).isNotEqualTo(empty());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.test.autoconfigure.web.servlet;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.core.env.Environment;
import org.springframework.test.context.junit4.SpringRunner;
import static org.assertj.core.api.Assertions.assertThat;
/** 
 * Tests for the  {@link WebMvcTest#properties properties} attribute of{@link WebMvcTest @WebMvcTest}.
 * @author Artsiom Yudovin
 */
@RunWith(SpringRunner.class) @WebMvcTest(properties="spring.profiles.active=test") public class WebMvcTestPropertiesIntegrationTests {
  @Autowired private Environment environment;
  @Test public void environmentWithNewProfile(){
    assertThat(this.environment.getActiveProfiles()).containsExactly("test");
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.actuate.autoconfigure.metrics.jersey;
import java.net.URI;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.PathParam;
import io.micrometer.core.instrument.MeterRegistry;
import io.micrometer.core.instrument.Tag;
import io.micrometer.core.instrument.Timer;
import io.micrometer.jersey2.server.DefaultJerseyTagsProvider;
import io.micrometer.jersey2.server.JerseyTagsProvider;
import io.micrometer.jersey2.server.MetricsApplicationEventListener;
import org.glassfish.jersey.server.ResourceConfig;
import org.glassfish.jersey.server.monitoring.RequestEvent;
import org.junit.Test;
import org.springframework.boot.actuate.autoconfigure.metrics.MetricsAutoConfiguration;
import org.springframework.boot.actuate.autoconfigure.metrics.export.simple.SimpleMetricsExportAutoConfiguration;
import org.springframework.boot.actuate.autoconfigure.metrics.test.MetricsRun;
import org.springframework.boot.autoconfigure.AutoConfigurations;
import org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration;
import org.springframework.boot.autoconfigure.jersey.ResourceConfigCustomizer;
import org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryAutoConfiguration;
import org.springframework.boot.test.context.FilteredClassLoader;
import org.springframework.boot.test.context.assertj.AssertableWebApplicationContext;
import org.springframework.boot.test.context.runner.ApplicationContextRunner;
import org.springframework.boot.test.context.runner.WebApplicationContextRunner;
import org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext;
import org.springframework.context.annotation.Bean;
import org.springframework.web.client.RestTemplate;
import static org.assertj.core.api.Assertions.assertThat;
/** 
 * Tests for  {@link JerseyServerMetricsAutoConfiguration}.
 * @author Michael Weirauch
 * @author Michael Simons
 */
public class JerseyServerMetricsAutoConfigurationTests {
  private final ApplicationContextRunner contextRunner=new ApplicationContextRunner().with(MetricsRun.simple()).withConfiguration(AutoConfigurations.of(JerseyServerMetricsAutoConfiguration.class));
  private final WebApplicationContextRunner webContextRunner=new WebApplicationContextRunner(AnnotationConfigServletWebServerApplicationContext::new).withConfiguration(AutoConfigurations.of(JerseyAutoConfiguration.class,JerseyServerMetricsAutoConfiguration.class,ServletWebServerFactoryAutoConfiguration.class,SimpleMetricsExportAutoConfiguration.class,MetricsAutoConfiguration.class)).withUserConfiguration(ResourceConfiguration.class).withPropertyValues("server.port:0");
  @Test public void shouldOnlyBeActiveInWebApplicationContext(){
    this.contextRunner.run((context) -> assertThat(context).doesNotHaveBean(ResourceConfigCustomizer.class));
  }
  @Test public void shouldProvideAllNecessaryBeans(){
    this.webContextRunner.run((context) -> assertThat(context).hasSingleBean(DefaultJerseyTagsProvider.class).hasSingleBean(ResourceConfigCustomizer.class));
  }
  @Test public void shouldHonorExistingTagProvider(){
    this.webContextRunner.withUserConfiguration(CustomJerseyTagsProviderConfiguration.class).run((context) -> assertThat(context).hasSingleBean(CustomJerseyTagsProvider.class));
  }
  @Test public void httpRequestsAreTimed(){
    this.webContextRunner.run((context) -> {
      doRequest(context);
      MeterRegistry registry=context.getBean(MeterRegistry.class);
      Timer timer=registry.get("http.server.requests").tag("uri","/users/{id}").timer();
      assertThat(timer.count()).isEqualTo(1);
    }
);
  }
  @Test public void noHttpRequestsTimedWhenJerseyInstrumentationMissingFromClasspath(){
    this.webContextRunner.withClassLoader(new FilteredClassLoader(MetricsApplicationEventListener.class)).run((context) -> {
      doRequest(context);
      MeterRegistry registry=context.getBean(MeterRegistry.class);
      assertThat(registry.find("http.server.requests").timer()).isNull();
    }
);
  }
  private static void doRequest(  AssertableWebApplicationContext context){
    int port=context.getSourceApplicationContext(AnnotationConfigServletWebServerApplicationContext.class).getWebServer().getPort();
    RestTemplate restTemplate=new RestTemplate();
    restTemplate.getForEntity(URI.create("http://localhost:" + port + "/users/3"),String.class);
  }
static class ResourceConfiguration {
    @Bean ResourceConfig resourceConfig(){
      return new ResourceConfig().register(new TestResource());
    }
@Path("/users") public class TestResource {
      @GET @Path("/{id}") public String getUser(      @PathParam("id") String id){
        return id;
      }
    }
  }
static class CustomJerseyTagsProviderConfiguration {
    @Bean JerseyTagsProvider customJerseyTagsProvider(){
      return new CustomJerseyTagsProvider();
    }
  }
static class CustomJerseyTagsProvider implements JerseyTagsProvider {
    @Override public Iterable<Tag> httpRequestTags(    RequestEvent event){
      return null;
    }
    @Override public Iterable<Tag> httpLongRequestTags(    RequestEvent event){
      return null;
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.actuate.autoconfigure.security.reactive;
import java.net.URI;
import java.util.Collections;
import java.util.List;
import org.junit.Test;
import reactor.core.publisher.Mono;
import org.springframework.beans.BeansException;
import org.springframework.boot.actuate.autoconfigure.endpoint.EndpointAutoConfiguration;
import org.springframework.boot.actuate.autoconfigure.endpoint.web.WebEndpointAutoConfiguration;
import org.springframework.boot.actuate.autoconfigure.env.EnvironmentEndpointAutoConfiguration;
import org.springframework.boot.actuate.autoconfigure.health.HealthEndpointAutoConfiguration;
import org.springframework.boot.actuate.autoconfigure.health.HealthIndicatorAutoConfiguration;
import org.springframework.boot.actuate.autoconfigure.info.InfoEndpointAutoConfiguration;
import org.springframework.boot.autoconfigure.AutoConfigurations;
import org.springframework.boot.autoconfigure.security.reactive.ReactiveSecurityAutoConfiguration;
import org.springframework.boot.autoconfigure.security.reactive.ReactiveUserDetailsServiceAutoConfiguration;
import org.springframework.boot.test.context.assertj.AssertableReactiveWebApplicationContext;
import org.springframework.boot.test.context.runner.ReactiveWebApplicationContextRunner;
import org.springframework.context.ApplicationContext;
import org.springframework.context.ApplicationContextAware;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.http.HttpHeaders;
import org.springframework.http.server.reactive.ServerHttpRequest;
import org.springframework.http.server.reactive.ServerHttpResponse;
import org.springframework.mock.http.server.reactive.MockServerHttpRequest;
import org.springframework.mock.http.server.reactive.MockServerHttpResponse;
import org.springframework.security.authentication.ReactiveAuthenticationManager;
import org.springframework.security.config.web.server.ServerHttpSecurity;
import org.springframework.security.web.server.SecurityWebFilterChain;
import org.springframework.security.web.server.WebFilterChainProxy;
import org.springframework.web.server.ServerWebExchange;
import org.springframework.web.server.WebHandler;
import org.springframework.web.server.adapter.HttpWebHandlerAdapter;
import static org.assertj.core.api.Assertions.assertThat;
import static org.mockito.Mockito.mock;
/** 
 * Tests for  {@link ReactiveManagementWebSecurityAutoConfiguration}.
 * @author Madhura Bhave
 */
public class ReactiveManagementWebSecurityAutoConfigurationTests {
  private ReactiveWebApplicationContextRunner contextRunner=new ReactiveWebApplicationContextRunner().withConfiguration(AutoConfigurations.of(HealthIndicatorAutoConfiguration.class,HealthEndpointAutoConfiguration.class,InfoEndpointAutoConfiguration.class,EnvironmentEndpointAutoConfiguration.class,EndpointAutoConfiguration.class,WebEndpointAutoConfiguration.class,ReactiveSecurityAutoConfiguration.class,ReactiveUserDetailsServiceAutoConfiguration.class,ReactiveManagementWebSecurityAutoConfiguration.class));
  @Test public void permitAllForHealth(){
    this.contextRunner.run((context) -> assertThat(getAuthenticateHeader(context,"/actuator/health")).isNull());
  }
  @Test public void permitAllForInfo(){
    this.contextRunner.run((context) -> assertThat(getAuthenticateHeader(context,"/actuator/info")).isNull());
  }
  @Test public void securesEverythingElse(){
    this.contextRunner.run((context) -> {
      assertThat(getAuthenticateHeader(context,"/actuator").get(0)).contains("Basic realm=");
      assertThat(getAuthenticateHeader(context,"/foo").toString()).contains("Basic realm=");
    }
);
  }
  @Test public void usesMatchersBasedOffConfiguredActuatorBasePath(){
    this.contextRunner.withPropertyValues("management.endpoints.web.base-path=/").run((context) -> {
      assertThat(getAuthenticateHeader(context,"/health")).isNull();
      assertThat(getAuthenticateHeader(context,"/foo").get(0)).contains("Basic realm=");
    }
);
  }
  @Test public void backsOffIfCustomSecurityIsAdded(){
    this.contextRunner.withUserConfiguration(CustomSecurityConfiguration.class).run((context) -> {
      assertThat(getLocationHeader(context,"/actuator/health").toString()).contains("/login");
      assertThat(getLocationHeader(context,"/foo")).isNull();
    }
);
  }
  @Test public void backsOffWhenWebFilterChainProxyBeanPresent(){
    this.contextRunner.withUserConfiguration(WebFilterChainProxyConfiguration.class).run((context) -> {
      assertThat(getLocationHeader(context,"/actuator/health").toString()).contains("/login");
      assertThat(getLocationHeader(context,"/foo").toString()).contains("/login");
    }
);
  }
  private List<String> getAuthenticateHeader(  AssertableReactiveWebApplicationContext context,  String path){
    ServerWebExchange exchange=performFilter(context,path);
    return exchange.getResponse().getHeaders().get(HttpHeaders.WWW_AUTHENTICATE);
  }
  private ServerWebExchange performFilter(  AssertableReactiveWebApplicationContext context,  String path){
    ServerWebExchange exchange=webHandler(context).createExchange(MockServerHttpRequest.get(path).build(),new MockServerHttpResponse());
    WebFilterChainProxy proxy=context.getBean(WebFilterChainProxy.class);
    proxy.filter(exchange,(serverWebExchange) -> Mono.empty()).block();
    return exchange;
  }
  private URI getLocationHeader(  AssertableReactiveWebApplicationContext context,  String path){
    ServerWebExchange exchange=performFilter(context,path);
    return exchange.getResponse().getHeaders().getLocation();
  }
  private TestHttpWebHandlerAdapter webHandler(  AssertableReactiveWebApplicationContext context){
    TestHttpWebHandlerAdapter adapter=new TestHttpWebHandlerAdapter(mock(WebHandler.class));
    adapter.setApplicationContext(context);
    return adapter;
  }
private static class TestHttpWebHandlerAdapter extends HttpWebHandlerAdapter {
    TestHttpWebHandlerAdapter(    WebHandler delegate){
      super(delegate);
    }
    @Override protected ServerWebExchange createExchange(    ServerHttpRequest request,    ServerHttpResponse response){
      return super.createExchange(request,response);
    }
  }
@Configuration static class CustomSecurityConfiguration {
    @Bean public SecurityWebFilterChain springSecurityFilterChain(    ServerHttpSecurity http){
      return http.authorizeExchange().pathMatchers("/foo").permitAll().anyExchange().authenticated().and().formLogin().and().build();
    }
  }
@Configuration static class WebFilterChainProxyConfiguration {
    @Bean public ReactiveAuthenticationManager authenticationManager(){
      return mock(ReactiveAuthenticationManager.class);
    }
    @Bean public WebFilterChainProxy webFilterChainProxy(    ServerHttpSecurity http){
      return new WebFilterChainProxy(getFilterChains(http));
    }
    @Bean public TestServerHttpSecurity http(    ReactiveAuthenticationManager authenticationManager){
      TestServerHttpSecurity httpSecurity=new TestServerHttpSecurity();
      httpSecurity.authenticationManager(authenticationManager);
      return httpSecurity;
    }
    private List<SecurityWebFilterChain> getFilterChains(    ServerHttpSecurity http){
      return Collections.singletonList(http.authorizeExchange().anyExchange().authenticated().and().formLogin().and().build());
    }
private static class TestServerHttpSecurity extends ServerHttpSecurity implements ApplicationContextAware {
      @Override public void setApplicationContext(      ApplicationContext applicationContext) throws BeansException {
        super.setApplicationContext(applicationContext);
      }
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.actuate.endpoint.invoke.convert;
import java.time.OffsetDateTime;
import org.junit.Test;
import org.springframework.core.convert.support.DefaultConversionService;
import static org.assertj.core.api.Assertions.assertThat;
/** 
 * Tests for  {@link IsoOffsetDateTimeConverter}.
 * @author Phillip Webb
 */
public class IsoOffsetDateTimeConverterTests {
  @Test public void convertShouldConvertIsoDate(){
    IsoOffsetDateTimeConverter converter=new IsoOffsetDateTimeConverter();
    OffsetDateTime time=converter.convert("2011-12-03T10:15:30+01:00");
    assertThat(time).isNotNull();
  }
  @Test public void registerConverterShouldRegister(){
    DefaultConversionService service=new DefaultConversionService();
    IsoOffsetDateTimeConverter.registerConverter(service);
    OffsetDateTime time=service.convert("2011-12-03T10:15:30+01:00",OffsetDateTime.class);
    assertThat(time).isNotNull();
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.boot.jdbc;
import org.junit.Test;
import static org.assertj.core.api.Assertions.assertThat;
import static org.assertj.core.api.Assertions.assertThatIllegalArgumentException;
/** 
 * Tests for  {@link EmbeddedDatabaseConnection}.
 * @author Stephane Nicoll
 */
public class EmbeddedDatabaseConnectionTests {
  @Test public void h2CustomDatabaseName(){
    assertThat(EmbeddedDatabaseConnection.H2.getUrl("mydb")).isEqualTo("jdbc:h2:mem:mydb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE");
  }
  @Test public void derbyCustomDatabaseName(){
    assertThat(EmbeddedDatabaseConnection.DERBY.getUrl("myderbydb")).isEqualTo("jdbc:derby:memory:myderbydb;create=true");
  }
  @Test public void hsqlCustomDatabaseName(){
    assertThat(EmbeddedDatabaseConnection.HSQL.getUrl("myhsql")).isEqualTo("jdbc:hsqldb:mem:myhsql");
  }
  @Test public void getUrlWithNullDatabaseName(){
    assertThatIllegalArgumentException().isThrownBy(() -> EmbeddedDatabaseConnection.HSQL.getUrl(null)).withMessageContaining("DatabaseName must not be empty");
  }
  @Test public void getUrlWithEmptyDatabaseName(){
    assertThatIllegalArgumentException().isThrownBy(() -> EmbeddedDatabaseConnection.HSQL.getUrl("  ")).withMessageContaining("DatabaseName must not be empty");
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from spring-boot-2.1.1.RELEASE~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.reactive.config;
import java.util.List;
import org.junit.Before;
import org.junit.Test;
import org.springframework.beans.DirectFieldAccessor;
import org.springframework.core.Ordered;
import org.springframework.http.codec.json.Jackson2JsonEncoder;
import org.springframework.web.context.support.StaticWebApplicationContext;
import org.springframework.web.reactive.result.view.HttpMessageWriterView;
import org.springframework.web.reactive.result.view.UrlBasedViewResolver;
import org.springframework.web.reactive.result.view.View;
import org.springframework.web.reactive.result.view.ViewResolver;
import org.springframework.web.reactive.result.view.freemarker.FreeMarkerConfigurer;
import org.springframework.web.reactive.result.view.script.ScriptTemplateConfigurer;
import org.springframework.web.reactive.result.view.script.ScriptTemplateViewResolver;
import static org.junit.Assert.*;
/** 
 * Unit tests for  {@link ViewResolverRegistry}.
 * @author Rossen Stoyanchev
 * @author Sebastien Deleuze
 */
public class ViewResolverRegistryTests {
  private ViewResolverRegistry registry;
  @Before public void setup(){
    StaticWebApplicationContext context=new StaticWebApplicationContext();
    context.registerSingleton("freeMarkerConfigurer",FreeMarkerConfigurer.class);
    context.registerSingleton("scriptTemplateConfigurer",ScriptTemplateConfigurer.class);
    this.registry=new ViewResolverRegistry(context);
  }
  @Test public void order(){
    assertEquals(Ordered.LOWEST_PRECEDENCE,this.registry.getOrder());
  }
  @Test public void hasRegistrations(){
    assertFalse(this.registry.hasRegistrations());
    this.registry.freeMarker();
    assertTrue(this.registry.hasRegistrations());
  }
  @Test public void noResolvers(){
    assertNotNull(this.registry.getViewResolvers());
    assertEquals(0,this.registry.getViewResolvers().size());
    assertFalse(this.registry.hasRegistrations());
  }
  @Test public void customViewResolver(){
    UrlBasedViewResolver viewResolver=new UrlBasedViewResolver();
    this.registry.viewResolver(viewResolver);
    assertSame(viewResolver,this.registry.getViewResolvers().get(0));
    assertEquals(1,this.registry.getViewResolvers().size());
  }
  @Test public void defaultViews() throws Exception {
    View view=new HttpMessageWriterView(new Jackson2JsonEncoder());
    this.registry.defaultViews(view);
    assertEquals(1,this.registry.getDefaultViews().size());
    assertSame(view,this.registry.getDefaultViews().get(0));
  }
  @Test public void scriptTemplate(){
    this.registry.scriptTemplate().prefix("/").suffix(".html");
    List<ViewResolver> viewResolvers=this.registry.getViewResolvers();
    assertEquals(1,viewResolvers.size());
    assertEquals(ScriptTemplateViewResolver.class,viewResolvers.get(0).getClass());
    DirectFieldAccessor accessor=new DirectFieldAccessor(viewResolvers.get(0));
    assertEquals("/",accessor.getPropertyValue("prefix"));
    assertEquals(".html",accessor.getPropertyValue("suffix"));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.reactive.function.client;
import java.net.URI;
import java.nio.charset.StandardCharsets;
import org.junit.Test;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import reactor.test.StepVerifier;
import org.springframework.core.io.buffer.DataBuffer;
import org.springframework.core.io.buffer.DataBufferUtils;
import org.springframework.core.io.buffer.DefaultDataBufferFactory;
import org.springframework.core.io.buffer.support.DataBufferTestUtils;
import org.springframework.http.HttpHeaders;
import org.springframework.http.HttpMethod;
import org.springframework.http.HttpStatus;
import org.springframework.web.reactive.function.BodyExtractors;
import static org.junit.Assert.*;
import static org.mockito.Mockito.*;
/** 
 * Unit tests for  {@link ExchangeFilterFunctions}.
 * @author Arjen Poutsma
 */
public class ExchangeFilterFunctionsTests {
  private static final URI DEFAULT_URL=URI.create("http://example.com");
  @Test public void andThen(){
    ClientRequest request=ClientRequest.create(HttpMethod.GET,DEFAULT_URL).build();
    ClientResponse response=mock(ClientResponse.class);
    ExchangeFunction exchange=r -> Mono.just(response);
    boolean[] filtersInvoked=new boolean[2];
    ExchangeFilterFunction filter1=(r,n) -> {
      assertFalse(filtersInvoked[0]);
      assertFalse(filtersInvoked[1]);
      filtersInvoked[0]=true;
      assertFalse(filtersInvoked[1]);
      return n.exchange(r);
    }
;
    ExchangeFilterFunction filter2=(r,n) -> {
      assertTrue(filtersInvoked[0]);
      assertFalse(filtersInvoked[1]);
      filtersInvoked[1]=true;
      return n.exchange(r);
    }
;
    ExchangeFilterFunction filter=filter1.andThen(filter2);
    ClientResponse result=filter.filter(request,exchange).block();
    assertEquals(response,result);
    assertTrue(filtersInvoked[0]);
    assertTrue(filtersInvoked[1]);
  }
  @Test public void apply(){
    ClientRequest request=ClientRequest.create(HttpMethod.GET,DEFAULT_URL).build();
    ClientResponse response=mock(ClientResponse.class);
    ExchangeFunction exchange=r -> Mono.just(response);
    boolean[] filterInvoked=new boolean[1];
    ExchangeFilterFunction filter=(r,n) -> {
      assertFalse(filterInvoked[0]);
      filterInvoked[0]=true;
      return n.exchange(r);
    }
;
    ExchangeFunction filteredExchange=filter.apply(exchange);
    ClientResponse result=filteredExchange.exchange(request).block();
    assertEquals(response,result);
    assertTrue(filterInvoked[0]);
  }
  @Test public void basicAuthenticationUsernamePassword(){
    ClientRequest request=ClientRequest.create(HttpMethod.GET,DEFAULT_URL).build();
    ClientResponse response=mock(ClientResponse.class);
    ExchangeFunction exchange=r -> {
      assertTrue(r.headers().containsKey(HttpHeaders.AUTHORIZATION));
      assertTrue(r.headers().getFirst(HttpHeaders.AUTHORIZATION).startsWith("Basic "));
      return Mono.just(response);
    }
;
    ExchangeFilterFunction auth=ExchangeFilterFunctions.basicAuthentication("foo","bar");
    assertFalse(request.headers().containsKey(HttpHeaders.AUTHORIZATION));
    ClientResponse result=auth.filter(request,exchange).block();
    assertEquals(response,result);
  }
  @Test(expected=IllegalArgumentException.class) public void basicAuthenticationInvalidCharacters(){
    ClientRequest request=ClientRequest.create(HttpMethod.GET,DEFAULT_URL).build();
    ExchangeFunction exchange=r -> Mono.just(mock(ClientResponse.class));
    ExchangeFilterFunctions.basicAuthentication("foo","\ud83d\udca9").filter(request,exchange);
  }
  @Test @SuppressWarnings("deprecation") public void basicAuthenticationAttributes(){
    ClientRequest request=ClientRequest.create(HttpMethod.GET,DEFAULT_URL).attributes(org.springframework.web.reactive.function.client.ExchangeFilterFunctions.Credentials.basicAuthenticationCredentials("foo","bar")).build();
    ClientResponse response=mock(ClientResponse.class);
    ExchangeFunction exchange=r -> {
      assertTrue(r.headers().containsKey(HttpHeaders.AUTHORIZATION));
      assertTrue(r.headers().getFirst(HttpHeaders.AUTHORIZATION).startsWith("Basic "));
      return Mono.just(response);
    }
;
    ExchangeFilterFunction auth=ExchangeFilterFunctions.basicAuthentication();
    assertFalse(request.headers().containsKey(HttpHeaders.AUTHORIZATION));
    ClientResponse result=auth.filter(request,exchange).block();
    assertEquals(response,result);
  }
  @Test @SuppressWarnings("deprecation") public void basicAuthenticationAbsentAttributes(){
    ClientRequest request=ClientRequest.create(HttpMethod.GET,DEFAULT_URL).build();
    ClientResponse response=mock(ClientResponse.class);
    ExchangeFunction exchange=r -> {
      assertFalse(r.headers().containsKey(HttpHeaders.AUTHORIZATION));
      return Mono.just(response);
    }
;
    ExchangeFilterFunction auth=ExchangeFilterFunctions.basicAuthentication();
    assertFalse(request.headers().containsKey(HttpHeaders.AUTHORIZATION));
    ClientResponse result=auth.filter(request,exchange).block();
    assertEquals(response,result);
  }
  @Test public void statusHandlerMatch(){
    ClientRequest request=ClientRequest.create(HttpMethod.GET,DEFAULT_URL).build();
    ClientResponse response=mock(ClientResponse.class);
    when(response.statusCode()).thenReturn(HttpStatus.NOT_FOUND);
    ExchangeFunction exchange=r -> Mono.just(response);
    ExchangeFilterFunction errorHandler=ExchangeFilterFunctions.statusError(HttpStatus::is4xxClientError,r -> new MyException());
    Mono<ClientResponse> result=errorHandler.filter(request,exchange);
    StepVerifier.create(result).expectError(MyException.class).verify();
  }
  @Test public void statusHandlerNoMatch(){
    ClientRequest request=ClientRequest.create(HttpMethod.GET,DEFAULT_URL).build();
    ClientResponse response=mock(ClientResponse.class);
    when(response.statusCode()).thenReturn(HttpStatus.NOT_FOUND);
    Mono<ClientResponse> result=ExchangeFilterFunctions.statusError(HttpStatus::is5xxServerError,req -> new MyException()).filter(request,req -> Mono.just(response));
    StepVerifier.create(result).expectNext(response).expectComplete().verify();
  }
  @Test public void limitResponseSize(){
    DefaultDataBufferFactory bufferFactory=new DefaultDataBufferFactory();
    DataBuffer b1=dataBuffer("foo",bufferFactory);
    DataBuffer b2=dataBuffer("bar",bufferFactory);
    DataBuffer b3=dataBuffer("baz",bufferFactory);
    ClientRequest request=ClientRequest.create(HttpMethod.GET,DEFAULT_URL).build();
    ClientResponse response=ClientResponse.create(HttpStatus.OK).body(Flux.just(b1,b2,b3)).build();
    Mono<ClientResponse> result=ExchangeFilterFunctions.limitResponseSize(5).filter(request,req -> Mono.just(response));
    StepVerifier.create(result.flatMapMany(res -> res.body(BodyExtractors.toDataBuffers()))).consumeNextWith(buffer -> assertEquals("foo",string(buffer))).consumeNextWith(buffer -> assertEquals("ba",string(buffer))).expectComplete().verify();
  }
  private String string(  DataBuffer buffer){
    String value=DataBufferTestUtils.dumpString(buffer,StandardCharsets.UTF_8);
    DataBufferUtils.release(buffer);
    return value;
  }
  private DataBuffer dataBuffer(  String foo,  DefaultDataBufferFactory bufferFactory){
    return bufferFactory.wrap(foo.getBytes(StandardCharsets.UTF_8));
  }
@SuppressWarnings("serial") private static class MyException extends Exception {
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.oxm.jibx;
import java.io.StringWriter;
import javax.xml.transform.stream.StreamResult;
import org.junit.Assume;
import org.junit.BeforeClass;
import org.junit.Test;
import org.springframework.oxm.AbstractMarshallerTests;
import static org.junit.Assert.*;
import static org.xmlunit.matchers.CompareMatcher.*;
/** 
 * NOTE: These tests fail under Eclipse/IDEA because JiBX binding does not occur by default. The Gradle build should succeed, however.
 * @author Arjen Poutsma
 * @author Sam Brannen
 */
public class JibxMarshallerTests extends AbstractMarshallerTests<JibxMarshaller> {
  @BeforeClass public static void compilerAssumptions(){
    Assume.assumeTrue(System.getProperty("java.version").startsWith("1.8."));
  }
  @Override protected JibxMarshaller createMarshaller() throws Exception {
    JibxMarshaller marshaller=new JibxMarshaller();
    marshaller.setTargetPackage("org.springframework.oxm.jibx");
    marshaller.afterPropertiesSet();
    return marshaller;
  }
  @Override protected Object createFlights(){
    Flights flights=new Flights();
    FlightType flight=new FlightType();
    flight.setNumber(42L);
    flights.addFlight(flight);
    return flights;
  }
  @Test(expected=IllegalArgumentException.class) public void afterPropertiesSetNoContextPath() throws Exception {
    JibxMarshaller marshaller=new JibxMarshaller();
    marshaller.afterPropertiesSet();
  }
  @Test public void indentation() throws Exception {
    marshaller.setIndent(4);
    StringWriter writer=new StringWriter();
    marshaller.marshal(flights,new StreamResult(writer));
    String expected="<?xml version=\"1.0\"?>\n" + "<flights xmlns=\"http://samples.springframework.org/flight\">\n" + "    <flight>\n"+ "        <number>42</number>\n"+ "    </flight>\n"+ "</flights>";
    assertThat(writer.toString(),isSimilarTo(expected).ignoreWhitespace());
  }
  @Test public void encodingAndStandalone() throws Exception {
    marshaller.setEncoding("ISO-8859-1");
    marshaller.setStandalone(Boolean.TRUE);
    StringWriter writer=new StringWriter();
    marshaller.marshal(flights,new StreamResult(writer));
    assertTrue("Encoding and standalone not set",writer.toString().startsWith("<?xml version=\"1.0\" encoding=\"ISO-8859-1\" standalone=\"yes\"?>"));
  }
  @Test public void dtd() throws Exception {
    marshaller.setDocTypeRootElementName("flights");
    marshaller.setDocTypeSystemId("flights.dtd");
    StringWriter writer=new StringWriter();
    marshaller.marshal(flights,new StreamResult(writer));
    assertTrue("doc type not written",writer.toString().contains("<!DOCTYPE flights SYSTEM \"flights.dtd\">"));
  }
  @Test public void supports() throws Exception {
    assertTrue("JibxMarshaller does not support Flights",marshaller.supports(Flights.class));
    assertTrue("JibxMarshaller does not support FlightType",marshaller.supports(FlightType.class));
    assertFalse("JibxMarshaller supports illegal type",marshaller.supports(getClass()));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.jms.listener.endpoint;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.ExpectedException;
import org.springframework.jms.support.QosSettings;
import static org.junit.Assert.*;
/** 
 * @author Stephane Nicoll
 */
public class JmsMessageEndpointManagerTests {
  @Rule public final ExpectedException thrown=ExpectedException.none();
  @Test public void isPubSubDomainWithQueue(){
    JmsMessageEndpointManager endpoint=new JmsMessageEndpointManager();
    JmsActivationSpecConfig config=new JmsActivationSpecConfig();
    config.setPubSubDomain(false);
    endpoint.setActivationSpecConfig(config);
    assertEquals(false,endpoint.isPubSubDomain());
    assertEquals(false,endpoint.isReplyPubSubDomain());
  }
  @Test public void isPubSubDomainWithTopic(){
    JmsMessageEndpointManager endpoint=new JmsMessageEndpointManager();
    JmsActivationSpecConfig config=new JmsActivationSpecConfig();
    config.setPubSubDomain(true);
    endpoint.setActivationSpecConfig(config);
    assertEquals(true,endpoint.isPubSubDomain());
    assertEquals(true,endpoint.isReplyPubSubDomain());
  }
  @Test public void pubSubDomainCustomForReply(){
    JmsMessageEndpointManager endpoint=new JmsMessageEndpointManager();
    JmsActivationSpecConfig config=new JmsActivationSpecConfig();
    config.setPubSubDomain(true);
    config.setReplyPubSubDomain(false);
    endpoint.setActivationSpecConfig(config);
    assertEquals(true,endpoint.isPubSubDomain());
    assertEquals(false,endpoint.isReplyPubSubDomain());
  }
  @Test public void customReplyQosSettings(){
    JmsMessageEndpointManager endpoint=new JmsMessageEndpointManager();
    JmsActivationSpecConfig config=new JmsActivationSpecConfig();
    QosSettings settings=new QosSettings(1,3,5);
    config.setReplyQosSettings(settings);
    endpoint.setActivationSpecConfig(config);
    assertNotNull(endpoint.getReplyQosSettings());
    assertEquals(1,endpoint.getReplyQosSettings().getDeliveryMode());
    assertEquals(3,endpoint.getReplyQosSettings().getPriority());
    assertEquals(5,endpoint.getReplyQosSettings().getTimeToLive());
  }
  @Test public void isPubSubDomainWithNoConfig(){
    JmsMessageEndpointManager endpoint=new JmsMessageEndpointManager();
    this.thrown.expect(IllegalStateException.class);
    endpoint.isPubSubDomain();
  }
  @Test public void isReplyPubSubDomainWithNoConfig(){
    JmsMessageEndpointManager endpoint=new JmsMessageEndpointManager();
    this.thrown.expect(IllegalStateException.class);
    endpoint.isReplyPubSubDomain();
  }
  @Test public void getReplyQosSettingsWithNoConfig(){
    JmsMessageEndpointManager endpoint=new JmsMessageEndpointManager();
    this.thrown.expect(IllegalStateException.class);
    endpoint.getReplyQosSettings();
  }
  @Test public void getMessageConverterNoConfig(){
    JmsMessageEndpointManager endpoint=new JmsMessageEndpointManager();
    assertNull(endpoint.getMessageConverter());
  }
  @Test public void getDestinationResolverNoConfig(){
    JmsMessageEndpointManager endpoint=new JmsMessageEndpointManager();
    assertNull(endpoint.getDestinationResolver());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.jms.config;
import java.util.HashSet;
import java.util.Iterator;
import java.util.Map;
import java.util.Set;
import javax.jms.ConnectionFactory;
import javax.jms.Message;
import javax.jms.MessageListener;
import javax.jms.TextMessage;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;
import org.springframework.beans.DirectFieldAccessor;
import org.springframework.beans.factory.config.BeanDefinition;
import org.springframework.beans.factory.parsing.ComponentDefinition;
import org.springframework.beans.factory.parsing.CompositeComponentDefinition;
import org.springframework.beans.factory.parsing.EmptyReaderEventListener;
import org.springframework.beans.factory.parsing.PassThroughSourceExtractor;
import org.springframework.beans.factory.parsing.ReaderEventListener;
import org.springframework.beans.factory.xml.XmlBeanDefinitionReader;
import org.springframework.context.Phased;
import org.springframework.context.support.ClassPathXmlApplicationContext;
import org.springframework.jca.endpoint.GenericMessageEndpointManager;
import org.springframework.jms.listener.DefaultMessageListenerContainer;
import org.springframework.jms.listener.adapter.MessageListenerAdapter;
import org.springframework.jms.listener.endpoint.JmsMessageEndpointManager;
import org.springframework.tests.sample.beans.TestBean;
import org.springframework.util.ErrorHandler;
import org.springframework.util.backoff.BackOff;
import org.springframework.util.backoff.FixedBackOff;
import static org.junit.Assert.*;
import static org.mockito.BDDMockito.*;
/** 
 * @author Mark Fisher
 * @author Juergen Hoeller
 * @author Christian Dupuis
 * @author Stephane Nicoll
 */
public class JmsNamespaceHandlerTests {
  private static final String DEFAULT_CONNECTION_FACTORY="connectionFactory";
  private static final String EXPLICIT_CONNECTION_FACTORY="testConnectionFactory";
  private ToolingTestApplicationContext context;
  @Before public void setUp() throws Exception {
    this.context=new ToolingTestApplicationContext("jmsNamespaceHandlerTests.xml",getClass());
  }
  @After public void tearDown() throws Exception {
    this.context.close();
  }
  @Test public void testBeansCreated(){
    Map<String,?> containers=context.getBeansOfType(DefaultMessageListenerContainer.class);
    assertEquals("Context should contain 3 JMS listener containers",3,containers.size());
    containers=context.getBeansOfType(GenericMessageEndpointManager.class);
    assertEquals("Context should contain 3 JCA endpoint containers",3,containers.size());
    Map<String,JmsListenerContainerFactory> containerFactories=context.getBeansOfType(JmsListenerContainerFactory.class);
    assertEquals("Context should contain 3 JmsListenerContainerFactory instances",3,containerFactories.size());
  }
  @Test public void testContainerConfiguration() throws Exception {
    Map<String,DefaultMessageListenerContainer> containers=context.getBeansOfType(DefaultMessageListenerContainer.class);
    ConnectionFactory defaultConnectionFactory=context.getBean(DEFAULT_CONNECTION_FACTORY,ConnectionFactory.class);
    ConnectionFactory explicitConnectionFactory=context.getBean(EXPLICIT_CONNECTION_FACTORY,ConnectionFactory.class);
    int defaultConnectionFactoryCount=0;
    int explicitConnectionFactoryCount=0;
    for (    DefaultMessageListenerContainer container : containers.values()) {
      if (container.getConnectionFactory().equals(defaultConnectionFactory)) {
        defaultConnectionFactoryCount++;
      }
 else       if (container.getConnectionFactory().equals(explicitConnectionFactory)) {
        explicitConnectionFactoryCount++;
      }
    }
    assertEquals("1 container should have the default connectionFactory",1,defaultConnectionFactoryCount);
    assertEquals("2 containers should have the explicit connectionFactory",2,explicitConnectionFactoryCount);
  }
  @Test public void testJcaContainerConfiguration() throws Exception {
    Map<String,JmsMessageEndpointManager> containers=context.getBeansOfType(JmsMessageEndpointManager.class);
    assertTrue("listener3 not found",containers.containsKey("listener3"));
    JmsMessageEndpointManager listener3=containers.get("listener3");
    assertEquals("Wrong resource adapter",context.getBean("testResourceAdapter"),listener3.getResourceAdapter());
    assertEquals("Wrong activation spec factory",context.getBean("testActivationSpecFactory"),new DirectFieldAccessor(listener3).getPropertyValue("activationSpecFactory"));
    Object endpointFactory=new DirectFieldAccessor(listener3).getPropertyValue("endpointFactory");
    Object messageListener=new DirectFieldAccessor(endpointFactory).getPropertyValue("messageListener");
    assertEquals("Wrong message listener",MessageListenerAdapter.class,messageListener.getClass());
    MessageListenerAdapter adapter=(MessageListenerAdapter)messageListener;
    DirectFieldAccessor adapterFieldAccessor=new DirectFieldAccessor(adapter);
    assertEquals("Message converter not set properly",context.getBean("testMessageConverter"),adapterFieldAccessor.getPropertyValue("messageConverter"));
    assertEquals("Wrong delegate",context.getBean("testBean1"),adapterFieldAccessor.getPropertyValue("delegate"));
    assertEquals("Wrong method name","setName",adapterFieldAccessor.getPropertyValue("defaultListenerMethod"));
  }
  @Test public void testJmsContainerFactoryConfiguration(){
    Map<String,DefaultJmsListenerContainerFactory> containers=context.getBeansOfType(DefaultJmsListenerContainerFactory.class);
    DefaultJmsListenerContainerFactory factory=containers.get("testJmsFactory");
    assertNotNull("No factory registered with testJmsFactory id",factory);
    DefaultMessageListenerContainer container=factory.createListenerContainer(createDummyEndpoint());
    assertEquals("explicit connection factory not set",context.getBean(EXPLICIT_CONNECTION_FACTORY),container.getConnectionFactory());
    assertEquals("explicit destination resolver not set",context.getBean("testDestinationResolver"),container.getDestinationResolver());
    assertEquals("explicit message converter not set",context.getBean("testMessageConverter"),container.getMessageConverter());
    assertEquals("Wrong pub/sub",true,container.isPubSubDomain());
    assertEquals("Wrong durable flag",true,container.isSubscriptionDurable());
    assertEquals("wrong cache",DefaultMessageListenerContainer.CACHE_CONNECTION,container.getCacheLevel());
    assertEquals("wrong concurrency",3,container.getConcurrentConsumers());
    assertEquals("wrong concurrency",5,container.getMaxConcurrentConsumers());
    assertEquals("wrong prefetch",50,container.getMaxMessagesPerTask());
    assertEquals("Wrong phase",99,container.getPhase());
    assertSame(context.getBean("testBackOff"),new DirectFieldAccessor(container).getPropertyValue("backOff"));
  }
  @Test public void testJcaContainerFactoryConfiguration(){
    Map<String,DefaultJcaListenerContainerFactory> containers=context.getBeansOfType(DefaultJcaListenerContainerFactory.class);
    DefaultJcaListenerContainerFactory factory=containers.get("testJcaFactory");
    assertNotNull("No factory registered with testJcaFactory id",factory);
    JmsMessageEndpointManager container=factory.createListenerContainer(createDummyEndpoint());
    assertEquals("explicit resource adapter not set",context.getBean("testResourceAdapter"),container.getResourceAdapter());
    assertEquals("explicit message converter not set",context.getBean("testMessageConverter"),container.getActivationSpecConfig().getMessageConverter());
    assertEquals("Wrong pub/sub",true,container.isPubSubDomain());
    assertEquals("wrong concurrency",5,container.getActivationSpecConfig().getMaxConcurrency());
    assertEquals("Wrong prefetch",50,container.getActivationSpecConfig().getPrefetchSize());
    assertEquals("Wrong phase",77,container.getPhase());
  }
  @Test public void testListeners() throws Exception {
    TestBean testBean1=context.getBean("testBean1",TestBean.class);
    TestBean testBean2=context.getBean("testBean2",TestBean.class);
    TestMessageListener testBean3=context.getBean("testBean3",TestMessageListener.class);
    assertNull(testBean1.getName());
    assertNull(testBean2.getName());
    assertNull(testBean3.message);
    TextMessage message1=mock(TextMessage.class);
    given(message1.getText()).willReturn("Test1");
    MessageListener listener1=getListener("listener1");
    listener1.onMessage(message1);
    assertEquals("Test1",testBean1.getName());
    TextMessage message2=mock(TextMessage.class);
    given(message2.getText()).willReturn("Test2");
    MessageListener listener2=getListener("listener2");
    listener2.onMessage(message2);
    assertEquals("Test2",testBean2.getName());
    TextMessage message3=mock(TextMessage.class);
    MessageListener listener3=getListener(DefaultMessageListenerContainer.class.getName() + "#0");
    listener3.onMessage(message3);
    assertSame(message3,testBean3.message);
  }
  @Test public void testRecoveryInterval(){
    Object testBackOff=context.getBean("testBackOff");
    BackOff backOff1=getBackOff("listener1");
    BackOff backOff2=getBackOff("listener2");
    long recoveryInterval3=getRecoveryInterval(DefaultMessageListenerContainer.class.getName() + "#0");
    assertSame(testBackOff,backOff1);
    assertSame(testBackOff,backOff2);
    assertEquals(DefaultMessageListenerContainer.DEFAULT_RECOVERY_INTERVAL,recoveryInterval3);
  }
  @Test public void testConcurrency(){
    DefaultMessageListenerContainer listener0=this.context.getBean(DefaultMessageListenerContainer.class.getName() + "#0",DefaultMessageListenerContainer.class);
    DefaultMessageListenerContainer listener1=this.context.getBean("listener1",DefaultMessageListenerContainer.class);
    DefaultMessageListenerContainer listener2=this.context.getBean("listener2",DefaultMessageListenerContainer.class);
    assertEquals("Wrong concurrency on listener using placeholder",2,listener0.getConcurrentConsumers());
    assertEquals("Wrong concurrency on listener using placeholder",3,listener0.getMaxConcurrentConsumers());
    assertEquals("Wrong concurrency on listener1",3,listener1.getConcurrentConsumers());
    assertEquals("Wrong max concurrency on listener1",5,listener1.getMaxConcurrentConsumers());
    assertEquals("Wrong custom concurrency on listener2",5,listener2.getConcurrentConsumers());
    assertEquals("Wrong custom max concurrency on listener2",10,listener2.getMaxConcurrentConsumers());
    JmsMessageEndpointManager listener3=this.context.getBean("listener3",JmsMessageEndpointManager.class);
    JmsMessageEndpointManager listener4=this.context.getBean("listener4",JmsMessageEndpointManager.class);
    assertEquals("Wrong concurrency on listener3",5,listener3.getActivationSpecConfig().getMaxConcurrency());
    assertEquals("Wrong custom concurrency on listener4",7,listener4.getActivationSpecConfig().getMaxConcurrency());
  }
  @Test public void testResponseDestination(){
    DefaultMessageListenerContainer listener1=this.context.getBean("listener1",DefaultMessageListenerContainer.class);
    DefaultMessageListenerContainer listener2=this.context.getBean("listener2",DefaultMessageListenerContainer.class);
    assertEquals("Wrong destination type on listener1",true,listener1.isPubSubDomain());
    assertEquals("Wrong destination type on listener2",true,listener2.isPubSubDomain());
    assertEquals("Wrong response destination type on listener1",false,listener1.isReplyPubSubDomain());
    assertEquals("Wrong response destination type on listener2",false,listener2.isReplyPubSubDomain());
    JmsMessageEndpointManager listener3=this.context.getBean("listener3",JmsMessageEndpointManager.class);
    JmsMessageEndpointManager listener4=this.context.getBean("listener4",JmsMessageEndpointManager.class);
    assertEquals("Wrong destination type on listener3",true,listener3.isPubSubDomain());
    assertEquals("Wrong destination type on listener4",true,listener4.isPubSubDomain());
    assertEquals("Wrong response destination type on listener3",false,listener3.isReplyPubSubDomain());
    assertEquals("Wrong response destination type on listener4",false,listener4.isReplyPubSubDomain());
  }
  @Test public void testErrorHandlers(){
    ErrorHandler expected=this.context.getBean("testErrorHandler",ErrorHandler.class);
    ErrorHandler errorHandler1=getErrorHandler("listener1");
    ErrorHandler errorHandler2=getErrorHandler("listener2");
    ErrorHandler defaultErrorHandler=getErrorHandler(DefaultMessageListenerContainer.class.getName() + "#0");
    assertSame(expected,errorHandler1);
    assertSame(expected,errorHandler2);
    assertNull(defaultErrorHandler);
  }
  @Test public void testPhases(){
    int phase1=getPhase("listener1");
    int phase2=getPhase("listener2");
    int phase3=getPhase("listener3");
    int phase4=getPhase("listener4");
    int defaultPhase=getPhase(DefaultMessageListenerContainer.class.getName() + "#0");
    assertEquals(99,phase1);
    assertEquals(99,phase2);
    assertEquals(77,phase3);
    assertEquals(77,phase4);
    assertEquals(Integer.MAX_VALUE,defaultPhase);
  }
  @Test public void testComponentRegistration(){
    assertTrue("Parser should have registered a component named 'listener1'",context.containsComponentDefinition("listener1"));
    assertTrue("Parser should have registered a component named 'listener2'",context.containsComponentDefinition("listener2"));
    assertTrue("Parser should have registered a component named 'listener3'",context.containsComponentDefinition("listener3"));
    assertTrue("Parser should have registered a component named '" + DefaultMessageListenerContainer.class.getName() + "#0'",context.containsComponentDefinition(DefaultMessageListenerContainer.class.getName() + "#0"));
    assertTrue("Parser should have registered a component named '" + JmsMessageEndpointManager.class.getName() + "#0'",context.containsComponentDefinition(JmsMessageEndpointManager.class.getName() + "#0"));
    assertTrue("Parser should have registered a component named 'testJmsFactory",context.containsComponentDefinition("testJmsFactory"));
    assertTrue("Parser should have registered a component named 'testJcaFactory",context.containsComponentDefinition("testJcaFactory"));
    assertTrue("Parser should have registered a component named 'testJcaFactory",context.containsComponentDefinition("onlyJmsFactory"));
  }
  @Test public void testSourceExtraction(){
    Iterator<ComponentDefinition> iterator=context.getRegisteredComponents();
    while (iterator.hasNext()) {
      ComponentDefinition compDef=iterator.next();
      assertNotNull("CompositeComponentDefinition '" + compDef.getName() + "' has no source attachment",compDef.getSource());
      validateComponentDefinition(compDef);
    }
  }
  private void validateComponentDefinition(  ComponentDefinition compDef){
    BeanDefinition[] beanDefs=compDef.getBeanDefinitions();
    for (    BeanDefinition beanDef : beanDefs) {
      assertNotNull("BeanDefinition has no source attachment",beanDef.getSource());
    }
  }
  private MessageListener getListener(  String containerBeanName){
    DefaultMessageListenerContainer container=this.context.getBean(containerBeanName,DefaultMessageListenerContainer.class);
    return (MessageListener)container.getMessageListener();
  }
  private ErrorHandler getErrorHandler(  String containerBeanName){
    DefaultMessageListenerContainer container=this.context.getBean(containerBeanName,DefaultMessageListenerContainer.class);
    return (ErrorHandler)new DirectFieldAccessor(container).getPropertyValue("errorHandler");
  }
  private BackOff getBackOff(  String containerBeanName){
    DefaultMessageListenerContainer container=this.context.getBean(containerBeanName,DefaultMessageListenerContainer.class);
    return (BackOff)new DirectFieldAccessor(container).getPropertyValue("backOff");
  }
  private long getRecoveryInterval(  String containerBeanName){
    BackOff backOff=getBackOff(containerBeanName);
    assertEquals(FixedBackOff.class,backOff.getClass());
    return ((FixedBackOff)backOff).getInterval();
  }
  private int getPhase(  String containerBeanName){
    Object container=this.context.getBean(containerBeanName);
    if (!(container instanceof Phased)) {
      throw new IllegalStateException("Container '" + containerBeanName + "' does not implement Phased.");
    }
    return ((Phased)container).getPhase();
  }
  private JmsListenerEndpoint createDummyEndpoint(){
    SimpleJmsListenerEndpoint endpoint=new SimpleJmsListenerEndpoint();
    endpoint.setMessageListener(new MessageListenerAdapter());
    endpoint.setDestination("testQueue");
    return endpoint;
  }
public static class TestMessageListener implements MessageListener {
    public Message message;
    @Override public void onMessage(    Message message){
      this.message=message;
    }
  }
  /** 
 * Internal extension that registers a  {@link ReaderEventListener} to storeregistered  {@link ComponentDefinition}s.
 */
private static class ToolingTestApplicationContext extends ClassPathXmlApplicationContext {
    private Set<ComponentDefinition> registeredComponents;
    public ToolingTestApplicationContext(    String path,    Class<?> clazz){
      super(path,clazz);
    }
    @Override protected void initBeanDefinitionReader(    XmlBeanDefinitionReader beanDefinitionReader){
      this.registeredComponents=new HashSet<>();
      beanDefinitionReader.setEventListener(new StoringReaderEventListener(this.registeredComponents));
      beanDefinitionReader.setSourceExtractor(new PassThroughSourceExtractor());
    }
    public boolean containsComponentDefinition(    String name){
      for (      ComponentDefinition cd : this.registeredComponents) {
        if (cd instanceof CompositeComponentDefinition) {
          ComponentDefinition[] innerCds=((CompositeComponentDefinition)cd).getNestedComponents();
          for (          ComponentDefinition innerCd : innerCds) {
            if (innerCd.getName().equals(name)) {
              return true;
            }
          }
        }
 else {
          if (cd.getName().equals(name)) {
            return true;
          }
        }
      }
      return false;
    }
    public Iterator<ComponentDefinition> getRegisteredComponents(){
      return this.registeredComponents.iterator();
    }
  }
private static class StoringReaderEventListener extends EmptyReaderEventListener {
    protected final Set<ComponentDefinition> registeredComponents;
    public StoringReaderEventListener(    Set<ComponentDefinition> registeredComponents){
      this.registeredComponents=registeredComponents;
    }
    @Override public void componentRegistered(    ComponentDefinition componentDefinition){
      this.registeredComponents.add(componentDefinition);
    }
  }
static class TestErrorHandler implements ErrorHandler {
    @Override public void handleError(    Throwable t){
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.messaging.handler.annotation.support;
import java.lang.reflect.Method;
import java.util.Locale;
import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.ExpectedException;
import org.springframework.core.MethodParameter;
import org.springframework.messaging.Message;
import org.springframework.messaging.converter.MappingJackson2MessageConverter;
import org.springframework.messaging.converter.MessageConversionException;
import org.springframework.messaging.converter.MessageConverter;
import org.springframework.messaging.support.ErrorMessage;
import org.springframework.messaging.support.GenericMessage;
import org.springframework.messaging.support.MessageBuilder;
import static org.junit.Assert.*;
import static org.mockito.Mockito.*;
/** 
 * Unit tests for  {@link MessageMethodArgumentResolver}.
 * @author Stephane Nicoll
 * @author Juergen Hoeller
 */
public class MessageMethodArgumentResolverTests {
  @Rule public final ExpectedException thrown=ExpectedException.none();
  private MessageConverter converter;
  private MessageMethodArgumentResolver resolver;
  private Method method;
  @Before public void setup() throws Exception {
    this.method=MessageMethodArgumentResolverTests.class.getDeclaredMethod("handle",Message.class,Message.class,Message.class,Message.class,ErrorMessage.class,Message.class);
    this.converter=mock(MessageConverter.class);
    this.resolver=new MessageMethodArgumentResolver(this.converter);
  }
  @Test public void resolveWithPayloadTypeAsWildcard() throws Exception {
    Message<String> message=MessageBuilder.withPayload("test").build();
    MethodParameter parameter=new MethodParameter(this.method,0);
    assertTrue(this.resolver.supportsParameter(parameter));
    assertSame(message,this.resolver.resolveArgument(parameter,message));
  }
  @Test public void resolveWithMatchingPayloadType() throws Exception {
    Message<Integer> message=MessageBuilder.withPayload(123).build();
    MethodParameter parameter=new MethodParameter(this.method,1);
    assertTrue(this.resolver.supportsParameter(parameter));
    assertSame(message,this.resolver.resolveArgument(parameter,message));
  }
  @Test public void resolveWithPayloadTypeSubclass() throws Exception {
    Message<Integer> message=MessageBuilder.withPayload(123).build();
    MethodParameter parameter=new MethodParameter(this.method,2);
    assertTrue(this.resolver.supportsParameter(parameter));
    assertSame(message,this.resolver.resolveArgument(parameter,message));
  }
  @Test public void resolveWithConversion() throws Exception {
    Message<String> message=MessageBuilder.withPayload("test").build();
    MethodParameter parameter=new MethodParameter(this.method,1);
    when(this.converter.fromMessage(message,Integer.class)).thenReturn(4);
    @SuppressWarnings("unchecked") Message<Integer> actual=(Message<Integer>)this.resolver.resolveArgument(parameter,message);
    assertNotNull(actual);
    assertSame(message.getHeaders(),actual.getHeaders());
    assertEquals(new Integer(4),actual.getPayload());
  }
  @Test public void resolveWithConversionNoMatchingConverter() throws Exception {
    Message<String> message=MessageBuilder.withPayload("test").build();
    MethodParameter parameter=new MethodParameter(this.method,1);
    assertTrue(this.resolver.supportsParameter(parameter));
    thrown.expect(MessageConversionException.class);
    thrown.expectMessage(Integer.class.getName());
    thrown.expectMessage(String.class.getName());
    this.resolver.resolveArgument(parameter,message);
  }
  @Test public void resolveWithConversionEmptyPayload() throws Exception {
    Message<String> message=MessageBuilder.withPayload("").build();
    MethodParameter parameter=new MethodParameter(this.method,1);
    assertTrue(this.resolver.supportsParameter(parameter));
    thrown.expect(MessageConversionException.class);
    thrown.expectMessage("payload is empty");
    thrown.expectMessage(Integer.class.getName());
    thrown.expectMessage(String.class.getName());
    this.resolver.resolveArgument(parameter,message);
  }
  @Test public void resolveWithPayloadTypeUpperBound() throws Exception {
    Message<Integer> message=MessageBuilder.withPayload(123).build();
    MethodParameter parameter=new MethodParameter(this.method,3);
    assertTrue(this.resolver.supportsParameter(parameter));
    assertSame(message,this.resolver.resolveArgument(parameter,message));
  }
  @Test public void resolveWithPayloadTypeOutOfBound() throws Exception {
    Message<Locale> message=MessageBuilder.withPayload(Locale.getDefault()).build();
    MethodParameter parameter=new MethodParameter(this.method,3);
    assertTrue(this.resolver.supportsParameter(parameter));
    thrown.expect(MessageConversionException.class);
    thrown.expectMessage(Number.class.getName());
    thrown.expectMessage(Locale.class.getName());
    this.resolver.resolveArgument(parameter,message);
  }
  @Test public void resolveMessageSubclassMatch() throws Exception {
    ErrorMessage message=new ErrorMessage(new UnsupportedOperationException());
    MethodParameter parameter=new MethodParameter(this.method,4);
    assertTrue(this.resolver.supportsParameter(parameter));
    assertSame(message,this.resolver.resolveArgument(parameter,message));
  }
  @Test public void resolveWithMessageSubclassAndPayloadWildcard() throws Exception {
    ErrorMessage message=new ErrorMessage(new UnsupportedOperationException());
    MethodParameter parameter=new MethodParameter(this.method,0);
    assertTrue(this.resolver.supportsParameter(parameter));
    assertSame(message,this.resolver.resolveArgument(parameter,message));
  }
  @Test public void resolveWithWrongMessageType() throws Exception {
    UnsupportedOperationException ex=new UnsupportedOperationException();
    Message<? extends Throwable> message=new GenericMessage<Throwable>(ex);
    MethodParameter parameter=new MethodParameter(this.method,4);
    assertTrue(this.resolver.supportsParameter(parameter));
    thrown.expect(MethodArgumentTypeMismatchException.class);
    thrown.expectMessage(ErrorMessage.class.getName());
    thrown.expectMessage(GenericMessage.class.getName());
    assertSame(message,this.resolver.resolveArgument(parameter,message));
  }
  @Test public void resolveWithPayloadTypeAsWildcardAndNoConverter() throws Exception {
    this.resolver=new MessageMethodArgumentResolver();
    Message<String> message=MessageBuilder.withPayload("test").build();
    MethodParameter parameter=new MethodParameter(this.method,0);
    assertTrue(this.resolver.supportsParameter(parameter));
    assertSame(message,this.resolver.resolveArgument(parameter,message));
  }
  @Test public void resolveWithConversionNeededButNoConverter() throws Exception {
    this.resolver=new MessageMethodArgumentResolver();
    Message<String> message=MessageBuilder.withPayload("test").build();
    MethodParameter parameter=new MethodParameter(this.method,1);
    assertTrue(this.resolver.supportsParameter(parameter));
    thrown.expect(MessageConversionException.class);
    thrown.expectMessage(Integer.class.getName());
    thrown.expectMessage(String.class.getName());
    this.resolver.resolveArgument(parameter,message);
  }
  @Test public void resolveWithConversionEmptyPayloadButNoConverter() throws Exception {
    this.resolver=new MessageMethodArgumentResolver();
    Message<String> message=MessageBuilder.withPayload("").build();
    MethodParameter parameter=new MethodParameter(this.method,1);
    assertTrue(this.resolver.supportsParameter(parameter));
    thrown.expect(MessageConversionException.class);
    thrown.expectMessage("payload is empty");
    thrown.expectMessage(Integer.class.getName());
    thrown.expectMessage(String.class.getName());
    this.resolver.resolveArgument(parameter,message);
  }
  @Test public void resolveWithJacksonConverter() throws Exception {
    Message<String> inMessage=MessageBuilder.withPayload("{\"foo\":\"bar\"}").build();
    MethodParameter parameter=new MethodParameter(this.method,5);
    this.resolver=new MessageMethodArgumentResolver(new MappingJackson2MessageConverter());
    Object actual=this.resolver.resolveArgument(parameter,inMessage);
    assertTrue(actual instanceof Message);
    Message<?> outMessage=(Message<?>)actual;
    assertTrue(outMessage.getPayload() instanceof Foo);
    assertEquals("bar",((Foo)outMessage.getPayload()).getFoo());
  }
  @SuppressWarnings("unused") private void handle(  Message<?> wildcardPayload,  Message<Integer> integerPayload,  Message<Number> numberPayload,  Message<? extends Number> anyNumberPayload,  ErrorMessage subClass,  Message<Foo> fooPayload){
  }
static class Foo {
    private String foo;
    public String getFoo(){
      return foo;
    }
    public void setFoo(    String foo){
      this.foo=foo;
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.messaging.support;
import org.junit.Test;
import static org.hamcrest.CoreMatchers.*;
import static org.junit.Assert.*;
/** 
 * @author Gary Russell
 * @since 5.0
 */
public class ErrorMessageTests {
  @Test public void testToString(){
    ErrorMessage em=new ErrorMessage(new RuntimeException("foo"));
    String emString=em.toString();
    assertThat(emString,not(containsString("original")));
    em=new ErrorMessage(new RuntimeException("foo"),new GenericMessage<>("bar"));
    emString=em.toString();
    assertThat(emString,containsString("original"));
    assertThat(emString,containsString(em.getOriginalMessage().toString()));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.jdbc.datasource.init;
import java.sql.SQLException;
import org.junit.Before;
import org.junit.Test;
import org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType;
import static org.springframework.jdbc.datasource.init.ScriptUtils.*;
/** 
 * Integration tests for  {@link ScriptUtils}.
 * @author Sam Brannen
 * @since 4.0.3
 * @see ScriptUtilsUnitTests
 */
public class ScriptUtilsIntegrationTests extends AbstractDatabaseInitializationTests {
  protected EmbeddedDatabaseType getEmbeddedDatabaseType(){
    return EmbeddedDatabaseType.HSQL;
  }
  @Before public void setUpSchema() throws SQLException {
    executeSqlScript(db.getConnection(),usersSchema());
  }
  @Test public void executeSqlScriptContainingMultiLineComments() throws SQLException {
    executeSqlScript(db.getConnection(),resource("test-data-with-multi-line-comments.sql"));
    assertUsersDatabaseCreated("Hoeller","Brannen");
  }
  /** 
 * @since 4.2
 */
  @Test public void executeSqlScriptContainingSingleQuotesNestedInsideDoubleQuotes() throws SQLException {
    executeSqlScript(db.getConnection(),resource("users-data-with-single-quotes-nested-in-double-quotes.sql"));
    assertUsersDatabaseCreated("Hoeller","Brannen");
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.jdbc.core.namedparam;
import java.sql.Types;
import java.util.Arrays;
import org.junit.Test;
import org.springframework.tests.sample.beans.TestBean;
import static org.junit.Assert.*;
/** 
 * @author Rick Evans
 * @author Juergen Hoeller
 * @author Arjen Poutsma
 */
public class BeanPropertySqlParameterSourceTests {
  @Test(expected=IllegalArgumentException.class) public void withNullBeanPassedToCtor() throws Exception {
    new BeanPropertySqlParameterSource(null);
  }
  @Test(expected=IllegalArgumentException.class) public void getValueWhereTheUnderlyingBeanHasNoSuchProperty() throws Exception {
    BeanPropertySqlParameterSource source=new BeanPropertySqlParameterSource(new TestBean());
    source.getValue("thisPropertyDoesNotExist");
  }
  @Test public void successfulPropertyAccess(){
    BeanPropertySqlParameterSource source=new BeanPropertySqlParameterSource(new TestBean("tb",99));
    assertTrue(Arrays.asList(source.getReadablePropertyNames()).contains("name"));
    assertTrue(Arrays.asList(source.getReadablePropertyNames()).contains("age"));
    assertEquals("tb",source.getValue("name"));
    assertEquals(99,source.getValue("age"));
    assertEquals(Types.VARCHAR,source.getSqlType("name"));
    assertEquals(Types.INTEGER,source.getSqlType("age"));
  }
  @Test public void successfulPropertyAccessWithOverriddenSqlType(){
    BeanPropertySqlParameterSource source=new BeanPropertySqlParameterSource(new TestBean("tb",99));
    source.registerSqlType("age",Types.NUMERIC);
    assertEquals("tb",source.getValue("name"));
    assertEquals(99,source.getValue("age"));
    assertEquals(Types.VARCHAR,source.getSqlType("name"));
    assertEquals(Types.NUMERIC,source.getSqlType("age"));
  }
  @Test public void hasValueWhereTheUnderlyingBeanHasNoSuchProperty() throws Exception {
    BeanPropertySqlParameterSource source=new BeanPropertySqlParameterSource(new TestBean());
    assertFalse(source.hasValue("thisPropertyDoesNotExist"));
  }
  @Test(expected=IllegalArgumentException.class) public void getValueWhereTheUnderlyingBeanPropertyIsNotReadable() throws Exception {
    BeanPropertySqlParameterSource source=new BeanPropertySqlParameterSource(new NoReadableProperties());
    source.getValue("noOp");
  }
  @Test public void hasValueWhereTheUnderlyingBeanPropertyIsNotReadable() throws Exception {
    BeanPropertySqlParameterSource source=new BeanPropertySqlParameterSource(new NoReadableProperties());
    assertFalse(source.hasValue("noOp"));
  }
@SuppressWarnings("unused") private static final class NoReadableProperties {
    public void setNoOp(    String noOp){
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.transaction;
import javax.transaction.HeuristicMixedException;
import javax.transaction.HeuristicRollbackException;
import javax.transaction.NotSupportedException;
import javax.transaction.RollbackException;
import javax.transaction.Status;
import javax.transaction.SystemException;
import javax.transaction.Transaction;
import javax.transaction.TransactionManager;
import javax.transaction.UserTransaction;
import org.junit.After;
import org.junit.Test;
import org.springframework.dao.OptimisticLockingFailureException;
import org.springframework.tests.transaction.MockJtaTransaction;
import org.springframework.transaction.jta.JtaTransactionManager;
import org.springframework.transaction.support.DefaultTransactionDefinition;
import org.springframework.transaction.support.TransactionCallbackWithoutResult;
import org.springframework.transaction.support.TransactionSynchronization;
import org.springframework.transaction.support.TransactionSynchronizationAdapter;
import org.springframework.transaction.support.TransactionSynchronizationManager;
import org.springframework.transaction.support.TransactionTemplate;
import static org.junit.Assert.*;
import static org.mockito.BDDMockito.*;
/** 
 * @author Juergen Hoeller
 * @since 12.05.2003
 */
public class JtaTransactionManagerTests {
  @Test public void jtaTransactionManagerWithCommit() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setName("txName");
    assertEquals(JtaTransactionManager.SYNCHRONIZATION_ALWAYS,ptm.getTransactionSynchronization());
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    assertNull(TransactionSynchronizationManager.getCurrentTransactionName());
    assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        TransactionSynchronizationManager.registerSynchronization(synch);
        assertEquals("txName",TransactionSynchronizationManager.getCurrentTransactionName());
        assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    assertNull(TransactionSynchronizationManager.getCurrentTransactionName());
    assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
    verify(ut).begin();
    verify(ut).commit();
    verify(synch).beforeCommit(false);
    verify(synch).beforeCompletion();
    verify(synch).afterCommit();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_COMMITTED);
  }
  @Test public void jtaTransactionManagerWithCommitAndSynchronizationOnActual() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    ptm.setTransactionSynchronization(JtaTransactionManager.SYNCHRONIZATION_ON_ACTUAL_TRANSACTION);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        TransactionSynchronizationManager.registerSynchronization(synch);
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).begin();
    verify(ut).commit();
    verify(synch).beforeCommit(false);
    verify(synch).beforeCompletion();
    verify(synch).afterCommit();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_COMMITTED);
  }
  @Test public void jtaTransactionManagerWithCommitAndSynchronizationNever() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    ptm.setTransactionSynchronization(JtaTransactionManager.SYNCHRONIZATION_NEVER);
    ptm.afterPropertiesSet();
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).begin();
    verify(ut).commit();
  }
  @Test public void jtaTransactionManagerWithRollback() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setTimeout(10);
    tt.setName("txName");
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    assertNull(TransactionSynchronizationManager.getCurrentTransactionName());
    assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        TransactionSynchronizationManager.registerSynchronization(synch);
        assertEquals("txName",TransactionSynchronizationManager.getCurrentTransactionName());
        assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    assertNull(TransactionSynchronizationManager.getCurrentTransactionName());
    assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
    verify(ut).setTransactionTimeout(10);
    verify(ut).begin();
    verify(ut).rollback();
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_ROLLED_BACK);
  }
  @Test public void jtaTransactionManagerWithRollbackAndSynchronizationOnActual() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    ptm.setTransactionSynchronization(JtaTransactionManager.SYNCHRONIZATION_ON_ACTUAL_TRANSACTION);
    tt.setTimeout(10);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        TransactionSynchronizationManager.registerSynchronization(synch);
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).setTransactionTimeout(10);
    verify(ut).begin();
    verify(ut).rollback();
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_ROLLED_BACK);
  }
  @Test public void jtaTransactionManagerWithRollbackAndSynchronizationNever() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    ptm.setTransactionSynchronizationName("SYNCHRONIZATION_NEVER");
    tt.setTimeout(10);
    ptm.afterPropertiesSet();
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).setTransactionTimeout(10);
    verify(ut).begin();
    verify(ut,atLeastOnce()).getStatus();
    verify(ut).rollback();
  }
  @Test public void jtaTransactionManagerWithExistingTransactionAndRollbackOnly() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        TransactionSynchronizationManager.registerSynchronization(synch);
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).setRollbackOnly();
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_UNKNOWN);
  }
  @Test public void jtaTransactionManagerWithExistingTransactionAndException() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    try {
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
          TransactionSynchronizationManager.registerSynchronization(synch);
          throw new IllegalStateException("I want a rollback");
        }
      }
);
      fail("Should have thrown IllegalStateException");
    }
 catch (    IllegalStateException ex) {
    }
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).setRollbackOnly();
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_UNKNOWN);
  }
  @Test public void jtaTransactionManagerWithExistingTransactionAndCommitException() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    willThrow(new OptimisticLockingFailureException("")).given(synch).beforeCommit(false);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    try {
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
          TransactionSynchronizationManager.registerSynchronization(synch);
        }
      }
);
      fail("Should have thrown OptimisticLockingFailureException");
    }
 catch (    OptimisticLockingFailureException ex) {
    }
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).setRollbackOnly();
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_UNKNOWN);
  }
  @Test public void jtaTransactionManagerWithExistingTransactionAndRollbackOnlyAndNoGlobalRollback() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    ptm.setGlobalRollbackOnParticipationFailure(false);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        TransactionSynchronizationManager.registerSynchronization(synch);
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).setRollbackOnly();
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_UNKNOWN);
  }
  @Test public void jtaTransactionManagerWithExistingTransactionAndExceptionAndNoGlobalRollback() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    ptm.setGlobalRollbackOnParticipationFailure(false);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    try {
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
          TransactionSynchronizationManager.registerSynchronization(synch);
          throw new IllegalStateException("I want a rollback");
        }
      }
);
      fail("Should have thrown IllegalStateException");
    }
 catch (    IllegalStateException ex) {
    }
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_UNKNOWN);
  }
  @Test public void jtaTransactionManagerWithExistingTransactionAndJtaSynchronization() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    TransactionManager tm=mock(TransactionManager.class);
    MockJtaTransaction tx=new MockJtaTransaction();
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    given(tm.getTransaction()).willReturn(tx);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut,tm);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        TransactionSynchronizationManager.registerSynchronization(synch);
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    assertNotNull(tx.getSynchronization());
    tx.getSynchronization().beforeCompletion();
    tx.getSynchronization().afterCompletion(Status.STATUS_ROLLEDBACK);
    verify(ut).setRollbackOnly();
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_ROLLED_BACK);
  }
  @Test public void jtaTransactionManagerWithExistingTransactionAndSynchronizationOnActual() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    ptm.setTransactionSynchronization(JtaTransactionManager.SYNCHRONIZATION_ON_ACTUAL_TRANSACTION);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        TransactionSynchronizationManager.registerSynchronization(synch);
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).setRollbackOnly();
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_UNKNOWN);
  }
  @Test public void jtaTransactionManagerWithExistingTransactionAndSynchronizationNever() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    ptm.setTransactionSynchronization(JtaTransactionManager.SYNCHRONIZATION_NEVER);
    ptm.afterPropertiesSet();
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).setRollbackOnly();
  }
  @Test public void jtaTransactionManagerWithExistingAndPropagationSupports() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_SUPPORTS);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        TransactionSynchronizationManager.registerSynchronization(synch);
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).setRollbackOnly();
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_UNKNOWN);
  }
  @Test public void jtaTransactionManagerWithPropagationSupports() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION);
    final TransactionSynchronization synch=mock(TransactionSynchronization.class);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_SUPPORTS);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        TransactionSynchronizationManager.registerSynchronization(synch);
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(synch).beforeCompletion();
    verify(synch).afterCompletion(TransactionSynchronization.STATUS_ROLLED_BACK);
  }
  @Test public void jtaTransactionManagerWithPropagationSupportsAndSynchronizationOnActual() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    ptm.setTransactionSynchronization(JtaTransactionManager.SYNCHRONIZATION_ON_ACTUAL_TRANSACTION);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_SUPPORTS);
    ptm.afterPropertiesSet();
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
  }
  @Test public void jtaTransactionManagerWithPropagationSupportsAndSynchronizationNever() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    ptm.setTransactionSynchronization(JtaTransactionManager.SYNCHRONIZATION_NEVER);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_SUPPORTS);
    ptm.afterPropertiesSet();
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
  }
  @Test public void jtaTransactionManagerWithPropagationNotSupported() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    TransactionManager tm=mock(TransactionManager.class);
    Transaction tx=mock(Transaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    given(tm.suspend()).willReturn(tx);
    JtaTransactionManager ptm=newJtaTransactionManager(ut,tm);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_NOT_SUPPORTED);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        status.setRollbackOnly();
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(tm).resume(tx);
  }
  @Test public void jtaTransactionManagerWithPropagationRequiresNew() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    TransactionManager tm=mock(TransactionManager.class);
    Transaction tx=mock(Transaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE);
    given(tm.suspend()).willReturn(tx);
    final JtaTransactionManager ptm=newJtaTransactionManager(ut,tm);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW);
    tt.setName("txName");
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        assertEquals("txName",TransactionSynchronizationManager.getCurrentTransactionName());
        assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
        TransactionTemplate tt2=new TransactionTemplate(ptm);
        tt2.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW);
        tt2.setReadOnly(true);
        tt2.setName("txName2");
        tt2.execute(new TransactionCallbackWithoutResult(){
          @Override protected void doInTransactionWithoutResult(          TransactionStatus status){
            assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
            assertEquals("txName2",TransactionSynchronizationManager.getCurrentTransactionName());
            assertTrue(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
          }
        }
);
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        assertEquals("txName",TransactionSynchronizationManager.getCurrentTransactionName());
        assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut,times(2)).begin();
    verify(ut,times(2)).commit();
    verify(tm).resume(tx);
  }
  @Test public void jtaTransactionManagerWithPropagationRequiresNewWithinSupports() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE);
    final JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_SUPPORTS);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
        assertFalse(TransactionSynchronizationManager.isActualTransactionActive());
        TransactionTemplate tt2=new TransactionTemplate(ptm);
        tt2.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW);
        tt2.execute(new TransactionCallbackWithoutResult(){
          @Override protected void doInTransactionWithoutResult(          TransactionStatus status){
            assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
            assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
            assertTrue(TransactionSynchronizationManager.isActualTransactionActive());
          }
        }
);
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
        assertFalse(TransactionSynchronizationManager.isActualTransactionActive());
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).begin();
    verify(ut).commit();
  }
  @Test public void jtaTransactionManagerWithPropagationRequiresNewAndExisting() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    TransactionManager tm=mock(TransactionManager.class);
    Transaction tx=mock(Transaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    given(tm.suspend()).willReturn(tx);
    JtaTransactionManager ptm=newJtaTransactionManager(ut,tm);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(ut).begin();
    verify(ut).commit();
    verify(tm).resume(tx);
  }
  @Test public void jtaTransactionManagerWithPropagationRequiresNewAndExistingWithSuspendException() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    TransactionManager tm=mock(TransactionManager.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    willThrow(new SystemException()).given(tm).suspend();
    JtaTransactionManager ptm=newJtaTransactionManager(ut,tm);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    try {
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        }
      }
);
      fail("Should have thrown TransactionSystemException");
    }
 catch (    TransactionSystemException ex) {
    }
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
  }
  @Test public void jtaTransactionManagerWithPropagationRequiresNewAndExistingWithBeginException() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    TransactionManager tm=mock(TransactionManager.class);
    Transaction tx=mock(Transaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    given(tm.suspend()).willReturn(tx);
    willThrow(new SystemException()).given(ut).begin();
    JtaTransactionManager ptm=newJtaTransactionManager(ut,tm);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    try {
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
        }
      }
);
      fail("Should have thrown CannotCreateTransactionException");
    }
 catch (    CannotCreateTransactionException ex) {
    }
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(tm).resume(tx);
  }
  @Test public void jtaTransactionManagerWithPropagationRequiresNewAndAdapter() throws Exception {
    TransactionManager tm=mock(TransactionManager.class);
    Transaction tx=mock(Transaction.class);
    given(tm.getStatus()).willReturn(Status.STATUS_ACTIVE);
    given(tm.suspend()).willReturn(tx);
    JtaTransactionManager ptm=newJtaTransactionManager(tm);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
        assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
      }
    }
);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    verify(tm).begin();
    verify(tm).commit();
    verify(tm).resume(tx);
  }
  @Test public void jtaTransactionManagerWithPropagationRequiresNewAndSuspensionNotSupported() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_REQUIRES_NEW);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    try {
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
        }
      }
);
      fail("Should have thrown TransactionSuspensionNotSupportedException");
    }
 catch (    TransactionSuspensionNotSupportedException ex) {
    }
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
  }
  @Test public void jtaTransactionManagerWithIsolationLevel() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION);
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.setIsolationLevel(TransactionDefinition.ISOLATION_SERIALIZABLE);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
        }
      }
);
      fail("Should have thrown InvalidIsolationLevelException");
    }
 catch (    InvalidIsolationLevelException ex) {
    }
  }
  @Test public void jtaTransactionManagerWithSystemExceptionOnIsExisting() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willThrow(new SystemException("system exception"));
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
        }
      }
);
      fail("Should have thrown TransactionSystemException");
    }
 catch (    TransactionSystemException ex) {
    }
  }
  @Test public void jtaTransactionManagerWithNestedBegin() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    TransactionTemplate tt=new TransactionTemplate(ptm);
    tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_NESTED);
    tt.execute(new TransactionCallbackWithoutResult(){
      @Override protected void doInTransactionWithoutResult(      TransactionStatus status){
      }
    }
);
    verify(ut).begin();
    verify(ut).commit();
  }
  @Test public void jtaTransactionManagerWithNotSupportedExceptionOnNestedBegin() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    willThrow(new NotSupportedException("not supported")).given(ut).begin();
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_NESTED);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
        }
      }
);
      fail("Should have thrown NestedTransactionNotSupportedException");
    }
 catch (    NestedTransactionNotSupportedException ex) {
    }
  }
  @Test public void jtaTransactionManagerWithUnsupportedOperationExceptionOnNestedBegin() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    willThrow(new UnsupportedOperationException("not supported")).given(ut).begin();
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.setPropagationBehavior(TransactionDefinition.PROPAGATION_NESTED);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
        }
      }
);
      fail("Should have thrown NestedTransactionNotSupportedException");
    }
 catch (    NestedTransactionNotSupportedException ex) {
    }
  }
  @Test public void jtaTransactionManagerWithSystemExceptionOnBegin() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION);
    willThrow(new SystemException("system exception")).given(ut).begin();
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
        }
      }
);
      fail("Should have thrown CannotCreateTransactionException");
    }
 catch (    CannotCreateTransactionException ex) {
    }
  }
  @Test public void jtaTransactionManagerWithRollbackExceptionOnCommit() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE);
    willThrow(new RollbackException("unexpected rollback")).given(ut).commit();
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter(){
            @Override public void afterCompletion(            int status){
              assertTrue("Correct completion status",status == TransactionSynchronization.STATUS_ROLLED_BACK);
            }
          }
);
        }
      }
);
      fail("Should have thrown UnexpectedRollbackException");
    }
 catch (    UnexpectedRollbackException ex) {
    }
    verify(ut).begin();
  }
  @Test public void jtaTransactionManagerWithNoExceptionOnGlobalRollbackOnly() throws Exception {
    doTestJtaTransactionManagerWithNoExceptionOnGlobalRollbackOnly(false);
  }
  @Test public void jtaTransactionManagerWithNoExceptionOnGlobalRollbackOnlyAndFailEarly() throws Exception {
    doTestJtaTransactionManagerWithNoExceptionOnGlobalRollbackOnly(true);
  }
  private void doTestJtaTransactionManagerWithNoExceptionOnGlobalRollbackOnly(  boolean failEarly) throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_MARKED_ROLLBACK,Status.STATUS_MARKED_ROLLBACK,Status.STATUS_MARKED_ROLLBACK);
    JtaTransactionManager tm=newJtaTransactionManager(ut);
    if (failEarly) {
      tm.setFailEarlyOnGlobalRollbackOnly(true);
    }
    TransactionStatus ts=tm.getTransaction(new DefaultTransactionDefinition());
    boolean outerTransactionBoundaryReached=false;
    try {
      assertTrue("Is new transaction",ts.isNewTransaction());
      TransactionTemplate tt=new TransactionTemplate(tm);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter(){
            @Override public void afterCompletion(            int status){
              assertTrue("Correct completion status",status == TransactionSynchronization.STATUS_ROLLED_BACK);
            }
          }
);
        }
      }
);
      outerTransactionBoundaryReached=true;
      tm.commit(ts);
      fail("Should have thrown UnexpectedRollbackException");
    }
 catch (    UnexpectedRollbackException ex) {
      if (!outerTransactionBoundaryReached) {
        tm.rollback(ts);
      }
      if (failEarly) {
        assertFalse(outerTransactionBoundaryReached);
      }
 else {
        assertTrue(outerTransactionBoundaryReached);
      }
    }
    verify(ut).begin();
    if (failEarly) {
      verify(ut).rollback();
    }
 else {
      verify(ut).commit();
    }
  }
  @Test public void jtaTransactionManagerWithHeuristicMixedExceptionOnCommit() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE);
    willThrow(new HeuristicMixedException("heuristic exception")).given(ut).commit();
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter(){
            @Override public void afterCompletion(            int status){
              assertTrue("Correct completion status",status == TransactionSynchronization.STATUS_UNKNOWN);
            }
          }
);
        }
      }
);
      fail("Should have thrown HeuristicCompletionException");
    }
 catch (    HeuristicCompletionException ex) {
      assertTrue(ex.getOutcomeState() == HeuristicCompletionException.STATE_MIXED);
    }
    verify(ut).begin();
  }
  @Test public void jtaTransactionManagerWithHeuristicRollbackExceptionOnCommit() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE);
    willThrow(new HeuristicRollbackException("heuristic exception")).given(ut).commit();
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter(){
            @Override public void afterCompletion(            int status){
              assertTrue("Correct completion status",status == TransactionSynchronization.STATUS_UNKNOWN);
            }
          }
);
        }
      }
);
      fail("Should have thrown HeuristicCompletionException");
    }
 catch (    HeuristicCompletionException ex) {
      assertTrue(ex.getOutcomeState() == HeuristicCompletionException.STATE_ROLLED_BACK);
    }
    verify(ut).begin();
  }
  @Test public void jtaTransactionManagerWithSystemExceptionOnCommit() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE);
    willThrow(new SystemException("system exception")).given(ut).commit();
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter(){
            @Override public void afterCompletion(            int status){
              assertTrue("Correct completion status",status == TransactionSynchronization.STATUS_UNKNOWN);
            }
          }
);
        }
      }
);
      fail("Should have thrown TransactionSystemException");
    }
 catch (    TransactionSystemException ex) {
    }
    verify(ut).begin();
  }
  @Test public void jtaTransactionManagerWithSystemExceptionOnRollback() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE);
    willThrow(new SystemException("system exception")).given(ut).rollback();
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter(){
            @Override public void afterCompletion(            int status){
              assertTrue("Correct completion status",status == TransactionSynchronization.STATUS_UNKNOWN);
            }
          }
);
          status.setRollbackOnly();
        }
      }
);
      fail("Should have thrown TransactionSystemException");
    }
 catch (    TransactionSystemException ex) {
    }
    verify(ut).begin();
  }
  @Test public void jtaTransactionManagerWithIllegalStateExceptionOnRollbackOnly() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    willThrow(new IllegalStateException("no existing transaction")).given(ut).setRollbackOnly();
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          status.setRollbackOnly();
        }
      }
);
      fail("Should have thrown TransactionSystemException");
    }
 catch (    TransactionSystemException ex) {
    }
  }
  @Test public void jtaTransactionManagerWithSystemExceptionOnRollbackOnly() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_ACTIVE);
    willThrow(new SystemException("system exception")).given(ut).setRollbackOnly();
    try {
      JtaTransactionManager ptm=newJtaTransactionManager(ut);
      TransactionTemplate tt=new TransactionTemplate(ptm);
      tt.execute(new TransactionCallbackWithoutResult(){
        @Override protected void doInTransactionWithoutResult(        TransactionStatus status){
          status.setRollbackOnly();
          TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter(){
            @Override public void afterCompletion(            int status){
              assertTrue("Correct completion status",status == TransactionSynchronization.STATUS_UNKNOWN);
            }
          }
);
        }
      }
);
      fail("Should have thrown TransactionSystemException");
    }
 catch (    TransactionSystemException ex) {
    }
  }
  @Test public void jtaTransactionManagerWithDoubleCommit() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE,Status.STATUS_ACTIVE);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    TransactionStatus status=ptm.getTransaction(new DefaultTransactionDefinition());
    assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
    ptm.commit(status);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    try {
      ptm.commit(status);
      fail("Should have thrown IllegalTransactionStateException");
    }
 catch (    IllegalTransactionStateException ex) {
    }
    verify(ut).begin();
    verify(ut).commit();
  }
  @Test public void jtaTransactionManagerWithDoubleRollback() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    TransactionStatus status=ptm.getTransaction(new DefaultTransactionDefinition());
    assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
    ptm.rollback(status);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    try {
      ptm.rollback(status);
      fail("Should have thrown IllegalTransactionStateException");
    }
 catch (    IllegalTransactionStateException ex) {
    }
    verify(ut).begin();
    verify(ut).rollback();
  }
  @Test public void jtaTransactionManagerWithRollbackAndCommit() throws Exception {
    UserTransaction ut=mock(UserTransaction.class);
    given(ut.getStatus()).willReturn(Status.STATUS_NO_TRANSACTION,Status.STATUS_ACTIVE);
    JtaTransactionManager ptm=newJtaTransactionManager(ut);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    TransactionStatus status=ptm.getTransaction(new DefaultTransactionDefinition());
    assertTrue(TransactionSynchronizationManager.isSynchronizationActive());
    ptm.rollback(status);
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    try {
      ptm.commit(status);
      fail("Should have thrown IllegalTransactionStateException");
    }
 catch (    IllegalTransactionStateException ex) {
    }
    verify(ut).begin();
    verify(ut).rollback();
  }
  protected JtaTransactionManager newJtaTransactionManager(  UserTransaction ut){
    return new JtaTransactionManager(ut);
  }
  protected JtaTransactionManager newJtaTransactionManager(  TransactionManager tm){
    return new JtaTransactionManager(tm);
  }
  protected JtaTransactionManager newJtaTransactionManager(  UserTransaction ut,  TransactionManager tm){
    return new JtaTransactionManager(ut,tm);
  }
  /** 
 * Prevent any side-effects due to this test modifying ThreadLocals that might affect subsequent tests when all tests are run in the same JVM, as with Eclipse.
 */
  @After public void tearDown(){
    assertTrue(TransactionSynchronizationManager.getResourceMap().isEmpty());
    assertFalse(TransactionSynchronizationManager.isSynchronizationActive());
    assertNull(TransactionSynchronizationManager.getCurrentTransactionName());
    assertFalse(TransactionSynchronizationManager.isCurrentTransactionReadOnly());
    assertNull(TransactionSynchronizationManager.getCurrentTransactionIsolationLevel());
    assertFalse(TransactionSynchronizationManager.isActualTransactionActive());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.transaction.interceptor;
import java.io.Serializable;
import java.util.Properties;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.ExpectedException;
import org.springframework.aop.framework.ProxyFactory;
import org.springframework.beans.factory.BeanFactory;
import org.springframework.beans.factory.NoSuchBeanDefinitionException;
import org.springframework.lang.Nullable;
import org.springframework.transaction.PlatformTransactionManager;
import org.springframework.transaction.TransactionDefinition;
import org.springframework.transaction.TransactionException;
import org.springframework.transaction.TransactionStatus;
import org.springframework.util.SerializationTestUtils;
import static org.junit.Assert.*;
import static org.mockito.BDDMockito.*;
/** 
 * Mock object based tests for TransactionInterceptor.
 * @author Rod Johnson
 * @since 16.03.2003
 */
public class TransactionInterceptorTests extends AbstractTransactionAspectTests {
  @Rule public final ExpectedException thrown=ExpectedException.none();
  @Override protected Object advised(  Object target,  PlatformTransactionManager ptm,  TransactionAttributeSource[] tas) throws Exception {
    TransactionInterceptor ti=new TransactionInterceptor();
    ti.setTransactionManager(ptm);
    ti.setTransactionAttributeSources(tas);
    ProxyFactory pf=new ProxyFactory(target);
    pf.addAdvice(0,ti);
    return pf.getProxy();
  }
  /** 
 * Template method to create an advised object given the target object and transaction setup. Creates a TransactionInterceptor and applies it.
 */
  @Override protected Object advised(  Object target,  PlatformTransactionManager ptm,  TransactionAttributeSource tas){
    TransactionInterceptor ti=new TransactionInterceptor();
    ti.setTransactionManager(ptm);
    assertEquals(ptm,ti.getTransactionManager());
    ti.setTransactionAttributeSource(tas);
    assertEquals(tas,ti.getTransactionAttributeSource());
    ProxyFactory pf=new ProxyFactory(target);
    pf.addAdvice(0,ti);
    return pf.getProxy();
  }
  /** 
 * A TransactionInterceptor should be serializable if its PlatformTransactionManager is.
 */
  @Test public void serializableWithAttributeProperties() throws Exception {
    TransactionInterceptor ti=new TransactionInterceptor();
    Properties props=new Properties();
    props.setProperty("methodName","PROPAGATION_REQUIRED");
    ti.setTransactionAttributes(props);
    PlatformTransactionManager ptm=new SerializableTransactionManager();
    ti.setTransactionManager(ptm);
    ti=(TransactionInterceptor)SerializationTestUtils.serializeAndDeserialize(ti);
    assertNotNull(ti.logger);
    assertTrue(ti.getTransactionManager() instanceof SerializableTransactionManager);
    assertNotNull(ti.getTransactionAttributeSource());
  }
  @Test public void serializableWithCompositeSource() throws Exception {
    NameMatchTransactionAttributeSource tas1=new NameMatchTransactionAttributeSource();
    Properties props=new Properties();
    props.setProperty("methodName","PROPAGATION_REQUIRED");
    tas1.setProperties(props);
    NameMatchTransactionAttributeSource tas2=new NameMatchTransactionAttributeSource();
    props=new Properties();
    props.setProperty("otherMethodName","PROPAGATION_REQUIRES_NEW");
    tas2.setProperties(props);
    TransactionInterceptor ti=new TransactionInterceptor();
    ti.setTransactionAttributeSources(tas1,tas2);
    PlatformTransactionManager ptm=new SerializableTransactionManager();
    ti.setTransactionManager(ptm);
    ti=(TransactionInterceptor)SerializationTestUtils.serializeAndDeserialize(ti);
    assertTrue(ti.getTransactionManager() instanceof SerializableTransactionManager);
    assertTrue(ti.getTransactionAttributeSource() instanceof CompositeTransactionAttributeSource);
    CompositeTransactionAttributeSource ctas=(CompositeTransactionAttributeSource)ti.getTransactionAttributeSource();
    assertTrue(ctas.getTransactionAttributeSources()[0] instanceof NameMatchTransactionAttributeSource);
    assertTrue(ctas.getTransactionAttributeSources()[1] instanceof NameMatchTransactionAttributeSource);
  }
  @Test public void determineTransactionManagerWithNoBeanFactory(){
    PlatformTransactionManager transactionManager=mock(PlatformTransactionManager.class);
    TransactionInterceptor ti=transactionInterceptorWithTransactionManager(transactionManager,null);
    assertSame(transactionManager,ti.determineTransactionManager(new DefaultTransactionAttribute()));
  }
  @Test public void determineTransactionManagerWithNoBeanFactoryAndNoTransactionAttribute(){
    PlatformTransactionManager transactionManager=mock(PlatformTransactionManager.class);
    TransactionInterceptor ti=transactionInterceptorWithTransactionManager(transactionManager,null);
    assertSame(transactionManager,ti.determineTransactionManager(null));
  }
  @Test public void determineTransactionManagerWithNoTransactionAttribute(){
    BeanFactory beanFactory=mock(BeanFactory.class);
    TransactionInterceptor ti=simpleTransactionInterceptor(beanFactory);
    assertNull(ti.determineTransactionManager(null));
  }
  @Test public void determineTransactionManagerWithQualifierUnknown(){
    BeanFactory beanFactory=mock(BeanFactory.class);
    TransactionInterceptor ti=simpleTransactionInterceptor(beanFactory);
    DefaultTransactionAttribute attribute=new DefaultTransactionAttribute();
    attribute.setQualifier("fooTransactionManager");
    thrown.expect(NoSuchBeanDefinitionException.class);
    thrown.expectMessage("'fooTransactionManager'");
    ti.determineTransactionManager(attribute);
  }
  @Test public void determineTransactionManagerWithQualifierAndDefault(){
    BeanFactory beanFactory=mock(BeanFactory.class);
    PlatformTransactionManager transactionManager=mock(PlatformTransactionManager.class);
    TransactionInterceptor ti=transactionInterceptorWithTransactionManager(transactionManager,beanFactory);
    PlatformTransactionManager fooTransactionManager=associateTransactionManager(beanFactory,"fooTransactionManager");
    DefaultTransactionAttribute attribute=new DefaultTransactionAttribute();
    attribute.setQualifier("fooTransactionManager");
    assertSame(fooTransactionManager,ti.determineTransactionManager(attribute));
  }
  @Test public void determineTransactionManagerWithQualifierAndDefaultName(){
    BeanFactory beanFactory=mock(BeanFactory.class);
    associateTransactionManager(beanFactory,"defaultTransactionManager");
    TransactionInterceptor ti=transactionInterceptorWithTransactionManagerName("defaultTransactionManager",beanFactory);
    PlatformTransactionManager fooTransactionManager=associateTransactionManager(beanFactory,"fooTransactionManager");
    DefaultTransactionAttribute attribute=new DefaultTransactionAttribute();
    attribute.setQualifier("fooTransactionManager");
    assertSame(fooTransactionManager,ti.determineTransactionManager(attribute));
  }
  @Test public void determineTransactionManagerWithEmptyQualifierAndDefaultName(){
    BeanFactory beanFactory=mock(BeanFactory.class);
    PlatformTransactionManager defaultTransactionManager=associateTransactionManager(beanFactory,"defaultTransactionManager");
    TransactionInterceptor ti=transactionInterceptorWithTransactionManagerName("defaultTransactionManager",beanFactory);
    DefaultTransactionAttribute attribute=new DefaultTransactionAttribute();
    attribute.setQualifier("");
    assertSame(defaultTransactionManager,ti.determineTransactionManager(attribute));
  }
  @Test public void determineTransactionManagerWithQualifierSeveralTimes(){
    BeanFactory beanFactory=mock(BeanFactory.class);
    TransactionInterceptor ti=simpleTransactionInterceptor(beanFactory);
    PlatformTransactionManager txManager=associateTransactionManager(beanFactory,"fooTransactionManager");
    DefaultTransactionAttribute attribute=new DefaultTransactionAttribute();
    attribute.setQualifier("fooTransactionManager");
    PlatformTransactionManager actual=ti.determineTransactionManager(attribute);
    assertSame(txManager,actual);
    PlatformTransactionManager actual2=ti.determineTransactionManager(attribute);
    assertSame(txManager,actual2);
    verify(beanFactory,times(1)).containsBean("fooTransactionManager");
    verify(beanFactory,times(1)).getBean("fooTransactionManager",PlatformTransactionManager.class);
  }
  @Test public void determineTransactionManagerWithBeanNameSeveralTimes(){
    BeanFactory beanFactory=mock(BeanFactory.class);
    TransactionInterceptor ti=transactionInterceptorWithTransactionManagerName("fooTransactionManager",beanFactory);
    PlatformTransactionManager txManager=associateTransactionManager(beanFactory,"fooTransactionManager");
    DefaultTransactionAttribute attribute=new DefaultTransactionAttribute();
    PlatformTransactionManager actual=ti.determineTransactionManager(attribute);
    assertSame(txManager,actual);
    PlatformTransactionManager actual2=ti.determineTransactionManager(attribute);
    assertSame(txManager,actual2);
    verify(beanFactory,times(1)).getBean("fooTransactionManager",PlatformTransactionManager.class);
  }
  @Test public void determineTransactionManagerDefaultSeveralTimes(){
    BeanFactory beanFactory=mock(BeanFactory.class);
    TransactionInterceptor ti=simpleTransactionInterceptor(beanFactory);
    PlatformTransactionManager txManager=mock(PlatformTransactionManager.class);
    given(beanFactory.getBean(PlatformTransactionManager.class)).willReturn(txManager);
    DefaultTransactionAttribute attribute=new DefaultTransactionAttribute();
    PlatformTransactionManager actual=ti.determineTransactionManager(attribute);
    assertSame(txManager,actual);
    PlatformTransactionManager actual2=ti.determineTransactionManager(attribute);
    assertSame(txManager,actual2);
    verify(beanFactory,times(1)).getBean(PlatformTransactionManager.class);
  }
  private TransactionInterceptor createTransactionInterceptor(  BeanFactory beanFactory,  String transactionManagerName,  PlatformTransactionManager transactionManager){
    TransactionInterceptor ti=new TransactionInterceptor();
    if (beanFactory != null) {
      ti.setBeanFactory(beanFactory);
    }
    if (transactionManagerName != null) {
      ti.setTransactionManagerBeanName(transactionManagerName);
    }
    if (transactionManager != null) {
      ti.setTransactionManager(transactionManager);
    }
    ti.setTransactionAttributeSource(new NameMatchTransactionAttributeSource());
    ti.afterPropertiesSet();
    return ti;
  }
  private TransactionInterceptor transactionInterceptorWithTransactionManager(  PlatformTransactionManager transactionManager,  BeanFactory beanFactory){
    return createTransactionInterceptor(beanFactory,null,transactionManager);
  }
  private TransactionInterceptor transactionInterceptorWithTransactionManagerName(  String transactionManagerName,  BeanFactory beanFactory){
    return createTransactionInterceptor(beanFactory,transactionManagerName,null);
  }
  private TransactionInterceptor simpleTransactionInterceptor(  BeanFactory beanFactory){
    return createTransactionInterceptor(beanFactory,null,null);
  }
  private PlatformTransactionManager associateTransactionManager(  BeanFactory beanFactory,  String name){
    PlatformTransactionManager transactionManager=mock(PlatformTransactionManager.class);
    given(beanFactory.containsBean(name)).willReturn(true);
    given(beanFactory.getBean(name,PlatformTransactionManager.class)).willReturn(transactionManager);
    return transactionManager;
  }
  /** 
 * We won't use this: we just want to know it's serializable.
 */
@SuppressWarnings("serial") public static class SerializableTransactionManager implements PlatformTransactionManager, Serializable {
    @Override public TransactionStatus getTransaction(    @Nullable TransactionDefinition definition) throws TransactionException {
      throw new UnsupportedOperationException();
    }
    @Override public void commit(    TransactionStatus status) throws TransactionException {
      throw new UnsupportedOperationException();
    }
    @Override public void rollback(    TransactionStatus status) throws TransactionException {
      throw new UnsupportedOperationException();
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.aop.aspectj.annotation;
import org.aspectj.lang.reflect.PerClauseKind;
import org.junit.Test;
import test.aop.PerTargetAspect;
import org.springframework.aop.Pointcut;
import org.springframework.aop.aspectj.annotation.AbstractAspectJAdvisorFactoryTests.ExceptionAspect;
import static org.junit.Assert.*;
/** 
 * @since 2.0
 * @author Rod Johnson
 * @author Chris Beams
 */
public class AspectMetadataTests {
  @Test(expected=IllegalArgumentException.class) public void testNotAnAspect(){
    new AspectMetadata(String.class,"someBean");
  }
  @Test public void testSingletonAspect(){
    AspectMetadata am=new AspectMetadata(ExceptionAspect.class,"someBean");
    assertFalse(am.isPerThisOrPerTarget());
    assertSame(Pointcut.TRUE,am.getPerClausePointcut());
    assertEquals(PerClauseKind.SINGLETON,am.getAjType().getPerClause().getKind());
  }
  @Test public void testPerTargetAspect(){
    AspectMetadata am=new AspectMetadata(PerTargetAspect.class,"someBean");
    assertTrue(am.isPerThisOrPerTarget());
    assertNotSame(Pointcut.TRUE,am.getPerClausePointcut());
    assertEquals(PerClauseKind.PERTARGET,am.getAjType().getPerClause().getKind());
  }
  @Test public void testPerThisAspect(){
    AspectMetadata am=new AspectMetadata(PerThisAspect.class,"someBean");
    assertTrue(am.isPerThisOrPerTarget());
    assertNotSame(Pointcut.TRUE,am.getPerClausePointcut());
    assertEquals(PerClauseKind.PERTHIS,am.getAjType().getPerClause().getKind());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.context.support;
import org.junit.Test;
import org.springframework.beans.MutablePropertyValues;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.AnnotationConfigUtils;
import org.springframework.mock.web.test.MockServletContext;
import org.springframework.tests.sample.beans.ITestBean;
import org.springframework.tests.sample.beans.TestBean;
import org.springframework.web.context.WebApplicationContext;
import static org.junit.Assert.*;
/** 
 * @author Juergen Hoeller
 */
public class SpringBeanAutowiringSupportTests {
  @Test public void testProcessInjectionBasedOnServletContext(){
    StaticWebApplicationContext wac=new StaticWebApplicationContext();
    AnnotationConfigUtils.registerAnnotationConfigProcessors(wac);
    MutablePropertyValues pvs=new MutablePropertyValues();
    pvs.add("name","tb");
    wac.registerSingleton("testBean",TestBean.class,pvs);
    MockServletContext sc=new MockServletContext();
    wac.setServletContext(sc);
    wac.refresh();
    sc.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE,wac);
    InjectionTarget target=new InjectionTarget();
    SpringBeanAutowiringSupport.processInjectionBasedOnServletContext(target,sc);
    assertTrue(target.testBean instanceof TestBean);
    assertEquals("tb",target.name);
  }
public static class InjectionTarget {
    @Autowired public ITestBean testBean;
    @Value("#{testBean.name}") public String name;
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.context.request.async;
import java.util.function.Consumer;
import org.junit.Test;
import org.springframework.web.context.request.async.DeferredResult.DeferredResultHandler;
import static org.junit.Assert.*;
import static org.mockito.Mockito.*;
/** 
 * DeferredResult tests.
 * @author Rossen Stoyanchev
 */
public class DeferredResultTests {
  @Test public void setResult(){
    DeferredResultHandler handler=mock(DeferredResultHandler.class);
    DeferredResult<String> result=new DeferredResult<>();
    result.setResultHandler(handler);
    assertTrue(result.setResult("hello"));
    verify(handler).handleResult("hello");
  }
  @Test public void setResultTwice(){
    DeferredResultHandler handler=mock(DeferredResultHandler.class);
    DeferredResult<String> result=new DeferredResult<>();
    result.setResultHandler(handler);
    assertTrue(result.setResult("hello"));
    assertFalse(result.setResult("hi"));
    verify(handler).handleResult("hello");
  }
  @Test public void isSetOrExpired(){
    DeferredResultHandler handler=mock(DeferredResultHandler.class);
    DeferredResult<String> result=new DeferredResult<>();
    result.setResultHandler(handler);
    assertFalse(result.isSetOrExpired());
    result.setResult("hello");
    assertTrue(result.isSetOrExpired());
    verify(handler).handleResult("hello");
  }
  @Test public void hasResult(){
    DeferredResultHandler handler=mock(DeferredResultHandler.class);
    DeferredResult<String> result=new DeferredResult<>();
    result.setResultHandler(handler);
    assertFalse(result.hasResult());
    assertNull(result.getResult());
    result.setResult("hello");
    assertEquals("hello",result.getResult());
  }
  @Test public void onCompletion() throws Exception {
    final StringBuilder sb=new StringBuilder();
    DeferredResult<String> result=new DeferredResult<>();
    result.onCompletion(new Runnable(){
      @Override public void run(){
        sb.append("completion event");
      }
    }
);
    result.getInterceptor().afterCompletion(null,null);
    assertTrue(result.isSetOrExpired());
    assertEquals("completion event",sb.toString());
  }
  @Test public void onTimeout() throws Exception {
    final StringBuilder sb=new StringBuilder();
    DeferredResultHandler handler=mock(DeferredResultHandler.class);
    DeferredResult<String> result=new DeferredResult<>(null,"timeout result");
    result.setResultHandler(handler);
    result.onTimeout(new Runnable(){
      @Override public void run(){
        sb.append("timeout event");
      }
    }
);
    result.getInterceptor().handleTimeout(null,null);
    assertEquals("timeout event",sb.toString());
    assertFalse("Should not be able to set result a second time",result.setResult("hello"));
    verify(handler).handleResult("timeout result");
  }
  @Test public void onError() throws Exception {
    final StringBuilder sb=new StringBuilder();
    DeferredResultHandler handler=mock(DeferredResultHandler.class);
    DeferredResult<String> result=new DeferredResult<>(null,"error result");
    result.setResultHandler(handler);
    Exception e=new Exception();
    result.onError(new Consumer<Throwable>(){
      @Override public void accept(      Throwable t){
        sb.append("error event");
      }
    }
);
    result.getInterceptor().handleError(null,null,e);
    assertEquals("error event",sb.toString());
    assertFalse("Should not be able to set result a second time",result.setResult("hello"));
    verify(handler).handleResult(e);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.context.request;
import javax.servlet.ServletContextEvent;
import org.junit.Test;
import org.springframework.beans.factory.support.GenericBeanDefinition;
import org.springframework.mock.web.test.MockHttpServletRequest;
import org.springframework.mock.web.test.MockServletContext;
import org.springframework.tests.sample.beans.DerivedTestBean;
import org.springframework.web.context.ContextCleanupListener;
import org.springframework.web.context.WebApplicationContext;
import org.springframework.web.context.support.GenericWebApplicationContext;
import static org.junit.Assert.*;
/** 
 * @author Juergen Hoeller
 */
public class WebApplicationContextScopeTests {
  private static final String NAME="scoped";
  private WebApplicationContext initApplicationContext(  String scope){
    MockServletContext sc=new MockServletContext();
    GenericWebApplicationContext ac=new GenericWebApplicationContext(sc);
    GenericBeanDefinition bd=new GenericBeanDefinition();
    bd.setBeanClass(DerivedTestBean.class);
    bd.setScope(scope);
    ac.registerBeanDefinition(NAME,bd);
    ac.refresh();
    return ac;
  }
  @Test public void testRequestScope(){
    WebApplicationContext ac=initApplicationContext(WebApplicationContext.SCOPE_REQUEST);
    MockHttpServletRequest request=new MockHttpServletRequest();
    ServletRequestAttributes requestAttributes=new ServletRequestAttributes(request);
    RequestContextHolder.setRequestAttributes(requestAttributes);
    try {
      assertNull(request.getAttribute(NAME));
      DerivedTestBean bean=ac.getBean(NAME,DerivedTestBean.class);
      assertSame(bean,request.getAttribute(NAME));
      assertSame(bean,ac.getBean(NAME));
      requestAttributes.requestCompleted();
      assertTrue(bean.wasDestroyed());
    }
  finally {
      RequestContextHolder.setRequestAttributes(null);
    }
  }
  @Test public void testSessionScope(){
    WebApplicationContext ac=initApplicationContext(WebApplicationContext.SCOPE_SESSION);
    MockHttpServletRequest request=new MockHttpServletRequest();
    ServletRequestAttributes requestAttributes=new ServletRequestAttributes(request);
    RequestContextHolder.setRequestAttributes(requestAttributes);
    try {
      assertNull(request.getSession().getAttribute(NAME));
      DerivedTestBean bean=ac.getBean(NAME,DerivedTestBean.class);
      assertSame(bean,request.getSession().getAttribute(NAME));
      assertSame(bean,ac.getBean(NAME));
      request.getSession().invalidate();
      assertTrue(bean.wasDestroyed());
    }
  finally {
      RequestContextHolder.setRequestAttributes(null);
    }
  }
  @Test public void testApplicationScope(){
    WebApplicationContext ac=initApplicationContext(WebApplicationContext.SCOPE_APPLICATION);
    assertNull(ac.getServletContext().getAttribute(NAME));
    DerivedTestBean bean=ac.getBean(NAME,DerivedTestBean.class);
    assertSame(bean,ac.getServletContext().getAttribute(NAME));
    assertSame(bean,ac.getBean(NAME));
    new ContextCleanupListener().contextDestroyed(new ServletContextEvent(ac.getServletContext()));
    assertTrue(bean.wasDestroyed());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.bind.support;
import java.util.List;
import javax.servlet.MultipartConfigElement;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import javax.servlet.http.Part;
import org.eclipse.jetty.server.Connector;
import org.eclipse.jetty.server.NetworkConnector;
import org.eclipse.jetty.server.Server;
import org.eclipse.jetty.servlet.ServletContextHandler;
import org.eclipse.jetty.servlet.ServletHolder;
import org.junit.AfterClass;
import org.junit.BeforeClass;
import org.junit.Test;
import org.springframework.core.io.ClassPathResource;
import org.springframework.core.io.Resource;
import org.springframework.http.MediaType;
import org.springframework.http.client.HttpComponentsClientHttpRequestFactory;
import org.springframework.util.LinkedMultiValueMap;
import org.springframework.util.MultiValueMap;
import org.springframework.web.client.RestTemplate;
import org.springframework.web.context.request.ServletWebRequest;
import static org.junit.Assert.*;
/** 
 * @author Brian Clozel
 * @author Sam Brannen
 */
public class WebRequestDataBinderIntegrationTests {
  private static Server jettyServer;
  private static final PartsServlet partsServlet=new PartsServlet();
  private static final PartListServlet partListServlet=new PartListServlet();
  private final RestTemplate template=new RestTemplate(new HttpComponentsClientHttpRequestFactory());
  protected static String baseUrl;
  protected static MediaType contentType;
  @BeforeClass public static void startJettyServer() throws Exception {
    jettyServer=new Server(0);
    ServletContextHandler handler=new ServletContextHandler();
    MultipartConfigElement multipartConfig=new MultipartConfigElement("");
    ServletHolder holder=new ServletHolder(partsServlet);
    holder.getRegistration().setMultipartConfig(multipartConfig);
    handler.addServlet(holder,"/parts");
    holder=new ServletHolder(partListServlet);
    holder.getRegistration().setMultipartConfig(multipartConfig);
    handler.addServlet(holder,"/partlist");
    jettyServer.setHandler(handler);
    jettyServer.start();
    Connector[] connectors=jettyServer.getConnectors();
    NetworkConnector connector=(NetworkConnector)connectors[0];
    baseUrl="http://localhost:" + connector.getLocalPort();
  }
  @AfterClass public static void stopJettyServer() throws Exception {
    if (jettyServer != null) {
      jettyServer.stop();
    }
  }
  @Test public void partsBinding(){
    PartsBean bean=new PartsBean();
    partsServlet.setBean(bean);
    MultiValueMap<String,Object> parts=new LinkedMultiValueMap<>();
    Resource firstPart=new ClassPathResource("/org/springframework/http/converter/logo.jpg");
    parts.add("firstPart",firstPart);
    parts.add("secondPart","secondValue");
    template.postForLocation(baseUrl + "/parts",parts);
    assertNotNull(bean.getFirstPart());
    assertNotNull(bean.getSecondPart());
  }
  @Test public void partListBinding(){
    PartListBean bean=new PartListBean();
    partListServlet.setBean(bean);
    MultiValueMap<String,Object> parts=new LinkedMultiValueMap<>();
    parts.add("partList","first value");
    parts.add("partList","second value");
    Resource logo=new ClassPathResource("/org/springframework/http/converter/logo.jpg");
    parts.add("partList",logo);
    template.postForLocation(baseUrl + "/partlist",parts);
    assertNotNull(bean.getPartList());
    assertEquals(parts.get("partList").size(),bean.getPartList().size());
  }
@SuppressWarnings("serial") private abstract static class AbstractStandardMultipartServlet<T> extends HttpServlet {
    private T bean;
    @Override public void service(    HttpServletRequest request,    HttpServletResponse response){
      WebRequestDataBinder binder=new WebRequestDataBinder(bean);
      ServletWebRequest webRequest=new ServletWebRequest(request,response);
      binder.bind(webRequest);
      response.setStatus(HttpServletResponse.SC_OK);
    }
    public void setBean(    T bean){
      this.bean=bean;
    }
  }
private static class PartsBean {
    public Part firstPart;
    public Part secondPart;
    public Part getFirstPart(){
      return firstPart;
    }
    @SuppressWarnings("unused") public void setFirstPart(    Part firstPart){
      this.firstPart=firstPart;
    }
    public Part getSecondPart(){
      return secondPart;
    }
    @SuppressWarnings("unused") public void setSecondPart(    Part secondPart){
      this.secondPart=secondPart;
    }
  }
@SuppressWarnings("serial") private static class PartsServlet extends AbstractStandardMultipartServlet<PartsBean> {
  }
private static class PartListBean {
    public List<Part> partList;
    public List<Part> getPartList(){
      return partList;
    }
    @SuppressWarnings("unused") public void setPartList(    List<Part> partList){
      this.partList=partList;
    }
  }
@SuppressWarnings("serial") private static class PartListServlet extends AbstractStandardMultipartServlet<PartListBean> {
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.method.annotation;
import java.util.Collections;
import java.util.Map;
import javax.servlet.http.Part;
import org.junit.Test;
import org.springframework.core.MethodParameter;
import org.springframework.mock.web.test.MockHttpServletRequest;
import org.springframework.mock.web.test.MockHttpServletResponse;
import org.springframework.mock.web.test.MockMultipartFile;
import org.springframework.mock.web.test.MockMultipartHttpServletRequest;
import org.springframework.mock.web.test.MockPart;
import org.springframework.util.LinkedMultiValueMap;
import org.springframework.util.MultiValueMap;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.context.request.NativeWebRequest;
import org.springframework.web.context.request.ServletWebRequest;
import org.springframework.web.method.ResolvableMethod;
import org.springframework.web.multipart.MultipartFile;
import static org.junit.Assert.*;
import static org.springframework.web.method.MvcAnnotationPredicates.*;
/** 
 * Test fixture with  {@link RequestParamMapMethodArgumentResolver}.
 * @author Arjen Poutsma
 * @author Rossen Stoyanchev
 * @author Juergen Hoeller
 */
public class RequestParamMapMethodArgumentResolverTests {
  private RequestParamMapMethodArgumentResolver resolver=new RequestParamMapMethodArgumentResolver();
  private MockHttpServletRequest request=new MockHttpServletRequest();
  private NativeWebRequest webRequest=new ServletWebRequest(request,new MockHttpServletResponse());
  private ResolvableMethod testMethod=ResolvableMethod.on(getClass()).named("handle").build();
  @Test public void supportsParameter(){
    MethodParameter param=this.testMethod.annot(requestParam().noName()).arg(Map.class,String.class,String.class);
    assertTrue(resolver.supportsParameter(param));
    param=this.testMethod.annotPresent(RequestParam.class).arg(MultiValueMap.class,String.class,String.class);
    assertTrue(resolver.supportsParameter(param));
    param=this.testMethod.annot(requestParam().name("name")).arg(Map.class,String.class,String.class);
    assertFalse(resolver.supportsParameter(param));
    param=this.testMethod.annotNotPresent(RequestParam.class).arg(Map.class,String.class,String.class);
    assertFalse(resolver.supportsParameter(param));
  }
  @Test public void resolveMapOfString() throws Exception {
    String name="foo";
    String value="bar";
    request.addParameter(name,value);
    Map<String,String> expected=Collections.singletonMap(name,value);
    MethodParameter param=this.testMethod.annot(requestParam().noName()).arg(Map.class,String.class,String.class);
    Object result=resolver.resolveArgument(param,null,webRequest,null);
    assertTrue(result instanceof Map);
    assertEquals("Invalid result",expected,result);
  }
  @Test public void resolveMultiValueMapOfString() throws Exception {
    String name="foo";
    String value1="bar";
    String value2="baz";
    request.addParameter(name,value1,value2);
    MultiValueMap<String,String> expected=new LinkedMultiValueMap<>(1);
    expected.add(name,value1);
    expected.add(name,value2);
    MethodParameter param=this.testMethod.annotPresent(RequestParam.class).arg(MultiValueMap.class,String.class,String.class);
    Object result=resolver.resolveArgument(param,null,webRequest,null);
    assertTrue(result instanceof MultiValueMap);
    assertEquals("Invalid result",expected,result);
  }
  @Test @SuppressWarnings("unchecked") public void resolveMapOfMultipartFile() throws Exception {
    MockMultipartHttpServletRequest request=new MockMultipartHttpServletRequest();
    MultipartFile expected1=new MockMultipartFile("mfile","Hello World".getBytes());
    MultipartFile expected2=new MockMultipartFile("other","Hello World 3".getBytes());
    request.addFile(expected1);
    request.addFile(expected2);
    webRequest=new ServletWebRequest(request);
    MethodParameter param=this.testMethod.annot(requestParam().noName()).arg(Map.class,String.class,MultipartFile.class);
    Object result=resolver.resolveArgument(param,null,webRequest,null);
    assertTrue(result instanceof Map);
    Map<String,MultipartFile> resultMap=(Map<String,MultipartFile>)result;
    assertEquals(2,resultMap.size());
    assertEquals(expected1,resultMap.get("mfile"));
    assertEquals(expected2,resultMap.get("other"));
  }
  @Test @SuppressWarnings("unchecked") public void resolveMultiValueMapOfMultipartFile() throws Exception {
    MockMultipartHttpServletRequest request=new MockMultipartHttpServletRequest();
    MultipartFile expected1=new MockMultipartFile("mfilelist","Hello World 1".getBytes());
    MultipartFile expected2=new MockMultipartFile("mfilelist","Hello World 2".getBytes());
    MultipartFile expected3=new MockMultipartFile("other","Hello World 3".getBytes());
    request.addFile(expected1);
    request.addFile(expected2);
    request.addFile(expected3);
    webRequest=new ServletWebRequest(request);
    MethodParameter param=this.testMethod.annot(requestParam().noName()).arg(MultiValueMap.class,String.class,MultipartFile.class);
    Object result=resolver.resolveArgument(param,null,webRequest,null);
    assertTrue(result instanceof MultiValueMap);
    MultiValueMap<String,MultipartFile> resultMap=(MultiValueMap<String,MultipartFile>)result;
    assertEquals(2,resultMap.size());
    assertEquals(2,resultMap.get("mfilelist").size());
    assertEquals(expected1,resultMap.get("mfilelist").get(0));
    assertEquals(expected2,resultMap.get("mfilelist").get(1));
    assertEquals(1,resultMap.get("other").size());
    assertEquals(expected3,resultMap.get("other").get(0));
  }
  @Test @SuppressWarnings("unchecked") public void resolveMapOfPart() throws Exception {
    MockHttpServletRequest request=new MockHttpServletRequest();
    request.setContentType("multipart/form-data");
    Part expected1=new MockPart("mfile","Hello World".getBytes());
    Part expected2=new MockPart("other","Hello World 3".getBytes());
    request.addPart(expected1);
    request.addPart(expected2);
    webRequest=new ServletWebRequest(request);
    MethodParameter param=this.testMethod.annot(requestParam().noName()).arg(Map.class,String.class,Part.class);
    Object result=resolver.resolveArgument(param,null,webRequest,null);
    assertTrue(result instanceof Map);
    Map<String,Part> resultMap=(Map<String,Part>)result;
    assertEquals(2,resultMap.size());
    assertEquals(expected1,resultMap.get("mfile"));
    assertEquals(expected2,resultMap.get("other"));
  }
  @Test @SuppressWarnings("unchecked") public void resolveMultiValueMapOfPart() throws Exception {
    MockHttpServletRequest request=new MockHttpServletRequest();
    request.setContentType("multipart/form-data");
    Part expected1=new MockPart("mfilelist","Hello World 1".getBytes());
    Part expected2=new MockPart("mfilelist","Hello World 2".getBytes());
    Part expected3=new MockPart("other","Hello World 3".getBytes());
    request.addPart(expected1);
    request.addPart(expected2);
    request.addPart(expected3);
    webRequest=new ServletWebRequest(request);
    MethodParameter param=this.testMethod.annot(requestParam().noName()).arg(MultiValueMap.class,String.class,Part.class);
    Object result=resolver.resolveArgument(param,null,webRequest,null);
    assertTrue(result instanceof MultiValueMap);
    MultiValueMap<String,Part> resultMap=(MultiValueMap<String,Part>)result;
    assertEquals(2,resultMap.size());
    assertEquals(2,resultMap.get("mfilelist").size());
    assertEquals(expected1,resultMap.get("mfilelist").get(0));
    assertEquals(expected2,resultMap.get("mfilelist").get(1));
    assertEquals(1,resultMap.get("other").size());
    assertEquals(expected3,resultMap.get("other").get(0));
  }
  public void handle(  @RequestParam Map<String,String> param1,  @RequestParam MultiValueMap<String,String> param2,  @RequestParam Map<String,MultipartFile> param3,  @RequestParam MultiValueMap<String,MultipartFile> param4,  @RequestParam Map<String,Part> param5,  @RequestParam MultiValueMap<String,Part> param6,  @RequestParam("name") Map<String,String> param7,  Map<String,String> param8){
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.method.support;
import org.junit.Before;
import org.junit.Test;
import org.springframework.core.MethodParameter;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
import static org.mockito.Mockito.mock;
import static org.mockito.Mockito.verify;
import static org.mockito.Mockito.verifyNoMoreInteractions;
import static org.mockito.Mockito.when;
/** 
 * Test fixture with  {@link HandlerMethodReturnValueHandlerComposite}.
 * @author Rossen Stoyanchev
 */
@SuppressWarnings("unused") public class HandlerMethodReturnValueHandlerCompositeTests {
  private HandlerMethodReturnValueHandlerComposite handlers;
  private HandlerMethodReturnValueHandler integerHandler;
  ModelAndViewContainer mavContainer;
  private MethodParameter integerType;
  private MethodParameter stringType;
  @Before public void setUp() throws Exception {
    this.integerType=new MethodParameter(getClass().getDeclaredMethod("handleInteger"),-1);
    this.stringType=new MethodParameter(getClass().getDeclaredMethod("handleString"),-1);
    this.integerHandler=mock(HandlerMethodReturnValueHandler.class);
    when(this.integerHandler.supportsReturnType(this.integerType)).thenReturn(true);
    this.handlers=new HandlerMethodReturnValueHandlerComposite();
    this.handlers.addHandler(this.integerHandler);
    mavContainer=new ModelAndViewContainer();
  }
  @Test public void supportsReturnType() throws Exception {
    assertTrue(this.handlers.supportsReturnType(this.integerType));
    assertFalse(this.handlers.supportsReturnType(this.stringType));
  }
  @Test public void handleReturnValue() throws Exception {
    this.handlers.handleReturnValue(55,this.integerType,this.mavContainer,null);
    verify(this.integerHandler).handleReturnValue(55,this.integerType,this.mavContainer,null);
  }
  @Test public void handleReturnValueWithMultipleHandlers() throws Exception {
    HandlerMethodReturnValueHandler anotherIntegerHandler=mock(HandlerMethodReturnValueHandler.class);
    when(anotherIntegerHandler.supportsReturnType(this.integerType)).thenReturn(true);
    this.handlers.handleReturnValue(55,this.integerType,this.mavContainer,null);
    verify(this.integerHandler).handleReturnValue(55,this.integerType,this.mavContainer,null);
    verifyNoMoreInteractions(anotherIntegerHandler);
  }
  @Test public void handleReturnValueWithAsyncHandler() throws Exception {
    Promise<Integer> promise=new Promise<>();
    MethodParameter promiseType=new MethodParameter(getClass().getDeclaredMethod("handlePromise"),-1);
    HandlerMethodReturnValueHandler responseBodyHandler=mock(HandlerMethodReturnValueHandler.class);
    when(responseBodyHandler.supportsReturnType(promiseType)).thenReturn(true);
    this.handlers.addHandler(responseBodyHandler);
    AsyncHandlerMethodReturnValueHandler promiseHandler=mock(AsyncHandlerMethodReturnValueHandler.class);
    when(promiseHandler.supportsReturnType(promiseType)).thenReturn(true);
    when(promiseHandler.isAsyncReturnValue(promise,promiseType)).thenReturn(true);
    this.handlers.addHandler(promiseHandler);
    this.handlers.handleReturnValue(promise,promiseType,this.mavContainer,null);
    verify(promiseHandler).isAsyncReturnValue(promise,promiseType);
    verify(promiseHandler).supportsReturnType(promiseType);
    verify(promiseHandler).handleReturnValue(promise,promiseType,this.mavContainer,null);
    verifyNoMoreInteractions(promiseHandler);
    verifyNoMoreInteractions(responseBodyHandler);
  }
  @Test(expected=IllegalArgumentException.class) public void noSuitableReturnValueHandler() throws Exception {
    this.handlers.handleReturnValue("value",this.stringType,null,null);
  }
  private Integer handleInteger(){
    return null;
  }
  private String handleString(){
    return null;
  }
  private Promise<Integer> handlePromise(){
    return null;
  }
private static class Promise<T> {
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.http;
import java.util.LinkedHashMap;
import java.util.Map;
import org.junit.Before;
import org.junit.Test;
import static org.junit.Assert.*;
/** 
 * @author Arjen Poutsma 
 */
public class HttpStatusTests {
  private Map<Integer,String> statusCodes=new LinkedHashMap<>();
  @Before public void createStatusCodes(){
    statusCodes.put(100,"CONTINUE");
    statusCodes.put(101,"SWITCHING_PROTOCOLS");
    statusCodes.put(102,"PROCESSING");
    statusCodes.put(103,"CHECKPOINT");
    statusCodes.put(200,"OK");
    statusCodes.put(201,"CREATED");
    statusCodes.put(202,"ACCEPTED");
    statusCodes.put(203,"NON_AUTHORITATIVE_INFORMATION");
    statusCodes.put(204,"NO_CONTENT");
    statusCodes.put(205,"RESET_CONTENT");
    statusCodes.put(206,"PARTIAL_CONTENT");
    statusCodes.put(207,"MULTI_STATUS");
    statusCodes.put(208,"ALREADY_REPORTED");
    statusCodes.put(226,"IM_USED");
    statusCodes.put(300,"MULTIPLE_CHOICES");
    statusCodes.put(301,"MOVED_PERMANENTLY");
    statusCodes.put(302,"FOUND");
    statusCodes.put(303,"SEE_OTHER");
    statusCodes.put(304,"NOT_MODIFIED");
    statusCodes.put(305,"USE_PROXY");
    statusCodes.put(307,"TEMPORARY_REDIRECT");
    statusCodes.put(308,"PERMANENT_REDIRECT");
    statusCodes.put(400,"BAD_REQUEST");
    statusCodes.put(401,"UNAUTHORIZED");
    statusCodes.put(402,"PAYMENT_REQUIRED");
    statusCodes.put(403,"FORBIDDEN");
    statusCodes.put(404,"NOT_FOUND");
    statusCodes.put(405,"METHOD_NOT_ALLOWED");
    statusCodes.put(406,"NOT_ACCEPTABLE");
    statusCodes.put(407,"PROXY_AUTHENTICATION_REQUIRED");
    statusCodes.put(408,"REQUEST_TIMEOUT");
    statusCodes.put(409,"CONFLICT");
    statusCodes.put(410,"GONE");
    statusCodes.put(411,"LENGTH_REQUIRED");
    statusCodes.put(412,"PRECONDITION_FAILED");
    statusCodes.put(413,"PAYLOAD_TOO_LARGE");
    statusCodes.put(414,"URI_TOO_LONG");
    statusCodes.put(415,"UNSUPPORTED_MEDIA_TYPE");
    statusCodes.put(416,"REQUESTED_RANGE_NOT_SATISFIABLE");
    statusCodes.put(417,"EXPECTATION_FAILED");
    statusCodes.put(418,"I_AM_A_TEAPOT");
    statusCodes.put(419,"INSUFFICIENT_SPACE_ON_RESOURCE");
    statusCodes.put(420,"METHOD_FAILURE");
    statusCodes.put(421,"DESTINATION_LOCKED");
    statusCodes.put(422,"UNPROCESSABLE_ENTITY");
    statusCodes.put(423,"LOCKED");
    statusCodes.put(424,"FAILED_DEPENDENCY");
    statusCodes.put(426,"UPGRADE_REQUIRED");
    statusCodes.put(428,"PRECONDITION_REQUIRED");
    statusCodes.put(429,"TOO_MANY_REQUESTS");
    statusCodes.put(431,"REQUEST_HEADER_FIELDS_TOO_LARGE");
    statusCodes.put(451,"UNAVAILABLE_FOR_LEGAL_REASONS");
    statusCodes.put(500,"INTERNAL_SERVER_ERROR");
    statusCodes.put(501,"NOT_IMPLEMENTED");
    statusCodes.put(502,"BAD_GATEWAY");
    statusCodes.put(503,"SERVICE_UNAVAILABLE");
    statusCodes.put(504,"GATEWAY_TIMEOUT");
    statusCodes.put(505,"HTTP_VERSION_NOT_SUPPORTED");
    statusCodes.put(506,"VARIANT_ALSO_NEGOTIATES");
    statusCodes.put(507,"INSUFFICIENT_STORAGE");
    statusCodes.put(508,"LOOP_DETECTED");
    statusCodes.put(509,"BANDWIDTH_LIMIT_EXCEEDED");
    statusCodes.put(510,"NOT_EXTENDED");
    statusCodes.put(511,"NETWORK_AUTHENTICATION_REQUIRED");
  }
  @Test public void fromMapToEnum(){
    for (    Map.Entry<Integer,String> entry : statusCodes.entrySet()) {
      int value=entry.getKey();
      HttpStatus status=HttpStatus.valueOf(value);
      assertEquals("Invalid value",value,status.value());
      assertEquals("Invalid name for [" + value + "]",entry.getValue(),status.name());
    }
  }
  @Test public void fromEnumToMap(){
    for (    HttpStatus status : HttpStatus.values()) {
      int value=status.value();
      if (value == 302 || value == 413 || value == 414) {
        continue;
      }
      assertTrue("Map has no value for [" + value + "]",statusCodes.containsKey(value));
      assertEquals("Invalid name for [" + value + "]",statusCodes.get(value),status.name());
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.socket;
import java.util.HashMap;
import java.util.Map;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.junit.After;
import org.junit.Before;
import org.junit.Rule;
import org.junit.rules.TestName;
import org.junit.runners.Parameterized.Parameter;
import org.springframework.context.Lifecycle;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.util.concurrent.ListenableFuture;
import org.springframework.web.context.support.AnnotationConfigWebApplicationContext;
import org.springframework.web.socket.client.WebSocketClient;
import org.springframework.web.socket.server.RequestUpgradeStrategy;
import org.springframework.web.socket.server.jetty.JettyRequestUpgradeStrategy;
import org.springframework.web.socket.server.standard.TomcatRequestUpgradeStrategy;
import org.springframework.web.socket.server.standard.UndertowRequestUpgradeStrategy;
import org.springframework.web.socket.server.support.DefaultHandshakeHandler;
/** 
 * Base class for WebSocket integration tests.
 * @author Rossen Stoyanchev
 * @author Sam Brannen
 */
public abstract class AbstractWebSocketIntegrationTests {
  private static Map<Class<?>,Class<?>> upgradeStrategyConfigTypes=new HashMap<>();
static {
    upgradeStrategyConfigTypes.put(JettyWebSocketTestServer.class,JettyUpgradeStrategyConfig.class);
    upgradeStrategyConfigTypes.put(TomcatWebSocketTestServer.class,TomcatUpgradeStrategyConfig.class);
    upgradeStrategyConfigTypes.put(UndertowTestServer.class,UndertowUpgradeStrategyConfig.class);
  }
  @Rule public final TestName testName=new TestName();
  @Parameter(0) public WebSocketTestServer server;
  @Parameter(1) public WebSocketClient webSocketClient;
  protected final Log logger=LogFactory.getLog(getClass());
  protected AnnotationConfigWebApplicationContext wac;
  @Before public void setup() throws Exception {
    logger.debug("Setting up '" + this.testName.getMethodName() + "', client="+ this.webSocketClient.getClass().getSimpleName()+ ", server="+ this.server.getClass().getSimpleName());
    this.wac=new AnnotationConfigWebApplicationContext();
    this.wac.register(getAnnotatedConfigClasses());
    this.wac.register(upgradeStrategyConfigTypes.get(this.server.getClass()));
    if (this.webSocketClient instanceof Lifecycle) {
      ((Lifecycle)this.webSocketClient).start();
    }
    this.server.setup();
    this.server.deployConfig(this.wac);
    this.server.start();
    this.wac.setServletContext(this.server.getServletContext());
    this.wac.refresh();
  }
  protected abstract Class<?>[] getAnnotatedConfigClasses();
  @After public void teardown() throws Exception {
    try {
      if (this.webSocketClient instanceof Lifecycle) {
        ((Lifecycle)this.webSocketClient).stop();
      }
    }
 catch (    Throwable t) {
      logger.error("Failed to stop WebSocket client",t);
    }
    try {
      this.server.undeployConfig();
    }
 catch (    Throwable t) {
      logger.error("Failed to undeploy application config",t);
    }
    try {
      this.server.stop();
    }
 catch (    Throwable t) {
      logger.error("Failed to stop server",t);
    }
    try {
      this.wac.close();
    }
 catch (    Throwable t) {
      logger.error("Failed to close WebApplicationContext",t);
    }
  }
  protected String getWsBaseUrl(){
    return "ws://localhost:" + this.server.getPort();
  }
  protected ListenableFuture<WebSocketSession> doHandshake(  WebSocketHandler clientHandler,  String endpointPath){
    return this.webSocketClient.doHandshake(clientHandler,getWsBaseUrl() + endpointPath);
  }
static abstract class AbstractRequestUpgradeStrategyConfig {
    @Bean public DefaultHandshakeHandler handshakeHandler(){
      return new DefaultHandshakeHandler(requestUpgradeStrategy());
    }
    public abstract RequestUpgradeStrategy requestUpgradeStrategy();
  }
@Configuration static class JettyUpgradeStrategyConfig extends AbstractRequestUpgradeStrategyConfig {
    @Bean public RequestUpgradeStrategy requestUpgradeStrategy(){
      return new JettyRequestUpgradeStrategy();
    }
  }
@Configuration static class TomcatUpgradeStrategyConfig extends AbstractRequestUpgradeStrategyConfig {
    @Bean public RequestUpgradeStrategy requestUpgradeStrategy(){
      return new TomcatRequestUpgradeStrategy();
    }
  }
@Configuration static class UndertowUpgradeStrategyConfig extends AbstractRequestUpgradeStrategyConfig {
    @Bean public RequestUpgradeStrategy requestUpgradeStrategy(){
      return new UndertowRequestUpgradeStrategy();
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.test.context.hierarchies.web;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.ApplicationContext;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.test.context.ContextConfiguration;
import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;
import org.springframework.web.context.WebApplicationContext;
import static org.junit.Assert.*;
/** 
 * @author Sam Brannen
 * @since 3.2.2
 */
@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration public class EarTests {
@Configuration static class EarConfig {
    @Bean public String ear(){
      return "ear";
    }
  }
  @Autowired private ApplicationContext context;
  @Autowired private String ear;
  @Test public void verifyEarConfig(){
    assertFalse(context instanceof WebApplicationContext);
    assertNull(context.getParent());
    assertEquals("ear",ear);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.test.context.junit;
import org.junit.platform.runner.JUnitPlatform;
import org.junit.platform.suite.api.ExcludeTags;
import org.junit.platform.suite.api.IncludeClassNamePatterns;
import org.junit.platform.suite.api.IncludeEngines;
import org.junit.platform.suite.api.SelectPackages;
import org.junit.platform.suite.api.UseTechnicalNames;
import org.junit.runner.RunWith;
/** 
 * JUnit 4 based test suite for tests that involve the Spring TestContext Framework and JUnit Jupiter (i.e., JUnit 5's programming model). <p>This class intentionally does not reside in the "jupiter" package so that the entire "jupiter" package can be excluded from the Gradle build. This class is therefore responsible for executing all JUnit Jupiter based tests in Spring's official test suite. <h3>Logging Configuration</h3> <p>In order for our log4j2 configuration to be used in an IDE, you must set the following system property before running any tests &mdash; for example, in <em>Run Configurations</em> in Eclipse. <pre style="code"> -Djava.util.logging.manager=org.apache.logging.log4j.jul.LogManager </pre>
 * @author Sam Brannen
 * @since 5.0
 */
@RunWith(JUnitPlatform.class) @IncludeEngines("junit-jupiter") @SelectPackages("org.springframework.test.context.junit.jupiter") @IncludeClassNamePatterns(".*Tests$") @ExcludeTags("failing-test-case") @UseTechnicalNames public class SpringJUnitJupiterTestSuite {
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.test.context.env;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.env.Environment;
import org.springframework.test.context.ContextConfiguration;
import org.springframework.test.context.TestPropertySource;
import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;
import static org.junit.Assert.*;
/** 
 * Integration tests that verify detection of a default properties file when  {@link TestPropertySource @TestPropertySource} is <em>empty</em>.
 * @author Sam Brannen
 * @since 4.1
 */
@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration @TestPropertySource public class DefaultPropertiesFileDetectionTestPropertySourceTests {
  @Autowired protected Environment env;
  @Test public void verifyPropertiesAreAvailableInEnvironment(){
    assertEnvironmentValue("riddle","auto detected");
  }
  protected void assertEnvironmentValue(  String key,  String expected){
    assertEquals("Value of key [" + key + "].",expected,env.getProperty(key));
  }
@Configuration static class Config {
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.test.context.junit4.annotation;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.test.context.ContextConfiguration;
import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;
import org.springframework.test.context.support.DelegatingSmartContextLoader;
import org.springframework.tests.sample.beans.Employee;
import static org.junit.Assert.*;
/** 
 * Integration tests that verify support for configuration classes in the Spring TestContext Framework in conjunction with the {@link DelegatingSmartContextLoader}.
 * @author Sam Brannen
 * @since 3.1
 * @see DefaultConfigClassesBaseTests
 */
@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration public class DefaultLoaderDefaultConfigClassesBaseTests {
@Configuration static class Config {
    @Bean public Employee employee(){
      Employee employee=new Employee();
      employee.setName("John Smith");
      employee.setAge(42);
      employee.setCompany("Acme Widgets, Inc.");
      return employee;
    }
  }
  @Autowired protected Employee employee;
  @Test public void verifyEmployeeSetFromBaseContextConfig(){
    assertNotNull("The employee field should have been autowired.",this.employee);
    assertEquals("John Smith",this.employee.getName());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.test.context.junit4;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import org.junit.Test;
import org.junit.runners.model.FrameworkMethod;
import org.springframework.test.annotation.Timed;
import org.springframework.test.context.TestContextManager;
import static org.junit.Assert.*;
/** 
 * Unit tests for  {@link SpringJUnit4ClassRunner}.
 * @author Sam Brannen
 * @author Rick Evans
 * @since 2.5
 */
public class SpringJUnit4ClassRunnerTests {
  @Test(expected=Exception.class) public void checkThatExceptionsAreNotSilentlySwallowed() throws Exception {
    SpringJUnit4ClassRunner runner=new SpringJUnit4ClassRunner(getClass()){
      @Override protected TestContextManager createTestContextManager(      Class<?> clazz){
        return new TestContextManager(clazz){
          @Override public void prepareTestInstance(          Object testInstance){
            throw new RuntimeException("This RuntimeException should be caught and wrapped in an Exception.");
          }
        }
;
      }
    }
;
    runner.createTest();
  }
  @Test public void getSpringTimeoutViaMetaAnnotation() throws Exception {
    SpringJUnit4ClassRunner runner=new SpringJUnit4ClassRunner(getClass());
    long timeout=runner.getSpringTimeout(new FrameworkMethod(getClass().getDeclaredMethod("springTimeoutWithMetaAnnotation")));
    assertEquals(10,timeout);
  }
  @Test public void getSpringTimeoutViaMetaAnnotationWithOverride() throws Exception {
    SpringJUnit4ClassRunner runner=new SpringJUnit4ClassRunner(getClass());
    long timeout=runner.getSpringTimeout(new FrameworkMethod(getClass().getDeclaredMethod("springTimeoutWithMetaAnnotationAndOverride")));
    assertEquals(42,timeout);
  }
  @MetaTimed void springTimeoutWithMetaAnnotation(){
  }
  @MetaTimedWithOverride(millis=42) void springTimeoutWithMetaAnnotationAndOverride(){
  }
  @Timed(millis=10) @Retention(RetentionPolicy.RUNTIME) private static @interface MetaTimed {}
  @Timed(millis=1000) @Retention(RetentionPolicy.RUNTIME) private static @interface MetaTimedWithOverride {  long millis() default 1000;
}
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.test.web.servlet;
import java.util.concurrent.CountDownLatch;
import org.junit.Test;
import org.springframework.mock.web.MockHttpServletRequest;
/** 
 * Test fixture for  {@link DefaultMvcResult}.
 * @author Rossen Stoyanchev
 */
public class DefaultMvcResultTests {
  private final DefaultMvcResult mvcResult=new DefaultMvcResult(new MockHttpServletRequest(),null);
  @Test public void getAsyncResultSuccess(){
    this.mvcResult.setAsyncResult("Foo");
    this.mvcResult.setAsyncDispatchLatch(new CountDownLatch(0));
    this.mvcResult.getAsyncResult();
  }
  @Test(expected=IllegalStateException.class) public void getAsyncResultFailure(){
    this.mvcResult.getAsyncResult(0);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.test.web.servlet.htmlunit;
import java.net.URL;
import java.util.Collections;
import com.gargoylesoftware.htmlunit.HttpWebConnection;
import com.gargoylesoftware.htmlunit.Page;
import com.gargoylesoftware.htmlunit.WebClient;
import com.gargoylesoftware.htmlunit.WebConnection;
import com.gargoylesoftware.htmlunit.WebRequest;
import com.gargoylesoftware.htmlunit.WebResponse;
import com.gargoylesoftware.htmlunit.WebResponseData;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.mockito.Mock;
import org.mockito.junit.MockitoJUnitRunner;
import org.springframework.stereotype.Controller;
import org.springframework.test.web.servlet.MockMvc;
import org.springframework.test.web.servlet.htmlunit.DelegatingWebConnection.DelegateWebConnection;
import org.springframework.test.web.servlet.setup.MockMvcBuilders;
import org.springframework.tests.Assume;
import org.springframework.tests.TestGroup;
import static org.hamcrest.CoreMatchers.equalTo;
import static org.hamcrest.CoreMatchers.sameInstance;
import static org.hamcrest.Matchers.*;
import static org.hamcrest.core.IsNot.not;
import static org.junit.Assert.*;
import static org.mockito.Mockito.*;
/** 
 * Unit and integration tests for  {@link DelegatingWebConnection}.
 * @author Rob Winch
 * @since 4.2
 */
@RunWith(MockitoJUnitRunner.class) public class DelegatingWebConnectionTests {
  private DelegatingWebConnection webConnection;
  private WebRequest request;
  private WebResponse expectedResponse;
  @Mock private WebRequestMatcher matcher1;
  @Mock private WebRequestMatcher matcher2;
  @Mock private WebConnection defaultConnection;
  @Mock private WebConnection connection1;
  @Mock private WebConnection connection2;
  @Before public void setup() throws Exception {
    request=new WebRequest(new URL("http://localhost/"));
    WebResponseData data=new WebResponseData("".getBytes("UTF-8"),200,"",Collections.emptyList());
    expectedResponse=new WebResponse(data,request,100L);
    webConnection=new DelegatingWebConnection(defaultConnection,new DelegateWebConnection(matcher1,connection1),new DelegateWebConnection(matcher2,connection2));
  }
  @Test public void getResponseDefault() throws Exception {
    when(defaultConnection.getResponse(request)).thenReturn(expectedResponse);
    WebResponse response=webConnection.getResponse(request);
    assertThat(response,sameInstance(expectedResponse));
    verify(matcher1).matches(request);
    verify(matcher2).matches(request);
    verifyNoMoreInteractions(connection1,connection2);
    verify(defaultConnection).getResponse(request);
  }
  @Test public void getResponseAllMatches() throws Exception {
    when(matcher1.matches(request)).thenReturn(true);
    when(connection1.getResponse(request)).thenReturn(expectedResponse);
    WebResponse response=webConnection.getResponse(request);
    assertThat(response,sameInstance(expectedResponse));
    verify(matcher1).matches(request);
    verifyNoMoreInteractions(matcher2,connection2,defaultConnection);
    verify(connection1).getResponse(request);
  }
  @Test public void getResponseSecondMatches() throws Exception {
    when(matcher2.matches(request)).thenReturn(true);
    when(connection2.getResponse(request)).thenReturn(expectedResponse);
    WebResponse response=webConnection.getResponse(request);
    assertThat(response,sameInstance(expectedResponse));
    verify(matcher1).matches(request);
    verify(matcher2).matches(request);
    verifyNoMoreInteractions(connection1,defaultConnection);
    verify(connection2).getResponse(request);
  }
  @Test public void verifyExampleInClassLevelJavadoc() throws Exception {
    Assume.group(TestGroup.PERFORMANCE);
    WebClient webClient=new WebClient();
    MockMvc mockMvc=MockMvcBuilders.standaloneSetup().build();
    MockMvcWebConnection mockConnection=new MockMvcWebConnection(mockMvc,webClient);
    WebRequestMatcher cdnMatcher=new UrlRegexRequestMatcher(".*?//code.jquery.com/.*");
    WebConnection httpConnection=new HttpWebConnection(webClient);
    webClient.setWebConnection(new DelegatingWebConnection(mockConnection,new DelegateWebConnection(cdnMatcher,httpConnection)));
    Page page=webClient.getPage("http://code.jquery.com/jquery-1.11.0.min.js");
    assertThat(page.getWebResponse().getStatusCode(),equalTo(200));
    assertThat(page.getWebResponse().getContentAsString(),not(isEmptyString()));
  }
@Controller static class TestController {
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.test.web.reactive.server.samples.bind;
import org.junit.Before;
import org.junit.Test;
import org.springframework.test.web.reactive.server.WebTestClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;
/** 
 * Sample tests demonstrating "mock" server tests binding to an annotated controller.
 * @author Rossen Stoyanchev
 */
public class ControllerTests {
  private WebTestClient client;
  @Before public void setUp() throws Exception {
    this.client=WebTestClient.bindToController(new TestController()).build();
  }
  @Test public void test() throws Exception {
    this.client.get().uri("/test").exchange().expectStatus().isOk().expectBody(String.class).isEqualTo("It works!");
  }
@RestController static class TestController {
    @GetMapping("/test") public String handle(){
      return "It works!";
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.test.web.client.match;
import java.io.IOException;
import org.hamcrest.Matchers;
import org.junit.Before;
import org.junit.Test;
import org.springframework.mock.http.client.MockClientHttpRequest;
/** 
 * Unit tests for  {@link XpathRequestMatchers}.
 * @author Rossen Stoyanchev
 */
public class XpathRequestMatchersTests {
  private static final String RESPONSE_CONTENT="<foo><bar>111</bar><bar>true</bar></foo>";
  private MockClientHttpRequest request;
  @Before public void setUp() throws IOException {
    this.request=new MockClientHttpRequest();
    this.request.getBody().write(RESPONSE_CONTENT.getBytes());
  }
  @Test public void testNodeMatcher() throws Exception {
    new XpathRequestMatchers("/foo/bar",null).node(Matchers.notNullValue()).match(this.request);
  }
  @Test(expected=AssertionError.class) public void testNodeMatcherNoMatch() throws Exception {
    new XpathRequestMatchers("/foo/bar",null).node(Matchers.nullValue()).match(this.request);
  }
  @Test public void testExists() throws Exception {
    new XpathRequestMatchers("/foo/bar",null).exists().match(this.request);
  }
  @Test(expected=AssertionError.class) public void testExistsNoMatch() throws Exception {
    new XpathRequestMatchers("/foo/Bar",null).exists().match(this.request);
  }
  @Test public void testDoesNotExist() throws Exception {
    new XpathRequestMatchers("/foo/Bar",null).doesNotExist().match(this.request);
  }
  @Test(expected=AssertionError.class) public void testDoesNotExistNoMatch() throws Exception {
    new XpathRequestMatchers("/foo/bar",null).doesNotExist().match(this.request);
  }
  @Test public void testNodeCount() throws Exception {
    new XpathRequestMatchers("/foo/bar",null).nodeCount(2).match(this.request);
  }
  @Test(expected=AssertionError.class) public void testNodeCountNoMatch() throws Exception {
    new XpathRequestMatchers("/foo/bar",null).nodeCount(1).match(this.request);
  }
  @Test public void testString() throws Exception {
    new XpathRequestMatchers("/foo/bar[1]",null).string("111").match(this.request);
  }
  @Test(expected=AssertionError.class) public void testStringNoMatch() throws Exception {
    new XpathRequestMatchers("/foo/bar[1]",null).string("112").match(this.request);
  }
  @Test public void testNumber() throws Exception {
    new XpathRequestMatchers("/foo/bar[1]",null).number(111.0).match(this.request);
  }
  @Test(expected=AssertionError.class) public void testNumberNoMatch() throws Exception {
    new XpathRequestMatchers("/foo/bar[1]",null).number(111.1).match(this.request);
  }
  @Test public void testBoolean() throws Exception {
    new XpathRequestMatchers("/foo/bar[2]",null).booleanValue(true).match(this.request);
  }
  @Test(expected=AssertionError.class) public void testBooleanNoMatch() throws Exception {
    new XpathRequestMatchers("/foo/bar[2]",null).booleanValue(false).match(this.request);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.test.annotation;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.reflect.Method;
import org.junit.BeforeClass;
import org.junit.Test;
import static org.junit.Assert.*;
/** 
 * Unit tests for  {@link ProfileValueUtils}.
 * @author Sam Brannen
 * @since 3.0
 */
public class ProfileValueUtilsTests {
  private static final String NON_ANNOTATED_METHOD="nonAnnotatedMethod";
  private static final String ENABLED_ANNOTATED_METHOD="enabledAnnotatedMethod";
  private static final String DISABLED_ANNOTATED_METHOD="disabledAnnotatedMethod";
  private static final String NAME="ProfileValueUtilsTests.profile_value.name";
  private static final String VALUE="enigma";
  @BeforeClass public static void setProfileValue(){
    System.setProperty(NAME,VALUE);
  }
  private void assertClassIsEnabled(  Class<?> testClass) throws Exception {
    assertTrue("Test class [" + testClass + "] should be enabled.",ProfileValueUtils.isTestEnabledInThisEnvironment(testClass));
  }
  private void assertClassIsDisabled(  Class<?> testClass) throws Exception {
    assertFalse("Test class [" + testClass + "] should be disabled.",ProfileValueUtils.isTestEnabledInThisEnvironment(testClass));
  }
  private void assertMethodIsEnabled(  String methodName,  Class<?> testClass) throws Exception {
    Method testMethod=testClass.getMethod(methodName);
    assertTrue("Test method [" + testMethod + "] should be enabled.",ProfileValueUtils.isTestEnabledInThisEnvironment(testMethod,testClass));
  }
  private void assertMethodIsDisabled(  String methodName,  Class<?> testClass) throws Exception {
    Method testMethod=testClass.getMethod(methodName);
    assertFalse("Test method [" + testMethod + "] should be disabled.",ProfileValueUtils.isTestEnabledInThisEnvironment(testMethod,testClass));
  }
  private void assertMethodIsEnabled(  ProfileValueSource profileValueSource,  String methodName,  Class<?> testClass) throws Exception {
    Method testMethod=testClass.getMethod(methodName);
    assertTrue("Test method [" + testMethod + "] should be enabled for ProfileValueSource ["+ profileValueSource+ "].",ProfileValueUtils.isTestEnabledInThisEnvironment(profileValueSource,testMethod,testClass));
  }
  private void assertMethodIsDisabled(  ProfileValueSource profileValueSource,  String methodName,  Class<?> testClass) throws Exception {
    Method testMethod=testClass.getMethod(methodName);
    assertFalse("Test method [" + testMethod + "] should be disabled for ProfileValueSource ["+ profileValueSource+ "].",ProfileValueUtils.isTestEnabledInThisEnvironment(profileValueSource,testMethod,testClass));
  }
  @Test public void isTestEnabledInThisEnvironmentForProvidedClass() throws Exception {
    assertClassIsEnabled(NonAnnotated.class);
    assertClassIsEnabled(EnabledAnnotatedSingleValue.class);
    assertClassIsEnabled(EnabledAnnotatedMultiValue.class);
    assertClassIsEnabled(MetaEnabledClass.class);
    assertClassIsEnabled(MetaEnabledWithCustomProfileValueSourceClass.class);
    assertClassIsEnabled(EnabledWithCustomProfileValueSourceOnTestInterface.class);
    assertClassIsDisabled(DisabledAnnotatedSingleValue.class);
    assertClassIsDisabled(DisabledAnnotatedSingleValueOnTestInterface.class);
    assertClassIsDisabled(DisabledAnnotatedMultiValue.class);
    assertClassIsDisabled(MetaDisabledClass.class);
    assertClassIsDisabled(MetaDisabledWithCustomProfileValueSourceClass.class);
  }
  @Test public void isTestEnabledInThisEnvironmentForProvidedMethodAndClass() throws Exception {
    assertMethodIsEnabled(NON_ANNOTATED_METHOD,NonAnnotated.class);
    assertMethodIsEnabled(NON_ANNOTATED_METHOD,EnabledAnnotatedSingleValue.class);
    assertMethodIsEnabled(ENABLED_ANNOTATED_METHOD,EnabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(DISABLED_ANNOTATED_METHOD,EnabledAnnotatedSingleValue.class);
    assertMethodIsEnabled(NON_ANNOTATED_METHOD,MetaEnabledAnnotatedSingleValue.class);
    assertMethodIsEnabled(ENABLED_ANNOTATED_METHOD,MetaEnabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(DISABLED_ANNOTATED_METHOD,MetaEnabledAnnotatedSingleValue.class);
    assertMethodIsEnabled(NON_ANNOTATED_METHOD,EnabledAnnotatedMultiValue.class);
    assertMethodIsEnabled(ENABLED_ANNOTATED_METHOD,EnabledAnnotatedMultiValue.class);
    assertMethodIsDisabled(DISABLED_ANNOTATED_METHOD,EnabledAnnotatedMultiValue.class);
    assertMethodIsDisabled(NON_ANNOTATED_METHOD,DisabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(ENABLED_ANNOTATED_METHOD,DisabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(DISABLED_ANNOTATED_METHOD,DisabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(NON_ANNOTATED_METHOD,DisabledAnnotatedSingleValueOnTestInterface.class);
    assertMethodIsDisabled(NON_ANNOTATED_METHOD,MetaDisabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(ENABLED_ANNOTATED_METHOD,MetaDisabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(DISABLED_ANNOTATED_METHOD,MetaDisabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(NON_ANNOTATED_METHOD,DisabledAnnotatedMultiValue.class);
    assertMethodIsDisabled(ENABLED_ANNOTATED_METHOD,DisabledAnnotatedMultiValue.class);
    assertMethodIsDisabled(DISABLED_ANNOTATED_METHOD,DisabledAnnotatedMultiValue.class);
  }
  @Test public void isTestEnabledInThisEnvironmentForProvidedProfileValueSourceMethodAndClass() throws Exception {
    ProfileValueSource profileValueSource=SystemProfileValueSource.getInstance();
    assertMethodIsEnabled(profileValueSource,NON_ANNOTATED_METHOD,NonAnnotated.class);
    assertMethodIsEnabled(profileValueSource,NON_ANNOTATED_METHOD,EnabledAnnotatedSingleValue.class);
    assertMethodIsEnabled(profileValueSource,ENABLED_ANNOTATED_METHOD,EnabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(profileValueSource,DISABLED_ANNOTATED_METHOD,EnabledAnnotatedSingleValue.class);
    assertMethodIsEnabled(profileValueSource,NON_ANNOTATED_METHOD,EnabledAnnotatedMultiValue.class);
    assertMethodIsEnabled(profileValueSource,ENABLED_ANNOTATED_METHOD,EnabledAnnotatedMultiValue.class);
    assertMethodIsDisabled(profileValueSource,DISABLED_ANNOTATED_METHOD,EnabledAnnotatedMultiValue.class);
    assertMethodIsDisabled(profileValueSource,NON_ANNOTATED_METHOD,DisabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(profileValueSource,ENABLED_ANNOTATED_METHOD,DisabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(profileValueSource,DISABLED_ANNOTATED_METHOD,DisabledAnnotatedSingleValue.class);
    assertMethodIsDisabled(profileValueSource,NON_ANNOTATED_METHOD,DisabledAnnotatedMultiValue.class);
    assertMethodIsDisabled(profileValueSource,ENABLED_ANNOTATED_METHOD,DisabledAnnotatedMultiValue.class);
    assertMethodIsDisabled(profileValueSource,DISABLED_ANNOTATED_METHOD,DisabledAnnotatedMultiValue.class);
  }
@SuppressWarnings("unused") private static class NonAnnotated {
    public void nonAnnotatedMethod(){
    }
  }
@SuppressWarnings("unused") @IfProfileValue(name=NAME,value=VALUE) private static class EnabledAnnotatedSingleValue {
    public void nonAnnotatedMethod(){
    }
    @IfProfileValue(name=NAME,value=VALUE) public void enabledAnnotatedMethod(){
    }
    @IfProfileValue(name=NAME,value=VALUE + "X") public void disabledAnnotatedMethod(){
    }
  }
@IfProfileValue(name=NAME,value=VALUE + "X") private interface IfProfileValueTestInterface {
  }
@SuppressWarnings("unused") private static class DisabledAnnotatedSingleValueOnTestInterface implements IfProfileValueTestInterface {
    public void nonAnnotatedMethod(){
    }
  }
@SuppressWarnings("unused") @IfProfileValue(name=NAME,values={"foo",VALUE,"bar"}) private static class EnabledAnnotatedMultiValue {
    public void nonAnnotatedMethod(){
    }
    @IfProfileValue(name=NAME,value=VALUE) public void enabledAnnotatedMethod(){
    }
    @IfProfileValue(name=NAME,value=VALUE + "X") public void disabledAnnotatedMethod(){
    }
  }
@SuppressWarnings("unused") @IfProfileValue(name=NAME,value=VALUE + "X") private static class DisabledAnnotatedSingleValue {
    public void nonAnnotatedMethod(){
    }
    @IfProfileValue(name=NAME,value=VALUE) public void enabledAnnotatedMethod(){
    }
    @IfProfileValue(name=NAME,value=VALUE + "X") public void disabledAnnotatedMethod(){
    }
  }
@SuppressWarnings("unused") @IfProfileValue(name=NAME,values={"foo","bar"}) private static class DisabledAnnotatedMultiValue {
    public void nonAnnotatedMethod(){
    }
    @IfProfileValue(name=NAME,value=VALUE) public void enabledAnnotatedMethod(){
    }
    @IfProfileValue(name=NAME,value=VALUE + "X") public void disabledAnnotatedMethod(){
    }
  }
  @IfProfileValue(name=NAME,value=VALUE) @Retention(RetentionPolicy.RUNTIME) private static @interface MetaEnabled {}
  @IfProfileValue(name=NAME,value=VALUE + "X") @Retention(RetentionPolicy.RUNTIME) private static @interface MetaDisabled {}
@MetaEnabled private static class MetaEnabledClass {
  }
@MetaDisabled private static class MetaDisabledClass {
  }
@SuppressWarnings("unused") @MetaEnabled private static class MetaEnabledAnnotatedSingleValue {
    public void nonAnnotatedMethod(){
    }
    @MetaEnabled public void enabledAnnotatedMethod(){
    }
    @MetaDisabled public void disabledAnnotatedMethod(){
    }
  }
@SuppressWarnings("unused") @MetaDisabled private static class MetaDisabledAnnotatedSingleValue {
    public void nonAnnotatedMethod(){
    }
    @MetaEnabled public void enabledAnnotatedMethod(){
    }
    @MetaDisabled public void disabledAnnotatedMethod(){
    }
  }
public static class HardCodedProfileValueSource implements ProfileValueSource {
    @Override public String get(    final String key){
      return (key.equals(NAME) ? "42" : null);
    }
  }
  @ProfileValueSourceConfiguration(HardCodedProfileValueSource.class) @IfProfileValue(name=NAME,value="42") @Retention(RetentionPolicy.RUNTIME) private static @interface MetaEnabledWithCustomProfileValueSource {}
  @ProfileValueSourceConfiguration(HardCodedProfileValueSource.class) @IfProfileValue(name=NAME,value="13") @Retention(RetentionPolicy.RUNTIME) private static @interface MetaDisabledWithCustomProfileValueSource {}
@MetaEnabledWithCustomProfileValueSource private static class MetaEnabledWithCustomProfileValueSourceClass {
  }
@MetaDisabledWithCustomProfileValueSource private static class MetaDisabledWithCustomProfileValueSourceClass {
  }
@ProfileValueSourceConfiguration(HardCodedProfileValueSource.class) private interface CustomProfileValueSourceTestInterface {
  }
@IfProfileValue(name=NAME,value="42") private static class EnabledWithCustomProfileValueSourceOnTestInterface implements CustomProfileValueSourceTestInterface {
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.remoting.rmi;
import java.lang.reflect.AccessibleObject;
import java.lang.reflect.Constructor;
import java.lang.reflect.Method;
import java.rmi.ConnectException;
import java.rmi.ConnectIOException;
import java.rmi.MarshalException;
import java.rmi.NoSuchObjectException;
import java.rmi.Remote;
import java.rmi.RemoteException;
import java.rmi.StubNotFoundException;
import java.rmi.UnknownHostException;
import java.rmi.UnmarshalException;
import org.aopalliance.intercept.MethodInvocation;
import org.junit.Test;
import org.springframework.remoting.RemoteAccessException;
import org.springframework.remoting.RemoteConnectFailureException;
import org.springframework.remoting.RemoteProxyFailureException;
import org.springframework.remoting.support.RemoteInvocation;
import static org.junit.Assert.*;
/** 
 * @author Juergen Hoeller
 * @since 16.05.2003
 */
public class RmiSupportTests {
  @Test public void rmiProxyFactoryBean() throws Exception {
    CountingRmiProxyFactoryBean factory=new CountingRmiProxyFactoryBean();
    factory.setServiceInterface(IRemoteBean.class);
    factory.setServiceUrl("rmi://localhost:1090/test");
    factory.afterPropertiesSet();
    assertTrue("Correct singleton value",factory.isSingleton());
    assertTrue(factory.getObject() instanceof IRemoteBean);
    IRemoteBean proxy=(IRemoteBean)factory.getObject();
    proxy.setName("myName");
    assertEquals("myName",RemoteBean.name);
    assertEquals(1,factory.counter);
  }
  @Test public void rmiProxyFactoryBeanWithRemoteException() throws Exception {
    doTestRmiProxyFactoryBeanWithException(RemoteException.class);
  }
  @Test public void rmiProxyFactoryBeanWithConnectException() throws Exception {
    doTestRmiProxyFactoryBeanWithException(ConnectException.class);
  }
  @Test public void rmiProxyFactoryBeanWithConnectIOException() throws Exception {
    doTestRmiProxyFactoryBeanWithException(ConnectIOException.class);
  }
  @Test public void rmiProxyFactoryBeanWithUnknownHostException() throws Exception {
    doTestRmiProxyFactoryBeanWithException(UnknownHostException.class);
  }
  @Test public void rmiProxyFactoryBeanWithNoSuchObjectException() throws Exception {
    doTestRmiProxyFactoryBeanWithException(NoSuchObjectException.class);
  }
  @Test public void rmiProxyFactoryBeanWithStubNotFoundException() throws Exception {
    doTestRmiProxyFactoryBeanWithException(StubNotFoundException.class);
  }
  @Test public void rmiProxyFactoryBeanWithMarshalException() throws Exception {
    doTestRmiProxyFactoryBeanWithException(MarshalException.class);
  }
  @Test public void rmiProxyFactoryBeanWithUnmarshalException() throws Exception {
    doTestRmiProxyFactoryBeanWithException(UnmarshalException.class);
  }
  private void doTestRmiProxyFactoryBeanWithException(  Class<?> exceptionClass) throws Exception {
    CountingRmiProxyFactoryBean factory=new CountingRmiProxyFactoryBean();
    factory.setServiceInterface(IRemoteBean.class);
    factory.setServiceUrl("rmi://localhost:1090/test");
    factory.afterPropertiesSet();
    assertTrue(factory.getObject() instanceof IRemoteBean);
    IRemoteBean proxy=(IRemoteBean)factory.getObject();
    try {
      proxy.setName(exceptionClass.getName());
      fail("Should have thrown " + exceptionClass.getName());
    }
 catch (    Exception ex) {
      if (exceptionClass.isInstance(ex)) {
      }
 else {
        throw ex;
      }
    }
    assertEquals(1,factory.counter);
  }
  @Test public void rmiProxyFactoryBeanWithConnectExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithExceptionAndRefresh(ConnectException.class);
  }
  @Test public void rmiProxyFactoryBeanWithConnectIOExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithExceptionAndRefresh(ConnectIOException.class);
  }
  @Test public void rmiProxyFactoryBeanWithUnknownHostExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithExceptionAndRefresh(UnknownHostException.class);
  }
  @Test public void rmiProxyFactoryBeanWithNoSuchObjectExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithExceptionAndRefresh(NoSuchObjectException.class);
  }
  @Test public void rmiProxyFactoryBeanWithStubNotFoundExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithExceptionAndRefresh(StubNotFoundException.class);
  }
  private void doTestRmiProxyFactoryBeanWithExceptionAndRefresh(  Class<?> exceptionClass) throws Exception {
    CountingRmiProxyFactoryBean factory=new CountingRmiProxyFactoryBean();
    factory.setServiceInterface(IRemoteBean.class);
    factory.setServiceUrl("rmi://localhost:1090/test");
    factory.setRefreshStubOnConnectFailure(true);
    factory.afterPropertiesSet();
    assertTrue(factory.getObject() instanceof IRemoteBean);
    IRemoteBean proxy=(IRemoteBean)factory.getObject();
    try {
      proxy.setName(exceptionClass.getName());
      fail("Should have thrown " + exceptionClass.getName());
    }
 catch (    Exception ex) {
      if (exceptionClass.isInstance(ex)) {
      }
 else {
        throw ex;
      }
    }
    assertEquals(2,factory.counter);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterface() throws Exception {
    CountingRmiProxyFactoryBean factory=new CountingRmiProxyFactoryBean();
    factory.setServiceInterface(IBusinessBean.class);
    factory.setServiceUrl("rmi://localhost:1090/test");
    factory.afterPropertiesSet();
    assertTrue(factory.getObject() instanceof IBusinessBean);
    IBusinessBean proxy=(IBusinessBean)factory.getObject();
    assertFalse(proxy instanceof IRemoteBean);
    proxy.setName("myName");
    assertEquals("myName",RemoteBean.name);
    assertEquals(1,factory.counter);
  }
  @Test public void rmiProxyFactoryBeanWithWrongBusinessInterface() throws Exception {
    CountingRmiProxyFactoryBean factory=new CountingRmiProxyFactoryBean();
    factory.setServiceInterface(IWrongBusinessBean.class);
    factory.setServiceUrl("rmi://localhost:1090/test");
    factory.afterPropertiesSet();
    assertTrue(factory.getObject() instanceof IWrongBusinessBean);
    IWrongBusinessBean proxy=(IWrongBusinessBean)factory.getObject();
    assertFalse(proxy instanceof IRemoteBean);
    try {
      proxy.setOtherName("name");
      fail("Should have thrown RemoteProxyFailureException");
    }
 catch (    RemoteProxyFailureException ex) {
      assertTrue(ex.getCause() instanceof NoSuchMethodException);
      assertTrue(ex.getMessage().contains("setOtherName"));
      assertTrue(ex.getMessage().contains("IWrongBusinessBean"));
    }
    assertEquals(1,factory.counter);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndRemoteException() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndException(RemoteException.class,RemoteAccessException.class);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndConnectException() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndException(ConnectException.class,RemoteConnectFailureException.class);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndConnectIOException() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndException(ConnectIOException.class,RemoteConnectFailureException.class);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndUnknownHostException() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndException(UnknownHostException.class,RemoteConnectFailureException.class);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndNoSuchObjectExceptionException() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndException(NoSuchObjectException.class,RemoteConnectFailureException.class);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndStubNotFoundException() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndException(StubNotFoundException.class,RemoteConnectFailureException.class);
  }
  private void doTestRmiProxyFactoryBeanWithBusinessInterfaceAndException(  Class<?> rmiExceptionClass,  Class<?> springExceptionClass) throws Exception {
    CountingRmiProxyFactoryBean factory=new CountingRmiProxyFactoryBean();
    factory.setServiceInterface(IBusinessBean.class);
    factory.setServiceUrl("rmi://localhost:1090/test");
    factory.afterPropertiesSet();
    assertTrue(factory.getObject() instanceof IBusinessBean);
    IBusinessBean proxy=(IBusinessBean)factory.getObject();
    assertFalse(proxy instanceof IRemoteBean);
    try {
      proxy.setName(rmiExceptionClass.getName());
      fail("Should have thrown " + rmiExceptionClass.getName());
    }
 catch (    Exception ex) {
      if (springExceptionClass.isInstance(ex)) {
      }
 else {
        throw ex;
      }
    }
    assertEquals(1,factory.counter);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndRemoteExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndExceptionAndRefresh(RemoteException.class,RemoteAccessException.class);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndConnectExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndExceptionAndRefresh(ConnectException.class,RemoteConnectFailureException.class);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndConnectIOExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndExceptionAndRefresh(ConnectIOException.class,RemoteConnectFailureException.class);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndUnknownHostExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndExceptionAndRefresh(UnknownHostException.class,RemoteConnectFailureException.class);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndNoSuchObjectExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndExceptionAndRefresh(NoSuchObjectException.class,RemoteConnectFailureException.class);
  }
  @Test public void rmiProxyFactoryBeanWithBusinessInterfaceAndStubNotFoundExceptionAndRefresh() throws Exception {
    doTestRmiProxyFactoryBeanWithBusinessInterfaceAndExceptionAndRefresh(StubNotFoundException.class,RemoteConnectFailureException.class);
  }
  private void doTestRmiProxyFactoryBeanWithBusinessInterfaceAndExceptionAndRefresh(  Class<?> rmiExceptionClass,  Class<?> springExceptionClass) throws Exception {
    CountingRmiProxyFactoryBean factory=new CountingRmiProxyFactoryBean();
    factory.setServiceInterface(IBusinessBean.class);
    factory.setServiceUrl("rmi://localhost:1090/test");
    factory.setRefreshStubOnConnectFailure(true);
    factory.afterPropertiesSet();
    assertTrue(factory.getObject() instanceof IBusinessBean);
    IBusinessBean proxy=(IBusinessBean)factory.getObject();
    assertFalse(proxy instanceof IRemoteBean);
    try {
      proxy.setName(rmiExceptionClass.getName());
      fail("Should have thrown " + rmiExceptionClass.getName());
    }
 catch (    Exception ex) {
      if (springExceptionClass.isInstance(ex)) {
      }
 else {
        throw ex;
      }
    }
    if (RemoteConnectFailureException.class.isAssignableFrom(springExceptionClass)) {
      assertEquals(2,factory.counter);
    }
 else {
      assertEquals(1,factory.counter);
    }
  }
  @Test public void rmiClientInterceptorRequiresUrl() throws Exception {
    RmiClientInterceptor client=new RmiClientInterceptor();
    client.setServiceInterface(IRemoteBean.class);
    try {
      client.afterPropertiesSet();
      fail("url isn't set, expected IllegalArgumentException");
    }
 catch (    IllegalArgumentException ex) {
    }
  }
  @Test public void remoteInvocation() throws NoSuchMethodException {
    final RemoteBean rb=new RemoteBean();
    final Method setNameMethod=rb.getClass().getDeclaredMethod("setName",String.class);
    MethodInvocation mi=new MethodInvocation(){
      @Override public Method getMethod(){
        return setNameMethod;
      }
      @Override public Object[] getArguments(){
        return new Object[]{"bla"};
      }
      @Override public Object proceed() throws Throwable {
        throw new UnsupportedOperationException();
      }
      @Override public Object getThis(){
        return rb;
      }
      @Override public AccessibleObject getStaticPart(){
        return setNameMethod;
      }
    }
;
    RemoteInvocation inv=new RemoteInvocation(mi);
    assertEquals("setName",inv.getMethodName());
    assertEquals("bla",inv.getArguments()[0]);
    assertEquals(String.class,inv.getParameterTypes()[0]);
    inv=new RemoteInvocation();
    inv.setArguments(new Object[]{"bla"});
    assertEquals("bla",inv.getArguments()[0]);
    inv.setMethodName("setName");
    assertEquals("setName",inv.getMethodName());
    inv.setParameterTypes(new Class<?>[]{String.class});
    assertEquals(String.class,inv.getParameterTypes()[0]);
    inv=new RemoteInvocation("setName",new Class<?>[]{String.class},new Object[]{"bla"});
    assertEquals("bla",inv.getArguments()[0]);
    assertEquals("setName",inv.getMethodName());
    assertEquals(String.class,inv.getParameterTypes()[0]);
  }
  @Test public void rmiInvokerWithSpecialLocalMethods() throws Exception {
    String serviceUrl="rmi://localhost:1090/test";
    RmiProxyFactoryBean factory=new RmiProxyFactoryBean(){
      @Override protected Remote lookupStub(){
        return new RmiInvocationHandler(){
          @Override public String getTargetInterfaceName(){
            return null;
          }
          @Override public Object invoke(          RemoteInvocation invocation) throws RemoteException {
            throw new RemoteException();
          }
        }
;
      }
    }
;
    factory.setServiceInterface(IBusinessBean.class);
    factory.setServiceUrl(serviceUrl);
    factory.afterPropertiesSet();
    IBusinessBean proxy=(IBusinessBean)factory.getObject();
    assertTrue(proxy.toString().contains("RMI invoker"));
    assertTrue(proxy.toString().contains(serviceUrl));
    assertEquals(proxy.hashCode(),proxy.hashCode());
    assertTrue(proxy.equals(proxy));
    try {
      proxy.setName("test");
      fail("Should have thrown RemoteAccessException");
    }
 catch (    RemoteAccessException ex) {
    }
  }
private static class CountingRmiProxyFactoryBean extends RmiProxyFactoryBean {
    private int counter=0;
    @Override protected Remote lookupStub(){
      counter++;
      return new RemoteBean();
    }
  }
public interface IBusinessBean {
    void setName(    String name);
  }
public interface IWrongBusinessBean {
    void setOtherName(    String name);
  }
public interface IRemoteBean extends Remote {
    void setName(    String name) throws RemoteException ;
  }
public static class RemoteBean implements IRemoteBean {
    private static String name;
    @Override public void setName(    String nam) throws RemoteException {
      if (nam != null && nam.endsWith("Exception")) {
        RemoteException rex;
        try {
          Class<?> exClass=Class.forName(nam);
          Constructor<?> ctor=exClass.getConstructor(String.class);
          rex=(RemoteException)ctor.newInstance("myMessage");
        }
 catch (        Exception ex) {
          throw new RemoteException("Illegal exception class name: " + nam,ex);
        }
        throw rex;
      }
      name=nam;
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.context.annotation;
import javax.annotation.Resource;
import org.junit.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.ApplicationContext;
import static org.hamcrest.CoreMatchers.*;
import static org.junit.Assert.*;
/** 
 * Tests changes introduced for SPR-8874, allowing beans of primitive types to be looked up via getBean(Class), or to be injected using @Autowired or @Injected or @Resource. Prior to these changes, an attempt to lookup or inject a bean of type boolean would fail because all spring beans are Objects, regardless of initial type due to the way that ObjectFactory works. Now these attempts to lookup or inject primitive types work, thanks to simple changes in AbstractBeanFactory using ClassUtils#isAssignable methods instead of the built-in Class#isAssignableFrom. The former takes into account primitives and their object wrapper types, whereas the latter does not.
 * @author Chris Beams
 * @since 3.1
 */
public class PrimitiveBeanLookupAndAutowiringTests {
  @Test public void primitiveLookupByName(){
    ApplicationContext ctx=new AnnotationConfigApplicationContext(Config.class);
    boolean b=ctx.getBean("b",boolean.class);
    assertThat(b,equalTo(true));
    int i=ctx.getBean("i",int.class);
    assertThat(i,equalTo(42));
  }
  @Test public void primitiveLookupByType(){
    ApplicationContext ctx=new AnnotationConfigApplicationContext(Config.class);
    boolean b=ctx.getBean(boolean.class);
    assertThat(b,equalTo(true));
    int i=ctx.getBean(int.class);
    assertThat(i,equalTo(42));
  }
  @Test public void primitiveAutowiredInjection(){
    ApplicationContext ctx=new AnnotationConfigApplicationContext(Config.class,AutowiredComponent.class);
    assertThat(ctx.getBean(AutowiredComponent.class).b,equalTo(true));
    assertThat(ctx.getBean(AutowiredComponent.class).i,equalTo(42));
  }
  @Test public void primitiveResourceInjection(){
    ApplicationContext ctx=new AnnotationConfigApplicationContext(Config.class,ResourceComponent.class);
    assertThat(ctx.getBean(ResourceComponent.class).b,equalTo(true));
    assertThat(ctx.getBean(ResourceComponent.class).i,equalTo(42));
  }
@Configuration static class Config {
    @Bean public boolean b(){
      return true;
    }
    @Bean public int i(){
      return 42;
    }
  }
static class AutowiredComponent {
    @Autowired boolean b;
    @Autowired int i;
  }
static class ResourceComponent {
    @Resource boolean b;
    @Autowired int i;
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.context.annotation;
import java.lang.annotation.Documented;
import java.lang.annotation.ElementType;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy;
import java.lang.annotation.Target;
import org.junit.Test;
import org.springframework.beans.factory.FactoryBean;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.context.ApplicationContext;
import org.springframework.core.type.AnnotatedTypeMetadata;
import org.springframework.core.type.AnnotationMetadata;
import org.springframework.util.Assert;
import static org.junit.Assert.*;
/** 
 * @author Dave Syer
 */
public class Spr11202Tests {
  @Test public void testWithImporter(){
    ApplicationContext context=new AnnotationConfigApplicationContext(Wrapper.class);
    assertEquals("foo",context.getBean("value"));
  }
  @Test public void testWithoutImporter(){
    ApplicationContext context=new AnnotationConfigApplicationContext(Config.class);
    assertEquals("foo",context.getBean("value"));
  }
@Configuration @Import(Selector.class) protected static class Wrapper {
  }
protected static class Selector implements ImportSelector {
    @Override public String[] selectImports(    AnnotationMetadata importingClassMetadata){
      return new String[]{Config.class.getName()};
    }
  }
@Configuration protected static class Config {
    @Bean public FooFactoryBean foo(){
      return new FooFactoryBean();
    }
    @Bean public String value() throws Exception {
      String name=foo().getObject().getName();
      Assert.state(name != null,"Name cannot be null");
      return name;
    }
    @Bean @Conditional(NoBarCondition.class) public String bar() throws Exception {
      return "bar";
    }
  }
protected static class NoBarCondition implements Condition {
    @Override public boolean matches(    ConditionContext context,    AnnotatedTypeMetadata metadata){
      if (context.getBeanFactory().getBeanNamesForAnnotation(Bar.class).length > 0) {
        return false;
      }
      return true;
    }
  }
  @Retention(RetentionPolicy.RUNTIME) @Documented @Target(ElementType.TYPE) protected @interface Bar {}
protected static class FooFactoryBean implements FactoryBean<Foo>, InitializingBean {
    private Foo foo=new Foo();
    @Override public Foo getObject() throws Exception {
      return foo;
    }
    @Override public Class<?> getObjectType(){
      return Foo.class;
    }
    @Override public boolean isSingleton(){
      return true;
    }
    @Override public void afterPropertiesSet() throws Exception {
      this.foo.name="foo";
    }
  }
protected static class Foo {
    private String name;
    public String getName(){
      return name;
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.context.conversionservice;
import org.junit.Test;
import org.springframework.context.support.ClassPathXmlApplicationContext;
import static org.junit.Assert.*;
/** 
 * @author Keith Donald
 */
public class ConversionServiceContextConfigTests {
  @Test public void testConfigOk(){
    ClassPathXmlApplicationContext context=new ClassPathXmlApplicationContext("org/springframework/context/conversionservice/conversionService.xml");
    TestClient client=context.getBean("testClient",TestClient.class);
    assertEquals(2,client.getBars().size());
    assertEquals("value1",client.getBars().get(0).getValue());
    assertEquals("value2",client.getBars().get(1).getValue());
    assertTrue(client.isBool());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.aop.config;
import org.junit.Test;
import org.springframework.aop.framework.Advised;
import org.springframework.aop.support.AopUtils;
import org.springframework.tests.sample.beans.ITestBean;
import static org.junit.Assert.*;
/** 
 * @author Rob Harrop
 * @author Chris Beams
 */
public class AopNamespaceHandlerProxyTargetClassTests extends AopNamespaceHandlerTests {
  @Test public void testIsClassProxy(){
    ITestBean bean=getTestBean();
    assertTrue("Should be a CGLIB proxy",AopUtils.isCglibProxy(bean));
    assertTrue("Should expose proxy",((Advised)bean).isExposeProxy());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.aop.aspectj;
import java.lang.reflect.Method;
import org.aspectj.lang.ProceedingJoinPoint;
import org.junit.Before;
import org.junit.Test;
import org.springframework.aop.MethodBeforeAdvice;
import org.springframework.beans.factory.BeanNameAware;
import org.springframework.context.support.ClassPathXmlApplicationContext;
import org.springframework.core.Ordered;
import org.springframework.lang.Nullable;
import org.springframework.tests.sample.beans.ITestBean;
import static org.junit.Assert.*;
/** 
 * @author Adrian Colyer
 * @author Chris Beams
 */
public class AspectAndAdvicePrecedenceTests {
  private PrecedenceTestAspect highPrecedenceAspect;
  private PrecedenceTestAspect lowPrecedenceAspect;
  private SimpleSpringBeforeAdvice highPrecedenceSpringAdvice;
  private SimpleSpringBeforeAdvice lowPrecedenceSpringAdvice;
  private ITestBean testBean;
  @Before public void setup(){
    ClassPathXmlApplicationContext ctx=new ClassPathXmlApplicationContext(getClass().getSimpleName() + ".xml",getClass());
    highPrecedenceAspect=(PrecedenceTestAspect)ctx.getBean("highPrecedenceAspect");
    lowPrecedenceAspect=(PrecedenceTestAspect)ctx.getBean("lowPrecedenceAspect");
    highPrecedenceSpringAdvice=(SimpleSpringBeforeAdvice)ctx.getBean("highPrecedenceSpringAdvice");
    lowPrecedenceSpringAdvice=(SimpleSpringBeforeAdvice)ctx.getBean("lowPrecedenceSpringAdvice");
    testBean=(ITestBean)ctx.getBean("testBean");
  }
  @Test public void testAdviceOrder(){
    PrecedenceTestAspect.Collaborator collaborator=new PrecedenceVerifyingCollaborator();
    this.highPrecedenceAspect.setCollaborator(collaborator);
    this.lowPrecedenceAspect.setCollaborator(collaborator);
    this.highPrecedenceSpringAdvice.setCollaborator(collaborator);
    this.lowPrecedenceSpringAdvice.setCollaborator(collaborator);
    this.testBean.getAge();
  }
private static class PrecedenceVerifyingCollaborator implements PrecedenceTestAspect.Collaborator {
    private static final String[] EXPECTED={"beforeAdviceOne(highPrecedenceAspect)","beforeAdviceTwo(highPrecedenceAspect)","aroundAdviceOne(highPrecedenceAspect)","aroundAdviceTwo(highPrecedenceAspect)","beforeAdviceOne(highPrecedenceSpringAdvice)","beforeAdviceOne(lowPrecedenceSpringAdvice)","beforeAdviceOne(lowPrecedenceAspect)","beforeAdviceTwo(lowPrecedenceAspect)","aroundAdviceOne(lowPrecedenceAspect)","aroundAdviceTwo(lowPrecedenceAspect)","aroundAdviceTwo(lowPrecedenceAspect)","aroundAdviceOne(lowPrecedenceAspect)","afterAdviceOne(lowPrecedenceAspect)","afterAdviceTwo(lowPrecedenceAspect)","aroundAdviceTwo(highPrecedenceAspect)","aroundAdviceOne(highPrecedenceAspect)","afterAdviceOne(highPrecedenceAspect)","afterAdviceTwo(highPrecedenceAspect)"};
    private int adviceInvocationNumber=0;
    private void checkAdvice(    String whatJustHappened){
      if (adviceInvocationNumber > (EXPECTED.length - 1)) {
        fail("Too many advice invocations, expecting " + EXPECTED.length + " but had "+ adviceInvocationNumber);
      }
      String expecting=EXPECTED[adviceInvocationNumber++];
      if (!whatJustHappened.equals(expecting)) {
        fail("Expecting '" + expecting + "' on advice invocation "+ adviceInvocationNumber+ " but got '"+ whatJustHappened+ "'");
      }
    }
    @Override public void beforeAdviceOne(    String beanName){
      checkAdvice("beforeAdviceOne(" + beanName + ")");
    }
    @Override public void beforeAdviceTwo(    String beanName){
      checkAdvice("beforeAdviceTwo(" + beanName + ")");
    }
    @Override public void aroundAdviceOne(    String beanName){
      checkAdvice("aroundAdviceOne(" + beanName + ")");
    }
    @Override public void aroundAdviceTwo(    String beanName){
      checkAdvice("aroundAdviceTwo(" + beanName + ")");
    }
    @Override public void afterAdviceOne(    String beanName){
      checkAdvice("afterAdviceOne(" + beanName + ")");
    }
    @Override public void afterAdviceTwo(    String beanName){
      checkAdvice("afterAdviceTwo(" + beanName + ")");
    }
  }
}
class PrecedenceTestAspect implements BeanNameAware, Ordered {
  private String name;
  private int order=Ordered.LOWEST_PRECEDENCE;
  private Collaborator collaborator;
  @Override public void setBeanName(  String name){
    this.name=name;
  }
  public void setOrder(  int order){
    this.order=order;
  }
  @Override public int getOrder(){
    return order;
  }
  public void setCollaborator(  Collaborator collaborator){
    this.collaborator=collaborator;
  }
  public void beforeAdviceOne(){
    this.collaborator.beforeAdviceOne(this.name);
  }
  public void beforeAdviceTwo(){
    this.collaborator.beforeAdviceTwo(this.name);
  }
  public int aroundAdviceOne(  ProceedingJoinPoint pjp){
    int ret=-1;
    this.collaborator.aroundAdviceOne(this.name);
    try {
      ret=((Integer)pjp.proceed()).intValue();
    }
 catch (    Throwable t) {
      throw new RuntimeException(t);
    }
    this.collaborator.aroundAdviceOne(this.name);
    return ret;
  }
  public int aroundAdviceTwo(  ProceedingJoinPoint pjp){
    int ret=-1;
    this.collaborator.aroundAdviceTwo(this.name);
    try {
      ret=((Integer)pjp.proceed()).intValue();
    }
 catch (    Throwable t) {
      throw new RuntimeException(t);
    }
    this.collaborator.aroundAdviceTwo(this.name);
    return ret;
  }
  public void afterAdviceOne(){
    this.collaborator.afterAdviceOne(this.name);
  }
  public void afterAdviceTwo(){
    this.collaborator.afterAdviceTwo(this.name);
  }
public interface Collaborator {
    void beforeAdviceOne(    String beanName);
    void beforeAdviceTwo(    String beanName);
    void aroundAdviceOne(    String beanName);
    void aroundAdviceTwo(    String beanName);
    void afterAdviceOne(    String beanName);
    void afterAdviceTwo(    String beanName);
  }
}
class SimpleSpringBeforeAdvice implements MethodBeforeAdvice, BeanNameAware {
  private PrecedenceTestAspect.Collaborator collaborator;
  private String name;
  @Override public void before(  Method method,  Object[] args,  @Nullable Object target) throws Throwable {
    this.collaborator.beforeAdviceOne(this.name);
  }
  public void setCollaborator(  PrecedenceTestAspect.Collaborator collaborator){
    this.collaborator=collaborator;
  }
  @Override public void setBeanName(  String name){
    this.name=name;
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.aop.scope;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Map;
import org.junit.Test;
import org.springframework.aop.support.AopUtils;
import org.springframework.beans.factory.support.DefaultListableBeanFactory;
import org.springframework.beans.factory.xml.XmlBeanDefinitionReader;
import org.springframework.context.support.GenericApplicationContext;
import org.springframework.core.io.ClassPathResource;
import org.springframework.tests.context.SimpleMapScope;
import org.springframework.tests.sample.beans.ITestBean;
import org.springframework.tests.sample.beans.TestBean;
import org.springframework.util.SerializationTestUtils;
import static org.junit.Assert.*;
/** 
 * @author Rob Harrop
 * @author Juergen Hoeller
 * @author Chris Beams
 */
public class ScopedProxyTests {
  private static final Class<?> CLASS=ScopedProxyTests.class;
  private static final String CLASSNAME=CLASS.getSimpleName();
  private static final ClassPathResource LIST_CONTEXT=new ClassPathResource(CLASSNAME + "-list.xml",CLASS);
  private static final ClassPathResource MAP_CONTEXT=new ClassPathResource(CLASSNAME + "-map.xml",CLASS);
  private static final ClassPathResource OVERRIDE_CONTEXT=new ClassPathResource(CLASSNAME + "-override.xml",CLASS);
  private static final ClassPathResource TESTBEAN_CONTEXT=new ClassPathResource(CLASSNAME + "-testbean.xml",CLASS);
  @Test public void testProxyAssignable() throws Exception {
    DefaultListableBeanFactory bf=new DefaultListableBeanFactory();
    new XmlBeanDefinitionReader(bf).loadBeanDefinitions(MAP_CONTEXT);
    Object baseMap=bf.getBean("singletonMap");
    assertTrue(baseMap instanceof Map);
  }
  @Test public void testSimpleProxy() throws Exception {
    DefaultListableBeanFactory bf=new DefaultListableBeanFactory();
    new XmlBeanDefinitionReader(bf).loadBeanDefinitions(MAP_CONTEXT);
    Object simpleMap=bf.getBean("simpleMap");
    assertTrue(simpleMap instanceof Map);
    assertTrue(simpleMap instanceof HashMap);
  }
  @Test public void testScopedOverride() throws Exception {
    GenericApplicationContext ctx=new GenericApplicationContext();
    new XmlBeanDefinitionReader(ctx).loadBeanDefinitions(OVERRIDE_CONTEXT);
    SimpleMapScope scope=new SimpleMapScope();
    ctx.getBeanFactory().registerScope("request",scope);
    ctx.refresh();
    ITestBean bean=(ITestBean)ctx.getBean("testBean");
    assertEquals("male",bean.getName());
    assertEquals(99,bean.getAge());
    assertTrue(scope.getMap().containsKey("scopedTarget.testBean"));
    assertEquals(TestBean.class,scope.getMap().get("scopedTarget.testBean").getClass());
  }
  @Test public void testJdkScopedProxy() throws Exception {
    DefaultListableBeanFactory bf=new DefaultListableBeanFactory();
    new XmlBeanDefinitionReader(bf).loadBeanDefinitions(TESTBEAN_CONTEXT);
    bf.setSerializationId("X");
    SimpleMapScope scope=new SimpleMapScope();
    bf.registerScope("request",scope);
    ITestBean bean=(ITestBean)bf.getBean("testBean");
    assertNotNull(bean);
    assertTrue(AopUtils.isJdkDynamicProxy(bean));
    assertTrue(bean instanceof ScopedObject);
    ScopedObject scoped=(ScopedObject)bean;
    assertEquals(TestBean.class,scoped.getTargetObject().getClass());
    bean.setAge(101);
    assertTrue(scope.getMap().containsKey("testBeanTarget"));
    assertEquals(TestBean.class,scope.getMap().get("testBeanTarget").getClass());
    ITestBean deserialized=(ITestBean)SerializationTestUtils.serializeAndDeserialize(bean);
    assertNotNull(deserialized);
    assertTrue(AopUtils.isJdkDynamicProxy(deserialized));
    assertEquals(101,bean.getAge());
    assertTrue(deserialized instanceof ScopedObject);
    ScopedObject scopedDeserialized=(ScopedObject)deserialized;
    assertEquals(TestBean.class,scopedDeserialized.getTargetObject().getClass());
    bf.setSerializationId(null);
  }
  @Test public void testCglibScopedProxy() throws Exception {
    DefaultListableBeanFactory bf=new DefaultListableBeanFactory();
    new XmlBeanDefinitionReader(bf).loadBeanDefinitions(LIST_CONTEXT);
    bf.setSerializationId("Y");
    SimpleMapScope scope=new SimpleMapScope();
    bf.registerScope("request",scope);
    TestBean tb=(TestBean)bf.getBean("testBean");
    assertTrue(AopUtils.isCglibProxy(tb.getFriends()));
    assertTrue(tb.getFriends() instanceof ScopedObject);
    ScopedObject scoped=(ScopedObject)tb.getFriends();
    assertEquals(ArrayList.class,scoped.getTargetObject().getClass());
    tb.getFriends().add("myFriend");
    assertTrue(scope.getMap().containsKey("scopedTarget.scopedList"));
    assertEquals(ArrayList.class,scope.getMap().get("scopedTarget.scopedList").getClass());
    ArrayList<?> deserialized=(ArrayList<?>)SerializationTestUtils.serializeAndDeserialize(tb.getFriends());
    assertNotNull(deserialized);
    assertTrue(AopUtils.isCglibProxy(deserialized));
    assertTrue(deserialized.contains("myFriend"));
    assertTrue(deserialized instanceof ScopedObject);
    ScopedObject scopedDeserialized=(ScopedObject)deserialized;
    assertEquals(ArrayList.class,scopedDeserialized.getTargetObject().getClass());
    bf.setSerializationId(null);
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.jndi;
import org.junit.Test;
import static org.junit.Assert.*;
/** 
 * @author Rod Johnson
 * @author Chris Beams
 */
public class JndiTemplateEditorTests {
  @Test public void testNullIsIllegalArgument(){
    try {
      new JndiTemplateEditor().setAsText(null);
      fail("Null is illegal");
    }
 catch (    IllegalArgumentException ex) {
    }
  }
  @Test public void testEmptyStringMeansNullEnvironment(){
    JndiTemplateEditor je=new JndiTemplateEditor();
    je.setAsText("");
    JndiTemplate jt=(JndiTemplate)je.getValue();
    assertTrue(jt.getEnvironment() == null);
  }
  @Test public void testCustomEnvironment(){
    JndiTemplateEditor je=new JndiTemplateEditor();
    je.setAsText("jndiInitialSomethingOrOther=org.springframework.myjndi.CompleteRubbish\nfoo=bar");
    JndiTemplate jt=(JndiTemplate)je.getValue();
    assertTrue(jt.getEnvironment().size() == 2);
    assertTrue(jt.getEnvironment().getProperty("jndiInitialSomethingOrOther").equals("org.springframework.myjndi.CompleteRubbish"));
    assertTrue(jt.getEnvironment().getProperty("foo").equals("bar"));
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.servlet.handler;
import javax.servlet.ServletException;
import org.junit.Before;
import org.junit.Test;
import org.springframework.context.support.StaticApplicationContext;
import org.springframework.mock.web.test.MockHttpServletRequest;
import org.springframework.mock.web.test.MockServletContext;
import org.springframework.web.context.ConfigurableWebApplicationContext;
import org.springframework.web.context.support.XmlWebApplicationContext;
import org.springframework.web.servlet.HandlerExecutionChain;
import org.springframework.web.servlet.HandlerMapping;
import static org.junit.Assert.*;
/** 
 * @author Rod Johnson
 * @author Juergen Hoeller
 */
public class BeanNameUrlHandlerMappingTests {
  public static final String CONF="/org/springframework/web/servlet/handler/map1.xml";
  private ConfigurableWebApplicationContext wac;
  @Before public void setUp() throws Exception {
    MockServletContext sc=new MockServletContext("");
    wac=new XmlWebApplicationContext();
    wac.setServletContext(sc);
    wac.setConfigLocations(new String[]{CONF});
    wac.refresh();
  }
  @Test public void requestsWithoutHandlers() throws Exception {
    HandlerMapping hm=(HandlerMapping)wac.getBean("handlerMapping");
    MockHttpServletRequest req=new MockHttpServletRequest("GET","/mypath/nonsense.html");
    req.setContextPath("/myapp");
    Object h=hm.getHandler(req);
    assertTrue("Handler is null",h == null);
    req=new MockHttpServletRequest("GET","/foo/bar/baz.html");
    h=hm.getHandler(req);
    assertTrue("Handler is null",h == null);
  }
  @Test public void requestsWithSubPaths() throws Exception {
    HandlerMapping hm=(HandlerMapping)wac.getBean("handlerMapping");
    doTestRequestsWithSubPaths(hm);
  }
  @Test public void requestsWithSubPathsInParentContext() throws Exception {
    BeanNameUrlHandlerMapping hm=new BeanNameUrlHandlerMapping();
    hm.setDetectHandlersInAncestorContexts(true);
    hm.setApplicationContext(new StaticApplicationContext(wac));
    doTestRequestsWithSubPaths(hm);
  }
  private void doTestRequestsWithSubPaths(  HandlerMapping hm) throws Exception {
    Object bean=wac.getBean("godCtrl");
    MockHttpServletRequest req=new MockHttpServletRequest("GET","/mypath/welcome.html");
    HandlerExecutionChain hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/myapp/mypath/welcome.html");
    req.setContextPath("/myapp");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/myapp/mypath/welcome.html");
    req.setContextPath("/myapp");
    req.setServletPath("/mypath/welcome.html");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/myapp/myservlet/mypath/welcome.html");
    req.setContextPath("/myapp");
    req.setServletPath("/myservlet");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/myapp/myapp/mypath/welcome.html");
    req.setContextPath("/myapp");
    req.setServletPath("/myapp");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/mypath/show.html");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/mypath/bookseats.html");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
  }
  @Test public void requestsWithFullPaths() throws Exception {
    BeanNameUrlHandlerMapping hm=new BeanNameUrlHandlerMapping();
    hm.setAlwaysUseFullPath(true);
    hm.setApplicationContext(wac);
    Object bean=wac.getBean("godCtrl");
    MockHttpServletRequest req=new MockHttpServletRequest("GET","/mypath/welcome.html");
    HandlerExecutionChain hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/myapp/mypath/welcome.html");
    req.setContextPath("/myapp");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/mypath/welcome.html");
    req.setContextPath("");
    req.setServletPath("/mypath");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/Myapp/mypath/welcome.html");
    req.setContextPath("/myapp");
    req.setServletPath("/mypath");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
  }
  @Test public void asteriskMatches() throws Exception {
    HandlerMapping hm=(HandlerMapping)wac.getBean("handlerMapping");
    Object bean=wac.getBean("godCtrl");
    MockHttpServletRequest req=new MockHttpServletRequest("GET","/mypath/test.html");
    HandlerExecutionChain hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/mypath/testarossa");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/mypath/tes");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec == null);
  }
  @Test public void overlappingMappings() throws Exception {
    BeanNameUrlHandlerMapping hm=(BeanNameUrlHandlerMapping)wac.getBean("handlerMapping");
    Object anotherHandler=new Object();
    hm.registerHandler("/mypath/testaross*",anotherHandler);
    Object bean=wac.getBean("godCtrl");
    MockHttpServletRequest req=new MockHttpServletRequest("GET","/mypath/test.html");
    HandlerExecutionChain hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == bean);
    req=new MockHttpServletRequest("GET","/mypath/testarossa");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec != null && hec.getHandler() == anotherHandler);
    req=new MockHttpServletRequest("GET","/mypath/tes");
    hec=hm.getHandler(req);
    assertTrue("Handler is correct bean",hec == null);
  }
  @Test public void doubleMappings() throws ServletException {
    BeanNameUrlHandlerMapping hm=(BeanNameUrlHandlerMapping)wac.getBean("handlerMapping");
    try {
      hm.registerHandler("/mypath/welcome.html",new Object());
      fail("Should have thrown IllegalStateException");
    }
 catch (    IllegalStateException ex) {
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.servlet.view;
import java.io.IOException;
import java.util.HashMap;
import java.util.Map;
import java.util.Properties;
import javax.servlet.ServletException;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import org.junit.Test;
import org.springframework.context.ApplicationContextException;
import org.springframework.mock.web.test.MockHttpServletRequest;
import org.springframework.mock.web.test.MockHttpServletResponse;
import org.springframework.mock.web.test.MockServletContext;
import org.springframework.web.context.WebApplicationContext;
import org.springframework.web.servlet.View;
import static org.junit.Assert.*;
import static org.mockito.BDDMockito.*;
/** 
 * Base tests for  {@link AbstractView}. <p>Not called  {@code AbstractViewTests} since doing so would cause itto be ignored in the Gradle build.
 * @author Rod Johnson
 * @author Sam Brannen
 */
public class BaseViewTests {
  @Test public void renderWithoutStaticAttributes() throws Exception {
    WebApplicationContext wac=mock(WebApplicationContext.class);
    given(wac.getServletContext()).willReturn(new MockServletContext());
    HttpServletRequest request=new MockHttpServletRequest();
    HttpServletResponse response=new MockHttpServletResponse();
    TestView tv=new TestView(wac);
    tv.setApplicationContext(wac);
    tv.setApplicationContext(wac);
    Map<String,Object> model=new HashMap<>();
    model.put("foo","bar");
    model.put("something",new Object());
    tv.render(model,request,response);
    checkContainsAll(model,tv.model);
    assertTrue(tv.initialized);
  }
  /** 
 * Test attribute passing, NOT CSV parsing.
 */
  @Test public void renderWithStaticAttributesNoCollision() throws Exception {
    WebApplicationContext wac=mock(WebApplicationContext.class);
    given(wac.getServletContext()).willReturn(new MockServletContext());
    HttpServletRequest request=new MockHttpServletRequest();
    HttpServletResponse response=new MockHttpServletResponse();
    TestView tv=new TestView(wac);
    tv.setApplicationContext(wac);
    Properties p=new Properties();
    p.setProperty("foo","bar");
    p.setProperty("something","else");
    tv.setAttributes(p);
    Map<String,Object> model=new HashMap<>();
    model.put("one",new HashMap<>());
    model.put("two",new Object());
    tv.render(model,request,response);
    checkContainsAll(model,tv.model);
    checkContainsAll(p,tv.model);
    assertTrue(tv.initialized);
  }
  @Test public void pathVarsOverrideStaticAttributes() throws Exception {
    WebApplicationContext wac=mock(WebApplicationContext.class);
    given(wac.getServletContext()).willReturn(new MockServletContext());
    HttpServletRequest request=new MockHttpServletRequest();
    HttpServletResponse response=new MockHttpServletResponse();
    TestView tv=new TestView(wac);
    tv.setApplicationContext(wac);
    Properties p=new Properties();
    p.setProperty("one","bar");
    p.setProperty("something","else");
    tv.setAttributes(p);
    Map<String,Object> pathVars=new HashMap<>();
    pathVars.put("one",new HashMap<>());
    pathVars.put("two",new Object());
    request.setAttribute(View.PATH_VARIABLES,pathVars);
    tv.render(new HashMap<>(),request,response);
    checkContainsAll(pathVars,tv.model);
    assertEquals(3,tv.model.size());
    assertEquals("else",tv.model.get("something"));
    assertTrue(tv.initialized);
  }
  @Test public void dynamicModelOverridesStaticAttributesIfCollision() throws Exception {
    WebApplicationContext wac=mock(WebApplicationContext.class);
    given(wac.getServletContext()).willReturn(new MockServletContext());
    HttpServletRequest request=new MockHttpServletRequest();
    HttpServletResponse response=new MockHttpServletResponse();
    TestView tv=new TestView(wac);
    tv.setApplicationContext(wac);
    Properties p=new Properties();
    p.setProperty("one","bar");
    p.setProperty("something","else");
    tv.setAttributes(p);
    Map<String,Object> model=new HashMap<>();
    model.put("one",new HashMap<>());
    model.put("two",new Object());
    tv.render(model,request,response);
    checkContainsAll(model,tv.model);
    assertEquals(3,tv.model.size());
    assertEquals("else",tv.model.get("something"));
    assertTrue(tv.initialized);
  }
  @Test public void dynamicModelOverridesPathVariables() throws Exception {
    WebApplicationContext wac=mock(WebApplicationContext.class);
    given(wac.getServletContext()).willReturn(new MockServletContext());
    TestView tv=new TestView(wac);
    tv.setApplicationContext(wac);
    MockHttpServletRequest request=new MockHttpServletRequest();
    MockHttpServletResponse response=new MockHttpServletResponse();
    Map<String,Object> pathVars=new HashMap<>();
    pathVars.put("one","bar");
    pathVars.put("something","else");
    request.setAttribute(View.PATH_VARIABLES,pathVars);
    Map<String,Object> model=new HashMap<>();
    model.put("one",new HashMap<>());
    model.put("two",new Object());
    tv.render(model,request,response);
    checkContainsAll(model,tv.model);
    assertEquals(3,tv.model.size());
    assertEquals("else",tv.model.get("something"));
    assertTrue(tv.initialized);
  }
  @Test public void ignoresNullAttributes(){
    AbstractView v=new ConcreteView();
    v.setAttributes(null);
    assertEquals(0,v.getStaticAttributes().size());
  }
  /** 
 * Test only the CSV parsing implementation.
 */
  @Test public void attributeCSVParsingIgnoresNull(){
    AbstractView v=new ConcreteView();
    v.setAttributesCSV(null);
    assertEquals(0,v.getStaticAttributes().size());
  }
  @Test public void attributeCSVParsingIgnoresEmptyString(){
    AbstractView v=new ConcreteView();
    v.setAttributesCSV("");
    assertEquals(0,v.getStaticAttributes().size());
  }
  /** 
 * Format is attname0={value1},attname1={value1}
 */
  @Test public void attributeCSVParsingValid(){
    AbstractView v=new ConcreteView();
    v.setAttributesCSV("foo=[bar],king=[kong]");
    assertTrue(v.getStaticAttributes().size() == 2);
    assertTrue(v.getStaticAttributes().get("foo").equals("bar"));
    assertTrue(v.getStaticAttributes().get("king").equals("kong"));
  }
  @Test public void attributeCSVParsingValidWithWeirdCharacters(){
    AbstractView v=new ConcreteView();
    String fooval="owfie   fue&3[][[[2 \n\n \r  \t 8\ufffd3";
    String kingval="";
    v.setAttributesCSV("foo=(" + fooval + "),king={"+ kingval+ "},f1=[we]");
    assertTrue(v.getStaticAttributes().size() == 3);
    assertTrue(v.getStaticAttributes().get("foo").equals(fooval));
    assertTrue(v.getStaticAttributes().get("king").equals(kingval));
  }
  @Test public void attributeCSVParsingInvalid(){
    AbstractView v=new ConcreteView();
    try {
      v.setAttributesCSV("fweoiruiu");
      fail();
    }
 catch (    IllegalArgumentException ex) {
    }
    try {
      v.setAttributesCSV("fweoiruiu=");
      fail();
    }
 catch (    IllegalArgumentException ex) {
    }
    try {
      v.setAttributesCSV("fweoiruiu=[");
      fail();
    }
 catch (    IllegalArgumentException ex) {
    }
    try {
      v.setAttributesCSV("fweoiruiu=[de],=");
      fail();
    }
 catch (    IllegalArgumentException ex) {
    }
  }
  @Test public void attributeCSVParsingIgnoresTrailingComma(){
    AbstractView v=new ConcreteView();
    v.setAttributesCSV("foo=[de],");
    assertEquals(1,v.getStaticAttributes().size());
  }
  /** 
 * Check that all keys in expected have same values in actual.
 */
  @SuppressWarnings({"rawtypes","unchecked"}) private void checkContainsAll(  Map expected,  Map<String,Object> actual){
    expected.forEach((k,v) -> assertEquals("Values for model key '" + k + "' must match",expected.get(k),actual.get(k)));
  }
  /** 
 * Trivial concrete subclass we can use when we're interested only in CSV parsing, which doesn't require lifecycle management
 */
private static class ConcreteView extends AbstractView {
    @Override protected void renderMergedOutputModel(    Map<String,Object> model,    HttpServletRequest request,    HttpServletResponse response) throws ServletException, IOException {
      throw new UnsupportedOperationException();
    }
  }
  /** 
 * Single threaded subclass of AbstractView to check superclass behavior.
 */
private static class TestView extends AbstractView {
    private final WebApplicationContext wac;
    boolean initialized;
    /** 
 * Captured model in render 
 */
    Map<String,Object> model;
    TestView(    WebApplicationContext wac){
      this.wac=wac;
    }
    @Override protected void renderMergedOutputModel(    Map<String,Object> model,    HttpServletRequest request,    HttpServletResponse response) throws ServletException, IOException {
      this.model=model;
    }
    /** 
 * @see org.springframework.context.support.ApplicationObjectSupport#initApplicationContext()
 */
    @Override protected void initApplicationContext() throws ApplicationContextException {
      if (initialized) {
        throw new RuntimeException("Already initialized");
      }
      this.initialized=true;
      assertTrue(getApplicationContext() == wac);
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.servlet.view;
import java.util.HashMap;
import java.util.Locale;
import java.util.Map;
import java.util.Properties;
import java.util.concurrent.atomic.AtomicInteger;
import javax.servlet.RequestDispatcher;
import javax.servlet.ServletContext;
import javax.servlet.ServletException;
import javax.servlet.ServletRequest;
import javax.servlet.ServletResponse;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import javax.servlet.jsp.jstl.core.Config;
import javax.servlet.jsp.jstl.fmt.LocalizationContext;
import org.junit.Test;
import org.springframework.beans.MutablePropertyValues;
import org.springframework.beans.PropertyValue;
import org.springframework.beans.factory.BeanDefinitionStoreException;
import org.springframework.context.ApplicationContextException;
import org.springframework.core.io.ClassPathResource;
import org.springframework.core.io.Resource;
import org.springframework.mock.web.test.MockHttpServletRequest;
import org.springframework.mock.web.test.MockHttpServletResponse;
import org.springframework.mock.web.test.MockRequestDispatcher;
import org.springframework.mock.web.test.MockServletContext;
import org.springframework.tests.sample.beans.TestBean;
import org.springframework.web.context.support.ServletContextResource;
import org.springframework.web.context.support.StaticWebApplicationContext;
import org.springframework.web.servlet.DispatcherServlet;
import org.springframework.web.servlet.View;
import org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolver;
import org.springframework.web.servlet.i18n.FixedLocaleResolver;
import org.springframework.web.servlet.support.RequestContext;
import org.springframework.web.servlet.theme.FixedThemeResolver;
import static org.junit.Assert.*;
/** 
 * @author Juergen Hoeller
 * @author Chris Beams
 * @since 18.06.2003
 */
public class ViewResolverTests {
  @Test public void testBeanNameViewResolver() throws ServletException {
    StaticWebApplicationContext wac=new StaticWebApplicationContext();
    wac.setServletContext(new MockServletContext());
    MutablePropertyValues pvs1=new MutablePropertyValues();
    pvs1.addPropertyValue(new PropertyValue("url","/example1.jsp"));
    wac.registerSingleton("example1",InternalResourceView.class,pvs1);
    MutablePropertyValues pvs2=new MutablePropertyValues();
    pvs2.addPropertyValue(new PropertyValue("url","/example2.jsp"));
    wac.registerSingleton("example2",JstlView.class,pvs2);
    BeanNameViewResolver vr=new BeanNameViewResolver();
    vr.setApplicationContext(wac);
    wac.refresh();
    View view=vr.resolveViewName("example1",Locale.getDefault());
    assertEquals("Correct view class",InternalResourceView.class,view.getClass());
    assertEquals("Correct URL","/example1.jsp",((InternalResourceView)view).getUrl());
    view=vr.resolveViewName("example2",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","/example2.jsp",((JstlView)view).getUrl());
  }
  @Test public void testUrlBasedViewResolverWithoutPrefixes() throws Exception {
    UrlBasedViewResolver vr=new UrlBasedViewResolver();
    vr.setViewClass(JstlView.class);
    doTestUrlBasedViewResolverWithoutPrefixes(vr);
  }
  @Test public void testUrlBasedViewResolverWithPrefixes() throws Exception {
    UrlBasedViewResolver vr=new UrlBasedViewResolver();
    vr.setViewClass(JstlView.class);
    doTestUrlBasedViewResolverWithPrefixes(vr);
  }
  @Test public void testInternalResourceViewResolverWithoutPrefixes() throws Exception {
    doTestUrlBasedViewResolverWithoutPrefixes(new InternalResourceViewResolver());
  }
  @Test public void testInternalResourceViewResolverWithPrefixes() throws Exception {
    doTestUrlBasedViewResolverWithPrefixes(new InternalResourceViewResolver());
  }
  private void doTestUrlBasedViewResolverWithoutPrefixes(  UrlBasedViewResolver vr) throws Exception {
    StaticWebApplicationContext wac=new StaticWebApplicationContext();
    wac.setServletContext(new MockServletContext());
    wac.refresh();
    vr.setApplicationContext(wac);
    vr.setContentType("myContentType");
    vr.setRequestContextAttribute("rc");
    View view=vr.resolveViewName("example1",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","example1",((InternalResourceView)view).getUrl());
    assertEquals("Correct textContentType","myContentType",((InternalResourceView)view).getContentType());
    view=vr.resolveViewName("example2",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","example2",((InternalResourceView)view).getUrl());
    assertEquals("Correct textContentType","myContentType",((InternalResourceView)view).getContentType());
    HttpServletRequest request=new MockHttpServletRequest(wac.getServletContext());
    HttpServletResponse response=new MockHttpServletResponse();
    request.setAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE,wac);
    request.setAttribute(DispatcherServlet.LOCALE_RESOLVER_ATTRIBUTE,new AcceptHeaderLocaleResolver());
    request.setAttribute(DispatcherServlet.THEME_RESOLVER_ATTRIBUTE,new FixedThemeResolver());
    Map<String,Object> model=new HashMap<>();
    TestBean tb=new TestBean();
    model.put("tb",tb);
    view.render(model,request,response);
    assertTrue("Correct tb attribute",tb.equals(request.getAttribute("tb")));
    assertTrue("Correct rc attribute",request.getAttribute("rc") instanceof RequestContext);
    view=vr.resolveViewName("redirect:myUrl",Locale.getDefault());
    assertEquals("Correct view class",RedirectView.class,view.getClass());
    assertEquals("Correct URL","myUrl",((RedirectView)view).getUrl());
    assertSame("View not initialized as bean",wac,((RedirectView)view).getApplicationContext());
    view=vr.resolveViewName("forward:myUrl",Locale.getDefault());
    assertEquals("Correct view class",InternalResourceView.class,view.getClass());
    assertEquals("Correct URL","myUrl",((InternalResourceView)view).getUrl());
  }
  private void doTestUrlBasedViewResolverWithPrefixes(  UrlBasedViewResolver vr) throws Exception {
    StaticWebApplicationContext wac=new StaticWebApplicationContext();
    wac.setServletContext(new MockServletContext());
    wac.refresh();
    vr.setPrefix("/WEB-INF/");
    vr.setSuffix(".jsp");
    vr.setApplicationContext(wac);
    View view=vr.resolveViewName("example1",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","/WEB-INF/example1.jsp",((InternalResourceView)view).getUrl());
    view=vr.resolveViewName("example2",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","/WEB-INF/example2.jsp",((InternalResourceView)view).getUrl());
    view=vr.resolveViewName("redirect:myUrl",Locale.getDefault());
    assertEquals("Correct view class",RedirectView.class,view.getClass());
    assertEquals("Correct URL","myUrl",((RedirectView)view).getUrl());
    view=vr.resolveViewName("forward:myUrl",Locale.getDefault());
    assertEquals("Correct view class",InternalResourceView.class,view.getClass());
    assertEquals("Correct URL","myUrl",((InternalResourceView)view).getUrl());
  }
  @Test public void testInternalResourceViewResolverWithAttributes() throws Exception {
    MockServletContext sc=new MockServletContext();
    StaticWebApplicationContext wac=new StaticWebApplicationContext();
    wac.setServletContext(sc);
    wac.refresh();
    InternalResourceViewResolver vr=new InternalResourceViewResolver();
    Properties props=new Properties();
    props.setProperty("key1","value1");
    vr.setAttributes(props);
    Map<String,Object> map=new HashMap<>();
    map.put("key2",new Integer(2));
    vr.setAttributesMap(map);
    vr.setApplicationContext(wac);
    View view=vr.resolveViewName("example1",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","example1",((InternalResourceView)view).getUrl());
    Map<String,Object> attributes=((InternalResourceView)view).getStaticAttributes();
    assertEquals("value1",attributes.get("key1"));
    assertEquals(new Integer(2),attributes.get("key2"));
    view=vr.resolveViewName("example2",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","example2",((InternalResourceView)view).getUrl());
    attributes=((InternalResourceView)view).getStaticAttributes();
    assertEquals("value1",attributes.get("key1"));
    assertEquals(new Integer(2),attributes.get("key2"));
    MockHttpServletRequest request=new MockHttpServletRequest(sc);
    HttpServletResponse response=new MockHttpServletResponse();
    request.setAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE,wac);
    request.setAttribute(DispatcherServlet.LOCALE_RESOLVER_ATTRIBUTE,new AcceptHeaderLocaleResolver());
    Map<String,Object> model=new HashMap<>();
    TestBean tb=new TestBean();
    model.put("tb",tb);
    view.render(model,request,response);
    assertTrue("Correct tb attribute",tb.equals(request.getAttribute("tb")));
    assertTrue("Correct rc attribute",request.getAttribute("rc") == null);
    assertEquals("value1",request.getAttribute("key1"));
    assertEquals(new Integer(2),request.getAttribute("key2"));
  }
  @Test public void testInternalResourceViewResolverWithContextBeans() throws Exception {
    MockServletContext sc=new MockServletContext();
    final StaticWebApplicationContext wac=new StaticWebApplicationContext();
    wac.registerSingleton("myBean",TestBean.class);
    wac.registerSingleton("myBean2",TestBean.class);
    wac.setServletContext(sc);
    wac.refresh();
    InternalResourceViewResolver vr=new InternalResourceViewResolver();
    Properties props=new Properties();
    props.setProperty("key1","value1");
    vr.setAttributes(props);
    Map<String,Object> map=new HashMap<>();
    map.put("key2",new Integer(2));
    vr.setAttributesMap(map);
    vr.setExposeContextBeansAsAttributes(true);
    vr.setApplicationContext(wac);
    MockHttpServletRequest request=new MockHttpServletRequest(sc){
      @Override public RequestDispatcher getRequestDispatcher(      String path){
        return new MockRequestDispatcher(path){
          @Override public void forward(          ServletRequest forwardRequest,          ServletResponse forwardResponse){
            assertTrue("Correct rc attribute",forwardRequest.getAttribute("rc") == null);
            assertEquals("value1",forwardRequest.getAttribute("key1"));
            assertEquals(new Integer(2),forwardRequest.getAttribute("key2"));
            assertSame(wac.getBean("myBean"),forwardRequest.getAttribute("myBean"));
            assertSame(wac.getBean("myBean2"),forwardRequest.getAttribute("myBean2"));
          }
        }
;
      }
    }
;
    HttpServletResponse response=new MockHttpServletResponse();
    request.setAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE,wac);
    request.setAttribute(DispatcherServlet.LOCALE_RESOLVER_ATTRIBUTE,new AcceptHeaderLocaleResolver());
    View view=vr.resolveViewName("example1",Locale.getDefault());
    view.render(new HashMap<String,Object>(),request,response);
  }
  @Test public void testInternalResourceViewResolverWithSpecificContextBeans() throws Exception {
    MockServletContext sc=new MockServletContext();
    final StaticWebApplicationContext wac=new StaticWebApplicationContext();
    wac.registerSingleton("myBean",TestBean.class);
    wac.registerSingleton("myBean2",TestBean.class);
    wac.setServletContext(sc);
    wac.refresh();
    InternalResourceViewResolver vr=new InternalResourceViewResolver();
    Properties props=new Properties();
    props.setProperty("key1","value1");
    vr.setAttributes(props);
    Map<String,Object> map=new HashMap<>();
    map.put("key2",new Integer(2));
    vr.setAttributesMap(map);
    vr.setExposedContextBeanNames(new String[]{"myBean2"});
    vr.setApplicationContext(wac);
    MockHttpServletRequest request=new MockHttpServletRequest(sc){
      @Override public RequestDispatcher getRequestDispatcher(      String path){
        return new MockRequestDispatcher(path){
          @Override public void forward(          ServletRequest forwardRequest,          ServletResponse forwardResponse){
            assertTrue("Correct rc attribute",forwardRequest.getAttribute("rc") == null);
            assertEquals("value1",forwardRequest.getAttribute("key1"));
            assertEquals(new Integer(2),forwardRequest.getAttribute("key2"));
            assertNull(forwardRequest.getAttribute("myBean"));
            assertSame(wac.getBean("myBean2"),forwardRequest.getAttribute("myBean2"));
          }
        }
;
      }
    }
;
    HttpServletResponse response=new MockHttpServletResponse();
    request.setAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE,wac);
    request.setAttribute(DispatcherServlet.LOCALE_RESOLVER_ATTRIBUTE,new AcceptHeaderLocaleResolver());
    View view=vr.resolveViewName("example1",Locale.getDefault());
    view.render(new HashMap<String,Object>(),request,response);
  }
  @Test public void testInternalResourceViewResolverWithJstl() throws Exception {
    Locale locale=!Locale.GERMAN.equals(Locale.getDefault()) ? Locale.GERMAN : Locale.FRENCH;
    MockServletContext sc=new MockServletContext();
    StaticWebApplicationContext wac=new StaticWebApplicationContext();
    wac.setServletContext(sc);
    wac.addMessage("code1",locale,"messageX");
    wac.refresh();
    InternalResourceViewResolver vr=new InternalResourceViewResolver();
    vr.setViewClass(JstlView.class);
    vr.setApplicationContext(wac);
    View view=vr.resolveViewName("example1",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","example1",((JstlView)view).getUrl());
    view=vr.resolveViewName("example2",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","example2",((JstlView)view).getUrl());
    MockHttpServletRequest request=new MockHttpServletRequest(sc);
    HttpServletResponse response=new MockHttpServletResponse();
    request.setAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE,wac);
    request.setAttribute(DispatcherServlet.LOCALE_RESOLVER_ATTRIBUTE,new FixedLocaleResolver(locale));
    Map<String,Object> model=new HashMap<>();
    TestBean tb=new TestBean();
    model.put("tb",tb);
    view.render(model,request,response);
    assertTrue("Correct tb attribute",tb.equals(request.getAttribute("tb")));
    assertTrue("Correct rc attribute",request.getAttribute("rc") == null);
    assertEquals(locale,Config.get(request,Config.FMT_LOCALE));
    LocalizationContext lc=(LocalizationContext)Config.get(request,Config.FMT_LOCALIZATION_CONTEXT);
    assertEquals("messageX",lc.getResourceBundle().getString("code1"));
  }
  @Test public void testInternalResourceViewResolverWithJstlAndContextParam() throws Exception {
    Locale locale=!Locale.GERMAN.equals(Locale.getDefault()) ? Locale.GERMAN : Locale.FRENCH;
    MockServletContext sc=new MockServletContext();
    sc.addInitParameter(Config.FMT_LOCALIZATION_CONTEXT,"org/springframework/web/context/WEB-INF/context-messages");
    StaticWebApplicationContext wac=new StaticWebApplicationContext();
    wac.setServletContext(sc);
    wac.addMessage("code1",locale,"messageX");
    wac.refresh();
    InternalResourceViewResolver vr=new InternalResourceViewResolver();
    vr.setViewClass(JstlView.class);
    vr.setApplicationContext(wac);
    View view=vr.resolveViewName("example1",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","example1",((JstlView)view).getUrl());
    view=vr.resolveViewName("example2",Locale.getDefault());
    assertEquals("Correct view class",JstlView.class,view.getClass());
    assertEquals("Correct URL","example2",((JstlView)view).getUrl());
    MockHttpServletRequest request=new MockHttpServletRequest(sc);
    HttpServletResponse response=new MockHttpServletResponse();
    request.setAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE,wac);
    request.setAttribute(DispatcherServlet.LOCALE_RESOLVER_ATTRIBUTE,new FixedLocaleResolver(locale));
    Map<String,Object> model=new HashMap<>();
    TestBean tb=new TestBean();
    model.put("tb",tb);
    view.render(model,request,response);
    assertTrue("Correct tb attribute",tb.equals(request.getAttribute("tb")));
    assertTrue("Correct rc attribute",request.getAttribute("rc") == null);
    assertEquals(locale,Config.get(request,Config.FMT_LOCALE));
    LocalizationContext lc=(LocalizationContext)Config.get(request,Config.FMT_LOCALIZATION_CONTEXT);
    assertEquals("message1",lc.getResourceBundle().getString("code1"));
    assertEquals("message2",lc.getResourceBundle().getString("code2"));
  }
  @Test public void testXmlViewResolver() throws Exception {
    StaticWebApplicationContext wac=new StaticWebApplicationContext();
    wac.registerSingleton("testBean",TestBean.class);
    wac.setServletContext(new MockServletContext());
    wac.refresh();
    TestBean testBean=(TestBean)wac.getBean("testBean");
    XmlViewResolver vr=new XmlViewResolver();
    vr.setLocation(new ClassPathResource("org/springframework/web/servlet/view/views.xml"));
    vr.setApplicationContext(wac);
    View view1=vr.resolveViewName("example1",Locale.getDefault());
    assertTrue("Correct view class",TestView.class.equals(view1.getClass()));
    assertTrue("Correct URL","/example1.jsp".equals(((InternalResourceView)view1).getUrl()));
    View view2=vr.resolveViewName("example2",Locale.getDefault());
    assertTrue("Correct view class",JstlView.class.equals(view2.getClass()));
    assertTrue("Correct URL","/example2new.jsp".equals(((InternalResourceView)view2).getUrl()));
    ServletContext sc=new MockServletContext();
    Map<String,Object> model=new HashMap<>();
    TestBean tb=new TestBean();
    model.put("tb",tb);
    HttpServletRequest request=new MockHttpServletRequest(sc);
    HttpServletResponse response=new MockHttpServletResponse();
    request.setAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE,wac);
    request.setAttribute(DispatcherServlet.LOCALE_RESOLVER_ATTRIBUTE,new AcceptHeaderLocaleResolver());
    request.setAttribute(DispatcherServlet.THEME_RESOLVER_ATTRIBUTE,new FixedThemeResolver());
    view1.render(model,request,response);
    assertTrue("Correct tb attribute",tb.equals(request.getAttribute("tb")));
    assertTrue("Correct test1 attribute","testvalue1".equals(request.getAttribute("test1")));
    assertTrue("Correct test2 attribute",testBean.equals(request.getAttribute("test2")));
    request=new MockHttpServletRequest(sc);
    response=new MockHttpServletResponse();
    request.setAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE,wac);
    request.setAttribute(DispatcherServlet.LOCALE_RESOLVER_ATTRIBUTE,new AcceptHeaderLocaleResolver());
    request.setAttribute(DispatcherServlet.THEME_RESOLVER_ATTRIBUTE,new FixedThemeResolver());
    view2.render(model,request,response);
    assertTrue("Correct tb attribute",tb.equals(request.getAttribute("tb")));
    assertTrue("Correct test1 attribute","testvalue1".equals(request.getAttribute("test1")));
    assertTrue("Correct test2 attribute","testvalue2".equals(request.getAttribute("test2")));
  }
  @Test public void testXmlViewResolverDefaultLocation(){
    StaticWebApplicationContext wac=new StaticWebApplicationContext(){
      @Override protected Resource getResourceByPath(      String path){
        assertTrue("Correct default location",XmlViewResolver.DEFAULT_LOCATION.equals(path));
        return super.getResourceByPath(path);
      }
    }
;
    wac.setServletContext(new MockServletContext());
    wac.refresh();
    XmlViewResolver vr=new XmlViewResolver();
    try {
      vr.setApplicationContext(wac);
      vr.afterPropertiesSet();
      fail("Should have thrown BeanDefinitionStoreException");
    }
 catch (    BeanDefinitionStoreException ex) {
    }
  }
  @Test public void testXmlViewResolverWithoutCache() throws Exception {
    StaticWebApplicationContext wac=new StaticWebApplicationContext(){
      @Override protected Resource getResourceByPath(      String path){
        assertTrue("Correct default location",XmlViewResolver.DEFAULT_LOCATION.equals(path));
        return super.getResourceByPath(path);
      }
    }
;
    wac.setServletContext(new MockServletContext());
    wac.refresh();
    XmlViewResolver vr=new XmlViewResolver();
    vr.setCache(false);
    try {
      vr.setApplicationContext(wac);
    }
 catch (    ApplicationContextException ex) {
      fail("Should not have thrown ApplicationContextException: " + ex.getMessage());
    }
    try {
      vr.resolveViewName("example1",Locale.getDefault());
      fail("Should have thrown BeanDefinitionStoreException");
    }
 catch (    BeanDefinitionStoreException ex) {
    }
  }
  @Test public void testCacheRemoval() throws Exception {
    StaticWebApplicationContext wac=new StaticWebApplicationContext();
    wac.setServletContext(new MockServletContext());
    wac.refresh();
    InternalResourceViewResolver vr=new InternalResourceViewResolver();
    vr.setViewClass(JstlView.class);
    vr.setApplicationContext(wac);
    View view=vr.resolveViewName("example1",Locale.getDefault());
    View cached=vr.resolveViewName("example1",Locale.getDefault());
    if (view != cached) {
      fail("Caching doesn't work");
    }
    vr.removeFromCache("example1",Locale.getDefault());
    cached=vr.resolveViewName("example1",Locale.getDefault());
    if (view == cached) {
      fail("View wasn't removed from cache");
    }
  }
  @Test public void testCacheUnresolved() throws Exception {
    final AtomicInteger count=new AtomicInteger();
    AbstractCachingViewResolver viewResolver=new AbstractCachingViewResolver(){
      @Override protected View loadView(      String viewName,      Locale locale) throws Exception {
        count.incrementAndGet();
        return null;
      }
    }
;
    viewResolver.setCacheUnresolved(false);
    viewResolver.resolveViewName("view",Locale.getDefault());
    viewResolver.resolveViewName("view",Locale.getDefault());
    assertEquals(2,count.intValue());
    viewResolver.setCacheUnresolved(true);
    viewResolver.resolveViewName("view",Locale.getDefault());
    viewResolver.resolveViewName("view",Locale.getDefault());
    viewResolver.resolveViewName("view",Locale.getDefault());
    viewResolver.resolveViewName("view",Locale.getDefault());
    viewResolver.resolveViewName("view",Locale.getDefault());
    assertEquals(3,count.intValue());
  }
public static class TestView extends InternalResourceView {
    public void setLocation(    Resource location){
      if (!(location instanceof ServletContextResource)) {
        throw new IllegalArgumentException("Expecting ClassPathResource, not " + location.getClass().getName());
      }
    }
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.servlet.view.script;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Locale;
import java.util.Map;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import javax.script.Invocable;
import javax.script.ScriptEngine;
import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.ExpectedException;
import org.springframework.beans.DirectFieldAccessor;
import org.springframework.context.ApplicationContextException;
import org.springframework.context.support.StaticApplicationContext;
import org.springframework.http.HttpHeaders;
import org.springframework.http.MediaType;
import org.springframework.mock.web.test.MockHttpServletRequest;
import org.springframework.mock.web.test.MockHttpServletResponse;
import org.springframework.mock.web.test.MockServletContext;
import org.springframework.web.context.support.StaticWebApplicationContext;
import org.springframework.web.servlet.DispatcherServlet;
import static org.junit.Assert.*;
import static org.mockito.BDDMockito.*;
/** 
 * Unit tests for  {@link ScriptTemplateView}.
 * @author Sebastien Deleuze
 */
public class ScriptTemplateViewTests {
  private ScriptTemplateView view;
  private ScriptTemplateConfigurer configurer;
  private StaticWebApplicationContext wac;
  @Rule public ExpectedException expectedException=ExpectedException.none();
  @Before public void setup(){
    this.configurer=new ScriptTemplateConfigurer();
    this.wac=new StaticWebApplicationContext();
    this.wac.getBeanFactory().registerSingleton("scriptTemplateConfigurer",this.configurer);
    this.view=new ScriptTemplateView();
  }
  @Test public void missingTemplate() throws Exception {
    MockServletContext servletContext=new MockServletContext();
    this.wac.setServletContext(servletContext);
    this.wac.refresh();
    this.view.setResourceLoaderPath("classpath:org/springframework/web/servlet/view/script/");
    this.view.setUrl("missing.txt");
    this.view.setEngine(mock(InvocableScriptEngine.class));
    this.configurer.setRenderFunction("render");
    this.view.setApplicationContext(this.wac);
    assertFalse(this.view.checkResource(Locale.ENGLISH));
  }
  @Test public void missingScriptTemplateConfig() throws Exception {
    this.expectedException.expect(ApplicationContextException.class);
    this.view.setApplicationContext(new StaticApplicationContext());
    this.expectedException.expectMessage(contains("ScriptTemplateConfig"));
  }
  @Test public void detectScriptTemplateConfigWithEngine(){
    InvocableScriptEngine engine=mock(InvocableScriptEngine.class);
    this.configurer.setEngine(engine);
    this.configurer.setRenderObject("Template");
    this.configurer.setRenderFunction("render");
    this.configurer.setContentType(MediaType.TEXT_PLAIN_VALUE);
    this.configurer.setCharset(StandardCharsets.ISO_8859_1);
    this.configurer.setSharedEngine(true);
    DirectFieldAccessor accessor=new DirectFieldAccessor(this.view);
    this.view.setApplicationContext(this.wac);
    assertEquals(engine,accessor.getPropertyValue("engine"));
    assertEquals("Template",accessor.getPropertyValue("renderObject"));
    assertEquals("render",accessor.getPropertyValue("renderFunction"));
    assertEquals(MediaType.TEXT_PLAIN_VALUE,accessor.getPropertyValue("contentType"));
    assertEquals(StandardCharsets.ISO_8859_1,accessor.getPropertyValue("charset"));
    assertEquals(true,accessor.getPropertyValue("sharedEngine"));
  }
  @Test public void detectScriptTemplateConfigWithEngineName(){
    this.configurer.setEngineName("nashorn");
    this.configurer.setRenderObject("Template");
    this.configurer.setRenderFunction("render");
    DirectFieldAccessor accessor=new DirectFieldAccessor(this.view);
    this.view.setApplicationContext(this.wac);
    assertEquals("nashorn",accessor.getPropertyValue("engineName"));
    assertNotNull(accessor.getPropertyValue("engine"));
    assertEquals("Template",accessor.getPropertyValue("renderObject"));
    assertEquals("render",accessor.getPropertyValue("renderFunction"));
    assertEquals(MediaType.TEXT_HTML_VALUE,accessor.getPropertyValue("contentType"));
    assertEquals(StandardCharsets.UTF_8,accessor.getPropertyValue("charset"));
  }
  @Test public void customEngineAndRenderFunction() throws Exception {
    ScriptEngine engine=mock(InvocableScriptEngine.class);
    given(engine.get("key")).willReturn("value");
    this.view.setEngine(engine);
    this.view.setRenderFunction("render");
    this.view.setApplicationContext(this.wac);
    engine=this.view.getEngine();
    assertNotNull(engine);
    assertEquals("value",engine.get("key"));
    DirectFieldAccessor accessor=new DirectFieldAccessor(this.view);
    assertNull(accessor.getPropertyValue("renderObject"));
    assertEquals("render",accessor.getPropertyValue("renderFunction"));
    assertEquals(StandardCharsets.UTF_8,accessor.getPropertyValue("charset"));
  }
  @Test public void nonSharedEngine() throws Exception {
    int iterations=20;
    this.view.setEngineName("nashorn");
    this.view.setRenderFunction("render");
    this.view.setSharedEngine(false);
    this.view.setApplicationContext(this.wac);
    ExecutorService executor=Executors.newFixedThreadPool(4);
    List<Future<Boolean>> results=new ArrayList<>();
    for (int i=0; i < iterations; i++) {
      results.add(executor.submit(() -> view.getEngine() != null));
    }
    assertEquals(iterations,results.size());
    for (int i=0; i < iterations; i++) {
      assertTrue(results.get(i).get());
    }
    executor.shutdown();
  }
  @Test public void nonInvocableScriptEngine() throws Exception {
    this.view.setEngine(mock(ScriptEngine.class));
    this.view.setApplicationContext(this.wac);
  }
  @Test public void nonInvocableScriptEngineWithRenderFunction() throws Exception {
    this.view.setEngine(mock(ScriptEngine.class));
    this.view.setRenderFunction("render");
    this.expectedException.expect(IllegalArgumentException.class);
    this.view.setApplicationContext(this.wac);
  }
  @Test public void engineAndEngineNameBothDefined(){
    this.view.setEngine(mock(InvocableScriptEngine.class));
    this.view.setEngineName("test");
    this.view.setRenderFunction("render");
    this.expectedException.expect(IllegalArgumentException.class);
    this.view.setApplicationContext(this.wac);
    this.expectedException.expectMessage(contains("'engine' or 'engineName'"));
  }
  @Test public void engineSetterAndNonSharedEngine(){
    this.view.setEngine(mock(InvocableScriptEngine.class));
    this.view.setRenderFunction("render");
    this.view.setSharedEngine(false);
    this.expectedException.expect(IllegalArgumentException.class);
    this.view.setApplicationContext(this.wac);
    this.expectedException.expectMessage(contains("sharedEngine"));
  }
  @Test public void resourceLoaderPath() throws Exception {
    MockServletContext servletContext=new MockServletContext();
    this.wac.setServletContext(servletContext);
    this.wac.refresh();
    MockHttpServletRequest request=new MockHttpServletRequest();
    request.setAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE,this.wac);
    MockHttpServletResponse response=new MockHttpServletResponse();
    Map<String,Object> model=new HashMap<>();
    InvocableScriptEngine engine=mock(InvocableScriptEngine.class);
    when(engine.invokeFunction(any(),any(),any(),any())).thenReturn("foo");
    this.view.setEngine(engine);
    this.view.setRenderFunction("render");
    this.view.setApplicationContext(this.wac);
    this.view.setUrl("org/springframework/web/servlet/view/script/empty.txt");
    this.view.render(model,request,response);
    assertEquals("foo",response.getContentAsString());
    response=new MockHttpServletResponse();
    this.view.setResourceLoaderPath("classpath:org/springframework/web/servlet/view/script/");
    this.view.setUrl("empty.txt");
    this.view.render(model,request,response);
    assertEquals("foo",response.getContentAsString());
    response=new MockHttpServletResponse();
    this.view.setResourceLoaderPath("classpath:org/springframework/web/servlet/view/script");
    this.view.setUrl("empty.txt");
    this.view.render(model,request,response);
    assertEquals("foo",response.getContentAsString());
  }
  @Test public void contentType() throws Exception {
    MockServletContext servletContext=new MockServletContext();
    this.wac.setServletContext(servletContext);
    this.wac.refresh();
    MockHttpServletRequest request=new MockHttpServletRequest();
    request.setAttribute(DispatcherServlet.WEB_APPLICATION_CONTEXT_ATTRIBUTE,this.wac);
    MockHttpServletResponse response=new MockHttpServletResponse();
    Map<String,Object> model=new HashMap<>();
    this.view.setEngine(mock(InvocableScriptEngine.class));
    this.view.setRenderFunction("render");
    this.view.setResourceLoaderPath("classpath:org/springframework/web/servlet/view/script/");
    this.view.setUrl("empty.txt");
    this.view.setApplicationContext(this.wac);
    this.view.render(model,request,response);
    assertEquals(MediaType.TEXT_HTML_VALUE + ";charset=" + StandardCharsets.UTF_8,response.getHeader(HttpHeaders.CONTENT_TYPE));
    response=new MockHttpServletResponse();
    this.view.setContentType(MediaType.TEXT_PLAIN_VALUE);
    this.view.render(model,request,response);
    assertEquals(MediaType.TEXT_PLAIN_VALUE + ";charset=" + StandardCharsets.UTF_8,response.getHeader(HttpHeaders.CONTENT_TYPE));
    response=new MockHttpServletResponse();
    this.view.setCharset(StandardCharsets.ISO_8859_1);
    this.view.render(model,request,response);
    assertEquals(MediaType.TEXT_PLAIN_VALUE + ";charset=" + StandardCharsets.ISO_8859_1,response.getHeader(HttpHeaders.CONTENT_TYPE));
  }
private interface InvocableScriptEngine extends ScriptEngine, Invocable {
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.web.servlet.resource;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import org.junit.Before;
import org.junit.Test;
import org.mockito.Mockito;
import org.springframework.core.io.ClassPathResource;
import org.springframework.core.io.Resource;
import org.springframework.mock.web.test.MockHttpServletRequest;
import org.springframework.util.StringUtils;
import org.springframework.web.servlet.resource.EncodedResourceResolver.EncodedResource;
import static org.junit.Assert.*;
/** 
 * Unit tests for {@link org.springframework.web.servlet.resource.CssLinkResourceTransformer}.
 * @author Rossen Stoyanchev
 * @author Brian Clozel
 * @since 4.1
 */
public class CssLinkResourceTransformerTests {
  private ResourceTransformerChain transformerChain;
  private MockHttpServletRequest request;
  @Before public void setUp(){
    VersionResourceResolver versionResolver=new VersionResourceResolver();
    versionResolver.setStrategyMap(Collections.singletonMap("/**",new ContentVersionStrategy()));
    PathResourceResolver pathResolver=new PathResourceResolver();
    pathResolver.setAllowedLocations(new ClassPathResource("test/",getClass()));
    List<ResourceResolver> resolvers=new ArrayList<>();
    resolvers.add(versionResolver);
    resolvers.add(new PathResourceResolver());
    ResourceUrlProvider resourceUrlProvider=createUrlProvider(resolvers);
    CssLinkResourceTransformer cssLinkTransformer=new CssLinkResourceTransformer();
    cssLinkTransformer.setResourceUrlProvider(resourceUrlProvider);
    this.transformerChain=new DefaultResourceTransformerChain(new DefaultResourceResolverChain(resolvers),Collections.singletonList(cssLinkTransformer));
  }
  private ResourceUrlProvider createUrlProvider(  List<ResourceResolver> resolvers){
    ResourceHttpRequestHandler resourceHandler=new ResourceHttpRequestHandler();
    resourceHandler.setResourceResolvers(resolvers);
    resourceHandler.setLocations(Collections.singletonList(new ClassPathResource("test/",getClass())));
    ResourceUrlProvider resourceUrlProvider=new ResourceUrlProvider();
    resourceUrlProvider.setHandlerMap(Collections.singletonMap("/static/**",resourceHandler));
    return resourceUrlProvider;
  }
  @Test public void transform() throws Exception {
    this.request=new MockHttpServletRequest("GET","/static/main.css");
    Resource css=getResource("main.css");
    String expected="\n" + "@import url(\"/static/bar-11e16cf79faee7ac698c805cf28248d2.css?#iefix\");\n" + "@import url('/static/bar-11e16cf79faee7ac698c805cf28248d2.css#bla-normal');\n"+ "@import url(/static/bar-11e16cf79faee7ac698c805cf28248d2.css);\n\n"+ "@import \"/static/foo-e36d2e05253c6c7085a91522ce43a0b4.css\";\n"+ "@import '/static/foo-e36d2e05253c6c7085a91522ce43a0b4.css';\n\n"+ "body { background: url(\"/static/images/image-f448cd1d5dba82b774f3202c878230b3.png?#iefix\") }\n";
    TransformedResource actual=(TransformedResource)this.transformerChain.transform(this.request,css);
    String result=new String(actual.getByteArray(),StandardCharsets.UTF_8);
    result=StringUtils.deleteAny(result,"\r");
    assertEquals(expected,result);
  }
  @Test public void transformNoLinks() throws Exception {
    this.request=new MockHttpServletRequest("GET","/static/foo.css");
    Resource expected=getResource("foo.css");
    Resource actual=this.transformerChain.transform(this.request,expected);
    assertSame(expected,actual);
  }
  @Test public void transformExtLinksNotAllowed() throws Exception {
    this.request=new MockHttpServletRequest("GET","/static/external.css");
    List<ResourceTransformer> transformers=Collections.singletonList(new CssLinkResourceTransformer());
    ResourceResolverChain mockChain=Mockito.mock(DefaultResourceResolverChain.class);
    ResourceTransformerChain chain=new DefaultResourceTransformerChain(mockChain,transformers);
    Resource resource=getResource("external.css");
    String expected="@import url(\"http://example.org/fonts/css\");\n" + "body { background: url(\"file:///home/spring/image.png\") }\n" + "figure { background: url(\"//example.org/style.css\")}";
    TransformedResource transformedResource=(TransformedResource)chain.transform(this.request,resource);
    String result=new String(transformedResource.getByteArray(),StandardCharsets.UTF_8);
    result=StringUtils.deleteAny(result,"\r");
    assertEquals(expected,result);
    List<Resource> locations=Collections.singletonList(resource);
    Mockito.verify(mockChain,Mockito.never()).resolveUrlPath("http://example.org/fonts/css",locations);
    Mockito.verify(mockChain,Mockito.never()).resolveUrlPath("file:///home/spring/image.png",locations);
    Mockito.verify(mockChain,Mockito.never()).resolveUrlPath("//example.org/style.css",locations);
  }
  @Test public void transformSkippedForNonCssResource() throws Exception {
    this.request=new MockHttpServletRequest("GET","/static/images/image.png");
    Resource expected=getResource("images/image.png");
    Resource actual=this.transformerChain.transform(this.request,expected);
    assertSame(expected,actual);
  }
  @Test public void transformSkippedForGzippedResource() throws Exception {
    EncodedResourceResolverTests.createGzippedFile("main.css");
    this.request=new MockHttpServletRequest("GET","/static/main.css");
    Resource original=new ClassPathResource("test/main.css",getClass());
    EncodedResource gzipped=new EncodedResource(original,"gzip",".gz");
    Resource actual=this.transformerChain.transform(this.request,gzipped);
    assertSame(gzipped,actual);
  }
  private Resource getResource(  String filePath){
    return new ClassPathResource("test/" + filePath,getClass());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.beans.propertyeditors;
import java.beans.PropertyEditor;
import org.junit.Test;
import static org.junit.Assert.*;
/** 
 * Unit tests for the  {@link ByteArrayPropertyEditor} class.
 * @author Rick Evans
 */
public class ByteArrayPropertyEditorTests {
  private final PropertyEditor byteEditor=new ByteArrayPropertyEditor();
  @Test public void sunnyDaySetAsText() throws Exception {
    final String text="Hideous towns make me throw... up";
    byteEditor.setAsText(text);
    Object value=byteEditor.getValue();
    assertNotNull(value);
    assertTrue(value instanceof byte[]);
    byte[] bytes=(byte[])value;
    for (int i=0; i < text.length(); ++i) {
      assertEquals("cyte[] differs at index '" + i + "'",text.charAt(i),bytes[i]);
    }
    assertEquals(text,byteEditor.getAsText());
  }
  @Test public void getAsTextReturnsEmptyStringIfValueIsNull() throws Exception {
    assertEquals("",byteEditor.getAsText());
    byteEditor.setAsText(null);
    assertEquals("",byteEditor.getAsText());
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.beans.factory.xml;
import org.junit.Test;
import org.springframework.beans.factory.BeanDefinitionStoreException;
import org.springframework.beans.factory.support.DefaultListableBeanFactory;
import org.springframework.core.io.ClassPathResource;
import org.springframework.tests.sample.beans.DummyBean;
import org.springframework.tests.sample.beans.TestBean;
import static org.junit.Assert.*;
/** 
 * @author Costin Leau
 */
public class SimpleConstructorNamespaceHandlerTests {
  @Test public void simpleValue() throws Exception {
    DefaultListableBeanFactory beanFactory=createFactory("simpleConstructorNamespaceHandlerTests.xml");
    String name="simple";
    DummyBean nameValue=beanFactory.getBean(name,DummyBean.class);
    assertEquals("simple",nameValue.getValue());
  }
  @Test public void simpleRef() throws Exception {
    DefaultListableBeanFactory beanFactory=createFactory("simpleConstructorNamespaceHandlerTests.xml");
    String name="simple-ref";
    DummyBean nameValue=beanFactory.getBean(name,DummyBean.class);
    assertEquals(beanFactory.getBean("name"),nameValue.getValue());
  }
  @Test public void nameValue() throws Exception {
    DefaultListableBeanFactory beanFactory=createFactory("simpleConstructorNamespaceHandlerTests.xml");
    String name="name-value";
    TestBean nameValue=beanFactory.getBean(name,TestBean.class);
    assertEquals(name,nameValue.getName());
    assertEquals(10,nameValue.getAge());
  }
  @Test public void nameRef() throws Exception {
    DefaultListableBeanFactory beanFactory=createFactory("simpleConstructorNamespaceHandlerTests.xml");
    TestBean nameValue=beanFactory.getBean("name-value",TestBean.class);
    DummyBean nameRef=beanFactory.getBean("name-ref",DummyBean.class);
    assertEquals("some-name",nameRef.getName());
    assertEquals(nameValue,nameRef.getSpouse());
  }
  @Test public void typeIndexedValue() throws Exception {
    DefaultListableBeanFactory beanFactory=createFactory("simpleConstructorNamespaceHandlerTests.xml");
    DummyBean typeRef=beanFactory.getBean("indexed-value",DummyBean.class);
    assertEquals("at",typeRef.getName());
    assertEquals("austria",typeRef.getValue());
    assertEquals(10,typeRef.getAge());
  }
  @Test public void typeIndexedRef() throws Exception {
    DefaultListableBeanFactory beanFactory=createFactory("simpleConstructorNamespaceHandlerTests.xml");
    DummyBean typeRef=beanFactory.getBean("indexed-ref",DummyBean.class);
    assertEquals("some-name",typeRef.getName());
    assertEquals(beanFactory.getBean("name-value"),typeRef.getSpouse());
  }
  @Test(expected=BeanDefinitionStoreException.class) public void ambiguousConstructor() throws Exception {
    DefaultListableBeanFactory bf=new DefaultListableBeanFactory();
    new XmlBeanDefinitionReader(bf).loadBeanDefinitions(new ClassPathResource("simpleConstructorNamespaceHandlerTestsWithErrors.xml",getClass()));
  }
  @Test public void constructorWithNameEndingInRef() throws Exception {
    DefaultListableBeanFactory beanFactory=createFactory("simpleConstructorNamespaceHandlerTests.xml");
    DummyBean derivedBean=beanFactory.getBean("beanWithRefConstructorArg",DummyBean.class);
    assertEquals(10,derivedBean.getAge());
    assertEquals("silly name",derivedBean.getName());
  }
  private DefaultListableBeanFactory createFactory(  String resourceName){
    DefaultListableBeanFactory bf=new DefaultListableBeanFactory();
    new XmlBeanDefinitionReader(bf).loadBeanDefinitions(new ClassPathResource(resourceName,getClass()));
    return bf;
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.core.serializer;
import java.io.NotSerializableException;
import java.io.Serializable;
import org.junit.Test;
import org.springframework.core.serializer.support.DeserializingConverter;
import org.springframework.core.serializer.support.SerializationFailedException;
import org.springframework.core.serializer.support.SerializingConverter;
import static org.junit.Assert.*;
/** 
 * @author Gary Russell
 * @author Mark Fisher
 * @since 3.0.5
 */
public class SerializationConverterTests {
  @Test public void serializeAndDeserializeString(){
    SerializingConverter toBytes=new SerializingConverter();
    byte[] bytes=toBytes.convert("Testing");
    DeserializingConverter fromBytes=new DeserializingConverter();
    assertEquals("Testing",fromBytes.convert(bytes));
  }
  @Test public void nonSerializableObject(){
    SerializingConverter toBytes=new SerializingConverter();
    try {
      toBytes.convert(new Object());
      fail("Expected IllegalArgumentException");
    }
 catch (    SerializationFailedException e) {
      assertNotNull(e.getCause());
      assertTrue(e.getCause() instanceof IllegalArgumentException);
    }
  }
  @Test public void nonSerializableField(){
    SerializingConverter toBytes=new SerializingConverter();
    try {
      toBytes.convert(new UnSerializable());
      fail("Expected SerializationFailureException");
    }
 catch (    SerializationFailedException e) {
      assertNotNull(e.getCause());
      assertTrue(e.getCause() instanceof NotSerializableException);
    }
  }
  @Test(expected=SerializationFailedException.class) public void deserializationFailure(){
    DeserializingConverter fromBytes=new DeserializingConverter();
    fromBytes.convert("Junk".getBytes());
  }
class UnSerializable implements Serializable {
    private static final long serialVersionUID=1L;
    @SuppressWarnings("unused") private Object object;
  }
}

 
 
 
~~~~~~~Test Classs~~~~~~~
 
package org.springframework.core.io.support;
import java.io.IOException;
import org.junit.Test;
import org.springframework.core.env.PropertySource;
import org.springframework.core.io.ByteArrayResource;
import org.springframework.core.io.ClassPathResource;
import static org.hamcrest.CoreMatchers.*;
import static org.junit.Assert.*;
/** 
 * Unit tests for  {@link ResourcePropertySource}.
 * @author Chris Beams
 * @author Sam Brannen
 * @since 3.1
 */
public class ResourcePropertySourceTests {
  private static final String PROPERTIES_PATH="org/springframework/core/io/example.properties";
  private static final String PROPERTIES_LOCATION="classpath:" + PROPERTIES_PATH;
  private static final String PROPERTIES_RESOURCE_DESCRIPTION="class path resource [" + PROPERTIES_PATH + "]";
  private static final String XML_PROPERTIES_PATH="org/springframework/core/io/example.xml";
  private static final String XML_PROPERTIES_LOCATION="classpath:" + XML_PROPERTIES_PATH;
  private static final String XML_PROPERTIES_RESOURCE_DESCRIPTION="class path resource [" + XML_PROPERTIES_PATH + "]";
  @Test public void withLocationAndGeneratedName() throws IOException {
    PropertySource<?> ps=new ResourcePropertySource(PROPERTIES_LOCATION);
    assertEquals("bar",ps.getProperty("foo"));
    assertThat(ps.getName(),is(PROPERTIES_RESOURCE_DESCRIPTION));
  }
  @Test public void xmlWithLocationAndGeneratedName() throws IOException {
    PropertySource<?> ps=new ResourcePropertySource(XML_PROPERTIES_LOCATION);
    assertEquals("bar",ps.getProperty("foo"));
    assertThat(ps.getName(),is(XML_PROPERTIES_RESOURCE_DESCRIPTION));
  }
  @Test public void withLocationAndExplicitName() throws IOException {
    PropertySource<?> ps=new ResourcePropertySource("ps1",PROPERTIES_LOCATION);
    assertEquals("bar",ps.getProperty("foo"));
    assertThat(ps.getName(),is("ps1"));
  }
  @Test public void withLocationAndExplicitNameAndExplicitClassLoader() throws IOException {
    PropertySource<?> ps=new ResourcePropertySource("ps1",PROPERTIES_LOCATION,getClass().getClassLoader());
    assertEquals("bar",ps.getProperty("foo"));
    assertThat(ps.getName(),is("ps1"));
  }
  @Test public void withLocationAndGeneratedNameAndExplicitClassLoader() throws IOException {
    PropertySource<?> ps=new ResourcePropertySource(PROPERTIES_LOCATION,getClass().getClassLoader());
    assertEquals("bar",ps.getProperty("foo"));
    assertThat(ps.getName(),is(PROPERTIES_RESOURCE_DESCRIPTION));
  }
  @Test public void withResourceAndGeneratedName() throws IOException {
    PropertySource<?> ps=new ResourcePropertySource(new ClassPathResource(PROPERTIES_PATH));
    assertEquals("bar",ps.getProperty("foo"));
    assertThat(ps.getName(),is(PROPERTIES_RESOURCE_DESCRIPTION));
  }
  @Test public void withResourceAndExplicitName() throws IOException {
    PropertySource<?> ps=new ResourcePropertySource("ps1",new ClassPathResource(PROPERTIES_PATH));
    assertEquals("bar",ps.getProperty("foo"));
    assertThat(ps.getName(),is("ps1"));
  }
  @Test public void withResourceHavingNoDescription() throws IOException {
    PropertySource<?> ps=new ResourcePropertySource(new ByteArrayResource("foo=bar".getBytes(),""));
    assertEquals("bar",ps.getProperty("foo"));
    assertEquals("Byte array resource []",ps.getName());
  }
}

 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from spring-framework-5.1.3.RELEASE~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
~~~~~~~~~~~~~~~~~~~ Random Samplings from zxing-BS-4.7.8~~~~~~~~~~~~~~~~~~~
 
 
 
 
 
