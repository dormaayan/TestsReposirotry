/** 
 * Tests for  {@link BucketingSink}. <p>This test only verifies the exactly once behaviour of the sink. Another test tests the rolling behaviour.
 */
public class BucketingSinkFaultToleranceITCase extends StreamFaultToleranceTestBase {
  static final long NUM_STRINGS=16_000;
  @ClassRule public static TemporaryFolder tempFolder=new TemporaryFolder();
  private static MiniDFSCluster hdfsCluster;
  private static org.apache.hadoop.fs.FileSystem dfs;
  private static String outPath;
  @BeforeClass public static void createHDFS() throws IOException {
    Configuration conf=new Configuration();
    File dataDir=tempFolder.newFolder();
    conf.set(MiniDFSCluster.HDFS_MINIDFS_BASEDIR,dataDir.getAbsolutePath());
    MiniDFSCluster.Builder builder=new MiniDFSCluster.Builder(conf);
    hdfsCluster=builder.build();
    dfs=hdfsCluster.getFileSystem();
    outPath="hdfs://" + NetUtils.hostAndPortToUrlString(hdfsCluster.getURI().getHost(),hdfsCluster.getNameNodePort()) + "/string-non-rolling-out";
  }
  @AfterClass public static void destroyHDFS(){
    if (hdfsCluster != null) {
      hdfsCluster.shutdown();
    }
  }
  @Override public void testProgram(  StreamExecutionEnvironment env){
    assertTrue("Broken test setup",NUM_STRINGS % 40 == 0);
    env.enableCheckpointing(20);
    env.setParallelism(12);
    env.disableOperatorChaining();
    DataStream<String> stream=env.addSource(new StringGeneratingSourceFunction(NUM_STRINGS)).startNewChain();
    DataStream<String> mapped=stream.map(new OnceFailingIdentityMapper(NUM_STRINGS));
    BucketingSink<String> sink=new BucketingSink<String>(outPath).setBucketer(new BasePathBucketer<String>()).setBatchSize(10000).setValidLengthPrefix("").setPendingPrefix("").setPendingSuffix(PENDING_SUFFIX).setInProgressSuffix(IN_PROGRESS_SUFFIX);
    mapped.addSink(sink);
  }
  @Override public void postSubmit() throws Exception {
    Pattern messageRegex=Pattern.compile("message (\\d*)");
    Set<Integer> readNumbers=new HashSet<>();
    HashSet<String> uniqMessagesRead=new HashSet<>();
    HashSet<String> messagesInCommittedFiles=new HashSet<>();
    RemoteIterator<LocatedFileStatus> files=dfs.listFiles(new Path(outPath),true);
    while (files.hasNext()) {
      LocatedFileStatus file=files.next();
      if (!file.getPath().toString().endsWith(".valid-length")) {
        int validLength=(int)file.getLen();
        if (dfs.exists(file.getPath().suffix(".valid-length"))) {
          FSDataInputStream inStream=dfs.open(file.getPath().suffix(".valid-length"));
          String validLengthString=inStream.readUTF();
          validLength=Integer.parseInt(validLengthString);
          System.out.println("VALID LENGTH: " + validLength);
        }
        FSDataInputStream inStream=dfs.open(file.getPath());
        byte[] buffer=new byte[validLength];
        inStream.readFully(0,buffer,0,validLength);
        inStream.close();
        ByteArrayInputStream bais=new ByteArrayInputStream(buffer);
        InputStreamReader inStreamReader=new InputStreamReader(bais);
        BufferedReader br=new BufferedReader(inStreamReader);
        String line=br.readLine();
        while (line != null) {
          Matcher matcher=messageRegex.matcher(line);
          if (matcher.matches()) {
            uniqMessagesRead.add(line);
            if (!file.getPath().toString().endsWith(IN_PROGRESS_SUFFIX) && !file.getPath().toString().endsWith(PENDING_SUFFIX)) {
              if (!messagesInCommittedFiles.add(line)) {
                Assert.fail("Duplicate entry in committed bucket.");
              }
            }
            int messageId=Integer.parseInt(matcher.group(1));
            readNumbers.add(messageId);
          }
 else {
            Assert.fail("Read line does not match expected pattern.");
          }
          line=br.readLine();
        }
        br.close();
        inStreamReader.close();
        bais.close();
      }
    }
    Assert.assertEquals(NUM_STRINGS,readNumbers.size());
    Assert.assertEquals(NUM_STRINGS,uniqMessagesRead.size());
  }
private static class OnceFailingIdentityMapper extends RichMapFunction<String,String> {
    private static final long serialVersionUID=1L;
    private static volatile boolean hasFailed=false;
    private final long numElements;
    private long failurePos;
    private long count;
    OnceFailingIdentityMapper(    long numElements){
      this.numElements=numElements;
    }
    @Override public void open(    org.apache.flink.configuration.Configuration parameters) throws IOException {
      long failurePosMin=(long)(0.7 * numElements / getRuntimeContext().getNumberOfParallelSubtasks());
      long failurePosMax=(long)(0.9 * numElements / getRuntimeContext().getNumberOfParallelSubtasks());
      failurePos=(new Random().nextLong() % (failurePosMax - failurePosMin)) + failurePosMin;
      count=0;
    }
    @Override public String map(    String value) throws Exception {
      count++;
      if (!hasFailed && count >= failurePos) {
        hasFailed=true;
        throw new Exception("Test Failure");
      }
      return value;
    }
  }
private static class StringGeneratingSourceFunction extends RichParallelSourceFunction<String> implements ListCheckpointed<Integer> {
    private static final long serialVersionUID=1L;
    private final long numElements;
    private int index;
    private volatile boolean isRunning=true;
    StringGeneratingSourceFunction(    long numElements){
      this.numElements=numElements;
    }
    @Override public void run(    SourceContext<String> ctx) throws Exception {
      final Object lockingObject=ctx.getCheckpointLock();
      final int step=getRuntimeContext().getNumberOfParallelSubtasks();
      if (index == 0) {
        index=getRuntimeContext().getIndexOfThisSubtask();
      }
      while (isRunning && index < numElements) {
        Thread.sleep(1);
synchronized (lockingObject) {
          ctx.collect("message " + index);
          index+=step;
        }
      }
    }
    @Override public void cancel(){
      isRunning=false;
    }
    private static String randomString(    StringBuilder bld,    Random rnd){
      final int len=rnd.nextInt(10) + 5;
      for (int i=0; i < len; i++) {
        char next=(char)(rnd.nextInt(20000) + 33);
        bld.append(next);
      }
      return bld.toString();
    }
    @Override public List<Integer> snapshotState(    long checkpointId,    long timestamp) throws Exception {
      return Collections.singletonList(index);
    }
    @Override public void restoreState(    List<Integer> state) throws Exception {
      if (state.isEmpty() || state.size() > 1) {
        throw new RuntimeException("Test failed due to unexpected recovered state size " + state.size());
      }
      this.index=state.get(0);
    }
  }
}
