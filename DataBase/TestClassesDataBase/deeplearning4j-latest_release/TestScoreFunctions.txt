@Slf4j public class TestScoreFunctions {
  @Test public void testROCScoreFunctions() throws Exception {
    for (    boolean auc : new boolean[]{true,false}) {
      for (      ROCScoreFunction.ROCType rocType : ROCScoreFunction.ROCType.values()) {
        String msg=(auc ? "AUC" : "AUPRC") + " - " + rocType;
        log.info("Starting: " + msg);
        ParameterSpace<Double> lr=new ContinuousParameterSpace(1e-5,1e-3);
        int nOut=(rocType == ROCScoreFunction.ROCType.ROC ? 2 : 10);
        LossFunctions.LossFunction lf=(rocType == ROCScoreFunction.ROCType.BINARY ? LossFunctions.LossFunction.XENT : LossFunctions.LossFunction.MCXENT);
        Activation a=(rocType == ROCScoreFunction.ROCType.BINARY ? Activation.SIGMOID : Activation.SOFTMAX);
        MultiLayerSpace mls=new MultiLayerSpace.Builder().trainingWorkspaceMode(WorkspaceMode.NONE).inferenceWorkspaceMode(WorkspaceMode.NONE).updater(new AdamSpace(lr)).weightInit(WeightInit.XAVIER).layer(new OutputLayerSpace.Builder().nIn(784).nOut(nOut).activation(a).lossFunction(lf).build()).build();
        CandidateGenerator cg=new RandomSearchGenerator(mls);
        ResultSaver rs=new InMemoryResultSaver();
        ScoreFunction sf=new ROCScoreFunction(rocType,(auc ? ROCScoreFunction.Metric.AUC : ROCScoreFunction.Metric.AUPRC));
        OptimizationConfiguration oc=new OptimizationConfiguration.Builder().candidateGenerator(cg).dataProvider(new DP(rocType)).modelSaver(rs).scoreFunction(sf).terminationConditions(new MaxCandidatesCondition(3)).rngSeed(12345).build();
        IOptimizationRunner runner=new LocalOptimizationRunner(oc,new MultiLayerNetworkTaskCreator());
        runner.execute();
        List<ResultReference> list=runner.getResults();
        for (        ResultReference rr : list) {
          DataSetIterator testIter=new MnistDataSetIterator(32,2000,false,false,true,12345);
          testIter.setPreProcessor(new PreProc(rocType));
          OptimizationResult or=rr.getResult();
          MultiLayerNetwork net=(MultiLayerNetwork)or.getResultReference().getResultModel();
          double expScore;
switch (rocType) {
case ROC:
            if (auc) {
              expScore=net.doEvaluation(testIter,new ROC())[0].calculateAUC();
            }
 else {
              expScore=net.doEvaluation(testIter,new ROC())[0].calculateAUCPR();
            }
          break;
case BINARY:
        if (auc) {
          expScore=net.doEvaluation(testIter,new ROCBinary())[0].calculateAverageAuc();
        }
 else {
          expScore=net.doEvaluation(testIter,new ROCBinary())[0].calculateAverageAUCPR();
        }
      break;
case MULTICLASS:
    if (auc) {
      expScore=net.doEvaluation(testIter,new ROCMultiClass())[0].calculateAverageAUC();
    }
 else {
      expScore=net.doEvaluation(testIter,new ROCMultiClass())[0].calculateAverageAUCPR();
    }
  break;
default :
throw new RuntimeException();
}
DataSetIterator iter=new MnistDataSetIterator(32,8000,false,true,true,12345);
iter.setPreProcessor(new PreProc(rocType));
assertEquals(msg,expScore,or.getScore(),1e-5);
}
}
}
}
@AllArgsConstructor public static class DP implements DataProvider {
protected ROCScoreFunction.ROCType rocType;
@Override public Object trainData(Map<String,Object> dataParameters){
try {
DataSetIterator iter=new MnistDataSetIterator(32,8000,false,true,true,12345);
iter.setPreProcessor(new PreProc(rocType));
return iter;
}
 catch (IOException e) {
throw new RuntimeException(e);
}
}
@Override public Object testData(Map<String,Object> dataParameters){
try {
DataSetIterator iter=new MnistDataSetIterator(32,2000,false,false,true,12345);
iter.setPreProcessor(new PreProc(rocType));
return iter;
}
 catch (IOException e) {
throw new RuntimeException(e);
}
}
@Override public Class<?> getDataType(){
return DataSetIterator.class;
}
}
@AllArgsConstructor public static class PreProc implements DataSetPreProcessor {
protected ROCScoreFunction.ROCType rocType;
@Override public void preProcess(DataSet toPreProcess){
switch (rocType) {
case ROC:
long mb=toPreProcess.getLabels().size(0);
INDArray argMax=Nd4j.argMax(toPreProcess.getLabels(),1);
INDArray newLabel=Nd4j.create(mb,2);
for (int i=0; i < mb; i++) {
int idx=(int)argMax.getDouble(i,0);
newLabel.putScalar(i,(idx < 5 ? 0 : 1),1.0);
}
toPreProcess.setLabels(newLabel);
break;
case BINARY:
case MULTICLASS:
break;
default :
throw new RuntimeException();
}
}
}
}
