/** 
 * Mocking test of partitioned committer. 
 */
public class TestStagingPartitionedJobCommit extends StagingTestBase.JobCommitterTest<PartitionedStagingCommitter> {
  @Override public void setupJob() throws Exception {
    super.setupJob();
    getWrapperFS().setLogEvents(MockS3AFileSystem.LOG_NAME);
  }
  @Override PartitionedStagingCommitter newJobCommitter() throws IOException {
    return new PartitionedStagingCommitterForTesting(createTaskAttemptForJob());
  }
  /** 
 * Subclass of the Partitioned Staging committer used in the test cases.
 */
private static final class PartitionedStagingCommitterForTesting extends PartitionedCommitterForTesting {
    private boolean aborted=false;
    private PartitionedStagingCommitterForTesting(    TaskAttemptContext context) throws IOException {
      super(OUTPUT_PATH,context);
    }
    @Override protected List<SinglePendingCommit> listPendingUploadsToCommit(    JobContext context) throws IOException {
      List<SinglePendingCommit> pending=Lists.newArrayList();
      for (      String dateint : Arrays.asList("20161115","20161116")) {
        for (        String hour : Arrays.asList("13","14")) {
          String key=OUTPUT_PREFIX + "/dateint=" + dateint+ "/hour="+ hour+ "/"+ UUID.randomUUID().toString()+ ".parquet";
          SinglePendingCommit commit=new SinglePendingCommit();
          commit.setBucket(BUCKET);
          commit.setDestinationKey(key);
          commit.setUri("s3a://" + BUCKET + "/"+ key);
          commit.setUploadId(UUID.randomUUID().toString());
          commit.setEtags(new ArrayList<>());
          pending.add(commit);
        }
      }
      return pending;
    }
    @Override protected void abortJobInternal(    JobContext context,    boolean suppressExceptions) throws IOException {
      this.aborted=true;
      super.abortJobInternal(context,suppressExceptions);
    }
  }
  @Test public void testDefaultFailAndAppend() throws Exception {
    FileSystem mockS3=getMockS3A();
    for (    String mode : Arrays.asList(null,CONFLICT_MODE_FAIL,CONFLICT_MODE_APPEND)) {
      if (mode != null) {
        getJob().getConfiguration().set(FS_S3A_COMMITTER_STAGING_CONFLICT_MODE,mode);
      }
 else {
        getJob().getConfiguration().unset(FS_S3A_COMMITTER_STAGING_CONFLICT_MODE);
      }
      PartitionedStagingCommitter committer=newJobCommitter();
      committer.commitJob(getJob());
      reset(mockS3);
      pathsExist(mockS3,"dateint=20161116","dateint=20161116/hour=10");
      committer.commitJob(getJob());
      verifyCompletion(mockS3);
      reset(mockS3);
      pathsExist(mockS3,"dateint=20161115/hour=14");
      committer.commitJob(getJob());
      verifyCompletion(mockS3);
    }
  }
  @Test public void testBadConflictMode() throws Throwable {
    getJob().getConfiguration().set(FS_S3A_COMMITTER_STAGING_CONFLICT_MODE,"merge");
    intercept(IllegalArgumentException.class,"MERGE","committer conflict",this::newJobCommitter);
  }
  @Test public void testReplace() throws Exception {
    S3AFileSystem mockS3=getMockS3A();
    getJob().getConfiguration().set(FS_S3A_COMMITTER_STAGING_CONFLICT_MODE,CONFLICT_MODE_REPLACE);
    PartitionedStagingCommitter committer=newJobCommitter();
    committer.commitJob(getJob());
    verifyReplaceCommitActions(mockS3);
    verifyCompletion(mockS3);
    reset(mockS3);
    pathsExist(mockS3,"dateint=20161115","dateint=20161115/hour=12");
    committer.commitJob(getJob());
    verifyReplaceCommitActions(mockS3);
    verifyCompletion(mockS3);
    reset(mockS3);
    pathsExist(mockS3,"dateint=20161115/hour=12","dateint=20161115/hour=13");
    canDelete(mockS3,"dateint=20161115/hour=13");
    committer.commitJob(getJob());
    verifyDeleted(mockS3,"dateint=20161115/hour=13");
    verifyReplaceCommitActions(mockS3);
    verifyCompletion(mockS3);
    reset(mockS3);
    pathsExist(mockS3,"dateint=20161116/hour=13","dateint=20161116/hour=14");
    canDelete(mockS3,"dateint=20161116/hour=13","dateint=20161116/hour=14");
    committer.commitJob(getJob());
    verifyReplaceCommitActions(mockS3);
    verifyDeleted(mockS3,"dateint=20161116/hour=13");
    verifyDeleted(mockS3,"dateint=20161116/hour=14");
    verifyCompletion(mockS3);
  }
  /** 
 * Verify the actions which replace does, essentially: delete the parent partitions.
 * @param mockS3 s3 mock
 */
  protected void verifyReplaceCommitActions(  FileSystem mockS3) throws IOException {
    verifyDeleted(mockS3,"dateint=20161115/hour=13");
    verifyDeleted(mockS3,"dateint=20161115/hour=14");
    verifyDeleted(mockS3,"dateint=20161116/hour=13");
    verifyDeleted(mockS3,"dateint=20161116/hour=14");
  }
  @Test public void testReplaceWithDeleteFailure() throws Exception {
    FileSystem mockS3=getMockS3A();
    getJob().getConfiguration().set(FS_S3A_COMMITTER_STAGING_CONFLICT_MODE,CONFLICT_MODE_REPLACE);
    final PartitionedStagingCommitter committer=newJobCommitter();
    pathsExist(mockS3,"dateint=20161116/hour=14");
    when(mockS3.delete(new Path(OUTPUT_PATH,"dateint=20161116/hour=14"),true)).thenThrow(new PathCommitException("fake","Fake IOException for delete"));
    intercept(PathCommitException.class,"Fake IOException for delete","Should throw the fake IOException",() -> committer.commitJob(getJob()));
    verifyReplaceCommitActions(mockS3);
    verifyDeleted(mockS3,"dateint=20161116/hour=14");
    assertTrue("Should have aborted",((PartitionedStagingCommitterForTesting)committer).aborted);
    verifyCompletion(mockS3);
  }
}
