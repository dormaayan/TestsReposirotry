/** 
 * Tests for ensuring the namenode retry cache works correctly for non-idempotent requests. Retry cache works based on tracking previously received request based on the ClientId and CallId received in RPC requests and storing the response. The response is replayed on retry when the same request is received again. The test works by manipulating the Rpc  {@link Server} current RPC call. Fortesting retried requests, an Rpc callId is generated only once using {@link #newCall()} and reused for many method calls. For testing non-retriedrequest, a new callId is generated using  {@link #newCall()}.
 */
public class TestNamenodeRetryCache {
  private static final byte[] CLIENT_ID=ClientId.getClientId();
  private static MiniDFSCluster cluster;
  private static ErasureCodingPolicy defaultEcPolicy=SystemErasureCodingPolicies.getByID(SystemErasureCodingPolicies.RS_6_3_POLICY_ID);
  private static int numDataNodes=defaultEcPolicy.getNumDataUnits() + defaultEcPolicy.getNumParityUnits() + 1;
  private static NamenodeProtocols nnRpc;
  private static final FsPermission perm=FsPermission.getDefault();
  private static DistributedFileSystem filesystem;
  private static int callId=100;
  private static Configuration conf;
  private static final int BlockSize=512;
  /** 
 * Start a cluster 
 */
  @Before public void setup() throws Exception {
    conf=new HdfsConfiguration();
    conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,BlockSize);
    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ENABLE_RETRY_CACHE_KEY,true);
    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ACLS_ENABLED_KEY,true);
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDataNodes).build();
    cluster.waitActive();
    nnRpc=cluster.getNameNode().getRpcServer();
    filesystem=cluster.getFileSystem();
  }
  /** 
 * Cleanup after the test 
 * @throws IOException 
 * @throws UnresolvedLinkException 
 * @throws SafeModeException 
 * @throws AccessControlException 
 */
  @After public void cleanup() throws IOException {
    if (cluster != null) {
      cluster.shutdown();
      cluster=null;
    }
  }
static class DummyCall extends Server.Call {
    private UserGroupInformation ugi;
    DummyCall(    int callId,    byte[] clientId){
      super(callId,1,null,null,RpcKind.RPC_PROTOCOL_BUFFER,clientId);
      try {
        ugi=UserGroupInformation.getCurrentUser();
      }
 catch (      IOException ioe) {
      }
    }
    @Override public UserGroupInformation getRemoteUser(){
      return ugi;
    }
  }
  /** 
 * Set the current Server RPC call 
 */
  public static void newCall(){
    Server.Call call=new DummyCall(++callId,CLIENT_ID);
    Server.getCurCall().set(call);
  }
  public static void resetCall(){
    Server.Call call=new DummyCall(RpcConstants.INVALID_CALL_ID,RpcConstants.DUMMY_CLIENT_ID);
    Server.getCurCall().set(call);
  }
  private void concatSetup(  String file1,  String file2) throws Exception {
    DFSTestUtil.createFile(filesystem,new Path(file1),BlockSize,(short)1,0L);
    DFSTestUtil.createFile(filesystem,new Path(file2),BlockSize,(short)1,0L);
  }
  /** 
 * Tests for concat call
 */
  @Test public void testConcat() throws Exception {
    resetCall();
    String file1="/testNamenodeRetryCache/testConcat/file1";
    String file2="/testNamenodeRetryCache/testConcat/file2";
    concatSetup(file1,file2);
    newCall();
    nnRpc.concat(file1,new String[]{file2});
    nnRpc.concat(file1,new String[]{file2});
    nnRpc.concat(file1,new String[]{file2});
    newCall();
    try {
      nnRpc.concat(file1,new String[]{file2});
      Assert.fail("testConcat - expected exception is not thrown");
    }
 catch (    IOException e) {
    }
  }
  /** 
 * Tests for delete call
 */
  @Test public void testDelete() throws Exception {
    String dir="/testNamenodeRetryCache/testDelete";
    newCall();
    nnRpc.mkdirs(dir,perm,true);
    newCall();
    Assert.assertTrue(nnRpc.delete(dir,false));
    Assert.assertTrue(nnRpc.delete(dir,false));
    Assert.assertTrue(nnRpc.delete(dir,false));
    newCall();
    Assert.assertFalse(nnRpc.delete(dir,false));
  }
  /** 
 * Test for createSymlink
 */
  @Test public void testCreateSymlink() throws Exception {
    String target="/testNamenodeRetryCache/testCreateSymlink/target";
    newCall();
    nnRpc.createSymlink(target,"/a/b",perm,true);
    nnRpc.createSymlink(target,"/a/b",perm,true);
    nnRpc.createSymlink(target,"/a/b",perm,true);
    newCall();
    try {
      nnRpc.createSymlink(target,"/a/b",perm,true);
      Assert.fail("testCreateSymlink - expected exception is not thrown");
    }
 catch (    IOException e) {
    }
  }
  /** 
 * Test for create file
 */
  @Test public void testCreate() throws Exception {
    String src="/testNamenodeRetryCache/testCreate/file";
    newCall();
    HdfsFileStatus status=nnRpc.create(src,perm,"holder",new EnumSetWritable<CreateFlag>(EnumSet.of(CreateFlag.CREATE)),true,(short)1,BlockSize,null,null);
    Assert.assertEquals(status,nnRpc.create(src,perm,"holder",new EnumSetWritable<CreateFlag>(EnumSet.of(CreateFlag.CREATE)),true,(short)1,BlockSize,null,null));
    Assert.assertEquals(status,nnRpc.create(src,perm,"holder",new EnumSetWritable<CreateFlag>(EnumSet.of(CreateFlag.CREATE)),true,(short)1,BlockSize,null,null));
    newCall();
    try {
      nnRpc.create(src,perm,"holder",new EnumSetWritable<CreateFlag>(EnumSet.of(CreateFlag.CREATE)),true,(short)1,BlockSize,null,null);
      Assert.fail("testCreate - expected exception is not thrown");
    }
 catch (    IOException e) {
    }
  }
  /** 
 * Test for rename1
 */
  @Test public void testAppend() throws Exception {
    String src="/testNamenodeRetryCache/testAppend/src";
    resetCall();
    DFSTestUtil.createFile(filesystem,new Path(src),128,(short)1,0L);
    newCall();
    LastBlockWithStatus b=nnRpc.append(src,"holder",new EnumSetWritable<>(EnumSet.of(CreateFlag.APPEND)));
    Assert.assertEquals(b,nnRpc.append(src,"holder",new EnumSetWritable<>(EnumSet.of(CreateFlag.APPEND))));
    Assert.assertEquals(b,nnRpc.append(src,"holder",new EnumSetWritable<>(EnumSet.of(CreateFlag.APPEND))));
    newCall();
    try {
      nnRpc.append(src,"holder",new EnumSetWritable<>(EnumSet.of(CreateFlag.APPEND)));
      Assert.fail("testAppend - expected exception is not thrown");
    }
 catch (    Exception e) {
    }
  }
  /** 
 * Test for rename1
 */
  @SuppressWarnings("deprecation") @Test public void testRename1() throws Exception {
    String src="/testNamenodeRetryCache/testRename1/src";
    String target="/testNamenodeRetryCache/testRename1/target";
    resetCall();
    nnRpc.mkdirs(src,perm,true);
    newCall();
    Assert.assertTrue(nnRpc.rename(src,target));
    Assert.assertTrue(nnRpc.rename(src,target));
    Assert.assertTrue(nnRpc.rename(src,target));
    newCall();
    Assert.assertFalse(nnRpc.rename(src,target));
  }
  /** 
 * Test for rename2
 */
  @Test public void testRename2() throws Exception {
    String src="/testNamenodeRetryCache/testRename2/src";
    String target="/testNamenodeRetryCache/testRename2/target";
    resetCall();
    nnRpc.mkdirs(src,perm,true);
    newCall();
    nnRpc.rename2(src,target,Rename.NONE);
    nnRpc.rename2(src,target,Rename.NONE);
    nnRpc.rename2(src,target,Rename.NONE);
    newCall();
    try {
      nnRpc.rename2(src,target,Rename.NONE);
      Assert.fail("testRename 2 expected exception is not thrown");
    }
 catch (    IOException e) {
    }
  }
  /** 
 * Make sure a retry call does not hang because of the exception thrown in the first call.
 */
  @Test(timeout=60000) public void testUpdatePipelineWithFailOver() throws Exception {
    cluster.shutdown();
    nnRpc=null;
    filesystem=null;
    cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(1).build();
    cluster.waitActive();
    NamenodeProtocols ns0=cluster.getNameNodeRpc(0);
    ExtendedBlock oldBlock=new ExtendedBlock();
    ExtendedBlock newBlock=new ExtendedBlock();
    DatanodeID[] newNodes=new DatanodeID[2];
    String[] newStorages=new String[2];
    newCall();
    try {
      ns0.updatePipeline("testClient",oldBlock,newBlock,newNodes,newStorages);
      fail("Expect StandbyException from the updatePipeline call");
    }
 catch (    StandbyException e) {
      GenericTestUtils.assertExceptionContains(HAServiceState.STANDBY.toString(),e);
    }
    cluster.transitionToActive(0);
    try {
      ns0.updatePipeline("testClient",oldBlock,newBlock,newNodes,newStorages);
    }
 catch (    IOException e) {
    }
  }
  /** 
 * Test for crateSnapshot
 */
  @Test public void testSnapshotMethods() throws Exception {
    String dir="/testNamenodeRetryCache/testCreateSnapshot/src";
    resetCall();
    nnRpc.mkdirs(dir,perm,true);
    nnRpc.allowSnapshot(dir);
    newCall();
    String name=nnRpc.createSnapshot(dir,"snap1");
    Assert.assertEquals(name,nnRpc.createSnapshot(dir,"snap1"));
    Assert.assertEquals(name,nnRpc.createSnapshot(dir,"snap1"));
    Assert.assertEquals(name,nnRpc.createSnapshot(dir,"snap1"));
    newCall();
    try {
      nnRpc.createSnapshot(dir,"snap1");
      Assert.fail("testSnapshotMethods expected exception is not thrown");
    }
 catch (    IOException e) {
    }
    newCall();
    nnRpc.renameSnapshot(dir,"snap1","snap2");
    nnRpc.renameSnapshot(dir,"snap1","snap2");
    nnRpc.renameSnapshot(dir,"snap1","snap2");
    newCall();
    try {
      nnRpc.renameSnapshot(dir,"snap1","snap2");
      Assert.fail("testSnapshotMethods expected exception is not thrown");
    }
 catch (    IOException e) {
    }
    newCall();
    nnRpc.deleteSnapshot(dir,"snap2");
    nnRpc.deleteSnapshot(dir,"snap2");
    nnRpc.deleteSnapshot(dir,"snap2");
    newCall();
    try {
      nnRpc.deleteSnapshot(dir,"snap2");
      Assert.fail("testSnapshotMethods expected exception is not thrown");
    }
 catch (    IOException e) {
    }
  }
  @Test public void testRetryCacheConfig(){
    Configuration conf=new HdfsConfiguration();
    Assert.assertNotNull(FSNamesystem.initRetryCache(conf));
    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_ENABLE_RETRY_CACHE_KEY,false);
    Assert.assertNull(FSNamesystem.initRetryCache(conf));
  }
  /** 
 * After run a set of operations, restart NN and check if the retry cache has been rebuilt based on the editlog.
 */
  @Test public void testRetryCacheRebuild() throws Exception {
    DFSTestUtil.runOperations(cluster,filesystem,conf,BlockSize,0);
    FSNamesystem namesystem=cluster.getNamesystem();
    LightWeightCache<CacheEntry,CacheEntry> cacheSet=(LightWeightCache<CacheEntry,CacheEntry>)namesystem.getRetryCache().getCacheSet();
    assertEquals("Retry cache size is wrong",39,cacheSet.size());
    Map<CacheEntry,CacheEntry> oldEntries=new HashMap<CacheEntry,CacheEntry>();
    Iterator<CacheEntry> iter=cacheSet.iterator();
    while (iter.hasNext()) {
      CacheEntry entry=iter.next();
      oldEntries.put(entry,entry);
    }
    cluster.restartNameNode();
    cluster.waitActive();
    namesystem=cluster.getNamesystem();
    assertTrue(namesystem.hasRetryCache());
    cacheSet=(LightWeightCache<CacheEntry,CacheEntry>)namesystem.getRetryCache().getCacheSet();
    assertEquals("Retry cache size is wrong",39,cacheSet.size());
    iter=cacheSet.iterator();
    while (iter.hasNext()) {
      CacheEntry entry=iter.next();
      assertTrue(oldEntries.containsKey(entry));
    }
  }
}
