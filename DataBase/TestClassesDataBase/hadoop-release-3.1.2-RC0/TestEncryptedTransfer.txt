@RunWith(Parameterized.class) public class TestEncryptedTransfer {
{
    LogManager.getLogger(SaslDataTransferServer.class).setLevel(Level.DEBUG);
    LogManager.getLogger(DataTransferSaslUtil.class).setLevel(Level.DEBUG);
  }
  @Rule public Timeout timeout=new Timeout(300000);
  @Parameters public static Collection<Object[]> data(){
    Collection<Object[]> params=new ArrayList<Object[]>();
    params.add(new Object[]{null});
    params.add(new Object[]{"org.apache.hadoop.hdfs.TestEncryptedTransfer$TestTrustedChannelResolver"});
    return params;
  }
  private static final Log LOG=LogFactory.getLog(TestEncryptedTransfer.class);
  private static final String PLAIN_TEXT="this is very secret plain text";
  private static final Path TEST_PATH=new Path("/non-encrypted-file");
  private MiniDFSCluster cluster=null;
  private Configuration conf=null;
  private FileSystem fs=null;
  private void setEncryptionConfigKeys(){
    conf.setBoolean(DFSConfigKeys.DFS_ENCRYPT_DATA_TRANSFER_KEY,true);
    conf.setBoolean(DFSConfigKeys.DFS_BLOCK_ACCESS_TOKEN_ENABLE_KEY,true);
    if (resolverClazz != null) {
      conf.set(HdfsClientConfigKeys.DFS_TRUSTEDCHANNEL_RESOLVER_CLASS,resolverClazz);
    }
  }
  private static FileSystem getFileSystem(  Configuration conf) throws IOException {
    Configuration localConf=new Configuration(conf);
    localConf.setBoolean(DFSConfigKeys.DFS_ENCRYPT_DATA_TRANSFER_KEY,false);
    localConf.unset(DFSConfigKeys.DFS_DATA_ENCRYPTION_ALGORITHM_KEY);
    return FileSystem.get(localConf);
  }
  String resolverClazz;
  public TestEncryptedTransfer(  String resolverClazz){
    this.resolverClazz=resolverClazz;
  }
  @Before public void setup() throws IOException {
    conf=new Configuration();
  }
  @After public void teardown() throws IOException {
    if (fs != null) {
      fs.close();
    }
    if (cluster != null) {
      cluster.shutdown();
    }
  }
  private FileChecksum writeUnencryptedAndThenRestartEncryptedCluster() throws IOException {
    cluster=new MiniDFSCluster.Builder(conf).build();
    fs=getFileSystem(conf);
    writeTestDataToFile(fs);
    assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
    FileChecksum checksum=fs.getFileChecksum(TEST_PATH);
    fs.close();
    cluster.shutdown();
    setEncryptionConfigKeys();
    cluster=new MiniDFSCluster.Builder(conf).manageDataDfsDirs(false).manageNameDfsDirs(false).format(false).startupOption(StartupOption.REGULAR).build();
    fs=getFileSystem(conf);
    return checksum;
  }
  private void testEncryptedRead(  String algorithm,  String cipherSuite,  boolean matchLog,  boolean readAfterRestart) throws IOException {
    conf.set(DFSConfigKeys.DFS_DATA_ENCRYPTION_ALGORITHM_KEY,algorithm);
    conf.set(HdfsClientConfigKeys.DFS_ENCRYPT_DATA_TRANSFER_CIPHER_SUITES_KEY,cipherSuite);
    FileChecksum checksum=writeUnencryptedAndThenRestartEncryptedCluster();
    LogCapturer logs=GenericTestUtils.LogCapturer.captureLogs(LogFactory.getLog(SaslDataTransferServer.class));
    LogCapturer logs1=GenericTestUtils.LogCapturer.captureLogs(LogFactory.getLog(DataTransferSaslUtil.class));
    try {
      assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
      assertEquals(checksum,fs.getFileChecksum(TEST_PATH));
    }
  finally {
      logs.stopCapturing();
      logs1.stopCapturing();
    }
    if (resolverClazz == null) {
      if (matchLog) {
        GenericTestUtils.assertMatches(logs.getOutput(),"Server using cipher suite");
        GenericTestUtils.assertMatches(logs1.getOutput(),"Creating IOStreamPair of CryptoInputStream and CryptoOutputStream.");
      }
 else {
        GenericTestUtils.assertDoesNotMatch(logs.getOutput(),"Server using cipher suite");
        GenericTestUtils.assertDoesNotMatch(logs1.getOutput(),"Creating IOStreamPair of CryptoInputStream and CryptoOutputStream.");
      }
    }
    if (readAfterRestart) {
      cluster.restartNameNode();
      fs=getFileSystem(conf);
      assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
      assertEquals(checksum,fs.getFileChecksum(TEST_PATH));
    }
  }
  @Test public void testEncryptedReadDefaultAlgorithmCipherSuite() throws IOException {
    testEncryptedRead("","",false,false);
  }
  @Test public void testEncryptedReadWithRC4() throws IOException {
    testEncryptedRead("rc4","",false,false);
  }
  @Test public void testEncryptedReadWithAES() throws IOException {
    testEncryptedRead("","AES/CTR/NoPadding",true,false);
  }
  @Test public void testEncryptedReadAfterNameNodeRestart() throws IOException {
    testEncryptedRead("","",false,true);
  }
  @Test public void testClientThatDoesNotSupportEncryption() throws IOException {
    conf.setInt(HdfsClientConfigKeys.Retry.WINDOW_BASE_KEY,10);
    writeUnencryptedAndThenRestartEncryptedCluster();
    DFSClient client=DFSClientAdapter.getDFSClient((DistributedFileSystem)fs);
    DFSClient spyClient=Mockito.spy(client);
    Mockito.doReturn(false).when(spyClient).shouldEncryptData();
    DFSClientAdapter.setDFSClient((DistributedFileSystem)fs,spyClient);
    LogCapturer logs=GenericTestUtils.LogCapturer.captureLogs(LogFactory.getLog(DataNode.class));
    try {
      assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
      if (resolverClazz != null && !resolverClazz.endsWith("TestTrustedChannelResolver")) {
        fail("Should not have been able to read without encryption enabled.");
      }
    }
 catch (    IOException ioe) {
      GenericTestUtils.assertExceptionContains("Could not obtain block:",ioe);
    }
 finally {
      logs.stopCapturing();
    }
    if (resolverClazz == null) {
      GenericTestUtils.assertMatches(logs.getOutput(),"Failed to read expected encryption handshake from client at");
    }
  }
  @Test public void testLongLivedReadClientAfterRestart() throws IOException {
    FileChecksum checksum=writeUnencryptedAndThenRestartEncryptedCluster();
    assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
    assertEquals(checksum,fs.getFileChecksum(TEST_PATH));
    cluster.restartNameNode();
    assertTrue(cluster.restartDataNode(0));
    assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
    assertEquals(checksum,fs.getFileChecksum(TEST_PATH));
  }
  @Test public void testLongLivedWriteClientAfterRestart() throws IOException {
    setEncryptionConfigKeys();
    cluster=new MiniDFSCluster.Builder(conf).build();
    fs=getFileSystem(conf);
    writeTestDataToFile(fs);
    assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
    cluster.restartNameNode();
    assertTrue(cluster.restartDataNodes());
    cluster.waitActive();
    writeTestDataToFile(fs);
    assertEquals(PLAIN_TEXT + PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
  }
  @Test public void testLongLivedClient() throws IOException, InterruptedException {
    FileChecksum checksum=writeUnencryptedAndThenRestartEncryptedCluster();
    BlockTokenSecretManager btsm=cluster.getNamesystem().getBlockManager().getBlockTokenSecretManager();
    btsm.setKeyUpdateIntervalForTesting(2 * 1000);
    btsm.setTokenLifetime(2 * 1000);
    btsm.clearAllKeysForTesting();
    assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
    assertEquals(checksum,fs.getFileChecksum(TEST_PATH));
    LOG.info("Sleeping so that encryption keys expire...");
    Thread.sleep(15 * 1000);
    LOG.info("Done sleeping.");
    assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
    assertEquals(checksum,fs.getFileChecksum(TEST_PATH));
  }
  @Test public void testFileChecksumWithInvalidEncryptionKey() throws IOException, InterruptedException, TimeoutException {
    if (resolverClazz != null) {
      return;
    }
    setEncryptionConfigKeys();
    cluster=new MiniDFSCluster.Builder(conf).build();
    fs=getFileSystem(conf);
    DFSClient client=DFSClientAdapter.getDFSClient((DistributedFileSystem)fs);
    DFSClient spyClient=Mockito.spy(client);
    DFSClientAdapter.setDFSClient((DistributedFileSystem)fs,spyClient);
    writeTestDataToFile(fs);
    FileChecksum checksum=fs.getFileChecksum(TEST_PATH);
    BlockTokenSecretManager btsm=cluster.getNamesystem().getBlockManager().getBlockTokenSecretManager();
    btsm.setKeyUpdateIntervalForTesting(2 * 1000);
    btsm.setTokenLifetime(2 * 1000);
    btsm.clearAllKeysForTesting();
    LOG.info("Wait until encryption keys become invalid...");
    DataEncryptionKey encryptionKey=spyClient.getEncryptionKey();
    List<DataNode> dataNodes=cluster.getDataNodes();
    for (    DataNode dn : dataNodes) {
      GenericTestUtils.waitFor(new Supplier<Boolean>(){
        @Override public Boolean get(){
          return !dn.getBlockPoolTokenSecretManager().get(encryptionKey.blockPoolId).hasKey(encryptionKey.keyId);
        }
      }
,100,30 * 1000);
    }
    LOG.info("The encryption key is invalid on all nodes now.");
    fs.getFileChecksum(TEST_PATH);
    Assert.assertTrue(client.getEncryptionKey() == null);
    Mockito.verify(spyClient,times(1)).clearDataEncryptionKey();
    FileChecksum verifyChecksum=fs.getFileChecksum(TEST_PATH);
    Assert.assertEquals(checksum,verifyChecksum);
  }
  @Test public void testLongLivedClientPipelineRecovery() throws IOException, InterruptedException, TimeoutException {
    if (resolverClazz != null) {
      return;
    }
    int numDataNodes=4;
    conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_REDUNDANCY_CONSIDERLOAD_KEY,false);
    setEncryptionConfigKeys();
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDataNodes).build();
    fs=getFileSystem(conf);
    DFSClient client=DFSClientAdapter.getDFSClient((DistributedFileSystem)fs);
    DFSClient spyClient=Mockito.spy(client);
    DFSClientAdapter.setDFSClient((DistributedFileSystem)fs,spyClient);
    writeTestDataToFile(fs);
    BlockTokenSecretManager btsm=cluster.getNamesystem().getBlockManager().getBlockTokenSecretManager();
    btsm.setKeyUpdateIntervalForTesting(2 * 1000);
    btsm.setTokenLifetime(2 * 1000);
    btsm.clearAllKeysForTesting();
    LOG.info("Wait until encryption keys become invalid...");
    DataEncryptionKey encryptionKey=spyClient.getEncryptionKey();
    List<DataNode> dataNodes=cluster.getDataNodes();
    for (    DataNode dn : dataNodes) {
      GenericTestUtils.waitFor(new Supplier<Boolean>(){
        @Override public Boolean get(){
          return !dn.getBlockPoolTokenSecretManager().get(encryptionKey.blockPoolId).hasKey(encryptionKey.keyId);
        }
      }
,100,30 * 1000);
    }
    LOG.info("The encryption key is invalid on all nodes now.");
    try (FSDataOutputStream out=fs.append(TEST_PATH)){
      DFSOutputStream dfstream=(DFSOutputStream)out.getWrappedStream();
      DatanodeInfo[] targets=dfstream.getPipeline();
      cluster.stopDataNode(targets[0].getXferAddr());
      out.write(PLAIN_TEXT.getBytes());
      out.hflush();
      assertFalse("The first datanode in the pipeline was not replaced.",Arrays.asList(dfstream.getPipeline()).contains(targets[0]));
    }
     Mockito.verify(spyClient,times(1)).clearDataEncryptionKey();
  }
  @Test public void testEncryptedWriteWithOneDn() throws IOException {
    testEncryptedWrite(1);
  }
  @Test public void testEncryptedWriteWithTwoDns() throws IOException {
    testEncryptedWrite(2);
  }
  @Test public void testEncryptedWriteWithMultipleDns() throws IOException {
    testEncryptedWrite(10);
  }
  private void testEncryptedWrite(  int numDns) throws IOException {
    setEncryptionConfigKeys();
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDns).build();
    fs=getFileSystem(conf);
    LogCapturer logs=GenericTestUtils.LogCapturer.captureLogs(LogFactory.getLog(SaslDataTransferServer.class));
    LogCapturer logs1=GenericTestUtils.LogCapturer.captureLogs(LogFactory.getLog(DataTransferSaslUtil.class));
    try {
      writeTestDataToFile(fs);
    }
  finally {
      logs.stopCapturing();
      logs1.stopCapturing();
    }
    assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
    if (resolverClazz == null) {
      GenericTestUtils.assertDoesNotMatch(logs.getOutput(),"Server using cipher suite");
      GenericTestUtils.assertDoesNotMatch(logs1.getOutput(),"Creating IOStreamPair of CryptoInputStream and CryptoOutputStream.");
    }
  }
  @Test public void testEncryptedAppend() throws IOException {
    setEncryptionConfigKeys();
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    fs=getFileSystem(conf);
    writeTestDataToFile(fs);
    assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
    writeTestDataToFile(fs);
    assertEquals(PLAIN_TEXT + PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
  }
  @Test public void testEncryptedAppendRequiringBlockTransfer() throws IOException {
    setEncryptionConfigKeys();
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(4).build();
    fs=getFileSystem(conf);
    writeTestDataToFile(fs);
    assertEquals(PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
    FSDataInputStream in=fs.open(TEST_PATH);
    List<LocatedBlock> locatedBlocks=DFSTestUtil.getAllBlocks(in);
    in.close();
    assertEquals(1,locatedBlocks.size());
    assertEquals(3,locatedBlocks.get(0).getLocations().length);
    DataNode dn=cluster.getDataNode(locatedBlocks.get(0).getLocations()[0].getIpcPort());
    dn.shutdown();
    writeTestDataToFile(fs);
    assertEquals(PLAIN_TEXT + PLAIN_TEXT,DFSTestUtil.readFile(fs,TEST_PATH));
  }
  private static void writeTestDataToFile(  FileSystem fs) throws IOException {
    OutputStream out=null;
    if (!fs.exists(TEST_PATH)) {
      out=fs.create(TEST_PATH);
    }
 else {
      out=fs.append(TEST_PATH);
    }
    out.write(PLAIN_TEXT.getBytes());
    out.close();
  }
static class TestTrustedChannelResolver extends TrustedChannelResolver {
    public boolean isTrusted(){
      return true;
    }
    public boolean isTrusted(    InetAddress peerAddress){
      return true;
    }
  }
}
